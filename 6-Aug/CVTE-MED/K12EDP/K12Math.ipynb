{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(542340, 3586)\n",
      "测试集准确率：0.838100\n",
      "Complete time: 1635.191542 s\n"
     ]
    }
   ],
   "source": [
    "#多分类逻辑回归\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "start = time.time()\n",
    "#1.加载训练文件\n",
    "data = pd.read_csv(\"/data/fjsdata/mathV.csv\",sep='|',low_memory=False)#iterator=True)\n",
    "#data = data.get_chunk(30000)\n",
    "data = data.fillna(0)#填补空值为零\n",
    "#data = data.dropna(axis=0,how='any')\n",
    "print (data.shape)\n",
    "#2.构造训练集和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data.drop(columns=['quid','qdiff']), data['qdiff'], test_size=.2)#8成训练，2成测试\n",
    "#3.lr多分类\n",
    "clf = LogisticRegression(penalty='l2',random_state=0, solver='lbfgs', multi_class='multinomial').fit(X_train,Y_train)\n",
    "#4.预测\n",
    "Y_pred= clf.predict(X_test)\n",
    "print ('测试集准确率：%f'% accuracy_score(Y_test, Y_pred))\n",
    "end = time.time()\n",
    "print (\"Complete time: %f s\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(542340, 3586)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pymc3/tuning/starting.py:61: UserWarning: find_MAP should not be used to initialize the NUTS sampler, simply call pymc3.sample() and it will automatically initialize NUTS in a better way.\n",
      "  warnings.warn('find_MAP should not be used to initialize the NUTS sampler, simply call pymc3.sample() and it will automatically initialize NUTS in a better way.')\n",
      "logp = -2.127e+05, ||grad|| = 11.838: 100%|██████████| 2756/2756 [12:04:03<00:00, 15.76s/it]   \n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "CompoundStep\n",
      ">Metropolis: [alfa]\n",
      ">Metropolis: [beta]\n",
      "Sampling 2 chains: 100%|██████████| 3000/3000 [9:22:53<00:00, 20.43s/draws]  \n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "100%|██████████| 2000/2000 [3:58:01<00:00,  7.19s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集准确率：0.835979\n",
      "Complete time: 92672.074004 s\n"
     ]
    }
   ],
   "source": [
    "#贝叶斯多分类逻辑回归\n",
    "import theano\n",
    "import pymc3 as pm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import theano.tensor as tt\n",
    "from sklearn import datasets\n",
    "import time\n",
    "import numpy as np\n",
    "starttime = time.time()\n",
    "#1.加载训练文件\n",
    "data = pd.read_csv(\"/data/fjsdata/mathV.csv\",sep='|',low_memory=False)\n",
    "data = data.fillna(0)#填补空值为零\n",
    "print (data.shape)\n",
    "#2.构造训练集和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data.drop(columns=['quid','qdiff']), data['qdiff'], test_size=.2)#8成训练，2成测试\n",
    "#3.构建softmax regression model\n",
    "X_input = theano.shared(X_train.values)#转numpy array\n",
    "Y_output = theano.shared(Y_train.values)#转numpy array\n",
    "with pm.Model() as EDP_model:\n",
    "    beta = pm.Normal('beta', mu=0, sd=6, shape=(3584,6))\n",
    "    alpha = pm.Normal('alfa', mu=0, sd=6, shape=6)\n",
    "    mu = tt.dot(X_input,beta) + alpha\n",
    "    p = pm.Deterministic('p', tt.nnet.softmax(mu))\n",
    "    Y_obs = pm.Categorical('Y_obs', p=p, observed=Y_output)\n",
    "#4.nuts采样\n",
    "with EDP_model:\n",
    "    start=pm.find_MAP()  # 参数初猜\n",
    "    step = pm.Metropolis()#多分类采样#step = pm.NUTS()连续采样\n",
    "    trace = pm.sample(1000,start=start,step=step,chains=2,cores=2)\n",
    "X_input.set_value(X_test.values)#测试集\n",
    "Y_output.set_value(Y_test.values)#测试集\n",
    "with EDP_model:\n",
    "    ppc = pm.sample_posterior_predictive(trace)#后验预测 \n",
    "    Y_pred = ppc['Y_obs'].mean(axis=0)\n",
    "print ('测试集准确率：%f'% accuracy_score(Y_test,Y_pred.round()))\n",
    "endtime = time.time()\n",
    "print (\"Complete time: %f s\" % (endtime - starttime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 3586)\n",
      "测试集准确率：0.893500\n",
      "Complete time: 360.567636 s\n"
     ]
    }
   ],
   "source": [
    "#决策树分类\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "start = time.time()\n",
    "#1.加载训练文件\n",
    "data = pd.read_csv(\"/data/fjsdata/mathV.csv\",sep='|',low_memory=False)\n",
    "data = data.fillna(0)#填补空值为零\n",
    "#data = data.dropna(axis=0,how='any')\n",
    "print (data.shape)\n",
    "#2.构造训练集和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data.drop(columns=['quid','qdiff']), data['qdiff'], test_size=.2)#8成训练，2成测试\n",
    "#3.决策树分类\n",
    "clf = DecisionTreeClassifier().fit(X_train,Y_train)\n",
    "#4.预测\n",
    "Y_pred= clf.predict(X_test)\n",
    "print ('测试集准确率：%f'% accuracy_score(Y_test, Y_pred))\n",
    "end = time.time()\n",
    "print (\"Complete time: %f s\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 3586)\n",
      "[1]\tvalid_0's multi_logloss: 0.813482\n",
      "[2]\tvalid_0's multi_logloss: 0.744894\n",
      "[3]\tvalid_0's multi_logloss: 0.688876\n",
      "[4]\tvalid_0's multi_logloss: 0.642017\n",
      "[5]\tvalid_0's multi_logloss: 0.602135\n",
      "[6]\tvalid_0's multi_logloss: 0.567829\n",
      "[7]\tvalid_0's multi_logloss: 0.537986\n",
      "[8]\tvalid_0's multi_logloss: 0.511875\n",
      "[9]\tvalid_0's multi_logloss: 0.48889\n",
      "[10]\tvalid_0's multi_logloss: 0.468556\n",
      "[11]\tvalid_0's multi_logloss: 0.450494\n",
      "[12]\tvalid_0's multi_logloss: 0.434406\n",
      "[13]\tvalid_0's multi_logloss: 0.420025\n",
      "[14]\tvalid_0's multi_logloss: 0.407099\n",
      "[15]\tvalid_0's multi_logloss: 0.395517\n",
      "[16]\tvalid_0's multi_logloss: 0.385069\n",
      "[17]\tvalid_0's multi_logloss: 0.375629\n",
      "[18]\tvalid_0's multi_logloss: 0.367126\n",
      "[19]\tvalid_0's multi_logloss: 0.359422\n",
      "[20]\tvalid_0's multi_logloss: 0.352438\n",
      "[21]\tvalid_0's multi_logloss: 0.346092\n",
      "[22]\tvalid_0's multi_logloss: 0.340335\n",
      "[23]\tvalid_0's multi_logloss: 0.335088\n",
      "[24]\tvalid_0's multi_logloss: 0.330293\n",
      "[25]\tvalid_0's multi_logloss: 0.325944\n",
      "[26]\tvalid_0's multi_logloss: 0.3219\n",
      "[27]\tvalid_0's multi_logloss: 0.318222\n",
      "[28]\tvalid_0's multi_logloss: 0.314775\n",
      "[29]\tvalid_0's multi_logloss: 0.311679\n",
      "[30]\tvalid_0's multi_logloss: 0.308831\n",
      "[31]\tvalid_0's multi_logloss: 0.306249\n",
      "[32]\tvalid_0's multi_logloss: 0.303812\n",
      "[33]\tvalid_0's multi_logloss: 0.301643\n",
      "[34]\tvalid_0's multi_logloss: 0.299649\n",
      "[35]\tvalid_0's multi_logloss: 0.297815\n",
      "[36]\tvalid_0's multi_logloss: 0.296106\n",
      "[37]\tvalid_0's multi_logloss: 0.294461\n",
      "[38]\tvalid_0's multi_logloss: 0.293025\n",
      "[39]\tvalid_0's multi_logloss: 0.291656\n",
      "[40]\tvalid_0's multi_logloss: 0.290393\n",
      "[41]\tvalid_0's multi_logloss: 0.289226\n",
      "[42]\tvalid_0's multi_logloss: 0.288102\n",
      "[43]\tvalid_0's multi_logloss: 0.28705\n",
      "[44]\tvalid_0's multi_logloss: 0.286104\n",
      "[45]\tvalid_0's multi_logloss: 0.285253\n",
      "[46]\tvalid_0's multi_logloss: 0.284393\n",
      "[47]\tvalid_0's multi_logloss: 0.28355\n",
      "[48]\tvalid_0's multi_logloss: 0.282829\n",
      "[49]\tvalid_0's multi_logloss: 0.282188\n",
      "[50]\tvalid_0's multi_logloss: 0.281569\n",
      "[51]\tvalid_0's multi_logloss: 0.280996\n",
      "[52]\tvalid_0's multi_logloss: 0.280431\n",
      "[53]\tvalid_0's multi_logloss: 0.279872\n",
      "[54]\tvalid_0's multi_logloss: 0.279391\n",
      "[55]\tvalid_0's multi_logloss: 0.278974\n",
      "[56]\tvalid_0's multi_logloss: 0.278576\n",
      "[57]\tvalid_0's multi_logloss: 0.278212\n",
      "[58]\tvalid_0's multi_logloss: 0.277838\n",
      "[59]\tvalid_0's multi_logloss: 0.27743\n",
      "[60]\tvalid_0's multi_logloss: 0.277096\n",
      "[61]\tvalid_0's multi_logloss: 0.276802\n",
      "[62]\tvalid_0's multi_logloss: 0.276535\n",
      "[63]\tvalid_0's multi_logloss: 0.276267\n",
      "[64]\tvalid_0's multi_logloss: 0.276037\n",
      "[65]\tvalid_0's multi_logloss: 0.2758\n",
      "[66]\tvalid_0's multi_logloss: 0.275582\n",
      "[67]\tvalid_0's multi_logloss: 0.275391\n",
      "[68]\tvalid_0's multi_logloss: 0.275196\n",
      "[69]\tvalid_0's multi_logloss: 0.275012\n",
      "[70]\tvalid_0's multi_logloss: 0.274853\n",
      "[71]\tvalid_0's multi_logloss: 0.27472\n",
      "[72]\tvalid_0's multi_logloss: 0.274601\n",
      "[73]\tvalid_0's multi_logloss: 0.274463\n",
      "[74]\tvalid_0's multi_logloss: 0.274313\n",
      "[75]\tvalid_0's multi_logloss: 0.274164\n",
      "[76]\tvalid_0's multi_logloss: 0.274025\n",
      "[77]\tvalid_0's multi_logloss: 0.273897\n",
      "[78]\tvalid_0's multi_logloss: 0.273783\n",
      "[79]\tvalid_0's multi_logloss: 0.273726\n",
      "[80]\tvalid_0's multi_logloss: 0.273638\n",
      "[81]\tvalid_0's multi_logloss: 0.273569\n",
      "[82]\tvalid_0's multi_logloss: 0.273515\n",
      "[83]\tvalid_0's multi_logloss: 0.273452\n",
      "[84]\tvalid_0's multi_logloss: 0.273412\n",
      "[85]\tvalid_0's multi_logloss: 0.273358\n",
      "[86]\tvalid_0's multi_logloss: 0.273322\n",
      "[87]\tvalid_0's multi_logloss: 0.273275\n",
      "[88]\tvalid_0's multi_logloss: 0.273214\n",
      "[89]\tvalid_0's multi_logloss: 0.273229\n",
      "[90]\tvalid_0's multi_logloss: 0.2732\n",
      "[91]\tvalid_0's multi_logloss: 0.273167\n",
      "[92]\tvalid_0's multi_logloss: 0.273142\n",
      "[93]\tvalid_0's multi_logloss: 0.273115\n",
      "[94]\tvalid_0's multi_logloss: 0.273058\n",
      "[95]\tvalid_0's multi_logloss: 0.273065\n",
      "[96]\tvalid_0's multi_logloss: 0.273088\n",
      "[97]\tvalid_0's multi_logloss: 0.273059\n",
      "[98]\tvalid_0's multi_logloss: 0.273066\n",
      "[99]\tvalid_0's multi_logloss: 0.273022\n",
      "[100]\tvalid_0's multi_logloss: 0.272993\n",
      "测试集准确率：0.891333\n",
      "Complete time: 3890.664356 s\n"
     ]
    }
   ],
   "source": [
    "#LGBM集成学习分类\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "start = time.time()\n",
    "#1.加载训练文件\n",
    "data = pd.read_csv(\"/data/fjsdata/mathV.csv\",sep='|',low_memory=False)\n",
    "data = data.fillna(0)#填补空值为零\n",
    "#data = data.dropna(axis=0,how='any')\n",
    "print (data.shape)\n",
    "#2.构造训练集和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data.drop(columns=['quid','qdiff']), data['qdiff'], test_size=.2)#8成训练，2成测试\n",
    "train_data=lgb.Dataset(X_train,label=Y_train)\n",
    "validation_data=lgb.Dataset(X_test,label=Y_test)\n",
    "#3.LGBM集成学习分类\n",
    "params={'learning_rate':0.1,\n",
    "        'lambda_l1':0.1,\n",
    "        'lambda_l2':0.2,\n",
    "        'max_depth':4,\n",
    "        'objective':'multiclass',\n",
    "        'num_class':6}\n",
    "clf=lgb.train(params,train_data,valid_sets=[validation_data])\n",
    "#4.预测\n",
    "Y_pred= clf.predict(X_test)\n",
    "Y_pred=[list(x).index(max(x)) for x in Y_pred]\n",
    "print ('测试集准确率：%f'% accuracy_score(Y_test, Y_pred))\n",
    "end = time.time()\n",
    "print (\"Complete time: %f s\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 3586)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pymc3/tuning/starting.py:61: UserWarning: find_MAP should not be used to initialize the NUTS sampler, simply call pymc3.sample() and it will automatically initialize NUTS in a better way.\n",
      "  warnings.warn('find_MAP should not be used to initialize the NUTS sampler, simply call pymc3.sample() and it will automatically initialize NUTS in a better way.')\n",
      "logp = -1.1357e+05, ||grad|| = 8.888: 100%|██████████| 2946/2946 [57:03<00:00,  1.16s/it]       \n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "CompoundStep\n",
      ">Metropolis: [w_2_out]\n",
      ">Metropolis: [w_1_2]\n",
      ">Metropolis: [w_in_1]\n",
      "Sampling 2 chains:  40%|████      | 12485/31000 [4:01:36<9:07:54,  1.78s/draws] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Sampling 2 chains: 100%|██████████| 31000/31000 [11:21:48<00:00,  2.91s/draws]  \n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "100%|██████████| 30000/30000 [5:44:36<00:00,  1.75it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集准确率：0.790000\n",
      "Complete time: 78568.874756 s\n"
     ]
    }
   ],
   "source": [
    "#贝叶斯神经网络\n",
    "import theano\n",
    "import pymc3 as pm\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import theano.tensor as tt\n",
    "import tensorflow as tf\n",
    "#1.贝叶斯神经网络模型定义\n",
    "def construct_nn(ann_input, ann_output):\n",
    "    n_hidden = 30\n",
    "    \n",
    "    # Initialize random weights between each layer\n",
    "    init_1 = np.random.randn(3584, n_hidden).astype(float)#3584列特征\n",
    "    init_2 = np.random.randn(n_hidden, n_hidden).astype(float)\n",
    "    init_out = np.random.randn(n_hidden,6).astype(float)#6个类别\n",
    "        \n",
    "    with pm.Model() as neural_network:\n",
    "        # Weights from input to hidden layer\n",
    "        weights_in_1 = pm.Normal('w_in_1', 0, sd=1,  shape=(3584, n_hidden), testval=init_1)\n",
    "        \n",
    "        # Weights from 1st to 2nd layer\n",
    "        weights_1_2 = pm.Normal('w_1_2', 0, sd=1,  shape=(n_hidden, n_hidden), testval=init_2)\n",
    "        \n",
    "        # Weights from hidden layer to output\n",
    "        weights_2_out = pm.Normal('w_2_out', 0, sd=1,  shape=(n_hidden,6), testval=init_out)\n",
    "        \n",
    "        # Build neural-network using tanh activation function\n",
    "        act_1 = pm.math.tanh(pm.math.dot(ann_input,weights_in_1))\n",
    "        act_2 = pm.math.tanh(pm.math.dot(act_1, weights_1_2))\n",
    "        act_out = pm.math.dot(act_2, weights_2_out)\n",
    "        p = pm.Deterministic('p', tt.nnet.softmax(act_out))\n",
    "        Y_obs = pm.Categorical('out', p=p, observed=ann_output)\n",
    "    return neural_network\n",
    "#2.加载训练文件\n",
    "starttime = time.time()\n",
    "data = pd.read_csv(\"/data/fjsdata/mathV.csv\",sep='|',low_memory=False) \n",
    "data = data.fillna(0)#填补空值为零\n",
    "print (data.shape)\n",
    "#3.构造训练集和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data.drop(columns=['quid','qdiff']), data['qdiff'], test_size=.2)#8成训练，2成测试\n",
    "ann_input = theano.shared(X_train.values)\n",
    "ann_output = theano.shared(Y_train.values)\n",
    "#4.模型训练\n",
    "neural_network = construct_nn(ann_input, ann_output) \n",
    "with neural_network:\n",
    "    start=pm.find_MAP()  # 参数初猜\n",
    "    step = pm.Metropolis()#多分类采样#step = pm.NUTS()连续采样\n",
    "    trace = pm.sample(15000,start=start,step=step,chains=2,cores=2)\n",
    "#5.后验预测\n",
    "ann_input.set_value(X_test.values)#测试集\n",
    "ann_output.set_value(Y_test.values)#测试集\n",
    "with neural_network:\n",
    "    ppc = pm.sample_posterior_predictive(trace)#后验预测 \n",
    "    Y_pred = ppc['out'].mean(axis=0)\n",
    "print ('测试集准确率：%f'% accuracy_score(Y_test,Y_pred.round()))\n",
    "endtime = time.time()\n",
    "print (\"Complete time: %f s\" % (endtime - starttime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
