{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(542340, 3586)\n",
      "(50000, 3586)\n"
     ]
    }
   ],
   "source": [
    "#对50万样本随机采样3万\n",
    "data = pd.read_csv(\"/data/fjsdata/mathV.csv\",sep='|',low_memory=False)\n",
    "data = data.fillna(0)#填补空值为零\n",
    "print(data.shape)\n",
    "#data = data.dropna(axis=0,how='any')\n",
    "data=data.sample(n=20000)#随机采样5万\n",
    "data.to_csv(\"/data/fjsdata/mathVR2W.csv\",index=False,sep='|')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3586)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -72,425, ||grad|| = 12.975: 100%|██████████| 479/479 [10:56<00:00,  1.37s/it]          \n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "CompoundStep\n",
      ">Metropolis: [alfa]\n",
      ">Metropolis: [beta]\n",
      "Sampling 2 chains: 100%|██████████| 11000/11000 [2:34:15<00:00,  1.48s/draws] \n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      " 86%|████████▌ | 8565/10000 [1:30:59<13:50,  1.73it/s]"
     ]
    }
   ],
   "source": [
    "#贝叶斯多分类逻辑回归\n",
    "import theano\n",
    "import pymc3 as pm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import theano.tensor as tt\n",
    "from sklearn import datasets\n",
    "import time\n",
    "import numpy as np\n",
    "starttime = time.time()\n",
    "#1.加载训练文件\n",
    "data = pd.read_csv(\"/data/fjsdata/mathVR3W.csv\",sep='|',low_memory=False)\n",
    "print (data.shape)\n",
    "#2.构造训练集和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data.drop(columns=['quid','qdiff']), data['qdiff'], test_size=.2)#8成训练，2成测试\n",
    "#3.构建softmax regression model\n",
    "X_input = theano.shared(X_train.values)#转numpy array\n",
    "Y_output = theano.shared(Y_train.values)#转numpy array\n",
    "with pm.Model() as EDP_model:\n",
    "    beta = pm.Normal('beta', mu=0, sd=6, shape=(3584,6))\n",
    "    alpha = pm.Normal('alfa', mu=0, sd=6, shape=6)\n",
    "    mu = tt.dot(X_input,beta) + alpha\n",
    "    p = pm.Deterministic('p', tt.nnet.softmax(mu))\n",
    "    Y_obs = pm.Categorical('Y_obs', p=p, observed=Y_output)\n",
    "#4.nuts采样\n",
    "with EDP_model:\n",
    "    start=pm.find_MAP()  # 参数初猜\n",
    "    step = pm.Metropolis()#多分类采样#step = pm.NUTS()连续采样\n",
    "    trace = pm.sample(5000,start=start,step=step,chains=2,cores=2)\n",
    "    #pm.traceplot(trace)\n",
    "X_input.set_value(X_test.values)#测试集\n",
    "Y_output.set_value(Y_test.values)#测试集\n",
    "with EDP_model:\n",
    "    ppc = pm.sample_posterior_predictive(trace)#后验预测 \n",
    "    Y_pred = ppc['Y_obs'].mean(axis=0)\n",
    "print ('测试集准确率：%f'% accuracy_score(Y_test,Y_pred.round()))\n",
    "endtime = time.time()\n",
    "print (\"Complete time: %f s\" % (endtime - starttime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3586)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -72,449, ||grad|| = 1.728: 100%|██████████| 598/598 [13:40<00:00,  1.37s/it]           \n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "CompoundStep\n",
      ">Metropolis: [alfa]\n",
      ">Metropolis: [beta]\n",
      "Sampling 2 chains: 100%|██████████| 3000/3000 [41:17<00:00,  1.43s/draws]\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "100%|██████████| 2000/2000 [20:58<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集准确率：0.842200\n",
      "Complete time: 4737.498118 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#贝叶斯多分类逻辑回归\n",
    "import theano\n",
    "import pymc3 as pm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import theano.tensor as tt\n",
    "from sklearn import datasets\n",
    "import time\n",
    "import numpy as np\n",
    "starttime = time.time()\n",
    "#1.加载训练文件\n",
    "data = pd.read_csv(\"/data/fjsdata/mathVR3W.csv\",sep='|',low_memory=False)\n",
    "print (data.shape)\n",
    "#2.构造训练集和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data.drop(columns=['quid','qdiff']), data['qdiff'], test_size=.2)#8成训练，2成测试\n",
    "#3.构建softmax regression model\n",
    "X_input = theano.shared(X_train.values)#转numpy array\n",
    "Y_output = theano.shared(Y_train.values)#转numpy array\n",
    "with pm.Model() as EDP_model:\n",
    "    beta = pm.Normal('beta', mu=0, sd=6, shape=(3584,6))\n",
    "    alpha = pm.Normal('alfa', mu=0, sd=6, shape=6)\n",
    "    mu = tt.dot(X_input,beta) + alpha\n",
    "    p = pm.Deterministic('p', tt.nnet.softmax(mu))\n",
    "    Y_obs = pm.Categorical('Y_obs', p=p, observed=Y_output)\n",
    "#4.nuts采样\n",
    "with EDP_model:\n",
    "    start=pm.find_MAP()  # 参数初猜\n",
    "    step = pm.Metropolis()#多分类采样#step = pm.NUTS()连续采样\n",
    "    trace = pm.sample(1000,start=start,step=step,chains=2,cores=2)\n",
    "    #pm.traceplot(trace)\n",
    "X_input.set_value(X_test.values)#测试集\n",
    "Y_output.set_value(Y_test.values)#测试集\n",
    "with EDP_model:\n",
    "    ppc = pm.sample_posterior_predictive(trace)#后验预测 \n",
    "    Y_pred = ppc['Y_obs'].mean(axis=0)\n",
    "print ('测试集准确率：%f'% accuracy_score(Y_test,Y_pred.round()))\n",
    "endtime = time.time()\n",
    "print (\"Complete time: %f s\" % (endtime - starttime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3586)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logp = -72,301, ||grad|| = 1.0057: 100%|██████████| 555/555 [15:04<00:00,  1.63s/it]          \n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "CompoundStep\n",
      ">Metropolis: [alfa]\n",
      ">Metropolis: [beta]\n",
      "Sampling 2 chains: 100%|██████████| 3000/3000 [47:37<00:00,  1.96s/draws]\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "100%|██████████| 2000/2000 [22:02<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      6481\n",
      "        1.0       0.00      0.00      0.00        15\n",
      "        2.0       0.00      0.00      0.00       499\n",
      "        3.0       0.54      1.00      0.70      1912\n",
      "        4.0       0.00      0.00      0.00      1075\n",
      "        5.0       0.00      0.00      0.00        18\n",
      "\n",
      "avg / total       0.75      0.84      0.78     10000\n",
      "\n",
      "Complete time: 5344.335855 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#贝叶斯多分类逻辑回归\n",
    "import theano\n",
    "import pymc3 as pm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "import theano.tensor as tt\n",
    "from sklearn import datasets\n",
    "import time\n",
    "import numpy as np\n",
    "starttime = time.time()\n",
    "#1.加载训练文件\n",
    "data = pd.read_csv(\"/data/fjsdata/mathVR3W.csv\",sep='|',low_memory=False)\n",
    "print (data.shape)\n",
    "#2.构造训练集和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data.drop(columns=['quid','qdiff']), data['qdiff'], test_size=.2)#8成训练，2成测试\n",
    "#3.构建softmax regression model\n",
    "X_input = theano.shared(X_train.values)#转numpy array\n",
    "Y_output = theano.shared(Y_train.values)#转numpy array\n",
    "with pm.Model() as EDP_model:\n",
    "    beta = pm.Normal('beta', mu=0, sd=6, shape=(3584,6))\n",
    "    alpha = pm.Normal('alfa', mu=0, sd=6, shape=6)\n",
    "    mu = tt.dot(X_input,beta) + alpha\n",
    "    p = pm.Deterministic('p', tt.nnet.softmax(mu))\n",
    "    Y_obs = pm.Categorical('Y_obs', p=p, observed=Y_output)\n",
    "#4.nuts采样\n",
    "with EDP_model:\n",
    "    start=pm.find_MAP()  # 参数初猜\n",
    "    step = pm.Metropolis()#多分类采样#step = pm.NUTS()连续采样\n",
    "    trace = pm.sample(1000,start=start,step=step,chains=2,cores=2)\n",
    "    #pm.traceplot(trace)\n",
    "X_input.set_value(X_test.values)#测试集\n",
    "Y_output.set_value(Y_test.values)#测试集\n",
    "with EDP_model:\n",
    "    ppc = pm.sample_posterior_predictive(trace)#后验预测 \n",
    "    Y_pred = ppc['Y_obs'].mean(axis=0)\n",
    "print (classification_report(Y_test,Y_pred.round()))\n",
    "endtime = time.time()\n",
    "print (\"Complete time: %f s\" % (endtime - starttime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3586)\n",
      "测试集准确率：0.836300\n",
      "Complete time: 126.200515 s\n"
     ]
    }
   ],
   "source": [
    "#多分类逻辑回归\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "start = time.time()\n",
    "#1.加载训练文件\n",
    "data = pd.read_csv(\"/data/fjsdata/mathVR3W.csv\",sep='|',low_memory=False)\n",
    "print (data.shape)\n",
    "#2.构造训练集和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data.drop(columns=['quid','qdiff']), data['qdiff'], test_size=.2)#8成训练，2成测试\n",
    "#3.lr多分类\n",
    "clf = LogisticRegression(penalty='l2',random_state=0, solver='lbfgs', multi_class='multinomial').fit(X_train,Y_train)\n",
    "#4.预测\n",
    "Y_pred= clf.predict(X_test)\n",
    "print ('测试集准确率：%f'% accuracy_score(Y_test, Y_pred))\n",
    "end = time.time()\n",
    "print (\"Complete time: %f s\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3586)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      6477\n",
      "        1.0       0.00      0.00      0.00        15\n",
      "        2.0       0.00      0.00      0.00       457\n",
      "        3.0       0.55      1.00      0.71      1946\n",
      "        4.0       0.00      0.00      0.00      1085\n",
      "        5.0       0.00      0.00      0.00        20\n",
      "\n",
      "avg / total       0.75      0.84      0.79     10000\n",
      "\n",
      "Complete time: 120.158093 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#多分类逻辑回归\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "start = time.time()\n",
    "#1.加载训练文件\n",
    "data = pd.read_csv(\"/data/fjsdata/mathVR3W.csv\",sep='|',low_memory=False)\n",
    "print (data.shape)\n",
    "#2.构造训练集和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data.drop(columns=['quid','qdiff']), data['qdiff'], test_size=.2)#8成训练，2成测试\n",
    "#3.lr多分类\n",
    "clf = LogisticRegression(penalty='l2',random_state=0, solver='lbfgs', multi_class='multinomial').fit(X_train,Y_train)\n",
    "#4.预测\n",
    "Y_pred= clf.predict(X_test)\n",
    "#target_names = ['class 0', 'class 1', 'class 2']\n",
    "print (classification_report(Y_test, Y_pred))#target_names=target_names\n",
    "end = time.time()\n",
    "print (\"Complete time: %f s\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3586)\n",
      "测试集准确率：0.840500\n",
      "Complete time: 190.479407 s\n"
     ]
    }
   ],
   "source": [
    "#多分类神经网络\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "start = time.time()\n",
    "#1.加载训练文件\n",
    "data = pd.read_csv(\"/data/fjsdata/mathVR3W.csv\",sep='|',low_memory=False)\n",
    "print (data.shape)\n",
    "#2.构造训练集和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data.drop(columns=['quid','qdiff']), data['qdiff'], test_size=.2)#8成训练，2成测试\n",
    "#3.多分类\n",
    "clf = MLPClassifier(hidden_layer_sizes=(100,100,100),solver='sgd').fit(X_train,Y_train)\n",
    "#4.预测\n",
    "Y_pred= clf.predict(X_test)\n",
    "print ('测试集准确率：%f'% accuracy_score(Y_test, Y_pred))\n",
    "end = time.time()\n",
    "print (\"Complete time: %f s\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3586)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      6453\n",
      "        1.0       0.00      0.00      0.00        12\n",
      "        2.0       0.00      0.00      0.00       470\n",
      "        3.0       0.53      1.00      0.69      1877\n",
      "        4.0       0.00      0.00      0.00      1174\n",
      "        5.0       0.00      0.00      0.00        14\n",
      "\n",
      "avg / total       0.74      0.83      0.78     10000\n",
      "\n",
      "Complete time: 168.994669 s\n"
     ]
    }
   ],
   "source": [
    "#多分类神经网络\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "start = time.time()\n",
    "#1.加载训练文件\n",
    "data = pd.read_csv(\"/data/fjsdata/mathVR3W.csv\",sep='|',low_memory=False)\n",
    "print (data.shape)\n",
    "#2.构造训练集和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data.drop(columns=['quid','qdiff']), data['qdiff'], test_size=.2)#8成训练，2成测试\n",
    "#3.多分类\n",
    "clf = MLPClassifier(hidden_layer_sizes=(100,100,100),solver='sgd').fit(X_train,Y_train)\n",
    "#4.预测\n",
    "Y_pred= clf.predict(X_test)\n",
    "print (classification_report(Y_test, Y_pred))\n",
    "end = time.time()\n",
    "print (\"Complete time: %f s\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3586)\n",
      "测试集准确率：0.833000\n",
      "Complete time: 92.101917 s\n"
     ]
    }
   ],
   "source": [
    "#决策树分类\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "start = time.time()\n",
    "#1.加载训练文件\n",
    "data = pd.read_csv(\"/data/fjsdata/mathVR3W.csv\",sep='|',low_memory=False)\n",
    "print (data.shape)\n",
    "#2.构造训练集和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data.drop(columns=['quid','qdiff']), data['qdiff'], test_size=.2)#8成训练，2成测试\n",
    "#3.决策树分类\n",
    "clf = DecisionTreeClassifier().fit(X_train,Y_train)\n",
    "#4.预测\n",
    "Y_pred= clf.predict(X_test)\n",
    "print ('测试集准确率：%f'% accuracy_score(Y_test, Y_pred))\n",
    "end = time.time()\n",
    "print (\"Complete time: %f s\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3586)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      6467\n",
      "        1.0       0.00      0.00      0.00        12\n",
      "        2.0       0.00      0.00      0.00       459\n",
      "        3.0       0.55      1.00      0.71      1935\n",
      "        4.0       0.00      0.00      0.00      1113\n",
      "        5.0       0.00      0.00      0.00        14\n",
      "\n",
      "avg / total       0.75      0.84      0.78     10000\n",
      "\n",
      "Complete time: 62.224018 s\n"
     ]
    }
   ],
   "source": [
    "#决策树分类\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "start = time.time()\n",
    "#1.加载训练文件\n",
    "data = pd.read_csv(\"/data/fjsdata/mathVR3W.csv\",sep='|',low_memory=False)\n",
    "print (data.shape)\n",
    "#2.构造训练集和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data.drop(columns=['quid','qdiff']), data['qdiff'], test_size=.2)#8成训练，2成测试\n",
    "#3.决策树分类\n",
    "clf = DecisionTreeClassifier().fit(X_train,Y_train)\n",
    "#4.预测\n",
    "Y_pred= clf.predict(X_test)\n",
    "print (classification_report(Y_test, Y_pred))\n",
    "end = time.time()\n",
    "print (\"Complete time: %f s\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3586)\n",
      "[1]\tvalid_0's multi_logloss: 0.924196\n",
      "[2]\tvalid_0's multi_logloss: 0.856042\n",
      "[3]\tvalid_0's multi_logloss: 0.799708\n",
      "[4]\tvalid_0's multi_logloss: 0.752158\n",
      "[5]\tvalid_0's multi_logloss: 0.71142\n",
      "[6]\tvalid_0's multi_logloss: 0.676144\n",
      "[7]\tvalid_0's multi_logloss: 0.645337\n",
      "[8]\tvalid_0's multi_logloss: 0.618253\n",
      "[9]\tvalid_0's multi_logloss: 0.594312\n",
      "[10]\tvalid_0's multi_logloss: 0.573057\n",
      "[11]\tvalid_0's multi_logloss: 0.554104\n",
      "[12]\tvalid_0's multi_logloss: 0.537158\n",
      "[13]\tvalid_0's multi_logloss: 0.521958\n",
      "[14]\tvalid_0's multi_logloss: 0.508284\n",
      "[15]\tvalid_0's multi_logloss: 0.495965\n",
      "[16]\tvalid_0's multi_logloss: 0.484833\n",
      "[17]\tvalid_0's multi_logloss: 0.474764\n",
      "[18]\tvalid_0's multi_logloss: 0.465634\n",
      "[19]\tvalid_0's multi_logloss: 0.457331\n",
      "[20]\tvalid_0's multi_logloss: 0.449798\n",
      "[21]\tvalid_0's multi_logloss: 0.442935\n",
      "[22]\tvalid_0's multi_logloss: 0.436684\n",
      "[23]\tvalid_0's multi_logloss: 0.430983\n",
      "[24]\tvalid_0's multi_logloss: 0.425772\n",
      "[25]\tvalid_0's multi_logloss: 0.421008\n",
      "[26]\tvalid_0's multi_logloss: 0.416647\n",
      "[27]\tvalid_0's multi_logloss: 0.412644\n",
      "[28]\tvalid_0's multi_logloss: 0.408974\n",
      "[29]\tvalid_0's multi_logloss: 0.405601\n",
      "[30]\tvalid_0's multi_logloss: 0.402501\n",
      "[31]\tvalid_0's multi_logloss: 0.399649\n",
      "[32]\tvalid_0's multi_logloss: 0.397021\n",
      "[33]\tvalid_0's multi_logloss: 0.394606\n",
      "[34]\tvalid_0's multi_logloss: 0.392376\n",
      "[35]\tvalid_0's multi_logloss: 0.390317\n",
      "[36]\tvalid_0's multi_logloss: 0.388417\n",
      "[37]\tvalid_0's multi_logloss: 0.386662\n",
      "[38]\tvalid_0's multi_logloss: 0.385043\n",
      "[39]\tvalid_0's multi_logloss: 0.383546\n",
      "[40]\tvalid_0's multi_logloss: 0.382169\n",
      "[41]\tvalid_0's multi_logloss: 0.380892\n",
      "[42]\tvalid_0's multi_logloss: 0.379708\n",
      "[43]\tvalid_0's multi_logloss: 0.378612\n",
      "[44]\tvalid_0's multi_logloss: 0.377601\n",
      "[45]\tvalid_0's multi_logloss: 0.37666\n",
      "[46]\tvalid_0's multi_logloss: 0.375788\n",
      "[47]\tvalid_0's multi_logloss: 0.374979\n",
      "[48]\tvalid_0's multi_logloss: 0.374226\n",
      "[49]\tvalid_0's multi_logloss: 0.373531\n",
      "[50]\tvalid_0's multi_logloss: 0.372884\n",
      "[51]\tvalid_0's multi_logloss: 0.372274\n",
      "[52]\tvalid_0's multi_logloss: 0.371713\n",
      "[53]\tvalid_0's multi_logloss: 0.371188\n",
      "[54]\tvalid_0's multi_logloss: 0.370704\n",
      "[55]\tvalid_0's multi_logloss: 0.370254\n",
      "[56]\tvalid_0's multi_logloss: 0.369841\n",
      "[57]\tvalid_0's multi_logloss: 0.369455\n",
      "[58]\tvalid_0's multi_logloss: 0.369104\n",
      "[59]\tvalid_0's multi_logloss: 0.368771\n",
      "[60]\tvalid_0's multi_logloss: 0.368466\n",
      "[61]\tvalid_0's multi_logloss: 0.36818\n",
      "[62]\tvalid_0's multi_logloss: 0.36792\n",
      "[63]\tvalid_0's multi_logloss: 0.367675\n",
      "[64]\tvalid_0's multi_logloss: 0.36745\n",
      "[65]\tvalid_0's multi_logloss: 0.36724\n",
      "[66]\tvalid_0's multi_logloss: 0.367047\n",
      "[67]\tvalid_0's multi_logloss: 0.366867\n",
      "[68]\tvalid_0's multi_logloss: 0.366705\n",
      "[69]\tvalid_0's multi_logloss: 0.36655\n",
      "[70]\tvalid_0's multi_logloss: 0.366414\n",
      "[71]\tvalid_0's multi_logloss: 0.366283\n",
      "[72]\tvalid_0's multi_logloss: 0.36617\n",
      "[73]\tvalid_0's multi_logloss: 0.366061\n",
      "[74]\tvalid_0's multi_logloss: 0.365967\n",
      "[75]\tvalid_0's multi_logloss: 0.365886\n",
      "[76]\tvalid_0's multi_logloss: 0.365795\n",
      "[77]\tvalid_0's multi_logloss: 0.365722\n",
      "[78]\tvalid_0's multi_logloss: 0.365655\n",
      "[79]\tvalid_0's multi_logloss: 0.365595\n",
      "[80]\tvalid_0's multi_logloss: 0.365535\n",
      "[81]\tvalid_0's multi_logloss: 0.36549\n",
      "[82]\tvalid_0's multi_logloss: 0.365449\n",
      "[83]\tvalid_0's multi_logloss: 0.36541\n",
      "[84]\tvalid_0's multi_logloss: 0.365383\n",
      "[85]\tvalid_0's multi_logloss: 0.365353\n",
      "[86]\tvalid_0's multi_logloss: 0.36533\n",
      "[87]\tvalid_0's multi_logloss: 0.365308\n",
      "[88]\tvalid_0's multi_logloss: 0.365285\n",
      "[89]\tvalid_0's multi_logloss: 0.365269\n",
      "[90]\tvalid_0's multi_logloss: 0.36524\n",
      "[91]\tvalid_0's multi_logloss: 0.365231\n",
      "[92]\tvalid_0's multi_logloss: 0.365219\n",
      "[93]\tvalid_0's multi_logloss: 0.365214\n",
      "[94]\tvalid_0's multi_logloss: 0.365205\n",
      "[95]\tvalid_0's multi_logloss: 0.365194\n",
      "[96]\tvalid_0's multi_logloss: 0.365179\n",
      "[97]\tvalid_0's multi_logloss: 0.365178\n",
      "[98]\tvalid_0's multi_logloss: 0.365177\n",
      "[99]\tvalid_0's multi_logloss: 0.365161\n",
      "[100]\tvalid_0's multi_logloss: 0.365159\n",
      "测试集准确率：0.837400\n",
      "Complete time: 1424.554115 s\n"
     ]
    }
   ],
   "source": [
    "#LGBM集成学习分类\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "start = time.time()\n",
    "#1.加载训练文件\n",
    "data = pd.read_csv(\"/data/fjsdata/mathVR3W.csv\",sep='|',low_memory=False)\n",
    "print (data.shape)\n",
    "#2.构造训练集和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data.drop(columns=['quid','qdiff']), data['qdiff'], test_size=.2)#8成训练，2成测试\n",
    "train_data=lgb.Dataset(X_train,label=Y_train)\n",
    "validation_data=lgb.Dataset(X_test,label=Y_test)\n",
    "#3.LGBM集成学习分类\n",
    "params={'learning_rate':0.1,\n",
    "        'lambda_l1':0.1,\n",
    "        'lambda_l2':0.2,\n",
    "        'max_depth':4,\n",
    "        'objective':'multiclass',\n",
    "        'num_class':6}\n",
    "clf=lgb.train(params,train_data,valid_sets=[validation_data])\n",
    "#4.预测\n",
    "Y_pred= clf.predict(X_test)\n",
    "Y_pred=[list(x).index(max(x)) for x in Y_pred]\n",
    "print ('测试集准确率：%f'% accuracy_score(Y_test, Y_pred))\n",
    "end = time.time()\n",
    "print (\"Complete time: %f s\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3586)\n",
      "[1]\tvalid_0's multi_logloss: 0.9206\n",
      "[2]\tvalid_0's multi_logloss: 0.852709\n",
      "[3]\tvalid_0's multi_logloss: 0.796531\n",
      "[4]\tvalid_0's multi_logloss: 0.749082\n",
      "[5]\tvalid_0's multi_logloss: 0.708403\n",
      "[6]\tvalid_0's multi_logloss: 0.673147\n",
      "[7]\tvalid_0's multi_logloss: 0.64234\n",
      "[8]\tvalid_0's multi_logloss: 0.61524\n",
      "[9]\tvalid_0's multi_logloss: 0.591278\n",
      "[10]\tvalid_0's multi_logloss: 0.569984\n",
      "[11]\tvalid_0's multi_logloss: 0.551004\n",
      "[12]\tvalid_0's multi_logloss: 0.534012\n",
      "[13]\tvalid_0's multi_logloss: 0.518768\n",
      "[14]\tvalid_0's multi_logloss: 0.505048\n",
      "[15]\tvalid_0's multi_logloss: 0.492664\n",
      "[16]\tvalid_0's multi_logloss: 0.481487\n",
      "[17]\tvalid_0's multi_logloss: 0.471354\n",
      "[18]\tvalid_0's multi_logloss: 0.462166\n",
      "[19]\tvalid_0's multi_logloss: 0.453817\n",
      "[20]\tvalid_0's multi_logloss: 0.446197\n",
      "[21]\tvalid_0's multi_logloss: 0.439274\n",
      "[22]\tvalid_0's multi_logloss: 0.432945\n",
      "[23]\tvalid_0's multi_logloss: 0.427172\n",
      "[24]\tvalid_0's multi_logloss: 0.421888\n",
      "[25]\tvalid_0's multi_logloss: 0.417042\n",
      "[26]\tvalid_0's multi_logloss: 0.412594\n",
      "[27]\tvalid_0's multi_logloss: 0.408516\n",
      "[28]\tvalid_0's multi_logloss: 0.404766\n",
      "[29]\tvalid_0's multi_logloss: 0.401318\n",
      "[30]\tvalid_0's multi_logloss: 0.398152\n",
      "[31]\tvalid_0's multi_logloss: 0.39522\n",
      "[32]\tvalid_0's multi_logloss: 0.392522\n",
      "[33]\tvalid_0's multi_logloss: 0.390025\n",
      "[34]\tvalid_0's multi_logloss: 0.387716\n",
      "[35]\tvalid_0's multi_logloss: 0.385574\n",
      "[36]\tvalid_0's multi_logloss: 0.383603\n",
      "[37]\tvalid_0's multi_logloss: 0.381772\n",
      "[38]\tvalid_0's multi_logloss: 0.380077\n",
      "[39]\tvalid_0's multi_logloss: 0.378498\n",
      "[40]\tvalid_0's multi_logloss: 0.377037\n",
      "[41]\tvalid_0's multi_logloss: 0.375668\n",
      "[42]\tvalid_0's multi_logloss: 0.374408\n",
      "[43]\tvalid_0's multi_logloss: 0.373241\n",
      "[44]\tvalid_0's multi_logloss: 0.372139\n",
      "[45]\tvalid_0's multi_logloss: 0.371118\n",
      "[46]\tvalid_0's multi_logloss: 0.370171\n",
      "[47]\tvalid_0's multi_logloss: 0.369274\n",
      "[48]\tvalid_0's multi_logloss: 0.368445\n",
      "[49]\tvalid_0's multi_logloss: 0.367674\n",
      "[50]\tvalid_0's multi_logloss: 0.366947\n",
      "[51]\tvalid_0's multi_logloss: 0.36627\n",
      "[52]\tvalid_0's multi_logloss: 0.365635\n",
      "[53]\tvalid_0's multi_logloss: 0.36504\n",
      "[54]\tvalid_0's multi_logloss: 0.364483\n",
      "[55]\tvalid_0's multi_logloss: 0.363961\n",
      "[56]\tvalid_0's multi_logloss: 0.363475\n",
      "[57]\tvalid_0's multi_logloss: 0.363019\n",
      "[58]\tvalid_0's multi_logloss: 0.362591\n",
      "[59]\tvalid_0's multi_logloss: 0.362186\n",
      "[60]\tvalid_0's multi_logloss: 0.361808\n",
      "[61]\tvalid_0's multi_logloss: 0.36145\n",
      "[62]\tvalid_0's multi_logloss: 0.361114\n",
      "[63]\tvalid_0's multi_logloss: 0.360796\n",
      "[64]\tvalid_0's multi_logloss: 0.360497\n",
      "[65]\tvalid_0's multi_logloss: 0.360218\n",
      "[66]\tvalid_0's multi_logloss: 0.359952\n",
      "[67]\tvalid_0's multi_logloss: 0.359703\n",
      "[68]\tvalid_0's multi_logloss: 0.35946\n",
      "[69]\tvalid_0's multi_logloss: 0.35924\n",
      "[70]\tvalid_0's multi_logloss: 0.359033\n",
      "[71]\tvalid_0's multi_logloss: 0.358824\n",
      "[72]\tvalid_0's multi_logloss: 0.35864\n",
      "[73]\tvalid_0's multi_logloss: 0.358459\n",
      "[74]\tvalid_0's multi_logloss: 0.358295\n",
      "[75]\tvalid_0's multi_logloss: 0.358136\n",
      "[76]\tvalid_0's multi_logloss: 0.357991\n",
      "[77]\tvalid_0's multi_logloss: 0.357853\n",
      "[78]\tvalid_0's multi_logloss: 0.357724\n",
      "[79]\tvalid_0's multi_logloss: 0.357601\n",
      "[80]\tvalid_0's multi_logloss: 0.357486\n",
      "[81]\tvalid_0's multi_logloss: 0.357376\n",
      "[82]\tvalid_0's multi_logloss: 0.357273\n",
      "[83]\tvalid_0's multi_logloss: 0.357174\n",
      "[84]\tvalid_0's multi_logloss: 0.357082\n",
      "[85]\tvalid_0's multi_logloss: 0.356997\n",
      "[86]\tvalid_0's multi_logloss: 0.356914\n",
      "[87]\tvalid_0's multi_logloss: 0.356838\n",
      "[88]\tvalid_0's multi_logloss: 0.356766\n",
      "[89]\tvalid_0's multi_logloss: 0.356698\n",
      "[90]\tvalid_0's multi_logloss: 0.356634\n",
      "[91]\tvalid_0's multi_logloss: 0.356574\n",
      "[92]\tvalid_0's multi_logloss: 0.356517\n",
      "[93]\tvalid_0's multi_logloss: 0.356461\n",
      "[94]\tvalid_0's multi_logloss: 0.35641\n",
      "[95]\tvalid_0's multi_logloss: 0.356362\n",
      "[96]\tvalid_0's multi_logloss: 0.356313\n",
      "[97]\tvalid_0's multi_logloss: 0.356271\n",
      "[98]\tvalid_0's multi_logloss: 0.356231\n",
      "[99]\tvalid_0's multi_logloss: 0.35619\n",
      "[100]\tvalid_0's multi_logloss: 0.356152\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      6444\n",
      "        1.0       0.00      0.00      0.00        12\n",
      "        2.0       0.00      0.00      0.00       471\n",
      "        3.0       0.54      1.00      0.70      1928\n",
      "        4.0       0.00      0.00      0.00      1138\n",
      "        5.0       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.75      0.84      0.78     10000\n",
      "\n",
      "Complete time: 1517.767658 s\n"
     ]
    }
   ],
   "source": [
    "#LGBM集成学习分类\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "start = time.time()\n",
    "#1.加载训练文件\n",
    "data = pd.read_csv(\"/data/fjsdata/mathVR3W.csv\",sep='|',low_memory=False)\n",
    "print (data.shape)\n",
    "#2.构造训练集和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data.drop(columns=['quid','qdiff']), data['qdiff'], test_size=.2)#8成训练，2成测试\n",
    "train_data=lgb.Dataset(X_train,label=Y_train)\n",
    "validation_data=lgb.Dataset(X_test,label=Y_test)\n",
    "#3.LGBM集成学习分类\n",
    "params={'learning_rate':0.1,\n",
    "        'lambda_l1':0.1,\n",
    "        'lambda_l2':0.2,\n",
    "        'max_depth':4,\n",
    "        'objective':'multiclass',\n",
    "        'num_class':6}\n",
    "clf=lgb.train(params,train_data,valid_sets=[validation_data])\n",
    "#4.预测\n",
    "Y_pred= clf.predict(X_test)\n",
    "Y_pred=[list(x).index(max(x)) for x in Y_pred]\n",
    "print (classification_report(Y_test, Y_pred))\n",
    "end = time.time()\n",
    "print (\"Complete time: %f s\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3586)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pymc3/tuning/starting.py:61: UserWarning: find_MAP should not be used to initialize the NUTS sampler, simply call pymc3.sample() and it will automatically initialize NUTS in a better way.\n",
      "  warnings.warn('find_MAP should not be used to initialize the NUTS sampler, simply call pymc3.sample() and it will automatically initialize NUTS in a better way.')\n",
      "logp = -3.1942e+05, ||grad|| = 0.75157: 100%|██████████| 2440/2440 [1:26:50<00:00,  2.14s/it]   \n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "CompoundStep\n",
      ">Metropolis: [w_2_out]\n",
      ">Metropolis: [w_1_2]\n",
      ">Metropolis: [w_in_1]\n",
      "Sampling 2 chains: 100%|██████████| 3000/3000 [1:26:25<00:00,  2.62s/draws]\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "100%|██████████| 2000/2000 [22:38<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集准确率：0.761900\n",
      "Complete time: 12595.549264 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#贝叶斯神经网络\n",
    "import theano\n",
    "import pymc3 as pm\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import theano.tensor as tt\n",
    "import tensorflow as tf\n",
    "#1.贝叶斯神经网络模型定义\n",
    "def construct_nn(ann_input, ann_output):\n",
    "    n_hidden = 30\n",
    "    \n",
    "    # Initialize random weights between each layer\n",
    "    init_1 = np.random.randn(3584, n_hidden).astype(float)#3584列特征\n",
    "    init_2 = np.random.randn(n_hidden, n_hidden).astype(float)\n",
    "    init_out = np.random.randn(n_hidden,6).astype(float)#6个类别\n",
    "        \n",
    "    with pm.Model() as neural_network:\n",
    "        # Weights from input to hidden layer\n",
    "        weights_in_1 = pm.Normal('w_in_1', 0, sd=6,  shape=(3584, n_hidden), testval=init_1)\n",
    "        \n",
    "        # Weights from 1st to 2nd layer\n",
    "        weights_1_2 = pm.Normal('w_1_2', 0, sd=6,  shape=(n_hidden, n_hidden), testval=init_2)\n",
    "        \n",
    "        # Weights from hidden layer to output\n",
    "        weights_2_out = pm.Normal('w_2_out', 0, sd=6,  shape=(n_hidden,6), testval=init_out)\n",
    "        \n",
    "        # Build neural-network using tanh activation function\n",
    "        act_1 = pm.math.tanh(pm.math.dot(ann_input,weights_in_1))\n",
    "        act_2 = pm.math.tanh(pm.math.dot(act_1, weights_1_2))\n",
    "        act_out = pm.math.dot(act_2, weights_2_out)\n",
    "        p = pm.Deterministic('p', tt.nnet.softmax(act_out))\n",
    "        Y_obs = pm.Categorical('out', p=p, observed=ann_output)\n",
    "    return neural_network\n",
    "starttime = time.time()\n",
    "#2.加载训练文件\n",
    "data = pd.read_csv(\"/data/fjsdata/mathVR3W.csv\",sep='|',low_memory=False)\n",
    "print (data.shape)\n",
    "#3.构造训练集和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data.drop(columns=['quid','qdiff']), data['qdiff'], test_size=.2)#8成训练，2成测试\n",
    "ann_input = theano.shared(X_train.values)\n",
    "ann_output = theano.shared(Y_train.values)\n",
    "#4.模型训练\n",
    "neural_network = construct_nn(ann_input, ann_output) \n",
    "with neural_network:\n",
    "    start=pm.find_MAP()  # 参数初猜\n",
    "    step = pm.Metropolis()#多分类采样#step = pm.NUTS()连续采样\n",
    "    trace = pm.sample(1000,start=start,step=step,chains=2,cores=2)\n",
    "#5.后验预测\n",
    "ann_input.set_value(X_test.values)#测试集\n",
    "ann_output.set_value(Y_test.values)#测试集\n",
    "with neural_network:\n",
    "    ppc = pm.sample_posterior_predictive(trace)#后验预测 \n",
    "    Y_pred = ppc['out'].mean(axis=0)\n",
    "print ('测试集准确率：%f'% accuracy_score(Y_test,Y_pred.round()))\n",
    "endtime = time.time()\n",
    "print (\"Complete time: %f s\" % (endtime - starttime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
