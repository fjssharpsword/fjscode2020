{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "from typing import Dict, List\n",
    "from PIL import Image\n",
    "from io import StringIO,BytesIO \n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize,normalize\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc,roc_auc_score \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.ndimage import zoom\n",
    "from functools import reduce\n",
    "from scipy.io import loadmat\n",
    "from skimage.measure import block_reduce\n",
    "from collections import Counter\n",
    "from scipy.sparse import coo_matrix,hstack, vstack\n",
    "import cv2\n",
    "import faiss \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.ops as ops\n",
    "torch.cuda.set_device(2)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585 / 585 The length of trainset is 585\n",
      "65 / 65 The length of testset is 65\n",
      "Completed data handle in 102 seconds\n"
     ]
    }
   ],
   "source": [
    "tstart = time.time()\n",
    "root_dir = '/data/fjsdata/MCBIR-Ins/origa650/' #the path of images\n",
    "trData = pd.read_csv(root_dir+\"trainset.csv\" , sep=',')\n",
    "teData = pd.read_csv(root_dir+\"testset.csv\" , sep=',')\n",
    "#trainset \n",
    "trN, trI, trM, trY = [],[],[],[]\n",
    "for iname, itype in np.array(trData).tolist():\n",
    "    iname=os.path.splitext(iname)[0].strip()[1:] #get rid of file extension\n",
    "    try:\n",
    "        trN.append(iname)\n",
    "        if itype==True: #glaucoma\n",
    "            trY.append(1)\n",
    "        else: trY.append(0) #False\n",
    "        image_path = os.path.join(root_dir, 'images', iname+'.jpg')\n",
    "        img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(256,256,3)\n",
    "        trI.append(img)\n",
    "        mask_path = os.path.join(root_dir,'mask', iname+'.mat')\n",
    "        mask = cv2.resize(loadmat(mask_path)['mask'],(256, 256))#(256,256)\n",
    "        trM.append(mask)\n",
    "    except:\n",
    "        print(iname+\":\"+str(image_path))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(trN),trData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of trainset is %d'%len(trN))\n",
    "#testset\n",
    "teN, teI, teM, teY = [],[],[],[]\n",
    "for iname, itype in np.array(teData).tolist():\n",
    "    iname=os.path.splitext(iname)[0].strip()[1:] #get rid of file extension\n",
    "    try:\n",
    "        teN.append(iname)\n",
    "        if itype==True: #glaucoma\n",
    "            teY.append(1)\n",
    "        else: teY.append(0) #False\n",
    "        image_path = os.path.join(root_dir, 'images', iname+'.jpg')\n",
    "        img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(256,256,3)\n",
    "        teI.append(img)\n",
    "        mask_path = os.path.join(root_dir,'mask', iname+'.mat')\n",
    "        mask = cv2.resize(loadmat(mask_path)['mask'],(256, 256))#(256,256)\n",
    "        teM.append(mask)\n",
    "    except:\n",
    "        print(iname+\":\"+str(image_path))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(teN),teData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of testset is %d'%len(teN))\n",
    "\n",
    "elapsed = time.time() - tstart\n",
    "print('Completed data handle in %d seconds' % int(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_urls = {\n",
    "    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\n",
    "    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\n",
    "    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n",
    "    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\n",
    "    'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\n",
    "    'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\n",
    "    'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\n",
    "    'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\n",
    "}\n",
    "\n",
    "class VGG(nn.Module):\n",
    "\n",
    "    def __init__(self, features, num_classes=2, init_weights=True):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "cfgs = {\n",
    "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "def vgg11(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 11-layer model (configuration \"A\") from\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['A'], batch_norm=False), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg11_bn(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['A'], batch_norm=True), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg13(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 13-layer model (configuration \"B\")\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['B'], batch_norm=False), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg13_bn(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['B'], batch_norm=True), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg16(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 16-layer model (configuration \"D\")\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['D'], batch_norm=False), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg16_bn(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 16-layer model (configuration \"D\") with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['D'], batch_norm=True), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg19(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 19-layer model (configuration \"E\")\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['E'], batch_norm=False), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg19_bn(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 19-layer model (configuration 'E') with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['E'], batch_norm=True), **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 59 / 59 : loss = 0.2935959Eopch:     1 mean_loss = 5.170773\n",
      " 59 / 59 : loss = 0.284961Eopch:     2 mean_loss = 0.686160\n",
      " 59 / 59 : loss = 0.596093Eopch:     3 mean_loss = 0.606985\n",
      " 59 / 59 : loss = 0.443133Eopch:     4 mean_loss = 0.629431\n",
      " 59 / 59 : loss = 1.083058Eopch:     5 mean_loss = 0.627706\n",
      " 59 / 59 : loss = 0.393913Eopch:     6 mean_loss = 0.607815\n",
      " 59 / 59 : loss = 0.868993Eopch:     7 mean_loss = 0.609853\n",
      " 59 / 59 : loss = 0.751607Eopch:     8 mean_loss = 0.612225\n",
      " 59 / 59 : loss = 1.091606Eopch:     9 mean_loss = 0.606122\n",
      " 59 / 59 : loss = 0.685781Eopch:    10 mean_loss = 0.612145\n",
      "best_loss = 0.606122\n",
      " 6 / 7 Sensitivity(TPR) of Normal: 1.000000\n",
      "Sensitivity(TPR) of Glaucoma: 0.000000\n",
      "AUC (Area Under Curve) of Micro: 0.491071\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEWCAYAAACEz/viAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO29e3yU5Zn4/b3C+XyKihoQyqkgSjiUgwdAEQWs9qBV6k9Xurra9m33pz287bbrrh+1u93Wnnbbbpdqa6WvoMVtixaoggoUkFMgBGIgREJICIRAYAhJhkzmev+YSRxCDjN5ZvLMM3N9P5/nMzPP4X6u5zt3cs/9HK5bVBXDMAwjvclwOwDDMAzDfawxMAzDMKwxMAzDMKwxMAzDMLDGwDAMw8AaA8MwDANrDAwjoYjISyLynNtxGEZ7WGNgpC0iUiwitSJSHTFd5XZchuEGXd0OwDBc5i5VXed2EIbhNtYzMIwIRGSuiJQ2m1csIreF3z8tIq+JyMsick5E9ovItIh1J4tITnjZq0DPiGVLRORvzcpWERkdfr9IRPLD25aJyDcSerCGEYE1BoYRO3cDK4CBwCrg5wAi0h34E7AMGAz8AbgnhnJfBB5X1X7AROCdOMZsGG1ijYGR7vxJRM6Epz9Fuc3fVHW1qjYQ+sc/KTx/JtAN+Kmq1qvqSmBHDLHUAxNEpL+qVqlqTgzbGoYjrDEw0p1Pq+rA8PTpKLc5HvG+BugpIl2Bq4AyvTj745EYYrkHWAQcEZENIjIrhm0NwxHWGBjGxZwHejd+EJEuwGVRblsOXC0iEjFveBtlD43cWFV3qOqngMsJnW56LbbQDaPjWGNgGBdzkNAv/TtFpBvwz0CPKLfdCgSAfxSRriLyWWB6xPJc4FoRyRaRnsDTjQtEpLuI/B8RGaCq9YAPaIjD8RhGVFhjYBgRqOpZ4MvAC0AZoV/zpW1u9NG2F4DPAkuAKuB+4H8jlh8EngHWAYXA35oV8RBQLCI+4IvAgw4OxTBiQmxwG8MwDMN6BoZhGIY1BoZhGIY1BoZhGAbWGBiGYRh4MFFdZmamjhgxwu0wDMMwPMWuXbsqVbXVZ2YS1hiIyG+ATwIVqjqxheUC/IzQE5c1wJJoHr8fMWIEO3fuBKCoqIhRo0bFNW6vYQ7MAZgDMAfQtgMRafNp+ESeJnoJWNDG8oXAmPD0GPDfse5g8ODBHQoslTAH5gDMAZgDcOYgYY2Bqm4ETrexyqeAlzXE+8BAEbkyln3U1NQ4CTElMAfmAMwBmANw5sDNC8hXA0cjPpeG50VNRoZd/zYH5gDMAaSPg6VLYc+e0Pt162Du3NC0aNFJTp482eFy3bQnLcxr8XFoEXlMRHaKyM7y8nIqKyspLy/nzJkzVFVVUVRURG1tLfn5+QSDQXJyQpcedu3aBUBOTg7BYJD8/Hxqa2spKiqiqqqKsrIyGssrLi6murqagoICAoEAubm5F5XR+JqXl4ff76ewsBCfz0dJSQkVFRVUVFRQUlKCz+ejsLAQv99PXl5ei2Xk5uYSCAQoKCigurqa4uLipmMqKyuL6ZjKyspS7phi/Z66deuWcscU6/dUVVWVcscU6/dUXl6ecsfU0vf029/6eeaZCxQVFeH3+1E9Rq9eJzl5sjuDBg1q9ZjaI6HpKERkBPBmKxeQ/wd4T1WXhz8fAOaqanlbZU6bNk0bLyAXFxeT7ncWmQNzAOYA0sfB3Lmh1/XrG9i/fz+HDh1i2rRpDB8+vE0HIrJLVae1uBB3by1dBXxFRFYAM4Cz7TUEzcnMzExIYF7CHJgDMAeQfg62bNlCMBhkwYIF9O4dyozuxEHCThOJyHJCKX3HiUipiDwiIl8UkS+GV1kNfAgcAn5NKFNkTJSWRpVMMqUxB+YAzAGkh4NAIMBll+1HpIHp06cze/bspoYAnDlIWM9AVT/fznIF/h8n+xg9erSTzVMCc2AOwBxA6js4fvw427dvp2fPTEQa6NHj0mE2nDjw9OX3/fv3ux2C65gDcwDmAFLbgc/nY9u2bUydOpUvfekGnnuue4vrOXHgufEMIi8gG4ZhpDKlpaWcP3+ecePG0dDQQJcuXTpcVnsXkD3dM2i8hSqdMQfmAMwBpJaDuro6Nm/ezO7duxk0aBBAU0OwZUtoagknDqxnYBiGkWTk5OSQkZHBddddd0lvoPHW0vfei61M6xmkOObAHIA5AO87qKmpYePGjfh8PiZPnkx2dnbMp4WsZ2AYhuFRVJVDhw6Rl5fH2LFjmTBhQpupNaxn0AKNj3KnM+bAHIA5AG86UFXq6+s5duwY8+bNY+LEiY5yLDlx4LnBbSIZO3as2yG4jjkwB2AOIDYHS5fCK69cPO+Tn4RvfCP0vvHXdyT33Qdf/jLU1MCiRZcuX7IkNFVWwr33Xrr8S1+C+++Ho0fhoYeCXHZZAb17n+LIkZuBOXz963DXXXDgADz++KXb//M/w223wdChcPx4y8flpB54umdQUlLidgiuYw7MAZgDiM3BH/8IGzYkMJg2OHeuitGj36Jv3+McOzY55u2//W144IGWlzmpB56+ZuDz+ejfv7/LEbmLOTAHYA4g+R00NDSQkZHB0aNHqa+v52Mf+xihAR/jR1sOUvqawZkzZ9wOwXXMgTkAcwDJ7eDkyZOsWbOG48ePM3z4cEaNGhX3hgCcOfD0NYOePXu6HYLrmANzAOYAYnPw7LOh16eeSlAwYYLBILt37+bo0aNMmTKFoUOHJnR/TuqBp3sGhmEYHWH9+tCUSOrq6hARevfuzcKFCxk+fHhCegPxwtONQV1dndshuI45MAdgDiB5HFy4cIH333+fd999F4Dx48e3mGE0EThx4OnGYODAgW6H4DrmwByAOYDkcFBRUcHq1avp2rUrt912W6f3BJw48HRjcOLECbdDcB1zYA7AHIC7Dmpra/H7/fTq1YsbbriBadOm0a1bt06Pw4kDT19AHj58uNshuI45MAdgDiA2B0OGxGefqsrhw4fZs2dP0zjE/fr1i0/hHcBJPfB0z+DgwYNuh+A65sAcgDmA2By8/npocoKqsmnTJg4cOMDcuXOTokF2Ug88/dCZYRhGZ6OqnDhxgqFDh1JZWcngwYMd5RPqLFL6oTOvp6yNB+bAHIA5gNgc/NM/haZY8fl8rFu3jry8PBoaGsjMzEyqhsBSWBuGYbTDgw9CaWno/Z49kJ0dWxrokydPsnHjRq677jrGjBmT1M8MtIT1DFIcc2AOwBxAyw6eeCI0NSc7u/Vkb82pqqqisrKSIUOGsGDBAsaOHZu0DYH1DAzDMFqgowPBQCixXF5eHh9++CGf+MQnGDZsWDxD63RSumeQm5vrdgiuYw7MAZgDiL+DzZs3U11dzcKFCz3TEDhx4OmeQSAQoGtXTz8q4RhzYA7AHEDLDmLtGdTX11NQUMCECRNoaGige/fucY0x0bRVD1K6Z3Do0CG3Q3Adc2AOwByAcwfl5eWsXr2a8+fPEwwGPdcQgDMHnv4pkZWV5XYIrmMOzAGYA2jZQbSjQPp8Pnbs2MH06dO58sor4xxZ5+GkHni6MaisrKRv375uh+Eq5sAcgDmAlh0sXdr6+qrK0aNHOX/+POPHj+eTn/xkUj0z0BGc1ANPNwbpXvnBHIA5AHMAsTmora1l586dnD17lhkzZgB4viEAZ/XA041BfX292yG4jjkwB2AOoGUHjz0Wem3eQ/jggw/o378/N9xwA126dOmE6DoHJ/XA041BMBh0OwTXMQfmAMwBtOwgMm/b+fPn2blzJ5MnT2by5MlJ++CYE5zUA083Br1793Y7BNcxB+YAzAG05UA5cOAg+/btY/z48fTt2zclGwJwVg88fZLs9OnTbofgOubAHIA5gNYcKF261FNRUcH8+fOZMGFCSlwbaA0n9cDTVq666iq3Q3Adc2AOwBzAxQ6CwSD79+/nmms20dDQnZtvvpn+/fu7GF3n4KQeJLQxEJEFInJARA6JyLdbWD5cRN4Vkd0isldEFsVS/uHDh+MXrEcxB+YAzAF85OD06dOsXbuWkydPMnjwVLKzXQ6sE3FSDxKWjkJEugAHgflAKbAD+Lyq5kessxTYrar/LSITgNWqOqKtciPTUQSDwZTu8kWDOTAHYA4gdCdN165dKS0tJRAIMGLEiJS9NtAabdUDN9NRTAcOqeqHqnoBWAF8qtk6CjT23QYAx2LZwZ49exwH6XXMgTkAc1BRUcHvf/97Tpw4wbBhwxg5cmTaNQTgrB4ksjG4Gjga8bk0PC+Sp4EHRaQUWA18taWCROQxEdkpIjvLy8uprKykvLycK664gqqqKoqKiqitrSU/P59gMEhOTg7wUW7vnJwcgsEg+fn51NbWUlRURFVVFWVlZTSWV1xcTHV1NQUFBQQCgabsf41lNL7m5eXh9/spLCzE5/NRUlJCRUUFFRUVlJSU4PP5KCwsxO/3k5eX12IZubm5BAIBCgoKqK6upri4uOmYysrKYjqmnj17ptwxxfo9TZkyJeWOKdbvKTMzM+WOKZrvKRgM8qc//YnNmzczZswY+vbte9ExffazNdx3n99Tx+Tke4r8W2h+TO2iqgmZgM8BL0R8fgj4r2brfA34evj9LCAfyGir3KlTp2ojO3fu1HTHHJgD1fR0UFNTo8FgUD/44AP1+/0tOpgzJzSlC23VA2CntvG/NZE9g1IgMgl4FpeeBnoEeA1AVbcCPYHMaHcwdepUhyF6H3NgDiC9HPj9frZu3cqGDRsA+PjHP0737t3TykFrOHGQyMZgBzBGREaKSHdgMbCq2TolwDwAERlPqDE4Ge0OGrt66Yw5MAeQPg5OnDjB6tWr6dGjB7fddttF1wXSxUFbOHGQ0MFtwreK/hToAvxGVb8nIs8Q6q6sCt9B9GugL6GLyf+vqr7VVpl2N9HFmANzAKnvoLa2loyMDOrr66mrqyMz89ITCC05cDLspRdJ1ruJUNXVqjpWVUep6vfC8/5FVVeF3+er6o2qOklVs9trCJpTUFCQiLA9hTkwB5C6DlSVoqIi1qxZw4kTJ+jbt2+LDQG07GDWrNCULjipB54e9rK2tpZevXq5HJG7mANzAKnpQFXZuHEjdXV1zJgxg4EDB7a5fio6iJW2HKT0sJfHjsX0WEJKYg7MAaSWA1Xl2LFjiAgTJ05k/vz57TYEkFoOOooTB57OWjp48GC3Q3Adc2AOIHUcnDlzhu3bt9OlSxeuuOIKhgwZEvW2LTm4557Q6+uvxyvC5MZJPfB0Y1BTU8OgQYPcDsNVzIE5gOR0sHQpvPLKR59XroTMTHjppdDUnJdfrmDnzr9RUnI9f/rTKJ599uIniBsvAj//PLz55sXb9uoFL7wQcvDss7B+fWj+nj2kVW4iJ/XA06eJUvnuiWgxB+YAktPBK6+E/hm3R69ep+jd+ySDB2eyYMECuncfDcSeSqIlB9nZ8MADMRflWZzUA09fQK6srGz1zoJ0wRyYA0hOB+3d1hkIBMjLy6O4uJhPfOITZGVlOdpfMjrobNpykNIXkKurq90OwXXMgTmA5HTwpS+FptbYsmULNTU1LFy40HFDAMnpoLNx4sDT1wzS/VcAmAMwB5CcDu6//9J5Fy5c4IMPPuDaa69l1qxZdOvWLW77S0YHnY0TB57uGZSWlrodguuYA3MAyeng6NHQ1EhZWRlr1qzB7/ejqnFtCCA5HXQ2Thx4+ppBIBCga1dPd24cYw7MASSng8hrBj6fjw0bNjB9+nSuuOKKhOwvGR10Nm05SOlrBvv373c7BNcxB+YAktWBMmDAEfLz8+nfvz933nlnwhoCSFYHnYsTB57uGRiGkZzU1NTw5S/voFu383z/+zNienjMSAwp3TNoHNEnnTEH5gCSz8GBAweoqRnMoUMLOq0hSDYHbuDEgfUMDMOIC+fOnWPnzp1MnTqV/v37p1366GTHegYpjjkwB+Cug2AwyAcffMBbb73FlVdeSb9+/QD4+tdDU2dh9cB6BoZhuISqUl9fz44dO5g0aRJ9+/Z1OySjFVK6Z5CXl+d2CK5jDswBdL6DhoYG9u7dy6ZNm+jevTs33njjJQ3BgQOhqbOweuDMgadvyh07dqzbIbiOOTAH0DkOtmyB73wnlFguK+t9LlzoR1nZNJ5/PpQQbt06eO65j9ZvzBjaWdcMrB44c+DpnkFJSYnbIbiOOTAHkFgHW7aEpmAwACjdutVSUTGRI0duJhDo3ep2nZ0x1OqBMwee7hkk8gEWr2AOzAEk1sF3vgN9+pzg8ce3sWLFdIYObTmp3G23hSa3sHrgzIGnewZnzpxxOwTXMQfmABLnoKGhgauv3sawYe8zbdo0hg4dmpD9xAOrB84ceLpn0LNnT7dDcB1zYA4gMQ5qamro1asXdXWDKC+fwlVXxTexXLyxeuDMgad7BoZhxJ+6ujo2b97Mpk2bADh1aizBYHI3BIZzPN0zqKurczsE1zEH5gDi5+D48eNs3bqVkSNHMnPmTERiH37SLaweOHPg6cZg4MCBbofgOubAHIBzBzU1NWRkZNCvXz9mz559UT6hn/7UaXSdg9UDZw48fZroxIkTbofgOubAHEDHHagqhYWFrF27lpMnT9KnT59LEstlZ4emZMfqgTMHnu4ZDB8+3O0QXMccmAPomANVZcOGDVy4cIF58+YxYMCAFtdbty706uZto9Fg9cCZA0/3DA4ePOh2CK5jDswBxOYgGAxSVlaGiHD99dczf/78VhsCCD1VHPlkcbJi9cCZA0tUZxhpRFVVFdu2baN79+7MmTOHLl26tLuNpaJODVI6UZ2lrDUHYA4gOgcVFRW8++67jB07lltuuSWqhsBLWD2wFNaGYbRBZWUlwWCQzMxM/H4/vXr1iml76xmkBtYzSHHMgTmAlh0EAgF27drF3/72N+rr68nIyIi5IfASVg+sZ2AYRgts2LCB7t27M2XKFHr06NHhchrHJBg3Lk6BGa4Ql56BiLwuIneKSEw9CRFZICIHROSQiHy7lXXuE5F8EdkvIq/EUn5ubm4sq6ck5sAcwEcOLly4wJ49ewgEAtx4443MmjXLUUMAoUbACw2B1QNnDqLqGYjIbcAXgJnAH4CXVLWgnW26AAeB+UApsAP4vKrmR6wzBngNuFVVq0TkclWtaKvcyJ5BIBCga1dPPyrhGHNgDiDkoLy8nF27dpGVlUV2dnbcnLzxRuj1rrviUlzCsHrQtoO49AxUdZ2q/h9gClAMvC0iW0TkCyLSWgar6cAhVf1QVS8AK4BPNVvnH4BfqGpVeD9tNgTNOXToUCyrpyTmwBwA7N27l71793LjjTcybdq0uP5T/NGPQlOyY/XAmYOoT/uIyBBgCfAosBv4GaHG4e1WNrkaOBrxuTQ8L5KxwFgR2Swi74vIglb2/ZiI7BSRneXl5VRWVlJeXk63bt2oqqqiqKiI2tpa8vPzCQaD5OTkAB9dTMnJySEYDJKfn09tbS1FRUVUVVVRVlZGY3nFxcVUV1dTUFBAIBBo6m41ltH4mpeXh9/vp7CwEJ/PR0lJCRUVFVRUVFBSUoLP56OwsBC/3980HmnzMnJzcwkEAhQUFFBdXU1xcXHTMZWVlcV0THV1dSl3TLF+T1lZWSl3TNF8T0eOHCEnJ4etW7fSr18/brrpJs6cORP3Y6quPueJv6cLFy4k5ffUmXUv8m+h+TG1R7Snif4X+DiwjNApovKIZTtb6nqIyOeAO1T10fDnh4DpqvrViHXeBOqB+4AsYBMwUVVbHaEh8jRRcXExI0aMaDf+VMYcpKeD8+fPs337durq6pg5cyZnz55NmAOv3FqajvWgOW05aO80UbR9yRdUdXWzgnuoqr+NwkuBYRGfs4BjLazzvqrWA4dF5AAwhtD1hXbp27dvVMGnMuYgPR0UFhZy+eWXM378eDIyMmhoaHA7JNdJx3rQHCcOoj1N1FJmkq3tbLMDGCMiI0WkO7AYWNVsnT8BtwCISCah00YfRhkT9fX10a6aspiD9HHg8/lYv349Pp+P7Oxsrr32WjIyQn/C6eKgLcyBMwdt9gxEZCih8/y9RGQy0DjSRX+gd1vbqmpARL4C/BXoAvxGVfeLyDPATlVdFV52u4jkAw3AN1X1VLTBB4PBaFdNWcxB6jsIBoN88MEHHDhwgIkTJ9KvX78W10kUy5YlrOi4kur1IBqcOGjvNNEdhC4aZwE/jph/DvhOe4WHTy2tbjbvXyLeK/C18BQzvXu32R6lBeYgtR2oKoFAAJ/Pxx133EGfPn1aXC+RDoYNa3+dZCCV60G0OHHQ5mkiVf2dqt4CLFHVWyKmu1X1fzu81zhx+vRpt0NwHXOQmg4aGhrIzc1l06ZNdO/enVmzZrXaEEBiHbz6amhKdlKxHsSKEwftnSZ6UFV/D4wQkUt+vavqj1vYrNO46qqr3Nx9UmAOvO9g6VJ45RWYNQv+/d9DieWeeeZ9zpwZyLFj0wkEQuvNmwdPPRV6v3AhRN4tGAyO4O674RvfCH1uvAMokvvugy9/GWpqYNGiS5cvWRKaKivh3ns/mr9nT2iks/vvj8PBJhCv14N44MRBexeQG3+K9AX6tTC5yuHDh90OwXXMgfcdvPJK6B8uBFBV/H4/VVWTKCm5iUCgZ1RlJHIw+OxseOCBhBUfN7xeD+KBEwfRPmdwmaqe7PBe4kjkcwbBYLDpbop0xRx438HcudC3bzn/8A/bmTFjBkOHDo25DK87iAfmoG0H8UphvUVE3hKRR0RkUEeCTAR7Qj+n0hpz4G0HDQ0NZGW9z9VXd7whAG87iBfmwJmDqFNYi8h0Qs8KfBrIB1aEryd0KpbC2kgFVJWamhp69+7N448XUVs7gmXL0jvJmpFY4ja4japuV9WvEUpAdxr4XRzic4QNZmEOwHsOamtr+dvf/sbmzZsBWLp0tOOGwGsOEoE56ITBbUSkP/AZQj2DUcAfgddUtdPtW8/A8DLl5eVs3bqV0aNHc+2116bcOMRG8hKvnkEukA08o6pjVfVbbjQEzWnMPJjOmANvOKiurqauro7+/ftzyy23cP311zc1BE88EZqc4AUHicYcOHMQbc9ANEnGx7S7iS7GHCS3A1Xl4MGD7Nu3jxkzZpCVlXXJOvHICprMDjoLc5DAu4lE5Kfht6tE5JKp4yHHh4KCNgdbSwvMQfI6UFXeffddjh49yvz581tsCOJFsjroTMyBMwftXbVqTFH1fIf3kEBGjhzpdgiuYw6Sz0EwGKSsrIxhw4YxZcoUBgwYgIi0v6EDks2BG5gDZw7ay03UeF0gW1U3RE6EriG4yrFjzYdHSD/MQXI5OH36NGvXrqWoqIiGhgYGDhyY8IYAksuBW5gDZw6iPcH2cAvzlnR4r3Fi8ODBbofgOuYgeRycOHGC9957jwkTJjBnzpyo7xQaOzY0OSFZHLiJOXDmoL1EdZ8HHgBGNrtG0A+IetyBRFFTU8OgQUnzQLQrmAP3HVRUVKCqXHbZZVRULGLJko/yCWVlwe/Dj2Y+8URjDqKPGDs2lKjOKW47SAbMgTMH7V0z2AKUA5nAjyLmnwP2dmiPcSTd7xwAcwDuOaivr2fPnj2UlZUxY8YMMjIyWLGiZ1OWz87E6oE5AGcO2mwMVPUIcASY1eE9JJBu3bq5HYLrmAP3HGzZsoWePXuyaNEiunfvDoTSUDemom7OT3966bx4YfXAHIAzB+3dWvq38Os5EfFFTOdExNfhvcaJ6upqt0NwHXPQuQ78fj85OTkEAgFuvPFGZsyY0dQQQKgRaKkhSDRWD8wBOHPQXs/gpvCr62MXtERmZqbbIbiOOegcB6pKSUkJOTk5XHPNNQB07Zo8ieWsHpgDcOYgqhNMIjJKRHqE388VkX8UkYEd3mucKC0tdTsE1zEHnePg3Llz7N+/n5tvvpkpU6a02hDcc09o6mysHpgDcOYg2nQUe4BpwAjgr8AqYJyqtjB4XmKJTEcRCASS6teZG5iDxDlQVT788ENqa2uZOHEiqtruMwPxSC3REawemANo20G8EtUFVTVAKHPpT1X1SeDKmCONM/v373c7BNcxB4lxUF1dzTvvvMOhQ4ea0kh0xsNjHcXqgTkAZw6ibUbrw88cPAzcFZ7n+qX7SZMmuR2C65iD+Dpo/PVfVFTEVVddxcc//vGkbgQasXpgDsCZg2h7Bl8gdHvp91T1sIiMBDp9lLPm2GAW5gDi5+Ds2bOsW7cOn8/HpEmTGD9+vCcaArB6AOYAOmFwm2TCBrcx4k0wGCQ/P5+DBw9y/fXXM2rUqA43As8+G3p96qk4BmgYcSAu1wxE5EYReVtEDorIhyJyWEQ+jF+YHcN+CZgDcOYgGAwSCASorq5mwYIFjB492lFv4Kmn3GkIrB6YA+icYS8LgCeBXUBD43xV7fT8RNYzMOJBIBAgLy8Pn8/HnDlz3A7HMBJOvO4mOquqa1S1QlVPNU5xirHD5OXluR2C65iD2B1UVFSwZs0aamtrmTFjRpvr/vKXodtFm0+NPP/8xfNFYOHCmMKJC1YPzAE4cxDt3UTvisgPgf8F/I0zVdXVQUfHOs37mwKYg+gd1NfX07VrVwKBAFOmTOHqq6+Oeyxz5sBnPhP3YtvF6oE5AGcOoj1N9G4Ls1VVb+3wnjtI5GmiwsJCxowZ09khJBXmIDoHZWVl7Ny5k5kzZ3LFFVdEVW5NTei1d2+nESYeqwfmANp20N5poqh6Bqp6SwdjSyjR/lGnMuagbQcNDQ28//77nD59OqaGAGBR+Pn6zn6auCNYPTAH4MxBtHcTXSEiL4rImvDnCSLySIf3GifOnDnjdgiuYw5adqCqVFdXk5GRwdChQ1m4cGFK/7OwemAOwJmDaC8gv0QoJ9FV4c8HgSc6vNc40bNnz/ZXSnHMwaUOampq2LhxI1u3bgVg1KhRKZ+zxuqBOQBnDqJtDDJV9TUgCBDOU9TQ9iYgIgtE5ICIHBKRb7ex3r0ioiLS6vksw4iGY8eOsXbtWoYMGcK8efM88wSxYbhNtD+XzovIEEABRGQmcLatDUSkC/ALYD5QCuwQkVWqmt9svX7APwLbYoydurq6WDdJOcxByMG5c+fo2rUrAwcOZN68eQwYMMDtsDoVqwfmAJw5iLYx+BqhtNWjREBwcGUAACAASURBVGQzcBlwbzvbTAcOqeqHACKyAvgUkN9svWeBHwDfiDboRgYOdH1IBddJdwfBYJDKykp27NjBzJkz43q76JIlcSsq4aR7PQBzAM4ctDfs5SdEZGj4eYI5wHcIPWfwFqFf+21xNXA04nNpeF5k+ZOBYar6ZjtxPCYiO0VkZ3l5OZWVlZSXl3Pw4EGqqqooKiqitraW/Px8gsEgOTmhxx8aH83Oyclpyj9TW1tLUVERVVVVlJWV0VhecXEx1dXVFBQUEAgEyM3NvaiMxte8vDz8fj+FhYX4fD5KSkqoqKigoqKCkpISfD4fhYWF+P3+pgdAmpeRm5tLIBCgoKCA6upqiouLm46prKwspmPau3dvyh1TtN9TfX09r776Kh9++CFDhw7l6quvjusxTZ6cy4MPdu4xdfR7OnDgQNJ+T51V9/bt25dyxxTr93TixIlWj6k92nzOQERygNtU9bSIzAZWAF8FsoHxqtpq70BEPgfcoaqPhj8/BExX1a+GP2cA7wBLVLVYRN4DvqGqbeaaiHzOwO/306NHj3YPMpVJRwcNDQ2UlpZyzTXXcPbsWXr06JGQi4eVlaFXL4ymmI71oDnmoG0HTtNRdFHV0+H39wNLVfV1VX0KGN3OtqXAsIjPWcCxiM/9gInAeyJSDMwEVsVyEfngwYPRrpqypJuDyspK1q5dy5EjR2hoaGDAgAEUFhYmZF/33huavEC61YOWMAfOHLR3zaCLiHQN3z00D3gshm13AGPCYx+UAYuBBxoXqupZoOk3V7Q9g0iuu+66aFdNWdLJwYkTJ9iyZQtTp05l2LBhTXcKpZOD1jAH5gCcOWivZ7Ac2CAifwZqgU0AIjKadu4mCjcgXyH0fMIHwGuqul9EnhGRuzsccQSWsjY9HBw/fpzjx49z2WWXsWjRIoYPH37RLaPp4KA9zIE5gASnsA7fRnol8Jaqng/PGwv0dSNRnaWwTh8uXLjA7t27OX78ODNmzGDo0KEdLmvpUnjlFfif/4Fx4+CNN+BHP7p0vWXLYNgwePVVePxxyM72RjoKw2gPxymsVfV9Vf1jY0MQnnfQ7YylYL8EILUdbN26lYyMDBYtWtRmQxCNg1degT17Ytt/djY88ED76yUDqVwPosUc2LCXRgpRV1fHvn37yM7ORkTo0qVLXMptHIPAfuUb6Uq8BrdJShrv801nUsWBqnL48GFWr15N165dY2oIUsWBE8yBOQBnDjydvevaa691OwTXSRUHPp+PAwcOMHfuXAYPHhzTtqniwAnmwByAMwee7hkcOnTI7RBcx8sOVJXCwkLy8vIYMGAAd9xxR8wNAUTn4J//OTSlKl6uB/HCHDhz4OmeQVZWltshuI5XHfh8PrZv304wGGwah7ijGUajcXDbbR0q2jN4tR7EE3PgzIGnewaVjfkC0hivOWi8YeHw4cMMGzaM+fPnO84wGo2DPXtiv5vIS3itHiQCc+DMgad7Bn379nU7BNfxkoOqqqqm7KKTJk2KW7nROHgiPBRTqt5N5KV6kCjMgTMHnm4M6uvr3Q7BdbzgoKGhgX379lFUVER2djb9+vWLa/lecJBozIE5AGcOPN0YBINBt0NwnWR3EAwGCQaD+P1+Fi5cSK9evRKyj3THHJgDcObA041B79693Q7BdZLVQWO+9+rqaubMmcP06dMTtq9kddCZmANzAM4cePoC8unTp9tfKcVJRgcnTpzgL3/5C/X19cycOTPh+0tGB52NOTAH4MyBp3sGV111ldshuE5nO2hM6xDJfffBl78MZ85c4NOf7kbfvg3AdKqrrwRCw0cuWRIaLKal8QG+9CW4/344ehQeeujS5V//Otx1Fxw4EEoe15xvfjOLUaNCdws1XiiO5N/+LTSlMva3YA7AmQNP9wwOHz7sdgiukywOjh49yrp1q+nTp4Lq6quaGoLO4Pjx4+2uc8MNoSlVSZZ64CbmwJkDTyeqCwaDZGR4uj1zjNsOGhoa2LJlC2fPnmXGjBlcdtllnR6D2w6SAXNgDqBtBymdqG5PKj9FFCWd6eD550MThB4e8/l8ZGRkkJWVxcKFC11pCMDqAZgDMAfgzIGnewZG59J4veAvfznP9u3baWhoYN68eR1OI2EYRueR0j0DG8yi8x3061fG2rVrufzyy7n11luToiGwemAOwByADW5jdAI+n4/PfrYbIsrrrwfo37+/2yEZhhEDKd0zyMlxfeRN10m0g2AwyP79+3n77bfp1auK+vreSdcQWD0wB2AOwJkDT/cM7O6BxDpQVdatW0fXrl2ZPn06997bB4A1axKyuw5j9cAcgDmANL6bqKCgwO0QXCcRDhoaGjh8+DAiwowZM5g7dy59+vRhzZrkawjA6gGYAzAH4MyBp59AHjlypNshuE68HZw8eZJt27YxcOBAhg8fnnSnhFrC6oE5AHMAzhx4umdw7Ngxt0NwnXg6OH78OJs3b2bSpEncdNNNlwxI/+yzoSnZsHpgDsAcgDMHnu4ZdGS83FQjHg6OHTtGRkYGV1xxBYsWLaJ79+4trrd+fej1qacc7zKuWD0wB2AOwJkDTzcGNTU1DBo0yO0wXCUaB489BgcPXjwvOxv+4z/85OTk8Ic/VHDgwEzOnxcg1BDMmgX//u+hde+5B06dCiWCy85OwEE4xOqBOQBzAM4cePo0UbrfOQDOHGzdupXu3btz8uSdnD9/RbvrZ2fDAw90eHcJw+qBOQBzAM4ceLpn0K1bN7dDcJ22HDz2WOh16dKP5tXW1pKXl8fkyZPJyLiZLl26sGxZ2/t4/fU4BJpArB6YAzAH4MyBp5vS6upqt0NwnbYcHDz40ekhVaWoqIg1a9bQs2dPMjIyLrlA7FWsHpgDMAfgzIGnewaZmZluh+A60Trw+XwcOnSIW265JeXOq1o9MAdgDsCZA0/3DEpLS90OwXXadqAMGXKAvXv3MmDAAG6//faUawjA6gGYAzAH4MyBp3sGo0ePdjsE12nNwdmzZxk1ahuqGYwYERqMPhkyjCYCqwfmAMwBOHPg6Z7B/v373Q7BdZo7aMw1deTIEQYNGkn//vM88RSxE6wemAMwB+DMQUIT1YnIAuBnQBfgBVX9frPlXwMeBQLASeDvVfVIW2VaCuvWOXXqFDt27OCGG25I+QbAMIzYcC1RnYh0AX4BLAQmAJ8XkQnNVtsNTFPV64GVwA9i2YcNZhFy0NDQwO7du9mwYQPjxo2jX79+bofVqVg9MAdgDiBJB7cRkVnA06p6R/jzPwGo6r+3sv5k4OeqemNb5VrP4GIaGhoIBoPs2bOH6667jp49ezYte/DB0Ovvf+9ScIZhJA1uprC+Gjga8bk0PK81HgFaTJAsIo+JyE4R2VleXk5lZSXl5eVs2rSJqqoqioqKqK2tJT8/n2Aw2DTAQ2MrmZOTQzAYJD8/n9raWoqKiqiqqqKsrIzG8oqLi6murqagoIBAIEBubu5FZTS+5uXl4ff7KSwsxOfzUVJSQkVFBRUVFZSUlODz+SgsLMTv95OXl9diGbm5uQQCAQoKCqiurqa4uLjpmMrKyqI6pu3bt7N9+3aWLVtGIBBg8ODB1NbWXnRMhw7VceRIg2eOqaPf065du1LumGL9njZu3JhyxxTr9/Tuu++m3DHF+j1F/i00P6b2SGTP4HPAHar6aPjzQ8B0Vf1qC+s+CHwFmKOq/rbKtZ5BKLvotm3bGDp0KJMnT241sVzjAPbvvddpoRmGkaS01zNI5K2lpcCwiM9ZwCX5VUXkNuC7RNEQNCcvL4/rrrvOUZBu8ctfwmuvXTq/8R/388/Dm29evKxPHz9vvhn6x5+bO4Of/GQo589X06dPaN6QIR+ljvinf0rexHLxxsv1IF6YA3MAzhwk8jTRDmCMiIwUke7AYmBV5Arh6wT/A9ytqhWx7mDs2LFxCTT5UQYMOMLIkas5efIkQ4cORWQoAL169W51q2RNLBdv0qcetI45MAfgzEGiby1dBPyU0K2lv1HV74nIM8BOVV0lIuuA64Dy8CYlqnp3W2VGniYqLCxkzJgxCYs/UdTUhF57t/5/vImGhgY2b97MuXPnmDFjxiWPm3vVQTwxB+YAzAG07cDN00So6mpgdbN5/xLx/jYn5V9xRftpl5ORRYtCr22dy1dVfD4fAwYM4JprriErK6vFxHJedRBPzIE5AHMAzhx4+gnkM2fOuB1CQjh37hzvvPMOO3fuRFW55pprWs0wmqoOYsEcmAMwB+DMgadzE0XeU58qlJaWsm3bNiZMmMC4cePazSeUig5ixRyYAzAH4MyBpxuDVOLMmTN0796dIUOGcPvtt6fdU8SGYbiLp08T1dXVuR2CY4LBIHl5ebzzzjucOXOGXr16xdQQpIIDp5gDcwDmAJw58HTPYODAgW6H0CGWLAm9qirr1q2jR48eLFiwgN7R3F7UDK86iCfmwByAOQBnDjzdMzhx4oTbIXSIBx8MMHv2h4gIs2bNYvbs2R1qCMC7DuKJOTAHYA7AmQNP9wyGDx/udggxc+LECTZu3M7AgUO45pprHF8b8KKDeGMOzAGYA3DmwNM9g4ONo717hOPHj/P+++/z8stT+N73bojLgPRec5AIzIE5AHMAzhwk9AnkRODFRHVlZWWICFdeeSWBQID587sBlkDOMIzOw80U1gmntYEcli4NZexsnNatC83fs+fi+Y3Tli2h5Vu2tLx8z57Q8nXrWl5+4EBo+RtvXDx/3rw6HnpoMxs35tC1a1dee02YP79bU3mJdJBOmANzAOYAnDnwdGMwderUFue/8gpx/YfbUYYN20Z9fW9mzVrI5Zdf3jQ/ngnkWnOQTpgDcwDmAJw58PRpol27drV48G7m8a+pqSEvL48pU6bQpUsXMjIS29625iCdMAfmAMwBtO2gvdNEnm4MWqPxtM24cZ0QUBhVpaioiL179zJ27FgmTJiQ8IbAMAwjWlL6mkHjsHPNGTeucxsCAJ/Px+HDh5k3bx4TJ07stIagNQfphDkwB2AOwJkDT/cMAoEAXbte+qjEG2+EXu+6K7GxBINBDhw4wIULF5g0aRKq2m5iuXjTmoN0whyYAzAH0LaDlO4ZHDp0qMX5P/pRaEokZ86c4e233+bYsWOMGjUKoNMbAmjdQTphDswBmANw5sDTzWhWVlan77Px139paSmjR4/mYx/7mCuNQCNuOEg20tFBfX09paWlTYnJgsEgH3zwgctRuYs5CP1/Onz4MFlZWXTr1i2mbT3dGFRWVtK3b99O3d/27du56aabmDhxYqftty0620Eyko4OSktL6devHyNGjEBE8Pv99OjRw+2wXMUchLKWVldXU1paysiRI2Pa1tONQWf9AwgEAuTm5lJSUsLUqVOTaqyBdPsn2BLp6KCurq6pIQDszjXMAUCXLl0YMmQIJ0+ejHlbTzcG9fX1Cd9HQ0MDELoesGjRoqT75dEZDpKddHUQeXrSazeCJAJzgKObWDzdGASDwRbnL1vmvOwLFy6we/du/H4/s2fPZsqUKc4LTQCtOUgnzIFhOMfT/arWxgAYNiw0dZRjx46xevVqMjIymDVrVscL6gQ6Og5CKmEO3DlF0qVLF7Kzs5k4cSJ33XVXq4OxP/3004jIRXe6/OQnP0FEiHyAdPfu3YgIf/3rXy/a/vjx4yxevJhRo0YxYcIEFi1a1GJ2zoyMDP74xz8iIhQUFDTNf++99/jkJz950bpLlixh5cqVQKhn+e1vf5sxY8YwceJEpk+fzpo1a6Jy4Pf7uf/++xk9ejQzZsyguLi41XUbGhqYPHnyRbG88847TJkyhYkTJ/Lwww8TCAQAKCgoYNasWfTo0YPnn3/+onL+/u//nssvv7zF65ZO6oGnG4PTp09TWXlp4rjJk+HVV2Mvr66uDlUlIyODG264gU984hMxX5HvbE6fPu12CK5jDmj6J9KZ9OrViz179rBv3z4GDx7ML37xi1bXve6661ixYkXT55UrVzJhwoSL1lm+fDk33XQTy5cvb5qnqnzmM59h7ty5FBUVkZ+fz7/927+1OIhLIBBoKiNyX+3x1FNPUV5ezr59+9i3bx9vvPEG586di2rbF198kUGDBnHo0CGefPJJvvWtb7W67s9+9jPGjx/f9DkYDPLwww+zYsUK9u3bxzXXXMPvfvc7AAYPHsx//ud/8o1vfOOScpYsWcLatWtb3IeTeuDZxuCll2D9+pZ//g8YAGfPRl9W4+1Yq1ev5uTJkwwdOvSixHLJzFVXXeV2CK5jDmDBgh6X/Cj65S9Dy2pqWs62+9JLoeUt/aCKlVmzZlFWVtbq8k9/+tP8+c9/BuDDDz9kwIABXHbZZU3LVZWVK1fy0ksv8dZbbzXdMvvuu+/SrVs3vvjFLzatm52dzc0333zJPi5cuMDmzZt58cUXo24Mampq+PWvf81//dd/NV0PvOKKK7jvvvui2v7Pf/4zDz/8MAD33nsv69evb/HaRWlpKX/5y1949NFHm+adOnWKHj16MHbsWADmz5/P66+/DsDll1/e6o/R2bNnM3jw4Bbj6d69e1Rxt4SnG4MXXqgnMzOUkK759Nhj0ZXT0NDAhg0bKCgoYO7cuZ5pBBo5fPiw2yG4jjlw97pJQ0MD69ev5+677251nf79+zNs2DD27dvH8uXLuf/++y9avnnzZkaOHMmoUaOYO3cuq1evBmDfvn1RJ59buXIlCxYsYOzYsQwePJicnJx2tzl06BDDhw+nf//+LS6///77yc7OvmR6+eWXgdBYJcPC56S7du3KgAEDOHXq1CXlPPHEE/zgBz+46DROZmYm9fX1TafKVq5cydGjR6M61tbw+/0d3tbTF5CdnCtWVc6ePcvAgQP52Mc+RlZWlidvTfv4xz/udgiuYw5gw4YMWruJpHfvtjP4Nv6gipXa2lqys7MpLi5m6tSpzJ8/v831Fy9ezIoVK/jrX//K+vXr+e1vf9u0bPny5SxevLhpvWXLlvHZz342pnhef/11nnjiiaYyli9fzpQpU1q9uyaau25ebed8c0u9gOblvvnmm1x++eVMnTqV9yJEiwgrVqzgySefxO/3c/vttztOp9GzZ88Ob+u9/34RVFdXd2g7n8/HunXryMnJQVUZPny4JxsCgD3JMHCDy5iD0OmOzqbxmsGRI0e4cOFC0zWD7373u02/oCO56667WLZs2SW/xBsaGnj99dd55plnGDFiBF/96ldZs2YN586d49prr41qwJZTp07xzjvv8OijjzJixAh++MMf8uqrr6KqDBkyhKqqqovWP336NJmZmYwePZqSkpJWrxG01zPIyspq+jUfCAQ4e/bsJadwNm/ezKpVqxgxYgSLFy/mnXfe4cEHHwRCp9c2bdrE9u3bmT17NmPGjGn3WNvCUT1QVU9NU6dOVVXVOXNCU6yUlJToypUrtaCgQIPBYOwFGEYSkJ+f73YI2qdPn6b3OTk5OmzYML1w4cIl6/3rv/6r/vCHP1RV1eXLl+uuXbtUVXXOnDm6Y8cOXbt2rd5+++0XbfN3f/d3+vLLL2swGNTp06fr0qVLm5Zt375d33vvvYvW/9WvfqWPPfbYRfNmz56tGzdu1Lq6Oh0xYkSTs+LiYh0+fLieOXNGVVW/+c1v6pIlS9Tv96uq6rFjx3TZsmVROfj5z3+ujz/+eNOxfe5zn2tz/XfffVfvvPPOps8nTpxQVdW6ujq99dZbdf369RetH+kuksOHD+u1117b6n5aqh/ATm3jf6s3fw6HifaKP0BVVRU1NTVkZmayYMECxo0b52pOoXhhQ/2ZA4Dz58+7uv/JkyczadKkdi/cLl68+JJndpYvX85nPvOZi+bdc889vPLKK4gIf/zjH3n77bcZNWoU1157LU8//fQlNw0sX76chQsXtlhGjx49+P3vf88XvvAFsrOzuffee3nhhRcYMGAAAM899xyXXXYZEyZMYOLEiXz605++6OJ2WzzyyCOcOnWK0aNH8+Mf/5jvf//7QOj29EWLFrW7/Q9/+EPGjx/P9ddfz1133cWtt94KhG6nzcrK4sc//jHPPfccWVlZ+Hw+AD7/+c8za9YsDhw4QFZWFi+++GJTeU7qgWdTWDf2htq7bNDQ0MC+ffsoKirihhtuYOjQoYkP0jASzAcffHDRbYqGEUlL9SNlU1j37g0FBW3fLaCqrFu3Dp/Px8KFC1OyIYjmjolUxxy43zNIBsyBMweevZvol78E1WxayhIRCAQoLi5m1KhR3HTTTfTp06fzA+wkml+kS0fMgT2FDeYAnDnwbM/gtdfgd7+rvWR+eXk5f/nLX6isrERVU7ohAC567D5dSVcHkad4Gx/SSmfMwUdZFDqCZ3sGcOk9teXl5Wzfvp3p06dz5ZVXuhRV5xJrzvJUJB0d9OzZk1OnTjFkyBBEJOmy6bqBOQg9gXzq1KkOPW+Q0MZARBYAPwO6AC+o6vebLe8BvAxMBU4B96tqcbTl+/0XgF4cPXqULl26cOWVV3LnnXem1TiokcNupivp6CArK4vS0tKmvPX19fVJn0cr0ZiD0Cnyvn37dmj0v4T91xSRLsAvgPlAKbBDRFapan7Eao8AVao6WkQWA/8B3H9paS3Tq1c9mzbt5OzZs8ycORMRSauGAGg1R0k6kY4OunXrdlGPqKqqikGDBrkYkfuYA2cOEnnNYDpwSFU/VNULwArgU83W+RTwu/D7lcA8ieHm/6ysHfTv35+FCxeSmZkZl6C9hhtPniYb5sAcgDkAZw4S2RhcDURmXSoNz2txHVUNAGeBIc0LEpHHRGSniOwsLy+nsrKS5cvL+da3Lmf48OEUFxdTW1tLfn4+wWCw6VbDxoeRcnJyCAaD5OfnU1tbS1FREVVVVZSVldFYXnFxMdXV1RQUFDQNcxlZRuNrXl4efr+fwsJCfD4fJSUlVFRUUFFRQUlJCT6fj8LCQvx+P3l5eS2WkZubSyAQoKCggOrqaoqLi6msrKS8vJyysjKqqqooKiqK6pjKyspS7phi/Z4yMjJS7phi/Z5OnTqVcscU6/dUXl6ecscU6/cU+bfQ/JjaI2EPnYnI54A7VPXR8OeHgOmq+tWIdfaH1ykNfy4Kr3Np2r8wjQ+dQWgg9HTtETRiDswBmAMwB9C2g/YeOkvkCfZSIHLAgSzgWCvrlIpIV2AA0OZIJbt27aoUkSPhj5lAZXzC9SzmwByAOQBzAG07uKatDRPZGOwAxojISKAMWAw80GydVcDDwFbgXuAdbaeroqpNSUNEZGdbLV06YA7MAZgDMAfgzEHCGgNVDYjIV4C/Erq19Dequl9EniGUPW8V8CKwTEQOEeoRLE5UPIZhGEbrJPQ+TFVdDaxuNu9fIt7XAZ9LZAyGYRhG+3g2HUWYpW4HkASYA3MA5gDMAThw4LkU1oZhGEb88XrPwDAMw4gD1hgYhmEY3mgMRGSBiBwQkUMi8u0WlvcQkVfDy7eJyIjOjzKxROHgayKSLyJ7RWS9iLR5T7EXac9BxHr3ioiKSMrdZhiNAxG5L1wX9ovIK50dY6KJ4m9huIi8KyK7w38P7Y8/6TFE5DciUiEi+1pZLiLyn2FHe0WkhZFfmtHWAMnJMBG6LbUI+BjQHcgFJjRb58vAr8LvFwOvuh23Cw5uAXqH338pHR2E1+sHbATeB6a5HbcL9WAMsBsYFP58udtxu+BgKfCl8PsJQLHbcSfAw2xgCrCvleWLgDWAADOBbe2V6YWeQcIT3nmAdh2o6ruq2pil6n1CT3ynEtHUA4BngR8AqTjSSTQO/gH4hapWAahqRSfHmGiicaBA//D7AVya+cDzqOpG2s7W8CngZQ3xPjBQRNoc5MULjUHcEt55mGgcRPIIoV8FqUS7DkRkMjBMVd/szMA6kWjqwVhgrIhsFpH3w2OKpBLROHgaeFBESgk95/RV0o9Y/2d4YqSzln7hN78fNpp1vEzUxyciDwLTgDkJjajzadOBiGQAPwGWdFZALhBNPehK6FTRXEK9w00iMlFVzyQ4ts4iGgefB15S1R+JyCxCWQ4mqmow8eElDTH/T/RCzyCWhHdEm/DOY0TjABG5DfgucLeq+jspts6iPQf9gInAeyJSTOg86aoUu4gc7d/Cn1W1XlUPAwcINQ6pQjQOHgFeA1DVrUBPQgnc0omo/mdE4oXGoCnhnYh0J3SBeFWzdRoT3kGUCe88RrsOwqdI/odQQ5Bq54mhHQeqelZVM1V1hKqOIHTd5G5V3elOuAkhmr+FPxG6mQARySR02ujDTo0ysUTjoASYByAi4wk1Bic7NUr3WQX8XfiuopnAWVUtb2uDpD9NpJbwLloHPwT6An8IXzsvUdW7XQs6zkTpIKWJ0sFfgdtFJB9oAL6pbYwP4jWidPB14Nci8iShUyNLUuzHISKynNCpwMzwtZF/BboBqOqvCF0rWQQcAmqAL7RbZoo5MgzDMDqAF04TGYZhGAnGGgPDMAzDGgPDMAzDGgPDMAwDawwMwzAMrDEwUpT2sjqG1/luOLPnXhHZIyIz4hzDahEZGH7/jyLygYj8fyJyd1tZV8Prbwm/jhCRB+IZl2G0hN1aaqQkIjIbqCaUrGtiC8tnAT8G5qqqP/yAVndVTUhSMxEpABaGnwqOZbu5wDdU9ZOJiMswGrGegZGSRJHV8UqgsjFth6pWNjYEIlIsIv8hItvD0+jw/MtE5HUR2RGebgzP7ysivxWRvHAv456IcjJF5FeEUi6vEpEnRWSJiPw8vM4VIvJHEckNTzeE51eH4/w+cHO45/KkiGwSkezGgwgnpLs+juqMNMUaAyNdeQsYJiIHReSXItI8sZ9PVacDPwd+Gp73M+AnqvoJ4B7ghfD8pwg97n+dql4PvBNZkKp+kVBemFtU9SfN9vOfwAZVnUQoP/3+Zsu/DWxS1ezwti8QTsYnImOBHqq6twPHbxgXYY2BkZaoajUwFXiMUN6aV0VkScQqyyNeZ4Xf3wb8yTkGzAAAAX9JREFUXET2EMr90l9E+oXn/yKi7KoYQrkV+O/wdg2qerad9f8AfFJEugF/D7wUw74Mo1WSPjeRYcQDERkGvBH++CtV/ZWqNgDvEcp0mkco2eFL4XUiL6Y1vs8AZqlqbbOyhU5Kma6qNSLyNqHBS+4jlK7cMBxjPQMjLVDVo+FTLdmq+isRGScikamds4EjEZ/vj3jdGn7/FvCVxhUizt03nz8ohtDWExqmFBHpIiL9my0/Ryg9dyQvEDq9tENVUylVu+Ei1hgYKUk4q+NWYJyIlIrII81W6Qv8TkIDx+8lNFbu0xHLe4jINuD/Ak+G5/0jMC18kTgf+GJ4/nPAIBHZJyK5hFNIR8n/BW4J90x2Adc2W74XCIQvLj8JoKq7AB/w2xj2YxhtYreWGkYzJDQ4zjRVrXQ7lpYQkasInd76eJqN3mUkEOsZGIaHEJG/A7YB37WGwIgn1jMwDMMwrGdgGIZhWGNgGIZhYI2BYRiGgTUGhmEYBtYYGIZhGMD/Dx4YFlNQQcTtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#define model\n",
    "model = vgg16_bn().cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "ce_loss  = nn.CrossEntropyLoss().cuda() #define cross-entropy loss\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(10):#iteration\n",
    "    losses = []\n",
    "    shuffled_idx = np.random.permutation(np.arange(len(trI)))\n",
    "    trI_batch = np.array(trI)[shuffled_idx]\n",
    "    trY_batch = np.array(trY)[shuffled_idx]\n",
    "    num_batches = len(trI) // batchSize + 1\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "        X_batch = torch.from_numpy(trI_batch[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        Y_batch = torch.from_numpy(trY_batch[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        #forword\n",
    "        Out_batch = model(X_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        loss = ce_loss(Out_batch,Y_batch)#loss\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        optimizer.step()#update parameters\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "ce_loss = ce_loss.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#test model\n",
    "teY_pred = []\n",
    "teY_prob = []\n",
    "num_batches = len(teI) // batchSize + 1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    out_batch = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    out_batch = F.log_softmax(out_batch,dim=1) \n",
    "    prob = out_batch.max(1,keepdim=True)[0]\n",
    "    teY_prob.extend(prob.cpu().data.numpy().tolist())\n",
    "    pred = out_batch.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(pred.cpu().data.numpy().flatten().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#TNR= TN / (FP+TN) ->low misdiagnosis rate->Specificity\n",
    "#TPR= TP / (TP+FN) -> low missed diagnosis rate->Sensitivity\n",
    "#ROC curves: y axis:Sensitivity, x axis:1-Specificity\n",
    "#confusion matrix\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, teY_pred, labels=labels) \n",
    "print ('Sensitivity(TPR) of Normal: %.6f'%float(cm[0][0]/np.sum(cm[0]))) \n",
    "print ('Sensitivity(TPR) of Glaucoma: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "#auc and roc\n",
    "teY_one_hot = label_binarize(np.array(teY), np.arange(len(labels)))\n",
    "auc_score = roc_auc_score(teY_one_hot, np.array(teY_prob), average='micro')#macro\n",
    "print ('AUC (Area Under Curve) of Micro: %.6f'% auc_score)\n",
    "#plot roc curve\n",
    "fpr_tce, tpr_tce, thresholds = roc_curve(teY_one_hot.ravel(),np.array(teY_prob).ravel()) \n",
    "#plt.plot(fpr_ce, tpr_ce, c = 'r', ls = '--', label = u'ATH(our) AUC=%.4f' % auc_score)\n",
    "plt.plot(fpr_tce, tpr_tce, c = 'b', ls = '--', label = u'R-MAC AUC=%.4f' % auc_score) \n",
    "plt.plot((0, 1), (0, 1), c = '#808080', lw = 1, ls = '--', alpha = 0.7)\n",
    "plt.xlim((-0.01, 1.02))\n",
    "plt.ylim((-0.01, 1.02))\n",
    "plt.xticks(np.arange(0, 1.1, 0.2))\n",
    "plt.yticks(np.arange(0, 1.1, 0.2))\n",
    "plt.xlabel('1-Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.grid(b=True, ls=':')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Fundus')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#release gpu memory and save model in CPU\n",
    "model = model.cpu()\n",
    "ce_loss = ce_loss.cpu()\n",
    "best_net = best_net.cpu()\n",
    "torch.cuda.empty_cache() \n",
    "torch.save(best_net.state_dict(), '/data/tmpexec/BLCF.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing PCA-w...\n",
      "DONE! 0.74s\n",
      "Fitting vocabulary\n",
      "DONE! 298.17s\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Code: https://github.com/imatge-upc/salbow/tree/master/src/BLCF\n",
    "       https://github.com/imatge-upc/retrieval-2016-icmr\n",
    "#Paper: CBMI2018《Saliency Weighted Convolutional Features for Instance Search》\n",
    "        ICMR2016《Bags of local convolutional features for scalable instance search》\n",
    "'''\n",
    "\n",
    "#load model and transfer to GPU\n",
    "device = torch.device(\"cuda\")\n",
    "best_net = vgg16_bn()\n",
    "best_net.load_state_dict(torch.load( '/data/tmpexec/BLCF.pkl'))\n",
    "best_net.to(device)\n",
    "#1. Extract features based on backbone and Aggregate R-MAC\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "best_net.features.register_forward_hook(get_activation('features'))\n",
    "\n",
    "# get codebook\n",
    "def get_codebook(ConvFeat, n_clusters=1000, n_components=100):\n",
    "    \"\"\"\n",
    "    Compute PCA and codebook models\n",
    "    arg: n_clusters --  size of vocabulary\n",
    "         n_components -- dim PCA model / None if not computing PCA\n",
    "    \"\"\"\n",
    "    print (\"computing PCA-w...\")\n",
    "    training_feats  = []\n",
    "    for i in range(len(ConvFeat)):\n",
    "        feat = np.transpose( np.array(ConvFeat[i]), (1,2,0) )\n",
    "        r, c, ch = feat.shape\n",
    "        feat = np.reshape( feat, (r*c, -1) )\n",
    "        training_feats.extend(feat)\n",
    "    training_feats = np.array(training_feats)\n",
    "    training_feats = normalize(training_feats)\n",
    "    t0 = time.time()\n",
    "    pca_model = PCA(n_components, whiten=True)\n",
    "    pca_model.fit(training_feats)\n",
    "    t1 = time.time()\n",
    "    print (\"DONE! %.2fs\" % (t1-t0))\n",
    "\n",
    "    training_feats = pca_model.transform(training_feats)\n",
    "    print (\"Fitting vocabulary\")\n",
    "    t0 = time.time()\n",
    "    kmeans =KMeans(n_clusters=n_clusters, random_state=0).fit(training_feats)\n",
    "    t1 = time.time()\n",
    "    print (\"DONE! %.2fs\" % (t1-t0))\n",
    "\n",
    "    return pca_model, kmeans #kmeans.cluster_centers_\n",
    "\n",
    "batchSize=10\n",
    "trF = []\n",
    "num_batches = len(trI) // batchSize + 1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(trI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    out_batch = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    feat_batch = activation['features'].squeeze()\n",
    "    trF.extend(feat_batch.cpu().numpy().tolist())\n",
    "    \n",
    "teF = []\n",
    "num_batches = len(teI) // batchSize + 1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    out_batch = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    feat_batch = activation['features'].squeeze()\n",
    "    teF.extend(feat_batch.cpu().numpy().tolist())\n",
    "    \n",
    "pca_model, kmeans = get_codebook(trF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(585, 1000)\n",
      "(65, 1000)\n",
      "Completed buliding index in 1 seconds\n",
      "mAP=0.4520, mIoU=0.7197\n"
     ]
    }
   ],
   "source": [
    "def get_bow( assignments, weights, n=1000):\n",
    "    '''\n",
    "    Funtion to build BoW representation given an assignment map.\n",
    "    args:\n",
    "        assignments - 2D map with assignments associated to each local feature\n",
    "        weights     - 2D maps with normalized (0-1) spatial weighting scheme\n",
    "        n           - size of the visual vocabulary (default 1000)\n",
    "    '''\n",
    "    # sparse encoding !\n",
    "    rows = np.array([], dtype=np.int)\n",
    "    cols = np.array([], dtype=np.int)\n",
    "    vals = np.array([], dtype=np.float)\n",
    "    n_docs = 0\n",
    "\n",
    "    # get counts\n",
    "    cnt = Counter(assignments.flatten())\n",
    "    ids = list(cnt.keys())#np.array(cnt.keys())\n",
    "    weights = weights.flatten()\n",
    "    weights = np.array([weights[np.where(assignments.flatten()==i)[0]].sum() for i in ids])\n",
    "\n",
    "    #save index\n",
    "    cols = np.append( cols, np.array(ids).astype(int) )\n",
    "    rows = np.append( rows, np.ones( len(cnt.keys()), dtype=int )*n_docs )\n",
    "    vals = np.append( vals, weights.astype(float) )\n",
    "    n_docs +=1\n",
    "\n",
    "    bow = coo_matrix( ( vals, (rows, cols) ), shape=(n_docs,n) )\n",
    "    bow = bow.tocsr()\n",
    "    #    bow = normalize(bow)\n",
    "    return bow\n",
    "#trainset\n",
    "for i in range(len(trF)):\n",
    "    feat = np.array(trF[i])\n",
    "    mask = np.array(trI[i])\n",
    "    #assignments maps\n",
    "    #feat = zoom(feat, (1,32,32), order=1) #interpolate=256/8=32\n",
    "    feat = np.reshape( feat, (feat.shape[0], -1) )\n",
    "    feat = np.transpose( feat, (1,0) )\n",
    "    feat = normalize(feat)\n",
    "    feat = pca_model.transform(feat)\n",
    "    feat = normalize(feat)\n",
    "    assigns = kmeans.predict(feat)\n",
    "    #Normalized saliency\n",
    "    mask = block_reduce( mask[:,:,0], (32,32), np.max )#downsample\n",
    "    mask = mask.astype(np.float32)\n",
    "    if not np.any(mask):\n",
    "        mask[...]=1\n",
    "    mask = mask / mask.max()\n",
    "    #get bags of words\n",
    "    bow = get_bow(assigns, mask)\n",
    "    if i == 0:\n",
    "        tr_bow = bow\n",
    "    else:\n",
    "        tr_bow = vstack( [tr_bow, bow] )\n",
    "tr_bow = normalize(tr_bow)\n",
    "print(tr_bow.shape)\n",
    "#testset\n",
    "for i in range(len(teF)):\n",
    "    feat = np.array(teF[i])\n",
    "    mask = np.array(teI[i])\n",
    "    #assignments maps\n",
    "    #feat = zoom(feat, (1,32,32), order=1) #interpolate=256/8=32\n",
    "    feat = np.reshape( feat, (feat.shape[0], -1) )\n",
    "    feat = np.transpose( feat, (1,0) )\n",
    "    feat = normalize(feat)\n",
    "    feat = pca_model.transform(feat)\n",
    "    feat = normalize(feat)\n",
    "    assigns = kmeans.predict(feat)\n",
    "    #Normalized saliency\n",
    "    mask = block_reduce( mask[:,:,0], (32,32), np.max )#downsample\n",
    "    mask = mask.astype(np.float32)\n",
    "    if not np.any(mask):\n",
    "        mask[...]=1\n",
    "    mask = mask / mask.max()\n",
    "    #get bags of words\n",
    "    bow = get_bow(assigns, mask)\n",
    "    if i == 0:\n",
    "        te_bow = bow\n",
    "    else:\n",
    "        te_bow = vstack( [te_bow, bow] )\n",
    "te_bow = normalize(te_bow)\n",
    "print(te_bow.shape)\n",
    "\n",
    "#evaluate\n",
    "#compute the size of lesion\n",
    "def Func_IOU_size(pred,target,n_classes = 3 ):\n",
    "    ious = []\n",
    "    # ignore IOU for background class\n",
    "    for cls in range(1,n_classes):\n",
    "        pred_inds = pred == cls\n",
    "        pred_sum = pred_inds.sum()\n",
    "        target_inds = target == cls\n",
    "        target_sum = target_inds.sum()\n",
    "        ious.append(round(float(min(pred_sum,target_sum)/max(pred_sum,target_sum)),4))\n",
    "    return np.mean(ious)\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(1000) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(tr_bow.toarray(), dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "for topk in [10]:\n",
    "    mAP = [] #mean average precision\n",
    "    mIoU = []\n",
    "    scores, neighbors = gpu_index.search(te_bow.toarray().astype('float32'), k=topk)\n",
    "    for i, teVal in enumerate(te_bow.toarray().tolist()):\n",
    "        stype = teY[i]\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        #for j in ranklist:\n",
    "        for j in neighbors[i].tolist():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                pos_len = pos_len +1\n",
    "                mAP.append(pos_len/rank_len) \n",
    "            else: \n",
    "                mAP.append(0)\n",
    "            mIoU.append(Func_IOU_size(teM[i],trM[j]))\n",
    "    print(\"mAP={:.4f}, mIoU={:.4f}\".format(np.mean(mAP),np.mean(mIoU)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_net = best_net.cpu()\n",
    "x_batch = x_batch.cpu()\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "--------below is the dataset split code and image show code--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    482\n",
      "True     168\n",
      "Name: diagnosis(glaucoma=True), dtype: int64\n",
      "False    433\n",
      "True     152\n",
      "Name: diagnosis(glaucoma=True), dtype: int64\n",
      "False    49\n",
      "True     16\n",
      "Name: diagnosis(glaucoma=True), dtype: int64\n"
     ]
    }
   ],
   "source": [
    "datas = pd.read_csv(root_dir+\"labels.csv\" , sep=',')\n",
    "datas = datas[['filename','diagnosis(glaucoma=True)']]\n",
    "print(datas['diagnosis(glaucoma=True)'].value_counts())\n",
    "trData, teData = train_test_split(datas, test_size=0.1) #split trainset and testset\n",
    "print(trData['diagnosis(glaucoma=True)'].value_counts())\n",
    "print(teData['diagnosis(glaucoma=True)'].value_counts())\n",
    "trData.to_csv( '/data/fjsdata/MCBIR-Ins/origa650/trainset.csv',index=False)\n",
    "teData.to_csv( '/data/fjsdata/MCBIR-Ins/origa650/testset.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
