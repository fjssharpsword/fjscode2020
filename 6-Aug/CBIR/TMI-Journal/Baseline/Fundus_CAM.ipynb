{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "from typing import Dict, List\n",
    "from PIL import Image\n",
    "from io import StringIO,BytesIO \n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc,roc_auc_score \n",
    "from sklearn.decomposition import PCA\n",
    "from functools import reduce\n",
    "from scipy.io import loadmat\n",
    "import cv2\n",
    "import faiss \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.ops as ops\n",
    "torch.cuda.set_device(0)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585 / 585 The length of trainset is 585\n",
      "65 / 65 The length of testset is 65\n",
      "Completed data handle in 96 seconds\n"
     ]
    }
   ],
   "source": [
    "tstart = time.time()\n",
    "root_dir = '/data/fjsdata/MCBIR-Ins/origa650/' #the path of images\n",
    "trData = pd.read_csv(root_dir+\"trainset.csv\" , sep=',')\n",
    "teData = pd.read_csv(root_dir+\"testset.csv\" , sep=',')\n",
    "#trainset \n",
    "trN, trI, trM, trY = [],[],[],[]\n",
    "for iname, itype in np.array(trData).tolist():\n",
    "    iname=os.path.splitext(iname)[0].strip()[1:] #get rid of file extension\n",
    "    try:\n",
    "        trN.append(iname)\n",
    "        if itype==True: #glaucoma\n",
    "            trY.append(1)\n",
    "        else: trY.append(0) #False\n",
    "        image_path = os.path.join(root_dir, 'images', iname+'.jpg')\n",
    "        img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(256,256,3)\n",
    "        trI.append(img)\n",
    "        mask_path = os.path.join(root_dir,'mask', iname+'.mat')\n",
    "        mask = cv2.resize(loadmat(mask_path)['mask'],(256, 256))#(256,256)\n",
    "        trM.append(mask)\n",
    "    except:\n",
    "        print(iname+\":\"+str(image_path))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(trN),trData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of trainset is %d'%len(trN))\n",
    "#testset\n",
    "teN, teI, teM, teY = [],[],[],[]\n",
    "for iname, itype in np.array(teData).tolist():\n",
    "    iname=os.path.splitext(iname)[0].strip()[1:] #get rid of file extension\n",
    "    try:\n",
    "        teN.append(iname)\n",
    "        if itype==True: #glaucoma\n",
    "            teY.append(1)\n",
    "        else: teY.append(0) #False\n",
    "        image_path = os.path.join(root_dir, 'images', iname+'.jpg')\n",
    "        img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(256,256,3)\n",
    "        teI.append(img)\n",
    "        mask_path = os.path.join(root_dir,'mask', iname+'.mat')\n",
    "        mask = cv2.resize(loadmat(mask_path)['mask'],(256, 256))#(256,256)\n",
    "        teM.append(mask)\n",
    "    except:\n",
    "        print(iname+\":\"+str(image_path))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(teN),teData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of testset is %d'%len(teN))\n",
    "\n",
    "elapsed = time.time() - tstart\n",
    "print('Completed data handle in %d seconds' % int(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "           'resnet152']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        feat = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(feat)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return feat, x\n",
    "\n",
    "\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet34(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet101(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet152(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-152 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 59 / 59 : loss = 0.346571Eopch:     1 mean_loss = 0.715596\n",
      " 59 / 59 : loss = 0.583824Eopch:     2 mean_loss = 0.671206\n",
      " 59 / 59 : loss = 0.930523Eopch:     3 mean_loss = 0.598780\n",
      " 59 / 59 : loss = 0.310603Eopch:     4 mean_loss = 0.586533\n",
      " 59 / 59 : loss = 0.760618Eopch:     5 mean_loss = 0.610982\n",
      " 59 / 59 : loss = 0.563972Eopch:     6 mean_loss = 0.576840\n",
      " 59 / 59 : loss = 0.681831Eopch:     7 mean_loss = 0.581950\n",
      " 59 / 59 : loss = 0.748712Eopch:     8 mean_loss = 0.577757\n",
      " 59 / 59 : loss = 0.592998Eopch:     9 mean_loss = 0.576319\n",
      " 59 / 59 : loss = 0.484512Eopch:    10 mean_loss = 0.576841\n",
      "best_loss = 0.576319\n",
      " 6 / 7 Sensitivity(TPR) of Normal: 0.959184\n",
      "Sensitivity(TPR) of Glaucoma: 0.062500\n",
      "AUC (Area Under Curve) of Micro: 0.359694\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#define model\n",
    "model = resnet50(num_classes=2).cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "ce_loss  = nn.CrossEntropyLoss().cuda() #define cross-entropy loss\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(10):#iteration\n",
    "    losses = []\n",
    "    shuffled_idx = np.random.permutation(np.arange(len(trI)))\n",
    "    trI_batch = np.array(trI)[shuffled_idx]\n",
    "    trY_batch = np.array(trY)[shuffled_idx]\n",
    "    num_batches = len(trI) // batchSize + 1\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "        X_batch = torch.from_numpy(trI_batch[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        Y_batch = torch.from_numpy(trY_batch[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        #forword\n",
    "        _,Out_batch = model(X_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        loss = ce_loss(Out_batch,Y_batch)#loss\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        optimizer.step()#update parameters\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "ce_loss = ce_loss.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#test model\n",
    "teY_pred = []\n",
    "teY_prob = []\n",
    "num_batches = len(teI) // batchSize + 1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    _,out_batch = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    out_batch = F.log_softmax(out_batch,dim=1) \n",
    "    prob = out_batch.max(1,keepdim=True)[0]\n",
    "    teY_prob.extend(prob.cpu().data.numpy().tolist())\n",
    "    pred = out_batch.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(pred.cpu().data.numpy().flatten().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#TNR= TN / (FP+TN) ->low misdiagnosis rate->Specificity\n",
    "#TPR= TP / (TP+FN) -> low missed diagnosis rate->Sensitivity\n",
    "#ROC curves: y axis:Sensitivity, x axis:1-Specificity\n",
    "#confusion matrix\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, teY_pred, labels=labels) \n",
    "print ('Sensitivity(TPR) of Normal: %.6f'%float(cm[0][0]/np.sum(cm[0]))) \n",
    "print ('Sensitivity(TPR) of Glaucoma: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "#auc and roc\n",
    "teY_one_hot = label_binarize(np.array(teY), np.arange(len(labels)))\n",
    "auc_score = roc_auc_score(teY_one_hot, np.array(teY_prob), average='micro')#macro\n",
    "print ('AUC (Area Under Curve) of Micro: %.6f'% auc_score)\n",
    "#plot roc curve\n",
    "fpr_tce, tpr_tce, thresholds = roc_curve(teY_one_hot.ravel(),np.array(teY_prob).ravel()) \n",
    "#plt.plot(fpr_ce, tpr_ce, c = 'r', ls = '--', label = u'ATH(our) AUC=%.4f' % auc_score)\n",
    "plt.plot(fpr_tce, tpr_tce, c = 'b', ls = '--', label = u'R-MAC AUC=%.4f' % auc_score) \n",
    "plt.plot((0, 1), (0, 1), c = '#808080', lw = 1, ls = '--', alpha = 0.7)\n",
    "plt.xlim((-0.01, 1.02))\n",
    "plt.ylim((-0.01, 1.02))\n",
    "plt.xticks(np.arange(0, 1.1, 0.2))\n",
    "plt.yticks(np.arange(0, 1.1, 0.2))\n",
    "plt.xlabel('1-Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.grid(b=True, ls=':')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Fundus')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#release gpu memory and save model in CPU\n",
    "model = model.cpu()\n",
    "ce_loss = ce_loss.cpu()\n",
    "best_net = best_net.cpu()\n",
    "torch.cuda.empty_cache() \n",
    "torch.save(best_net.state_dict(), '/data/tmpexec/CAM.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(585, 2048)\n",
      "Computing PCA with dimension reduction to:  512\n",
      "(512, 2048)\n",
      "PCA finished!\n",
      "Time elapsed computing PCA:  0.17978572845458984\n",
      "(585, 2048)\n",
      "Computing PCA with dimension reduction to:  512\n",
      "(512, 2048)\n",
      "PCA finished!\n",
      "Time elapsed computing PCA:  0.16672873497009277\n",
      "Completed buliding index in 23 seconds\n",
      "mAP=0.5357, mIoU=0.7245\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Code: https://github.com/imatge-upc/retrieval-2017-cam\n",
    "#Paper: BMVC2017《Class-Weighted Convolutional Features for Image Retrieval》\n",
    "'''\n",
    "# Extract region of interest from CAMs\n",
    "def extract_ROI(heatmap, threshold):\n",
    "    th = threshold * np.max(heatmap)\n",
    "    heatmap = heatmap > th\n",
    "    # Find the largest connected component\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(heatmap.astype('uint8'), mode=cv2.RETR_EXTERNAL, method=cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    areas = [cv2.contourArea(ctr) for ctr in contours]\n",
    "\n",
    "    max_contour = contours[areas.index(max(areas))]\n",
    "\n",
    "    x, y, w, h = cv2.boundingRect(max_contour)\n",
    "    if w == 0:\n",
    "        w = heatmap.shape[1]\n",
    "    if h == 0:\n",
    "        h = heatmap.shape[0]\n",
    "    return x, y, w, h\n",
    "\n",
    "def compute_crow_channel_weight(X):\n",
    "    \"\"\"\n",
    "    Given a tensor of features, compute channel weights as the\n",
    "    log of inverse channel sparsity.\n",
    "    :param ndarray X:\n",
    "        3d tensor of activations with dimensions (channels, height, width)\n",
    "    :returns ndarray:\n",
    "        a channel weight vector\n",
    "    \"\"\"\n",
    "    K, w, h = X.shape\n",
    "    area = float(w * h)\n",
    "    nonzeros = np.zeros(K, dtype=np.float32)\n",
    "    for i, x in enumerate(X):\n",
    "        nonzeros[i] = np.count_nonzero(x) / area\n",
    "\n",
    "    nzsum = nonzeros.sum()\n",
    "    for i, d in enumerate(nonzeros):\n",
    "        nonzeros[i] = np.log(nzsum / d) if d > 0. else 0.\n",
    "\n",
    "    return nonzeros\n",
    "\n",
    "def compute_pca(descriptors, pca_dim=512, whiten=True):\n",
    "    print (descriptors.shape)\n",
    "    t1 = time.time()\n",
    "    print( 'Computing PCA with dimension reduction to: ', pca_dim)\n",
    "    sys.stdout.flush()\n",
    "    pca = PCA(n_components=pca_dim, whiten=whiten)\n",
    "    pca.fit(descriptors)\n",
    "    print (pca.components_.shape)\n",
    "    print ('PCA finished!')\n",
    "    print ('Time elapsed computing PCA: ', time.time() - t1)\n",
    "    return pca\n",
    "\n",
    "\n",
    "def sum_pooling(features):\n",
    "    num_samples = features.shape[0]\n",
    "    num_features = features.shape[1]\n",
    "    sys.stdout.flush()\n",
    "    descriptors = np.zeros((num_samples, num_features), dtype=np.float32)\n",
    "    for i in range(0, num_samples):\n",
    "        #print 'Image: ', i\n",
    "        #sys.stdout.flush()\n",
    "        for f in range(0, num_features):\n",
    "            descriptors[i, f] = features[i, f].sum()\n",
    "    descriptors /= np.linalg.norm(descriptors, axis=1)[:, None]\n",
    "    return descriptors\n",
    "\n",
    "def weighted_cam_pooling(features, cams, max_pool=False, channel_weights=True):\n",
    "    '''\n",
    "    :param features: Feature Maps\n",
    "    :param cams: Class Activation Maps\n",
    "    :param max_pool: Perform also Max pooling\n",
    "    :param channel_weights: Channel Weighting as in Crow\n",
    "    :return: A descriptor for each CAM.\n",
    "    '''\n",
    "    t = time.time()\n",
    "    num_samples = features.shape[0]\n",
    "    num_features = features.shape[1]\n",
    "    num_classes = cams.shape[1]\n",
    "\n",
    "    wp_regions = np.zeros((num_features, num_classes), dtype=np.float32)\n",
    "    wsp_descriptors_reg = np.zeros((num_samples * num_classes, num_features), dtype=np.float32)\n",
    "    wmp_descriptors_reg = np.zeros((num_samples * num_classes, num_features), dtype=np.float32)\n",
    "\n",
    "    if max_pool:\n",
    "        mp_regions = np.zeros((num_features, num_classes), dtype=np.float32)\n",
    "\n",
    "    for i in range(0, num_samples):\n",
    "        #CROW\n",
    "        if channel_weights:\n",
    "            C = np.array(compute_crow_channel_weight(features[i]))\n",
    "\n",
    "        for f in range(0, num_features):\n",
    "            for k in range(0, num_classes):\n",
    "                # For each region compute avg weighted sum of activations and l2 normalize\n",
    "                if max_pool:\n",
    "                        mp_regions[f, k] = np.amax(np.multiply(features[i, f], cams[i, k]))\n",
    "                wp_regions[f, k] = np.multiply(features[i, f], cams[i, k]).sum()\n",
    "\n",
    "        if channel_weights:\n",
    "            wp_regions = wp_regions * C[:, None]\n",
    "        wp_regions /= np.linalg.norm(wp_regions, axis=0)\n",
    "\n",
    "        if max_pool:\n",
    "            if channel_weights:\n",
    "                mp_regions = mp_regions * C[:, None]\n",
    "            mp_regions /= np.linalg.norm(mp_regions, axis=0)\n",
    "\n",
    "        wsp_descriptors_reg[num_classes*i:num_classes*(i+1)] = np.transpose(wp_regions)\n",
    "\n",
    "        if max_pool:\n",
    "            wmp_descriptors_reg[num_classes*i:num_classes*(i+1)] = np.transpose(mp_regions)\n",
    "\n",
    "    #print 'Time elapsed computing image representations for the batch: ', time.time() - t\n",
    "\n",
    "    if max_pool:\n",
    "        return wsp_descriptors_reg, wmp_descriptors_reg\n",
    "    else:\n",
    "        return wsp_descriptors_reg\n",
    "    \n",
    "# General Descriptor Aggregation : PCA + Aggregation\n",
    "def descriptor_aggregation(descriptors_cams, num_images, num_classes, pca=None):\n",
    "\n",
    "    num_classes_ori = int(descriptors_cams.shape[0] / num_images)\n",
    "    descriptors = np.zeros((num_images, descriptors_cams.shape[1]), dtype=np.float32)\n",
    "\n",
    "    if pca is not None:\n",
    "        # Sometimes we may have errors during re-ranking due to bounding box generation on places where CAM=0\n",
    "        try:\n",
    "            descriptors_pca = pca.transform(descriptors_cams)\n",
    "        except:\n",
    "            print ('---------------------------->Exception')\n",
    "            desc_err = np.zeros((descriptors_cams.shape[0], descriptors_cams.shape[1]), dtype=np.float32)\n",
    "            for j in range(0, descriptors_cams.shape[0]):\n",
    "                try:\n",
    "                    desc_err[j] = pca.transform(descriptors_cams[j])\n",
    "                except:\n",
    "                    print ('---------------------------->Exception')\n",
    "                    print (j)\n",
    "                    desc_err[j] = desc_err[j-1]\n",
    "            descriptors_pca = desc_err\n",
    "\n",
    "        descriptors = np.zeros((num_images, descriptors_pca.shape[1]), dtype=np.float32)\n",
    "        #print descriptors_pca.shape\n",
    "\n",
    "    index = 0\n",
    "    for i in range(0, num_images):\n",
    "        index = num_classes_ori + index\n",
    "        if i == 0:\n",
    "            index = 0\n",
    "        if pca is not None:\n",
    "            for k in range(index, index+num_classes):\n",
    "                descriptors_pca[k] /= np.linalg.norm(descriptors_pca[k])\n",
    "                descriptors[i] += descriptors_pca[k]\n",
    "\n",
    "            descriptors[i] /= np.linalg.norm(descriptors[i])\n",
    "        else:\n",
    "            for k in range(index, index+num_classes):\n",
    "                descriptors[i] += descriptors_cams[k]\n",
    "            descriptors[i] /= np.linalg.norm(descriptors[i])\n",
    "\n",
    "    return descriptors\n",
    "\n",
    "#load model and transfer to GPU\n",
    "device = torch.device(\"cuda\")\n",
    "best_net = resnet50(num_classes=2)\n",
    "best_net.load_state_dict(torch.load( '/data/tmpexec/CAM.pkl'))\n",
    "best_net.to(device)\n",
    "\n",
    "weights_fc = best_net.fc.state_dict()['weight'] #tensor([2, 2048])\n",
    "weights_fc = np.transpose(weights_fc.cpu().numpy(), (1, 0)) #numpy(2048, 2)\n",
    "#extract feature-cam for trainset\n",
    "batchSize=10\n",
    "num_samples = len(trI)\n",
    "n_classes = 2\n",
    "class_list = np.zeros((num_samples, n_classes), dtype=np.int32)\n",
    "scores_vec = list()\n",
    "# Region of interest for re-ranking (bounding box coordinates --> (num samples, num_thresholds, x,y,dx,dy)\n",
    "bbox_coord = np.zeros((num_samples, 5, 4), dtype=np.int16)\n",
    "num_batches = len(trI) // batchSize + 1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(trI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    conv_outputs_cam, scores = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    conv_outputs_cam = conv_outputs_cam.data.cpu().numpy()\n",
    "    scores = scores.data.cpu().numpy()\n",
    "    if i == 0:\n",
    "        features_conv = np.zeros((num_samples, conv_outputs_cam.shape[1], conv_outputs_cam.shape[2], conv_outputs_cam.shape[3]))\n",
    "        cams = np.zeros((num_samples, n_classes, conv_outputs_cam.shape[2], conv_outputs_cam.shape[3]))\n",
    "        features_conv[min_idx:max_idx, :, :, :] = conv_outputs_cam\n",
    "    else:\n",
    "        features_conv[min_idx:max_idx, :, :, :] = conv_outputs_cam\n",
    "    \n",
    "    for ii in range(0, max_idx-min_idx):\n",
    "        indexed_scores = scores[ii].argsort()[::-1]\n",
    "        scores_vec.append(scores[ii])\n",
    "        for k in range(0, n_classes):\n",
    "            w_class = weights_fc[:, indexed_scores[k]]\n",
    "            cam = np.zeros(dtype=np.float32, shape=conv_outputs_cam.shape[2:4])\n",
    "            for ind, w in enumerate(w_class):\n",
    "                cam += w * conv_outputs_cam[ii, ind, :, :]\n",
    "            cam /= np.max(cam)\n",
    "            cam[np.where(cam < 0)] = 0\n",
    "            cams[min_idx+ii, k, :, :] = cam\n",
    "            class_list[min_idx+ii, k] = indexed_scores[k]\n",
    "            \n",
    "        heatmap = cams[min_idx+ii, 0]\n",
    "        bbox_coord[min_idx+ii, 0, :] = extract_ROI(heatmap=heatmap, threshold=0.01)# Full Image\n",
    "        bbox_coord[min_idx+ii, 1, :] = extract_ROI(heatmap=heatmap, threshold=0.1)\n",
    "        bbox_coord[min_idx+ii, 2, :] = extract_ROI(heatmap=heatmap, threshold=0.2)\n",
    "        bbox_coord[min_idx+ii, 3, :] = extract_ROI(heatmap=heatmap, threshold=0.3)\n",
    "        bbox_coord[min_idx+ii, 4, :] = extract_ROI(heatmap=heatmap, threshold=0.4)\n",
    "#output: features_conv, cams, class_list, scores_vec, bbox_coord\n",
    "#extract features    \n",
    "d_wp = weighted_cam_pooling(features_conv, cams)\n",
    "#d_sp = sum_pooling(features_conv)\n",
    "# Compute Query Descriptor\n",
    "trF = descriptor_aggregation(d_wp, num_samples, n_classes)\n",
    "trF_pca = compute_pca(trF)\n",
    "\n",
    "#extract feature-cam for testset\n",
    "batchSize=10\n",
    "num_samples = len(teI)\n",
    "n_classes = 2\n",
    "class_list = np.zeros((num_samples, n_classes), dtype=np.int32)\n",
    "scores_vec = list()\n",
    "# Region of interest for re-ranking (bounding box coordinates --> (num samples, num_thresholds, x,y,dx,dy)\n",
    "bbox_coord = np.zeros((num_samples, 5, 4), dtype=np.int16)\n",
    "num_batches = len(teI) // batchSize + 1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    conv_outputs_cam, scores = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    conv_outputs_cam = conv_outputs_cam.data.cpu().numpy()\n",
    "    scores = scores.data.cpu().numpy()\n",
    "    if i == 0:\n",
    "        features_conv = np.zeros((num_samples, conv_outputs_cam.shape[1], conv_outputs_cam.shape[2], conv_outputs_cam.shape[3]))\n",
    "        cams = np.zeros((num_samples, n_classes, conv_outputs_cam.shape[2], conv_outputs_cam.shape[3]))\n",
    "        features_conv[min_idx:max_idx, :, :, :] = conv_outputs_cam\n",
    "    else:\n",
    "        features_conv[min_idx:max_idx, :, :, :] = conv_outputs_cam\n",
    "    \n",
    "    for ii in range(0, max_idx-min_idx):\n",
    "        indexed_scores = scores[ii].argsort()[::-1]\n",
    "        scores_vec.append(scores[ii])\n",
    "        for k in range(0, n_classes):\n",
    "            w_class = weights_fc[:, indexed_scores[k]]\n",
    "            cam = np.zeros(dtype=np.float32, shape=conv_outputs_cam.shape[2:4])\n",
    "            for ind, w in enumerate(w_class):\n",
    "                cam += w * conv_outputs_cam[ii, ind, :, :]\n",
    "            cam /= np.max(cam)\n",
    "            cam[np.where(cam < 0)] = 0\n",
    "            cams[min_idx+ii, k, :, :] = cam\n",
    "            class_list[min_idx+ii, k] = indexed_scores[k]\n",
    "            \n",
    "        heatmap = cams[min_idx+ii, 0]\n",
    "        bbox_coord[min_idx+ii, 0, :] = extract_ROI(heatmap=heatmap, threshold=0.01)# Full Image\n",
    "        bbox_coord[min_idx+ii, 1, :] = extract_ROI(heatmap=heatmap, threshold=0.1)\n",
    "        bbox_coord[min_idx+ii, 2, :] = extract_ROI(heatmap=heatmap, threshold=0.2)\n",
    "        bbox_coord[min_idx+ii, 3, :] = extract_ROI(heatmap=heatmap, threshold=0.3)\n",
    "        bbox_coord[min_idx+ii, 4, :] = extract_ROI(heatmap=heatmap, threshold=0.4)\n",
    "#output: features_conv, cams, class_list, scores_vec, bbox_coord\n",
    "#extract features    \n",
    "d_wp = weighted_cam_pooling(features_conv, cams)\n",
    "#d_sp = sum_pooling(features_conv)\n",
    "# Compute Query Descriptor\n",
    "teF = descriptor_aggregation(d_wp, num_samples, n_classes)\n",
    "teF_pca = compute_pca(teF)\n",
    "\n",
    "#compute the size of lesion\n",
    "def Func_IOU_size(pred,target,n_classes = 3 ):\n",
    "    ious = []\n",
    "    # ignore IOU for background class\n",
    "    for cls in range(1,n_classes):\n",
    "        pred_inds = pred == cls\n",
    "        pred_sum = pred_inds.sum()\n",
    "        target_inds = target == cls\n",
    "        target_sum = target_inds.sum()\n",
    "        ious.append(round(float(min(pred_sum,target_sum)/max(pred_sum,target_sum)),4))\n",
    "    return np.mean(ious)\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(2048) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "for topk in [10]:\n",
    "    mAP = [] #mean average precision\n",
    "    mIoU = []\n",
    "    scores, neighbors = gpu_index.search(np.array(teF).astype('float32'), k=topk)\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        #for j in ranklist:\n",
    "        for j in neighbors[i].tolist():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                pos_len = pos_len +1\n",
    "                mAP.append(pos_len/rank_len) \n",
    "            else: \n",
    "                mAP.append(0)\n",
    "            mIoU.append(Func_IOU_size(teM[i],trM[j],n_classes=3))\n",
    "    print(\"mAP={:.4f}, mIoU={:.4f}\".format(np.mean(mAP),np.mean(mIoU)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_net = best_net.cpu()\n",
    "x_batch = x_batch.cpu()\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "--------below is the dataset split code and image show code--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    482\n",
      "True     168\n",
      "Name: diagnosis(glaucoma=True), dtype: int64\n",
      "False    433\n",
      "True     152\n",
      "Name: diagnosis(glaucoma=True), dtype: int64\n",
      "False    49\n",
      "True     16\n",
      "Name: diagnosis(glaucoma=True), dtype: int64\n"
     ]
    }
   ],
   "source": [
    "datas = pd.read_csv(root_dir+\"labels.csv\" , sep=',')\n",
    "datas = datas[['filename','diagnosis(glaucoma=True)']]\n",
    "print(datas['diagnosis(glaucoma=True)'].value_counts())\n",
    "trData, teData = train_test_split(datas, test_size=0.1) #split trainset and testset\n",
    "print(trData['diagnosis(glaucoma=True)'].value_counts())\n",
    "print(teData['diagnosis(glaucoma=True)'].value_counts())\n",
    "trData.to_csv( '/data/fjsdata/MCBIR-Ins/origa650/trainset.csv',index=False)\n",
    "teData.to_csv( '/data/fjsdata/MCBIR-Ins/origa650/testset.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
