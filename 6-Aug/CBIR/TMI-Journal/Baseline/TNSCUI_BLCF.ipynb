{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading faiss with AVX2 support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "from typing import Dict, List\n",
    "from PIL import Image\n",
    "from io import StringIO,BytesIO \n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize,normalize\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc,roc_auc_score \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.ndimage import zoom\n",
    "from functools import reduce\n",
    "from scipy.io import loadmat\n",
    "from skimage.measure import block_reduce\n",
    "from collections import Counter\n",
    "from scipy.sparse import coo_matrix,hstack, vstack\n",
    "import cv2\n",
    "import faiss \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.ops as ops\n",
    "torch.cuda.set_device(2)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3279 / 3279 The length of trainset is 3279\n",
      "365 / 365 The length of testset is 365\n",
      "Completed data handle in 127 seconds\n"
     ]
    }
   ],
   "source": [
    "tstart = time.time()\n",
    "root_dir = '/data/fjsdata/MCBIR-Ins/TNSCUI2020_train/' #the path of images\n",
    "trData = pd.read_csv(root_dir+\"trainset.csv\" , sep=',')\n",
    "teData = pd.read_csv(root_dir+\"testset.csv\" , sep=',')\n",
    "#trainset \n",
    "trN, trI, trM, trY = [],[],[],[]\n",
    "for iname, itype in np.array(trData).tolist():\n",
    "    try:\n",
    "        trN.append(iname)\n",
    "        trY.append(itype) #0 refer to Benign, and 1 refers to malignant\n",
    "        image_path = os.path.join(root_dir, 'image', iname)\n",
    "        img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(256,256,3)\n",
    "        trI.append(img)\n",
    "        mask_path = os.path.join(root_dir,'mask', iname)\n",
    "        mask = cv2.resize(cv2.imread(mask_path).astype(np.float32), (256, 256))#(256,256)\n",
    "        trM.append(mask)\n",
    "    except:\n",
    "        print(iname+\":\"+str(image_path))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(trN),trData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of trainset is %d'%len(trN))\n",
    "#testset\n",
    "teN, teI, teM, teY = [],[],[],[]\n",
    "for iname, itype in np.array(teData).tolist():\n",
    "    try:\n",
    "        teN.append(iname)\n",
    "        teY.append(itype) #0 refer to Benign, and 1 refers to malignant\n",
    "        image_path = os.path.join(root_dir, 'image', iname)\n",
    "        img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(256,256,3)\n",
    "        teI.append(img)\n",
    "        mask_path = os.path.join(root_dir,'mask', iname)\n",
    "        mask = cv2.resize(cv2.imread(mask_path).astype(np.float32), (256, 256))#(256,256)\n",
    "        teM.append(mask)\n",
    "    except:\n",
    "        print(iname+\":\"+str(image_path))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(teN),teData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of testset is %d'%len(teN))\n",
    "\n",
    "elapsed = time.time() - tstart\n",
    "print('Completed data handle in %d seconds' % int(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_urls = {\n",
    "    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\n",
    "    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\n",
    "    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n",
    "    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\n",
    "    'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\n",
    "    'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\n",
    "    'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\n",
    "    'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\n",
    "}\n",
    "\n",
    "class VGG(nn.Module):\n",
    "\n",
    "    def __init__(self, features, num_classes=2, init_weights=True):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "cfgs = {\n",
    "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "def vgg11(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 11-layer model (configuration \"A\") from\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['A'], batch_norm=False), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg11_bn(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['A'], batch_norm=True), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg13(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 13-layer model (configuration \"B\")\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['B'], batch_norm=False), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg13_bn(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['B'], batch_norm=True), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg16(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 16-layer model (configuration \"D\")\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['D'], batch_norm=False), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg16_bn(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 16-layer model (configuration \"D\") with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['D'], batch_norm=True), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg19(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 19-layer model (configuration \"E\")\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['E'], batch_norm=False), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg19_bn(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 19-layer model (configuration 'E') with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['E'], batch_norm=True), **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 328 / 328 : loss = 0.7013616Eopch:     1 mean_loss = 3.260489\n",
      " 328 / 328 : loss = 0.662188Eopch:     2 mean_loss = 0.702019\n",
      " 328 / 328 : loss = 0.706662Eopch:     3 mean_loss = 0.690516\n",
      " 328 / 328 : loss = 0.721545Eopch:     4 mean_loss = 0.691918\n",
      " 328 / 328 : loss = 0.674087Eopch:     5 mean_loss = 0.701559\n",
      " 328 / 328 : loss = 0.707324Eopch:     6 mean_loss = 0.688789\n",
      " 328 / 328 : loss = 0.646262Eopch:     7 mean_loss = 0.696946\n",
      " 328 / 328 : loss = 0.639549Eopch:     8 mean_loss = 0.689661\n",
      " 328 / 328 : loss = 0.688932Eopch:     9 mean_loss = 0.688646\n",
      " 328 / 328 : loss = 0.6084843Eopch:    10 mean_loss = 0.816482\n",
      "best_loss = 0.688646\n",
      " 36 / 37 Sensitivity(TPR) of Benign: 0.000000\n",
      "Sensitivity(TPR) of Malignant: 1.000000\n",
      "AUC (Area Under Curve) of Micro: 0.469273\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#define model\n",
    "model = vgg16_bn().cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "ce_loss  = nn.CrossEntropyLoss().cuda() #define cross-entropy loss\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(10):#iteration\n",
    "    losses = []\n",
    "    shuffled_idx = np.random.permutation(np.arange(len(trI)))\n",
    "    trI_batch = np.array(trI)[shuffled_idx]\n",
    "    trY_batch = np.array(trY)[shuffled_idx]\n",
    "    num_batches = len(trI) // batchSize + 1\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "        X_batch = torch.from_numpy(trI_batch[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        Y_batch = torch.from_numpy(trY_batch[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        #forword\n",
    "        Out_batch = model(X_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        loss = ce_loss(Out_batch,Y_batch)#loss\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        optimizer.step()#update parameters\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "ce_loss = ce_loss.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#test model\n",
    "teY_pred = []\n",
    "teY_prob = []\n",
    "num_batches = len(teI) // batchSize + 1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    out_batch = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    out_batch = F.log_softmax(out_batch,dim=1) \n",
    "    prob = out_batch.max(1,keepdim=True)[0]\n",
    "    teY_prob.extend(prob.cpu().data.numpy().tolist())\n",
    "    pred = out_batch.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(pred.cpu().data.numpy().flatten().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#TNR= TN / (FP+TN) ->low misdiagnosis rate->Specificity\n",
    "#TPR= TP / (TP+FN) -> low missed diagnosis rate->Sensitivity\n",
    "#ROC curves: y axis:Sensitivity, x axis:1-Specificity\n",
    "#confusion matrix\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, teY_pred, labels=labels) \n",
    "print ('Sensitivity(TPR) of Benign: %.6f'%float(cm[0][0]/np.sum(cm[0]))) \n",
    "print ('Sensitivity(TPR) of Malignant: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "#auc and roc\n",
    "teY_one_hot = label_binarize(np.array(teY), np.arange(len(labels)))\n",
    "auc_score = roc_auc_score(teY_one_hot, np.array(teY_prob), average='micro')#macro\n",
    "print ('AUC (Area Under Curve) of Micro: %.6f'% auc_score)\n",
    "#plot roc curve\n",
    "fpr_tce, tpr_tce, thresholds = roc_curve(teY_one_hot.ravel(),np.array(teY_prob).ravel()) \n",
    "#plt.plot(fpr_ce, tpr_ce, c = 'r', ls = '--', label = u'ATH(our) AUC=%.4f' % auc_score)\n",
    "plt.plot(fpr_tce, tpr_tce, c = 'b', ls = '--', label = u'R-MAC AUC=%.4f' % auc_score) \n",
    "plt.plot((0, 1), (0, 1), c = '#808080', lw = 1, ls = '--', alpha = 0.7)\n",
    "plt.xlim((-0.01, 1.02))\n",
    "plt.ylim((-0.01, 1.02))\n",
    "plt.xticks(np.arange(0, 1.1, 0.2))\n",
    "plt.yticks(np.arange(0, 1.1, 0.2))\n",
    "plt.xlabel('1-Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.grid(b=True, ls=':')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('TNSCUI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#release gpu memory and save model in CPU\n",
    "model = model.cpu()\n",
    "ce_loss = ce_loss.cpu()\n",
    "best_net = best_net.cpu()\n",
    "torch.cuda.empty_cache() \n",
    "torch.save(best_net.state_dict(), '/data/tmpexec/BLCF.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing PCA-w...\n",
      "DONE! 4.40s\n",
      "Fitting vocabulary\n",
      "DONE! 2428.80s\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Code: https://github.com/imatge-upc/salbow/tree/master/src/BLCF\n",
    "       https://github.com/imatge-upc/retrieval-2016-icmr\n",
    "#Paper: CBMI2018《Saliency Weighted Convolutional Features for Instance Search》\n",
    "        ICMR2016《Bags of local convolutional features for scalable instance search》\n",
    "'''\n",
    "\n",
    "#load model and transfer to GPU\n",
    "device = torch.device(\"cuda\")\n",
    "best_net = vgg16_bn()\n",
    "best_net.load_state_dict(torch.load( '/data/tmpexec/BLCF.pkl'))\n",
    "best_net.to(device)\n",
    "#1. Extract features based on backbone and Aggregate R-MAC\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "best_net.features.register_forward_hook(get_activation('features'))\n",
    "\n",
    "# get codebook\n",
    "def get_codebook(ConvFeat, n_clusters=1000, n_components=100):\n",
    "    \"\"\"\n",
    "    Compute PCA and codebook models\n",
    "    arg: n_clusters --  size of vocabulary\n",
    "         n_components -- dim PCA model / None if not computing PCA\n",
    "    \"\"\"\n",
    "    print (\"computing PCA-w...\")\n",
    "    training_feats  = []\n",
    "    for i in range(len(ConvFeat)):\n",
    "        feat = np.transpose( np.array(ConvFeat[i]), (1,2,0) )\n",
    "        r, c, ch = feat.shape\n",
    "        feat = np.reshape( feat, (r*c, -1) )\n",
    "        training_feats.extend(feat)\n",
    "    training_feats = np.array(training_feats)\n",
    "    training_feats = normalize(training_feats)\n",
    "    t0 = time.time()\n",
    "    pca_model = PCA(n_components, whiten=True)\n",
    "    pca_model.fit(training_feats)\n",
    "    t1 = time.time()\n",
    "    print (\"DONE! %.2fs\" % (t1-t0))\n",
    "\n",
    "    training_feats = pca_model.transform(training_feats)\n",
    "    print (\"Fitting vocabulary\")\n",
    "    t0 = time.time()\n",
    "    kmeans =KMeans(n_clusters=n_clusters, random_state=0).fit(training_feats)\n",
    "    t1 = time.time()\n",
    "    print (\"DONE! %.2fs\" % (t1-t0))\n",
    "\n",
    "    return pca_model, kmeans #kmeans.cluster_centers_\n",
    "\n",
    "batchSize=10\n",
    "trF = []\n",
    "num_batches = len(trI) // batchSize + 1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(trI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    out_batch = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    feat_batch = activation['features'].squeeze()\n",
    "    trF.extend(feat_batch.cpu().numpy().tolist())\n",
    "    \n",
    "teF = []\n",
    "num_batches = len(teI) // batchSize + 1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    out_batch = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    feat_batch = activation['features'].squeeze()\n",
    "    teF.extend(feat_batch.cpu().numpy().tolist())\n",
    "    \n",
    "pca_model, kmeans = get_codebook(trF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_net = best_net.cpu()\n",
    "x_batch = x_batch.cpu()\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3279, 1000)\n",
      "(365, 1000)\n",
      "Completed buliding index in 22 seconds\n",
      "mAP=0.3441, mIoU=0.3656\n"
     ]
    }
   ],
   "source": [
    "def get_bow( assignments, weights, n=1000):\n",
    "    '''\n",
    "    Funtion to build BoW representation given an assignment map.\n",
    "    args:\n",
    "        assignments - 2D map with assignments associated to each local feature\n",
    "        weights     - 2D maps with normalized (0-1) spatial weighting scheme\n",
    "        n           - size of the visual vocabulary (default 1000)\n",
    "    '''\n",
    "    # sparse encoding !\n",
    "    rows = np.array([], dtype=np.int)\n",
    "    cols = np.array([], dtype=np.int)\n",
    "    vals = np.array([], dtype=np.float)\n",
    "    n_docs = 0\n",
    "\n",
    "    # get counts\n",
    "    cnt = Counter(assignments.flatten())\n",
    "    ids = list(cnt.keys())#np.array(cnt.keys())\n",
    "    weights = weights.flatten()\n",
    "    weights = np.array([weights[np.where(assignments.flatten()==i)[0]].sum() for i in ids])\n",
    "\n",
    "    #save index\n",
    "    cols = np.append( cols, np.array(ids).astype(int) )\n",
    "    rows = np.append( rows, np.ones( len(cnt.keys()), dtype=int )*n_docs )\n",
    "    vals = np.append( vals, weights.astype(float) )\n",
    "    n_docs +=1\n",
    "\n",
    "    bow = coo_matrix( ( vals, (rows, cols) ), shape=(n_docs,n) )\n",
    "    bow = bow.tocsr()\n",
    "    #    bow = normalize(bow)\n",
    "    return bow\n",
    "#trainset\n",
    "for i in range(len(trF)):\n",
    "    feat = np.array(trF[i])\n",
    "    mask = np.array(trI[i])\n",
    "    #assignments maps\n",
    "    #feat = zoom(feat, (1,32,32), order=1) #interpolate=256/8=32\n",
    "    feat = np.reshape( feat, (feat.shape[0], -1) )\n",
    "    feat = np.transpose( feat, (1,0) )\n",
    "    feat = normalize(feat)\n",
    "    feat = pca_model.transform(feat)\n",
    "    feat = normalize(feat)\n",
    "    assigns = kmeans.predict(feat)\n",
    "    #Normalized saliency\n",
    "    mask = block_reduce( mask[:,:,0], (32,32), np.max )#downsample\n",
    "    mask = mask.astype(np.float32)\n",
    "    if not np.any(mask):\n",
    "        mask[...]=1\n",
    "    mask = mask / mask.max()\n",
    "    #get bags of words\n",
    "    bow = get_bow(assigns, mask)\n",
    "    if i == 0:\n",
    "        tr_bow = bow\n",
    "    else:\n",
    "        tr_bow = vstack( [tr_bow, bow] )\n",
    "tr_bow = normalize(tr_bow)\n",
    "print(tr_bow.shape)\n",
    "#testset\n",
    "for i in range(len(teF)):\n",
    "    feat = np.array(teF[i])\n",
    "    mask = np.array(teI[i])\n",
    "    #assignments maps\n",
    "    #feat = zoom(feat, (1,32,32), order=1) #interpolate=256/8=32\n",
    "    feat = np.reshape( feat, (feat.shape[0], -1) )\n",
    "    feat = np.transpose( feat, (1,0) )\n",
    "    feat = normalize(feat)\n",
    "    feat = pca_model.transform(feat)\n",
    "    feat = normalize(feat)\n",
    "    assigns = kmeans.predict(feat)\n",
    "    #Normalized saliency\n",
    "    mask = block_reduce( mask[:,:,0], (32,32), np.max )#downsample\n",
    "    mask = mask.astype(np.float32)\n",
    "    if not np.any(mask):\n",
    "        mask[...]=1\n",
    "    mask = mask / mask.max()\n",
    "    #get bags of words\n",
    "    bow = get_bow(assigns, mask)\n",
    "    if i == 0:\n",
    "        te_bow = bow\n",
    "    else:\n",
    "        te_bow = vstack( [te_bow, bow] )\n",
    "te_bow = normalize(te_bow)\n",
    "print(te_bow.shape)\n",
    "\n",
    "#evaluate\n",
    "#compute the size of lesion\n",
    "def Func_IOU_size(pred,target):\n",
    "    ious = []\n",
    "    # ignore IOU for background class\n",
    "    pred_inds = pred != 0\n",
    "    pred_sum = pred_inds.sum()\n",
    "    target_inds = target != 0\n",
    "    target_sum = target_inds.sum()\n",
    "    ious.append(round(float(min(pred_sum,target_sum)/max(pred_sum,target_sum)),4))\n",
    "    return np.mean(ious)\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(1000) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(tr_bow.toarray(), dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "for topk in [10]:\n",
    "    mAP = [] #mean average precision\n",
    "    mIoU = []\n",
    "    scores, neighbors = gpu_index.search(te_bow.toarray().astype('float32'), k=topk)\n",
    "    for i, teVal in enumerate(te_bow.toarray().tolist()):\n",
    "        stype = teY[i]\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        #for j in ranklist:\n",
    "        for j in neighbors[i].tolist():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                pos_len = pos_len +1\n",
    "                mAP.append(pos_len/rank_len) \n",
    "            else: \n",
    "                mAP.append(0)\n",
    "            mIoU.append(Func_IOU_size(teM[i],trM[j]))\n",
    "    print(\"mAP={:.4f}, mIoU={:.4f}\".format(np.mean(mAP),np.mean(mIoU)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "--------below is the dataset split code and image show code--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    482\n",
      "True     168\n",
      "Name: diagnosis(glaucoma=True), dtype: int64\n",
      "False    433\n",
      "True     152\n",
      "Name: diagnosis(glaucoma=True), dtype: int64\n",
      "False    49\n",
      "True     16\n",
      "Name: diagnosis(glaucoma=True), dtype: int64\n"
     ]
    }
   ],
   "source": [
    "datas = pd.read_csv(root_dir+\"labels.csv\" , sep=',')\n",
    "datas = datas[['filename','diagnosis(glaucoma=True)']]\n",
    "print(datas['diagnosis(glaucoma=True)'].value_counts())\n",
    "trData, teData = train_test_split(datas, test_size=0.1) #split trainset and testset\n",
    "print(trData['diagnosis(glaucoma=True)'].value_counts())\n",
    "print(teData['diagnosis(glaucoma=True)'].value_counts())\n",
    "trData.to_csv( '/data/fjsdata/MCBIR-Ins/origa650/trainset.csv',index=False)\n",
    "teData.to_csv( '/data/fjsdata/MCBIR-Ins/origa650/testset.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
