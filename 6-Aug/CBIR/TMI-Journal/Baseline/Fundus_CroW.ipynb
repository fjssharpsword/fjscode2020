{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading faiss with AVX2 support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "from typing import Dict, List\n",
    "from PIL import Image\n",
    "from io import StringIO,BytesIO \n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc,roc_auc_score \n",
    "from functools import reduce\n",
    "from scipy.io import loadmat\n",
    "import cv2\n",
    "import faiss \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.ops as ops\n",
    "torch.cuda.set_device(0)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585 / 585 The length of trainset is 585\n",
      "65 / 65 The length of testset is 65\n",
      "Completed data handle in 105 seconds\n"
     ]
    }
   ],
   "source": [
    "tstart = time.time()\n",
    "root_dir = '/data/fjsdata/MCBIR-Ins/origa650/' #the path of images\n",
    "trData = pd.read_csv(root_dir+\"trainset.csv\" , sep=',')\n",
    "teData = pd.read_csv(root_dir+\"testset.csv\" , sep=',')\n",
    "#trainset \n",
    "trN, trI, trM, trY = [],[],[],[]\n",
    "for iname, itype in np.array(trData).tolist():\n",
    "    iname=os.path.splitext(iname)[0].strip()[1:] #get rid of file extension\n",
    "    try:\n",
    "        trN.append(iname)\n",
    "        if itype==True: #glaucoma\n",
    "            trY.append(1)\n",
    "        else: trY.append(0) #False\n",
    "        image_path = os.path.join(root_dir, 'images', iname+'.jpg')\n",
    "        img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(256,256,3)\n",
    "        trI.append(img)\n",
    "        mask_path = os.path.join(root_dir,'mask', iname+'.mat')\n",
    "        mask = cv2.resize(loadmat(mask_path)['mask'],(256, 256))#(256,256)\n",
    "        trM.append(mask)\n",
    "    except:\n",
    "        print(iname+\":\"+str(image_path))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(trN),trData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of trainset is %d'%len(trN))\n",
    "#testset\n",
    "teN, teI, teM, teY = [],[],[],[]\n",
    "for iname, itype in np.array(teData).tolist():\n",
    "    iname=os.path.splitext(iname)[0].strip()[1:] #get rid of file extension\n",
    "    try:\n",
    "        teN.append(iname)\n",
    "        if itype==True: #glaucoma\n",
    "            teY.append(1)\n",
    "        else: teY.append(0) #False\n",
    "        image_path = os.path.join(root_dir, 'images', iname+'.jpg')\n",
    "        img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(256,256,3)\n",
    "        teI.append(img)\n",
    "        mask_path = os.path.join(root_dir,'mask', iname+'.mat')\n",
    "        mask = cv2.resize(loadmat(mask_path)['mask'],(256, 256))#(256,256)\n",
    "        teM.append(mask)\n",
    "    except:\n",
    "        print(iname+\":\"+str(image_path))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(teN),teData.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "print('The length of testset is %d'%len(teN))\n",
    "\n",
    "elapsed = time.time() - tstart\n",
    "print('Completed data handle in %d seconds' % int(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_urls = {\n",
    "    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\n",
    "    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\n",
    "    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n",
    "    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\n",
    "    'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\n",
    "    'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\n",
    "    'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\n",
    "    'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\n",
    "}\n",
    "\n",
    "class VGG(nn.Module):\n",
    "\n",
    "    def __init__(self, features, num_classes=2, init_weights=True):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "cfgs = {\n",
    "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "def vgg11(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 11-layer model (configuration \"A\") from\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['A'], batch_norm=False), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg11_bn(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['A'], batch_norm=True), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg13(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 13-layer model (configuration \"B\")\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['B'], batch_norm=False), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg13_bn(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['B'], batch_norm=True), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg16(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 16-layer model (configuration \"D\")\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['D'], batch_norm=False), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg16_bn(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 16-layer model (configuration \"D\") with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['D'], batch_norm=True), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg19(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 19-layer model (configuration \"E\")\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['E'], batch_norm=False), **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg19_bn(progress=True, **kwargs):\n",
    "    r\"\"\"VGG 19-layer model (configuration 'E') with batch normalization\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfgs['E'], batch_norm=True), **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 59 / 59 : loss = 2.0956531Eopch:     1 mean_loss = 5.845511\n",
      " 59 / 59 : loss = 0.411608Eopch:     2 mean_loss = 0.999487\n",
      " 59 / 59 : loss = 0.632881Eopch:     3 mean_loss = 0.666984\n",
      " 59 / 59 : loss = 0.712446Eopch:     4 mean_loss = 0.643580\n",
      " 59 / 59 : loss = 0.982064Eopch:     5 mean_loss = 0.609533\n",
      " 59 / 59 : loss = 0.525646Eopch:     6 mean_loss = 0.628790\n",
      " 59 / 59 : loss = 0.780276Eopch:     7 mean_loss = 0.604373\n",
      " 59 / 59 : loss = 0.502474Eopch:     8 mean_loss = 0.638678\n",
      " 59 / 59 : loss = 0.885404Eopch:     9 mean_loss = 0.613843\n",
      " 59 / 59 : loss = 0.412297Eopch:    10 mean_loss = 0.621251\n",
      "best_loss = 0.604373\n",
      " 6 / 7 Sensitivity(TPR) of Normal: 1.000000\n",
      "Sensitivity(TPR) of Glaucoma: 0.062500\n",
      "AUC (Area Under Curve) of Micro: 0.540816\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#define model\n",
    "model = vgg16_bn().cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "ce_loss  = nn.CrossEntropyLoss().cuda() #define cross-entropy loss\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(10):#iteration\n",
    "    losses = []\n",
    "    shuffled_idx = np.random.permutation(np.arange(len(trI)))\n",
    "    trI_batch = np.array(trI)[shuffled_idx]\n",
    "    trY_batch = np.array(trY)[shuffled_idx]\n",
    "    num_batches = len(trI) // batchSize + 1\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "        X_batch = torch.from_numpy(trI_batch[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        Y_batch = torch.from_numpy(trY_batch[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        #forword\n",
    "        Out_batch = model(X_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        loss = ce_loss(Out_batch,Y_batch)#loss\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        optimizer.step()#update parameters\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "ce_loss = ce_loss.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#test model\n",
    "teY_pred = []\n",
    "teY_prob = []\n",
    "num_batches = len(teI) // batchSize + 1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    out_batch = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    out_batch = F.log_softmax(out_batch,dim=1) \n",
    "    prob = out_batch.max(1,keepdim=True)[0]\n",
    "    teY_prob.extend(prob.cpu().data.numpy().tolist())\n",
    "    pred = out_batch.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(pred.cpu().data.numpy().flatten().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#TNR= TN / (FP+TN) ->low misdiagnosis rate->Specificity\n",
    "#TPR= TP / (TP+FN) -> low missed diagnosis rate->Sensitivity\n",
    "#ROC curves: y axis:Sensitivity, x axis:1-Specificity\n",
    "#confusion matrix\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, teY_pred, labels=labels) \n",
    "print ('Sensitivity(TPR) of Normal: %.6f'%float(cm[0][0]/np.sum(cm[0]))) \n",
    "print ('Sensitivity(TPR) of Glaucoma: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "#auc and roc\n",
    "teY_one_hot = label_binarize(np.array(teY), np.arange(len(labels)))\n",
    "auc_score = roc_auc_score(teY_one_hot, np.array(teY_prob), average='micro')#macro\n",
    "print ('AUC (Area Under Curve) of Micro: %.6f'% auc_score)\n",
    "#plot roc curve\n",
    "fpr_tce, tpr_tce, thresholds = roc_curve(teY_one_hot.ravel(),np.array(teY_prob).ravel()) \n",
    "#plt.plot(fpr_ce, tpr_ce, c = 'r', ls = '--', label = u'ATH(our) AUC=%.4f' % auc_score)\n",
    "plt.plot(fpr_tce, tpr_tce, c = 'b', ls = '--', label = u'R-MAC AUC=%.4f' % auc_score) \n",
    "plt.plot((0, 1), (0, 1), c = '#808080', lw = 1, ls = '--', alpha = 0.7)\n",
    "plt.xlim((-0.01, 1.02))\n",
    "plt.ylim((-0.01, 1.02))\n",
    "plt.xticks(np.arange(0, 1.1, 0.2))\n",
    "plt.yticks(np.arange(0, 1.1, 0.2))\n",
    "plt.xlabel('1-Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.grid(b=True, ls=':')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Fundus')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#release gpu memory and save model in CPU\n",
    "model = model.cpu()\n",
    "ce_loss = ce_loss.cpu()\n",
    "best_net = best_net.cpu()\n",
    "torch.cuda.empty_cache() \n",
    "torch.save(best_net.state_dict(), '/data/tmpexec/CroW.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Code: https://github.com/PyRetri/PyRetri\n",
    "       https://github.com/YahooArchive/crow\n",
    "#Paper: ECCV2017《Cross-dimensional Weighting for Aggregated Deep Convolutional Features》\n",
    "'''\n",
    "class CroW():\n",
    "    \"\"\"\n",
    "    Cross-dimensional Weighting for Aggregated Deep Convolutional Features.\n",
    "    c.f. https://arxiv.org/pdf/1512.04065.pdf\n",
    "    Args:\n",
    "        spatial_a (float): hyper-parameter for calculating spatial weight.\n",
    "        spatial_b (float): hyper-parameter for calculating spatial weight.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, spatial_a=2.0, spatial_b=2.0):\n",
    "       \n",
    "        self.first_show = True\n",
    "        self.spatial_a = spatial_a\n",
    "        self.spatial_b = spatial_b\n",
    "\n",
    "    def __call__(self, fea:torch.tensor) -> torch.tensor:\n",
    "        final_fea = None\n",
    "        if fea.ndimension() == 4:\n",
    "            spatial_weight = fea.sum(dim=1, keepdim=True)\n",
    "            z = (spatial_weight ** self.spatial_a).sum(dim=(2, 3), keepdim=True)\n",
    "            z = z ** (1.0 / self.spatial_a)\n",
    "            spatial_weight = (spatial_weight / z) ** (1.0 / self.spatial_b)\n",
    "\n",
    "            c, w, h = fea.shape[1:]\n",
    "            nonzeros = (fea!=0).float().sum(dim=(2, 3)) / 1.0 / (w * h) + 1e-6\n",
    "            channel_weight = torch.log(nonzeros.sum(dim=1, keepdim=True) / nonzeros)\n",
    "\n",
    "            fea = fea * spatial_weight\n",
    "            fea = fea.sum(dim=(2, 3))\n",
    "            fea = fea * channel_weight\n",
    "            \n",
    "            final_fea = fea\n",
    "\n",
    "        else:# In case of fc feature.\n",
    "            assert fea.ndimension() == 2\n",
    "            if self.first_show:\n",
    "                print(\"[Crow Aggregator]: find 2-dimension feature map, skip aggregation\")\n",
    "                self.first_show = False\n",
    "            final_fea = fea\n",
    "            \n",
    "        return final_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed buliding index in 22 seconds\n",
      "mAP=0.5154, mIoU=0.7187\n"
     ]
    }
   ],
   "source": [
    "#load model and transfer to GPU\n",
    "device = torch.device(\"cuda\")\n",
    "best_net = vgg16_bn()\n",
    "best_net.load_state_dict(torch.load( '/data/tmpexec/CroW.pkl'))\n",
    "best_net.to(device)\n",
    "#1. Extract features based on backbone and Aggregate R-MAC\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "best_net.features.register_forward_hook(get_activation('features'))\n",
    "\n",
    "batchSize=10\n",
    "crow = CroW()\n",
    "trF = []\n",
    "num_batches = len(trI) // batchSize + 1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(trI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    out_batch = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    feat_batch = activation['features'].squeeze()\n",
    "    feat_ret_batch = crow(feat_batch)\n",
    "    trF.extend(feat_ret_batch.cpu().numpy().tolist())\n",
    "teF = []\n",
    "num_batches = len(teI) // batchSize + 1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    out_batch = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    feat_batch = activation['features'].squeeze()\n",
    "    feat_ret_batch = crow(feat_batch)\n",
    "    teF.extend(feat_ret_batch.cpu().numpy().tolist())\n",
    "    \n",
    "#compute the size of lesion\n",
    "def Func_IOU_size(pred,target,n_classes = 3 ):\n",
    "    ious = []\n",
    "    # ignore IOU for background class\n",
    "    for cls in range(1,n_classes):\n",
    "        pred_inds = pred == cls\n",
    "        pred_sum = pred_inds.sum()\n",
    "        target_inds = target == cls\n",
    "        target_sum = target_inds.sum()\n",
    "        ious.append(round(float(min(pred_sum,target_sum)/max(pred_sum,target_sum)),4))\n",
    "    return np.mean(ious)\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(512) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "for topk in [10]:\n",
    "    mAP = [] #mean average precision\n",
    "    mIoU = []\n",
    "    scores, neighbors = gpu_index.search(np.array(teF).astype('float32'), k=topk)\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        #for j in ranklist:\n",
    "        for j in neighbors[i].tolist():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                pos_len = pos_len +1\n",
    "                mAP.append(pos_len/rank_len) \n",
    "            else: \n",
    "                mAP.append(0)\n",
    "            mIoU.append(Func_IOU_size(teM[i],trM[j],n_classes=3))\n",
    "    print(\"mAP={:.4f}, mIoU={:.4f}\".format(np.mean(mAP),np.mean(mIoU)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_net = best_net.cpu()\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "--------below is the dataset split code and image show code--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    482\n",
      "True     168\n",
      "Name: diagnosis(glaucoma=True), dtype: int64\n",
      "False    433\n",
      "True     152\n",
      "Name: diagnosis(glaucoma=True), dtype: int64\n",
      "False    49\n",
      "True     16\n",
      "Name: diagnosis(glaucoma=True), dtype: int64\n"
     ]
    }
   ],
   "source": [
    "datas = pd.read_csv(root_dir+\"labels.csv\" , sep=',')\n",
    "datas = datas[['filename','diagnosis(glaucoma=True)']]\n",
    "print(datas['diagnosis(glaucoma=True)'].value_counts())\n",
    "trData, teData = train_test_split(datas, test_size=0.1) #split trainset and testset\n",
    "print(trData['diagnosis(glaucoma=True)'].value_counts())\n",
    "print(teData['diagnosis(glaucoma=True)'].value_counts())\n",
    "trData.to_csv( '/data/fjsdata/MCBIR-Ins/origa650/trainset.csv',index=False)\n",
    "teData.to_csv( '/data/fjsdata/MCBIR-Ins/origa650/testset.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
