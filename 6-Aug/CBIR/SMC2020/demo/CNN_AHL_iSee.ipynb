{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.Develop Env: linux+cuda9+python3+opencv+pytorch+faiss\n",
    "2.Dataset: Fundus-iSee with 10000 images(AMD-720, DR-270, glaucoma-450,myopia-790,norm-7770)\n",
    "        trainset(9000): AMD-648, DR-243, glaucoma-405, myopia-711, norm-6993(699), \n",
    "        testset(1000): AMD-72, DR-27, glaucoma-45, myopia-79, norm=777(77)\n",
    "3.Performance Metric: \n",
    "  1)MHR(Mean Hit Ratio):  for evaluating the precison of relevance retrieval;\n",
    "  2)MAP(Mean Average Precision): for evaluation the rank of relevance retrieval;\n",
    "  3)MRR(Mean Reciprocal Rank): for evaluation the first hit rank of relevance retrieval;\n",
    "  4)Memory consumption and Retrieval Speed.\n",
    "4.Algorithm: \n",
    "  1)Baseline: CNN-FCL,CNN-HL\n",
    "  2)Attention: CNN-AH(AHNet)\n",
    "  3)effectiveness: CNN-FCL<CNN-HL<CNN-AH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from scipy.spatial.distance import pdist\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "#import faiss\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.cuda.set_device(7)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2706 / 9000 The length of train set is 2706\n",
      "300 / 1000 The length of test set is 300\n",
      "Completed buliding index in 217 seconds\n"
     ]
    }
   ],
   "source": [
    "#1. Read data with List storage Data:[name,type],I:[img],Y[type]\n",
    "def TypetoNum(itype): #map the type into number.\n",
    "    if itype =='AMD': return 0\n",
    "    elif itype =='DR': return 1\n",
    "    elif itype =='glaucoma': return 2\n",
    "    elif itype =='myopia': return 3\n",
    "    else: return 4 #norm\n",
    "    \n",
    "root_dir = '/data/fjsdata/fundus/iSee/iSee_multi_dataset/' #the path of images\n",
    "trainset = pd.read_csv(\"/data/fjsdata/fundus/iSee/iSee_multi_dataset/CBIR_iSee_train.csv\" , sep=',')#load trainset\n",
    "testset = pd.read_csv(\"/data/fjsdata/fundus/iSee/iSee_multi_dataset/CBIR_iSee_test.csv\" , sep=',')#load testset\n",
    "tstart = time.time()\n",
    "#read train image with CV\n",
    "trData, trI, trY = [],[],[]\n",
    "norm = 699\n",
    "for iname, itype in np.array(trainset).tolist():\n",
    "    if iname.endswith(\".jpg\"):\n",
    "        try:\n",
    "            image_dir = root_dir+'img_data_%s'%itype\n",
    "            image_path = os.path.join(image_dir, iname)\n",
    "            if itype == 'norm':\n",
    "                if norm>0:\n",
    "                    img = cv2.resize(cv2.imread(image_path).astype(np.float32), (1024, 1024))#(1920,1920,3)->(1024,1024,3)\n",
    "                    trData.append([iname,itype])\n",
    "                    trI.append(img)\n",
    "                    trY.append(TypetoNum(itype))\n",
    "                    norm = norm - 1\n",
    "            else:\n",
    "                img = cv2.resize(cv2.imread(image_path).astype(np.float32), (1024, 1024))#(1920,1920,3)->(1024,1024,3)\n",
    "                trData.append([iname,itype,img])\n",
    "                trI.append(img)\n",
    "                trY.append(TypetoNum(itype))    \n",
    "        except:\n",
    "            print(iname+\":\"+str(image_path))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(trData),trainset.shape[0]))\n",
    "        sys.stdout.flush()\n",
    "print('The length of train set is %d'%len(trData))\n",
    "#read test image with CV\n",
    "teData, teI, teY = [],[],[]\n",
    "norm = 77\n",
    "for iname, itype in np.array(testset).tolist():\n",
    "    if iname.endswith(\".jpg\"):\n",
    "        try:\n",
    "            image_dir = root_dir+'img_data_%s'%itype\n",
    "            image_path = os.path.join(image_dir, iname)\n",
    "            if itype == 'norm':\n",
    "                if norm>0:\n",
    "                    img = cv2.resize(cv2.imread(image_path).astype(np.float32), (1024, 1024))#(1920,1920,3)->(1024,1024,3)\n",
    "                    teData.append([iname,itype])\n",
    "                    teI.append(img)\n",
    "                    teY.append(TypetoNum(itype))\n",
    "                    norm = norm - 1\n",
    "            else:\n",
    "                img = cv2.resize(cv2.imread(image_path).astype(np.float32), (1024, 1024))#(1920,1920,3)->(1024,1024,3)\n",
    "                teData.append([iname,itype,img])\n",
    "                teI.append(img)\n",
    "                teY.append(TypetoNum(itype)) \n",
    "        except:\n",
    "            print(iname+\":\"+str(image_path))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(teData),testset.shape[0]))\n",
    "        sys.stdout.flush()\n",
    "print('The length of test set is %d'%len(teData))\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.973474502563477\n",
      "conv1.weight\n",
      "tensor([-0.0891, -0.1904, -0.1932])\n",
      "14.561971664428711\n",
      "conv1.weight\n",
      "tensor([-0.0900, -0.1895, -0.1939])\n",
      "11.177960395812988\n",
      "conv1.weight\n",
      "tensor([-0.0909, -0.1885, -0.1944])\n",
      "7.792870998382568\n",
      "conv1.weight\n",
      "tensor([-0.0918, -0.1876, -0.1943])\n",
      "6.397558212280273\n",
      "conv1.weight\n",
      "tensor([-0.0926, -0.1869, -0.1947])\n",
      "5.35432243347168\n",
      "conv1.weight\n",
      "tensor([-0.0933, -0.1862, -0.1953])\n",
      "3.8476147651672363\n",
      "conv1.weight\n",
      "tensor([-0.0940, -0.1854, -0.1959])\n",
      "2.394160270690918\n",
      "conv1.weight\n",
      "tensor([-0.0948, -0.1846, -0.1961])\n",
      "2.3385796546936035\n",
      "conv1.weight\n",
      "tensor([-0.0956, -0.1839, -0.1963])\n",
      "1.7661316394805908\n",
      "conv1.weight\n",
      "tensor([-0.0962, -0.1833, -0.1966])\n",
      "tensor([[-0.0483,  0.1939, -0.0687, -0.0665,  0.0502, -0.1055, -0.2227,\n",
      "          0.1499, -0.3042,  0.0651,  0.2311,  0.1104,  0.2581, -0.6016,\n",
      "         -0.4715,  0.3705],\n",
      "        [ 0.0878, -0.1001,  0.2517, -0.2332, -0.3573,  0.0679,  0.0597,\n",
      "         -0.2617,  0.3333,  0.1726, -0.1621, -0.0552, -0.1382,  0.2058,\n",
      "          0.0470, -0.1806],\n",
      "        [-0.2961, -0.0692, -0.2788,  0.5873,  0.0089, -0.3505,  0.0900,\n",
      "         -0.2719,  0.1128,  0.3579, -0.2033, -0.3391, -0.3003,  0.1021,\n",
      "         -0.0319, -0.2367],\n",
      "        [ 0.1774,  0.0628,  0.0535, -0.0813, -0.1318,  0.1480, -0.3637,\n",
      "          0.1678,  0.2504,  0.0513,  0.3074, -0.1266,  0.2113, -0.0808,\n",
      "          0.0892,  0.1088],\n",
      "        [-0.3766,  0.3223, -0.2593,  0.2416,  0.2946,  0.0265, -0.3064,\n",
      "          0.3020, -0.3263,  0.2399,  0.1190,  0.2010,  0.0605, -0.6900,\n",
      "         -0.4189,  0.0847],\n",
      "        [-0.1844, -0.1497, -0.0430, -0.2885, -0.2745, -0.0427, -0.2960,\n",
      "         -0.2385, -0.4910, -0.0261,  0.1717,  0.1868,  0.3915, -0.1465,\n",
      "         -0.3667,  0.5189],\n",
      "        [ 0.2126,  0.3902,  0.1801, -0.3152,  0.0949,  0.3699, -0.1545,\n",
      "          0.5513,  0.3101, -0.6063,  0.2231,  0.1031, -0.1913, -0.0668,\n",
      "          0.1459,  0.3119],\n",
      "        [-0.0461,  0.3401, -0.0271,  0.0397,  0.1424,  0.4399,  0.0302,\n",
      "          0.3113,  0.0560, -0.5613, -0.3320,  0.3757,  0.1948, -0.3942,\n",
      "          0.0628,  0.1336],\n",
      "        [-0.0536, -0.0675, -0.0987,  0.1137, -0.1510, -0.1271,  0.0402,\n",
      "         -0.0962, -0.1970,  0.2021, -0.2372,  0.1155,  0.1276, -0.1072,\n",
      "         -0.1289,  0.3157],\n",
      "        [ 0.3990,  0.3192,  0.0080, -0.2028, -0.0776, -0.4384, -0.2134,\n",
      "          0.0998,  0.3365,  0.2092,  0.1956, -0.0944, -0.5044,  0.0567,\n",
      "          0.1450,  0.0490]])\n",
      "tensor([[-1.,  1., -1., -1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1.,\n",
      "          1., -1., -1.,  1.],\n",
      "        [ 1., -1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1., -1., -1.,\n",
      "         -1.,  1.,  1., -1.],\n",
      "        [-1., -1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1., -1.,\n",
      "         -1.,  1., -1., -1.],\n",
      "        [ 1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1., -1.,\n",
      "          1., -1.,  1.,  1.],\n",
      "        [-1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,\n",
      "          1., -1., -1.,  1.],\n",
      "        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1.,  1.,\n",
      "          1., -1., -1.,  1.],\n",
      "        [ 1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,\n",
      "         -1., -1.,  1.,  1.],\n",
      "        [-1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,\n",
      "          1., -1.,  1.,  1.],\n",
      "        [-1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1.,  1.,\n",
      "          1., -1., -1.,  1.],\n",
      "        [ 1.,  1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,  1., -1.,\n",
      "         -1.,  1.,  1.,  1.]])\n",
      "torch.Size([10, 16])\n"
     ]
    }
   ],
   "source": [
    "#2. define Attention-based Hashing network with pytorch\n",
    "class SpatialAttention(nn.Module):#spatial attention layer\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "class AttHashNet(nn.Module): #Attention-based Hashint Network:AHNet\n",
    "    def __init__(self,inChannels=3):\n",
    "        super(AttHashNet, self).__init__()\n",
    "        #(channels, Height, Width)\n",
    "        #layer1: Convolution, (3,1024,1024)->(16,512,512)\n",
    "        self.conv1 = nn.Conv2d(in_channels=inChannels, out_channels=16, kernel_size=3, padding=1, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        #layer2: max pooling,(16,512,512)->(16,256,256)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, padding=1, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        #layer3: Spatial Attention Layer, (16,256,256)->(16,256,256)\n",
    "        self.sa = SpatialAttention()\n",
    "        #layer4: Convolution, (16,256,256)->(8,128,128)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3, padding=1, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(8)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        #layer5: mean pooling, (8,128,128)->(8,64,64)\n",
    "        self.avgpool1 = nn.AvgPool2d(kernel_size=3, padding=1, stride=2)\n",
    "        self.bn4 = nn.BatchNorm2d(8)\n",
    "        #layer6: Convolution, (8,64,64)->(4,32,32)\n",
    "        self.conv3 = nn.Conv2d(in_channels=8, out_channels=4, kernel_size=3, padding=1, stride=2)\n",
    "        self.bn5 = nn.BatchNorm2d(4)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        #layer7: mean pooling, (4,32,32)->(4,16,16)\n",
    "        self.avgpool2 = nn.AvgPool2d(kernel_size=3, padding=1, stride=2)\n",
    "        self.bn6 = nn.BatchNorm2d(4)\n",
    "        #layer8: fully connected, 4*16*16->512\n",
    "        self.fcl1 = nn.Linear(4*16*16,512)\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "        #layer9: Hashing layer, 512->16\n",
    "        self.fcl2 = nn.Linear(512,16)#\n",
    "        self.tanh = nn.Tanh() #{-1,1}\n",
    "              \n",
    "    def forward(self,x):\n",
    "        #input: (batch_size, in_channels, Height, Width)\n",
    "        #output: (batch_size, out_channels, Height, Width)\n",
    "        #layer1: convolution\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        #layer2: max pooling\n",
    "        x = self.maxpool(x)\n",
    "        x = self.bn2(x)\n",
    "        #layer3: Attention\n",
    "        x = self.sa(x)*x\n",
    "        #layer4: Convolution\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu2(x)\n",
    "        #layer5: mean pooling\n",
    "        x = self.avgpool1(x)\n",
    "        x = self.bn4(x)\n",
    "        #layer6: Convolution\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu3(x)\n",
    "        #layer7: mean pooling\n",
    "        x = self.avgpool2(x)\n",
    "        x = self.bn6(x)\n",
    "        #layer8:fully connected\n",
    "        x = x.view(x.size(0),-1) #transfer three dims to one dim\n",
    "        x = self.fcl1(x)\n",
    "        x = self.relu4(x)\n",
    "        #layer9: Hashing layer\n",
    "        x = self.fcl2(x)\n",
    "        x = self.tanh(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "#https://pytorch-cn.readthedocs.io/zh/latest/    \n",
    "#https://github.com/filipradenovic/cnnimageretrieval-pytorch/blob/master/cirtorch/layers/functional.py\n",
    "class HashLossFunc(nn.Module):\n",
    "    def __init__(self, margin=0.5, alpha=0.01):\n",
    "        super(HashLossFunc, self).__init__()\n",
    "        self.alpha = alpha #regularization\n",
    "        self.margin = margin #margin threshold\n",
    "        \n",
    "    def forward(self,h1,h2,y): \n",
    "        #h1=h2:NxD,y:N\n",
    "        dim = h1.shape[1]\n",
    "        euc_dist = F.pairwise_distance(h1, h2, p=2, eps=1e-06) # Calcualte Euclidean Distance\n",
    "        sim_term = 0.5*(1-y)*euc_dist #penalize the similar iamge pairs when y=0\n",
    "        unsim_term = 0.5*y*torch.clamp(self.margin*dim-euc_dist,0)#penalize the unsimlar image pairs when y =1\n",
    "        reg_term = self.alpha * ( torch.sum((torch.abs(h1)-1),dim=1) + torch.sum((torch.abs(h2)-1),dim=1) ) #regularization term\n",
    "        #loss = torch.mean(sim_term + unsim_term + reg_term) \n",
    "        loss = torch.sum(sim_term + unsim_term+ reg_term) \n",
    "        return loss\n",
    "\n",
    "#test network: valid\n",
    "x1 = torch.rand(10,3,1024,1024)#.cuda()\n",
    "x2 = torch.rand(10,3,1024,1024)#.cuda()\n",
    "y = torch.FloatTensor([0,1,1,0,1,0,0,0,1,1])#.cuda()\n",
    "model = AttHashNet()#.cuda()\n",
    "criterion  = HashLossFunc(margin=0.5)#.cuda() #define loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    out1 = model(x1)#out.grad_fn\n",
    "    out2 = model(x2)\n",
    "    loss = criterion(out1,out2,y)\n",
    "    print (loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #observe the variant of model.parameters\n",
    "    for i in model.named_parameters():\n",
    "        print(i[0])\n",
    "        print(i[1][0][0][0])\n",
    "        break\n",
    "#output\n",
    "x3 = torch.rand(10,3,1024,1024)#.cuda()\n",
    "out3 = model(x3)\n",
    "print (out3)\n",
    "out3 = torch.sign(out3) #Binarization,[-1,1]->{-1,1}\n",
    "print (out3)\n",
    "print (out3.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 541 / 542 : loss = 12.958289mean_loss = 17.267654\n",
      " 29 / 30 0 mHR@5=0.248667, mAP@5=0.231767, mRR@5=0.827257\n",
      "mHR@10=0.229667, mAP@10=0.207737, mRR@10=0.721920\n",
      "mHR@15=0.225556, mAP@15=0.196997, mRR@15=0.679519\n",
      "mHR@20=0.221833, mAP@20=0.184072, mRR@20=0.579847\n"
     ]
    }
   ],
   "source": [
    "#3. Train and evaluate model \n",
    "def onlineGenImgPairs(batchSize):\n",
    "    idx_sf = random.sample(range(0, len(trY)),2*batchSize)\n",
    "    trI1_sf, trI2_sf, trY1_sf, trY2_sf = [],[],[],[]\n",
    "    flag = 0\n",
    "    for i in idx_sf:\n",
    "        if flag==0:\n",
    "            trI1_sf.append(trI[i])\n",
    "            trY1_sf.append(trY[i])\n",
    "            flag =1\n",
    "        else:\n",
    "            trI2_sf.append(trI[i])\n",
    "            trY2_sf.append(trY[i])\n",
    "            flag =0\n",
    "    trY_sf = np.where((np.array(trY1_sf)-np.array(trY2_sf))!=0,1,0)\n",
    "    return np.array(trI1_sf),np.array(trI2_sf),trY_sf\n",
    "        \n",
    "#define model\n",
    "model = AttHashNet().cuda()\n",
    "criterion  = HashLossFunc(margin=0.5).cuda() #define loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "#train model\n",
    "batchSize = 10\n",
    "epochSize = len(trY)//batchSize+1\n",
    "losses = []\n",
    "for epoch in range(2*epochSize):#iteration\n",
    "    #grad vanish\n",
    "    optimizer.zero_grad() \n",
    "    #genenate training images pair\n",
    "    trI1_sf, trI2_sf, trY_sf = onlineGenImgPairs(batchSize)\n",
    "    I1_batch = torch.from_numpy(trI1_sf).type(torch.FloatTensor).cuda()\n",
    "    I2_batch = torch.from_numpy(trI2_sf).type(torch.FloatTensor).cuda()\n",
    "    Y_batch = torch.from_numpy(trY_sf).type(torch.FloatTensor).cuda()\n",
    "    #forword\n",
    "    X1_batch = model(I1_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "    X2_batch = model(I2_batch.permute(0, 3, 1, 2))\n",
    "    #binary-like loss\n",
    "    loss = criterion(X1_batch,X2_batch,Y_batch)\n",
    "    #backward\n",
    "    loss.backward()\n",
    "    #update parameters\n",
    "    optimizer.step()\n",
    "    #show loss\n",
    "    sys.stdout.write('\\r {} / {} : loss = {}'.format(epoch, 2*epochSize, float('%0.6f'%loss.item())))\n",
    "    sys.stdout.flush()     \n",
    "    losses.append(loss.item())\n",
    "print(\"mean_loss = %.6f\" % (np.mean(losses)))\n",
    "\n",
    "#release gpu memory\n",
    "#model = model.cpu()\n",
    "#torch.cuda.empty_cache()\n",
    "#hash code of train data from model\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize\n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch = torch.sign(model(I_batch.permute(0, 3, 1, 2)))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#hash code of test data from model\n",
    "teF = []\n",
    "num_batches = len(teI) // batchSize\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(teI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch = torch.sign(model(I_batch.permute(0, 3, 1, 2)))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    teF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#Evaluate model\n",
    "#train data with list: trData, trI, trF, trY\n",
    "#test data with list: teData, teI, teF, teY\n",
    "for topk in [5,10,15,20]:\n",
    "    MHR = [] #mean Hit ratio \n",
    "    MAP = [] #mean average precision\n",
    "    MRR = [] #mean reciprocal rank\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        map_item_score = {}\n",
    "        for j, trVal in enumerate(trF):\n",
    "            map_item_score[j] = pdist(np.vstack([teVal,trVal]),'hamming')\n",
    "        ranklist = heapq.nsmallest(topk, map_item_score, key=map_item_score.get)\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        mrr_flag = 0\n",
    "        for j in ranklist:\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                MHR.append(1)\n",
    "                pos_len = pos_len +1\n",
    "                MAP.append(pos_len/rank_len) \n",
    "                if mrr_flag==0: \n",
    "                    MRR.append(pos_len/rank_len)\n",
    "                    mrr_flag =1\n",
    "            else: \n",
    "                MHR.append(0)\n",
    "                MAP.append(0)   \n",
    "    print(\"mHR@{}={:.6f}, mAP@{}={:.6f}, mRR@{}={:.6f}\".format(topk,np.mean(MHR),topk,np.mean(MAP), topk, np.mean(MRR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
