{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.Develop Env: linux+cuda9+python3+opencv+pytorch+faiss\n",
    "2.Dataset: Fundus-iSee with 10000 images(AMD-720, DR-270, glaucoma-450,myopia-790,norm-7770)\n",
    "        trainset(9000): AMD-648, DR-243, glaucoma-405, myopia-711, norm-6993(699), \n",
    "        testset(1000): AMD-72, DR-27, glaucoma-45, myopia-79, norm=777(77)\n",
    "3.Performance Metric: \n",
    "  1)MHR(Mean Hit Ratio):  for evaluating the precison of relevance retrieval;\n",
    "  2)MAP(Mean Average Precision): for evaluation the rank of relevance retrieval;\n",
    "  3)MRR(Mean Reciprocal Rank): for evaluation the first hit rank of relevance retrieval;\n",
    "  4)Memory consumption and Retrieval Speed.\n",
    "4.Algorithm: \n",
    "  1)Baseline: CNN-FCL,CNN-HL\n",
    "  2)Attention: CNN-AH(AHNet)\n",
    "  3)effectiveness: CNN-FCL<CNN-HL<CNN-AH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from scipy.spatial.distance import pdist\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "#import faiss\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.cuda.set_device(6)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2706 / 9000 The length of train set is 2706\n",
      "300 / 1000 The length of test set is 300\n",
      "Completed buliding index in 252 seconds\n"
     ]
    }
   ],
   "source": [
    "#1. Read data with List storage Data:[name,type],I:[img],Y[type]\n",
    "def TypetoNum(itype): #map the type into number.\n",
    "    if itype =='AMD': return 0\n",
    "    elif itype =='DR': return 1\n",
    "    elif itype =='glaucoma': return 2\n",
    "    elif itype =='myopia': return 3\n",
    "    else: return 4 #norm\n",
    "    \n",
    "root_dir = '/data/fjsdata/fundus/iSee/iSee_multi_dataset/' #the path of images\n",
    "trainset = pd.read_csv(\"/data/fjsdata/fundus/iSee/iSee_multi_dataset/CBIR_iSee_train.csv\" , sep=',')#load trainset\n",
    "testset = pd.read_csv(\"/data/fjsdata/fundus/iSee/iSee_multi_dataset/CBIR_iSee_test.csv\" , sep=',')#load testset\n",
    "tstart = time.time()\n",
    "#read train image with CV\n",
    "trData, trI, trY = [],[],[]\n",
    "norm = 699\n",
    "for iname, itype in np.array(trainset).tolist():\n",
    "    if iname.endswith(\".jpg\"):\n",
    "        try:\n",
    "            image_dir = root_dir+'img_data_%s'%itype\n",
    "            image_path = os.path.join(image_dir, iname)\n",
    "            if itype == 'norm':\n",
    "                if norm>0:\n",
    "                    img = cv2.resize(cv2.imread(image_path).astype(np.float32), (1024, 1024))#(1920,1920,3)->(1024,1024,3)\n",
    "                    trData.append([iname,itype])\n",
    "                    trI.append(img)\n",
    "                    trY.append(TypetoNum(itype))\n",
    "                    norm = norm - 1\n",
    "            else:\n",
    "                img = cv2.resize(cv2.imread(image_path).astype(np.float32), (1024, 1024))#(1920,1920,3)->(1024,1024,3)\n",
    "                trData.append([iname,itype,img])\n",
    "                trI.append(img)\n",
    "                trY.append(TypetoNum(itype))    \n",
    "        except:\n",
    "            print(iname+\":\"+str(image_path))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(trData),trainset.shape[0]))\n",
    "        sys.stdout.flush()\n",
    "print('The length of train set is %d'%len(trData))\n",
    "#read test image with CV\n",
    "teData, teI, teY = [],[],[]\n",
    "norm = 77\n",
    "for iname, itype in np.array(testset).tolist():\n",
    "    if iname.endswith(\".jpg\"):\n",
    "        try:\n",
    "            image_dir = root_dir+'img_data_%s'%itype\n",
    "            image_path = os.path.join(image_dir, iname)\n",
    "            if itype == 'norm':\n",
    "                if norm>0:\n",
    "                    img = cv2.resize(cv2.imread(image_path).astype(np.float32), (1024, 1024))#(1920,1920,3)->(1024,1024,3)\n",
    "                    teData.append([iname,itype])\n",
    "                    teI.append(img)\n",
    "                    teY.append(TypetoNum(itype))\n",
    "                    norm = norm - 1\n",
    "            else:\n",
    "                img = cv2.resize(cv2.imread(image_path).astype(np.float32), (1024, 1024))#(1920,1920,3)->(1024,1024,3)\n",
    "                teData.append([iname,itype,img])\n",
    "                teI.append(img)\n",
    "                teY.append(TypetoNum(itype)) \n",
    "        except:\n",
    "            print(iname+\":\"+str(image_path))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(teData),testset.shape[0]))\n",
    "        sys.stdout.flush()\n",
    "print('The length of test set is %d'%len(teData))\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.995450973510742\n",
      "conv1.weight\n",
      "tensor([ 0.0754,  0.1585,  0.0313])\n",
      "15.436433792114258\n",
      "conv1.weight\n",
      "tensor([ 0.0747,  0.1588,  0.0313])\n",
      "12.814181327819824\n",
      "conv1.weight\n",
      "tensor([ 0.0738,  0.1594,  0.0310])\n",
      "10.03760051727295\n",
      "conv1.weight\n",
      "tensor([ 0.0729,  0.1601,  0.0305])\n",
      "8.423099517822266\n",
      "conv1.weight\n",
      "tensor([ 0.0720,  0.1605,  0.0306])\n",
      "7.161287307739258\n",
      "conv1.weight\n",
      "tensor([ 0.0712,  0.1606,  0.0309])\n",
      "5.6336798667907715\n",
      "conv1.weight\n",
      "tensor([ 0.0703,  0.1606,  0.0314])\n",
      "4.115677833557129\n",
      "conv1.weight\n",
      "tensor([ 0.0693,  0.1608,  0.0320])\n",
      "3.4611454010009766\n",
      "conv1.weight\n",
      "tensor([ 0.0686,  0.1606,  0.0326])\n",
      "2.7435686588287354\n",
      "conv1.weight\n",
      "tensor([ 0.0680,  0.1604,  0.0331])\n",
      "tensor([[ 0.0691,  0.1754, -0.4687,  0.0312,  0.1165,  0.0399,  0.2555,\n",
      "          0.3013, -0.2165,  0.2874,  0.1823,  0.3269,  0.2370,  0.1615,\n",
      "         -0.1863, -0.0795],\n",
      "        [ 0.4347, -0.0392,  0.4377,  0.0435, -0.3726, -0.2297, -0.3650,\n",
      "         -0.4303,  0.2160, -0.0966, -0.2228, -0.1138,  0.0160, -0.2974,\n",
      "          0.0950,  0.2769],\n",
      "        [-0.2671, -0.3063,  0.0971, -0.0121,  0.2303,  0.1494,  0.1219,\n",
      "         -0.0761,  0.1155, -0.3093, -0.1471, -0.0016, -0.2618, -0.1603,\n",
      "         -0.1527, -0.0538],\n",
      "        [ 0.2458,  0.1842, -0.5571, -0.2820,  0.1476,  0.2987,  0.2158,\n",
      "          0.3901, -0.2384,  0.2254,  0.0996,  0.4106,  0.1313,  0.1423,\n",
      "         -0.2654, -0.0368],\n",
      "        [-0.1376, -0.2070,  0.4031,  0.2834,  0.0588, -0.2015, -0.1298,\n",
      "         -0.4792,  0.3603, -0.4096, -0.2660, -0.2614, -0.1393, -0.3985,\n",
      "          0.0058,  0.4116],\n",
      "        [-0.1220, -0.2029, -0.0335,  0.2742,  0.3752,  0.0463,  0.0879,\n",
      "          0.0728, -0.1356, -0.2083,  0.0281, -0.0717, -0.1032,  0.0885,\n",
      "          0.0216, -0.0536],\n",
      "        [ 0.1533,  0.2566,  0.0678,  0.1039,  0.0489,  0.0972,  0.0928,\n",
      "         -0.0122,  0.0379,  0.0029, -0.1594,  0.0128,  0.1631, -0.0925,\n",
      "          0.0925,  0.0027],\n",
      "        [-0.0225, -0.1380,  0.1541,  0.4162,  0.1379,  0.1394,  0.0127,\n",
      "         -0.1130,  0.1641, -0.4508, -0.0988, -0.0879, -0.3200, -0.2010,\n",
      "         -0.1158,  0.3957],\n",
      "        [-0.0107, -0.2638, -0.1932, -0.1961,  0.1283, -0.0267, -0.0749,\n",
      "          0.2154, -0.4613,  0.1646,  0.1121, -0.1085, -0.2497,  0.1426,\n",
      "         -0.3724, -0.2751],\n",
      "        [-0.0508, -0.2545,  0.4417,  0.4580,  0.0509,  0.0151, -0.0595,\n",
      "         -0.0172,  0.3302, -0.5491, -0.0940, -0.3362, -0.4559, -0.3628,\n",
      "         -0.1173,  0.1459]])\n",
      "tensor([[ 1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
      "          1.,  1., -1., -1.],\n",
      "        [ 1., -1.,  1.,  1., -1., -1., -1., -1.,  1., -1., -1., -1.,\n",
      "          1., -1.,  1.,  1.],\n",
      "        [-1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,\n",
      "         -1., -1., -1., -1.],\n",
      "        [ 1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
      "          1.,  1., -1., -1.],\n",
      "        [-1., -1.,  1.,  1.,  1., -1., -1., -1.,  1., -1., -1., -1.,\n",
      "         -1., -1.,  1.,  1.],\n",
      "        [-1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1., -1.,\n",
      "         -1.,  1.,  1., -1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1.,\n",
      "          1., -1.,  1.,  1.],\n",
      "        [-1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,\n",
      "         -1., -1., -1.,  1.],\n",
      "        [-1., -1., -1., -1.,  1., -1., -1.,  1., -1.,  1.,  1., -1.,\n",
      "         -1.,  1., -1., -1.],\n",
      "        [-1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1., -1., -1., -1.,\n",
      "         -1., -1., -1.,  1.]])\n",
      "torch.Size([10, 16])\n"
     ]
    }
   ],
   "source": [
    "#2. define Attention-based Hashing network with pytorch\n",
    "class CNN_HL_Net(nn.Module): #deep Hashint Network:DHNet\n",
    "    def __init__(self,inChannels=3):\n",
    "        super(CNN_HL_Net, self).__init__()\n",
    "        #(channels, Height, Width)\n",
    "        #layer1: Convolution, (3,1024,1024)->(16,512,512)\n",
    "        self.conv1 = nn.Conv2d(in_channels=inChannels, out_channels=16, kernel_size=3, padding=1, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        #layer2: max pooling,(16,512,512)->(16,256,256)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, padding=1, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        #layer3: Convolution, (16,256,256)->(8,128,128)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3, padding=1, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(8)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        #layer4: mean pooling, (8,128,128)->(8,64,64)\n",
    "        self.avgpool1 = nn.AvgPool2d(kernel_size=3, padding=1, stride=2)\n",
    "        self.bn4 = nn.BatchNorm2d(8)\n",
    "        #layer5: Convolution, (8,64,64)->(4,32,32)\n",
    "        self.conv3 = nn.Conv2d(in_channels=8, out_channels=4, kernel_size=3, padding=1, stride=2)\n",
    "        self.bn5 = nn.BatchNorm2d(4)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        #layer6: mean pooling, (4,32,32)->(4,16,16)\n",
    "        self.avgpool2 = nn.AvgPool2d(kernel_size=3, padding=1, stride=2)\n",
    "        self.bn6 = nn.BatchNorm2d(4)\n",
    "        #layer7: fully connected, 4*16*16->512\n",
    "        self.fcl1 = nn.Linear(4*16*16,512)\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "        #layer8: Hashing layer, 512->16\n",
    "        self.fcl2 = nn.Linear(512,16)#\n",
    "        self.tanh = nn.Tanh() #{-1,1}\n",
    "              \n",
    "    def forward(self,x):\n",
    "        #input: (batch_size, in_channels, Height, Width)\n",
    "        #output: (batch_size, out_channels, Height, Width)\n",
    "        #layer1: convolution\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        #layer2: max pooling\n",
    "        x = self.maxpool(x)\n",
    "        x = self.bn2(x)\n",
    "        #layer3: Convolution\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu2(x)\n",
    "        #layer4: mean pooling\n",
    "        x = self.avgpool1(x)\n",
    "        x = self.bn4(x)\n",
    "        #layer5: Convolution\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu3(x)\n",
    "        #layer6: mean pooling\n",
    "        x = self.avgpool2(x)\n",
    "        x = self.bn6(x)\n",
    "        #layer7:fully connected\n",
    "        x = x.view(x.size(0),-1) #transfer three dims to one dim\n",
    "        x = self.fcl1(x)\n",
    "        x = self.relu4(x)\n",
    "        #layer8: Hashing layer\n",
    "        x = self.fcl2(x)\n",
    "        x = self.tanh(x)\n",
    "                \n",
    "        return x\n",
    "    \n",
    "#https://pytorch-cn.readthedocs.io/zh/latest/    \n",
    "#https://github.com/filipradenovic/cnnimageretrieval-pytorch/blob/master/cirtorch/layers/functional.py\n",
    "class HashLossFunc(nn.Module):\n",
    "    def __init__(self, margin=0.5, alpha=0.01):\n",
    "        super(HashLossFunc, self).__init__()\n",
    "        self.alpha = alpha #regularization\n",
    "        self.margin = margin #margin threshold\n",
    "    \n",
    "    def forward(self,h1,h2,y): \n",
    "        #h1=h2:NxD,y:N\n",
    "        dim = h1.shape[1]\n",
    "        euc_dist = F.pairwise_distance(h1, h2, p=2, eps=1e-06) # Calcualte Euclidean Distance\n",
    "        sim_term = 0.5*(1-y)*euc_dist #penalize the similar iamge pairs when y=0\n",
    "        unsim_term = 0.5*y*torch.clamp(self.margin*dim-euc_dist,0)#penalize the unsimlar image pairs when y =1\n",
    "        reg_term = self.alpha * ( torch.sum((torch.abs(h1)-1),dim=1) + torch.sum((torch.abs(h2)-1),dim=1) ) #regularization term\n",
    "        #loss = torch.mean(sim_term + unsim_term + reg_term) \n",
    "        loss = torch.sum(sim_term + unsim_term+ reg_term) \n",
    "        return loss\n",
    "\n",
    "#test network: valid\n",
    "x1 = torch.rand(10,3,1024,1024)#.cuda()\n",
    "x2 = torch.rand(10,3,1024,1024)#.cuda()\n",
    "y = torch.FloatTensor([0,1,1,0,1,0,0,0,1,1])#.cuda()\n",
    "model = CNN_HL_Net()#.cuda()\n",
    "criterion  = HashLossFunc(margin=0.5)#.cuda() #define loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    out1 = model(x1)#out.grad_fn\n",
    "    out2 = model(x2)\n",
    "    loss = criterion(out1,out2,y)\n",
    "    print (loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #observe the variant of model.parameters\n",
    "    for i in model.named_parameters():\n",
    "        print(i[0])\n",
    "        print(i[1][0][0][0])\n",
    "        break\n",
    "#output\n",
    "x3 = torch.rand(10,3,1024,1024)#.cuda()\n",
    "out3 = model(x3)\n",
    "print (out3)\n",
    "out3 = torch.sign(out3) #Binarization,[-1,1]->{-1,1}\n",
    "print (out3)\n",
    "print (out3.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 541 / 542 : loss = 11.488976mean_loss = 17.248382\n",
      " 29 / 30 1 mHR@5=0.228000, mAP@5=0.223478, mRR@5=0.927273\n",
      "mHR@10=0.224667, mAP@10=0.209224, mRR@10=0.768060\n",
      "mHR@15=0.224222, mAP@15=0.199052, mRR@15=0.692135\n",
      "mHR@20=0.221500, mAP@20=0.190360, mRR@20=0.619061\n"
     ]
    }
   ],
   "source": [
    "#3.train and evaluate model\n",
    "def onlineGenImgPairs(batchSize):\n",
    "    idx_sf = random.sample(range(0, len(trY)),2*batchSize)\n",
    "    trI1_sf, trI2_sf, trY1_sf, trY2_sf = [],[],[],[]\n",
    "    flag = 0\n",
    "    for i in idx_sf:\n",
    "        if flag==0:\n",
    "            trI1_sf.append(trI[i])\n",
    "            trY1_sf.append(trY[i])\n",
    "            flag =1\n",
    "        else:\n",
    "            trI2_sf.append(trI[i])\n",
    "            trY2_sf.append(trY[i])\n",
    "            flag =0\n",
    "    trY_sf = np.where((np.array(trY1_sf)-np.array(trY2_sf))!=0,1,0)\n",
    "    return np.array(trI1_sf),np.array(trI2_sf),trY_sf\n",
    "        \n",
    "#define model\n",
    "model = CNN_HL_Net().cuda()\n",
    "criterion  = HashLossFunc(margin=0.5).cuda() #define loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "#train model\n",
    "batchSize = 10\n",
    "epochSize = len(trY)//batchSize+1\n",
    "losses = []\n",
    "for epoch in range(2*epochSize):#iteration\n",
    "    #grad vanish\n",
    "    optimizer.zero_grad() \n",
    "    #genenate training images pair\n",
    "    trI1_sf, trI2_sf, trY_sf = onlineGenImgPairs(batchSize)\n",
    "    I1_batch = torch.from_numpy(trI1_sf).type(torch.FloatTensor).cuda()\n",
    "    I2_batch = torch.from_numpy(trI2_sf).type(torch.FloatTensor).cuda()\n",
    "    Y_batch = torch.from_numpy(trY_sf).type(torch.FloatTensor).cuda()\n",
    "    #forword\n",
    "    X1_batch = model(I1_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "    X2_batch = model(I2_batch.permute(0, 3, 1, 2))\n",
    "    #binary-like loss\n",
    "    loss = criterion(X1_batch,X2_batch,Y_batch)\n",
    "    #backward\n",
    "    loss.backward()\n",
    "    #update parameters\n",
    "    optimizer.step()\n",
    "    #show loss\n",
    "    sys.stdout.write('\\r {} / {} : loss = {}'.format(epoch, 2*epochSize, float('%0.6f'%loss.item())))\n",
    "    sys.stdout.flush()     \n",
    "    losses.append(loss.item())\n",
    "print(\"mean_loss = %.6f\" % (np.mean(losses)))\n",
    "\n",
    "#release gpu memory\n",
    "#model = model.cpu()\n",
    "#torch.cuda.empty_cache()\n",
    "#hash code of train data from model\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize+1\n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch = torch.sign(model(I_batch.permute(0, 3, 1, 2)))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#hash code of test data from model\n",
    "teF = []\n",
    "num_batches = len(teI) // batchSize\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(teI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch = torch.sign(model(I_batch.permute(0, 3, 1, 2)))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    teF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#train data with list: trData, trI, trF, trY\n",
    "#test data with list: teData, teI, teF, teY\n",
    "for topk in [5,10,15,20]:\n",
    "    MHR = [] #mean Hit ratio \n",
    "    MAP = [] #mean average precision\n",
    "    MRR = [] #mean reciprocal rank\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        map_item_score = {}\n",
    "        for j, trVal in enumerate(trF):\n",
    "            map_item_score[j] = pdist(np.vstack([teVal,trVal]),'hamming')\n",
    "        ranklist = heapq.nsmallest(topk, map_item_score, key=map_item_score.get)\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        mrr_flag = 0\n",
    "        for j in ranklist:\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                MHR.append(1)\n",
    "                pos_len = pos_len +1\n",
    "                MAP.append(pos_len/rank_len) \n",
    "                if mrr_flag==0: \n",
    "                    MRR.append(pos_len/rank_len)\n",
    "                    mrr_flag =1\n",
    "            else: \n",
    "                MHR.append(0)\n",
    "                MAP.append(0)   \n",
    "    print(\"mHR@{}={:.6f}, mAP@{}={:.6f}, mRR@{}={:.6f}\".format(topk,np.mean(MHR),topk,np.mean(MAP), topk, np.mean(MRR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
