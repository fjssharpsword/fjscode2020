{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.Develop Env: linux+cuda9+python3+opencv+pytorch+faiss\n",
    "2.Dataset: Fundus-iSee with 10000 images(AMD-720, DR-270, glaucoma-450,myopia-790,norm-7770)\n",
    "        trainset(9000): AMD-648, DR-243, glaucoma-405, myopia-711, norm-6993(699), \n",
    "        testset(1000): AMD-72, DR-27, glaucoma-45, myopia-79, norm=777(77)\n",
    "3.Performance Metric: \n",
    "  1)MHR(Mean Hit Ratio):  for evaluating the precison of relevance retrieval;\n",
    "  2)MAP(Mean Average Precision): for evaluation the rank of relevance retrieval;\n",
    "  3)MRR(Mean Reciprocal Rank): for evaluation the first hit rank of relevance retrieval;\n",
    "  4)Memory consumption and Retrieval Speed.\n",
    "4.Algorithm: \n",
    "  1)Baseline: CNN-FCL,CNN-HL\n",
    "  2)Attention: CNN-AH(AHNet)\n",
    "  3)effectiveness: CNN-FCL<CNN-HL<CNN-AH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from scipy.spatial.distance import pdist\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "#import faiss\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.cuda.set_device(5)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2706 / 9000 The length of train set is 2706\n",
      "300 / 1000 The length of test set is 300\n",
      "Completed buliding index in 220 seconds\n"
     ]
    }
   ],
   "source": [
    "#1. Read data with List storage Data:[name,type],I:[img],Y[type]\n",
    "def TypetoNum(itype): #map the type into number.\n",
    "    if itype =='AMD': return 0\n",
    "    elif itype =='DR': return 1\n",
    "    elif itype =='glaucoma': return 2\n",
    "    elif itype =='myopia': return 3\n",
    "    else: return 4 #norm\n",
    "    \n",
    "root_dir = '/data/fjsdata/fundus/iSee/iSee_multi_dataset/' #the path of images\n",
    "trainset = pd.read_csv(\"/data/fjsdata/fundus/iSee/iSee_multi_dataset/CBIR_iSee_train.csv\" , sep=',')#load trainset\n",
    "testset = pd.read_csv(\"/data/fjsdata/fundus/iSee/iSee_multi_dataset/CBIR_iSee_test.csv\" , sep=',')#load testset\n",
    "tstart = time.time()\n",
    "#read train image with CV\n",
    "trData, trI, trY = [],[],[]\n",
    "norm = 699\n",
    "for iname, itype in np.array(trainset).tolist():\n",
    "    if iname.endswith(\".jpg\"):\n",
    "        try:\n",
    "            image_dir = root_dir+'img_data_%s'%itype\n",
    "            image_path = os.path.join(image_dir, iname)\n",
    "            if itype == 'norm':\n",
    "                if norm>0:\n",
    "                    img = cv2.resize(cv2.imread(image_path).astype(np.float32), (1024, 1024))#(1920,1920,3)->(1024,1024,3)\n",
    "                    trData.append([iname,itype])\n",
    "                    trI.append(img)\n",
    "                    trY.append(TypetoNum(itype))\n",
    "                    norm = norm - 1\n",
    "            else:\n",
    "                img = cv2.resize(cv2.imread(image_path).astype(np.float32), (1024, 1024))#(1920,1920,3)->(1024,1024,3)\n",
    "                trData.append([iname,itype,img])\n",
    "                trI.append(img)\n",
    "                trY.append(TypetoNum(itype))    \n",
    "        except:\n",
    "            print(iname+\":\"+str(image_path))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(trData),trainset.shape[0]))\n",
    "        sys.stdout.flush()\n",
    "print('The length of train set is %d'%len(trData))\n",
    "#read test image with CV\n",
    "teData, teI, teY = [],[],[]\n",
    "norm = 77\n",
    "for iname, itype in np.array(testset).tolist():\n",
    "    if iname.endswith(\".jpg\"):\n",
    "        try:\n",
    "            image_dir = root_dir+'img_data_%s'%itype\n",
    "            image_path = os.path.join(image_dir, iname)\n",
    "            if itype == 'norm':\n",
    "                if norm>0:\n",
    "                    img = cv2.resize(cv2.imread(image_path).astype(np.float32), (1024, 1024))#(1920,1920,3)->(1024,1024,3)\n",
    "                    teData.append([iname,itype])\n",
    "                    teI.append(img)\n",
    "                    teY.append(TypetoNum(itype))\n",
    "                    norm = norm - 1\n",
    "            else:\n",
    "                img = cv2.resize(cv2.imread(image_path).astype(np.float32), (1024, 1024))#(1920,1920,3)->(1024,1024,3)\n",
    "                teData.append([iname,itype,img])\n",
    "                teI.append(img)\n",
    "                teY.append(TypetoNum(itype)) \n",
    "        except:\n",
    "            print(iname+\":\"+str(image_path))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(teData),testset.shape[0]))\n",
    "        sys.stdout.flush()\n",
    "print('The length of test set is %d'%len(teData))\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:80: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.597808599472046\n",
      "conv1.weight\n",
      "tensor([-0.1370,  0.0693,  0.0283])\n",
      "1.0785161256790161\n",
      "conv1.weight\n",
      "tensor([-0.1373,  0.0698,  0.0279])\n",
      "0.7979228496551514\n",
      "conv1.weight\n",
      "tensor([-0.1372,  0.0705,  0.0274])\n",
      "0.6365795135498047\n",
      "conv1.weight\n",
      "tensor([-0.1370,  0.0707,  0.0268])\n",
      "0.5375972390174866\n",
      "conv1.weight\n",
      "tensor([-0.1369,  0.0708,  0.0261])\n",
      "0.4756961762905121\n",
      "conv1.weight\n",
      "tensor([-0.1368,  0.0707,  0.0255])\n",
      "0.4359434247016907\n",
      "conv1.weight\n",
      "tensor([-0.1367,  0.0705,  0.0249])\n",
      "0.40972647070884705\n",
      "conv1.weight\n",
      "tensor([-0.1366,  0.0703,  0.0243])\n",
      "0.39210301637649536\n",
      "conv1.weight\n",
      "tensor([-0.1365,  0.0700,  0.0238])\n",
      "0.37974879145622253\n",
      "conv1.weight\n",
      "tensor([-0.1365,  0.0697,  0.0233])\n",
      "tensor([[ 0.0126, -0.4354,  0.7358, -0.3279,  0.0964, -0.1032,  0.0251,\n",
      "          0.0671, -0.3541,  0.1048, -0.2245, -0.0713,  0.0981, -0.3019,\n",
      "         -0.0763, -0.3924],\n",
      "        [-0.2796, -0.4190,  0.6042, -0.1088,  0.2098, -0.0519, -0.1614,\n",
      "         -0.2900, -0.5231,  0.6286, -0.5180, -0.5717, -0.1499, -0.0641,\n",
      "         -0.2040, -0.2051],\n",
      "        [-0.3552, -0.6642,  0.6478, -0.0942,  0.3250,  0.0988, -0.1476,\n",
      "         -0.2584, -0.1124,  0.3132, -0.5809, -0.2650,  0.3680, -0.6628,\n",
      "         -0.1631, -0.0010],\n",
      "        [ 0.5833, -0.1066,  0.4511, -0.3111,  0.0538, -0.3561, -0.2830,\n",
      "         -0.5321, -0.3872,  0.6228, -0.2672, -0.4205, -0.2053,  0.5105,\n",
      "         -0.2763, -0.0691],\n",
      "        [-0.0379, -0.2094,  0.4713, -0.0013,  0.2720, -0.3556,  0.0795,\n",
      "         -0.0534, -0.0985,  0.2867, -0.2555, -0.0439,  0.1377, -0.3558,\n",
      "         -0.4235,  0.2471],\n",
      "        [ 0.4115, -0.1686,  0.3313,  0.0857, -0.1116, -0.3676, -0.0543,\n",
      "          0.2222,  0.4960, -0.0238,  0.1978,  0.4767,  0.1434, -0.2598,\n",
      "         -0.1566, -0.3695],\n",
      "        [ 0.2363, -0.5129,  0.3948,  0.2537,  0.2340, -0.0543, -0.0141,\n",
      "          0.3067,  0.5632, -0.0250, -0.2869,  0.2674,  0.3395, -0.0649,\n",
      "          0.0442, -0.5803],\n",
      "        [ 0.4465,  0.3422, -0.0216,  0.0579,  0.0054, -0.7552,  0.0600,\n",
      "          0.0594,  0.3528,  0.2613,  0.0207,  0.4569,  0.6297, -0.4662,\n",
      "         -0.7167,  0.2272],\n",
      "        [-0.3499, -0.4729,  0.6180,  0.4714, -0.0566, -0.0809, -0.3741,\n",
      "          0.0748, -0.3641,  0.5802, -0.2637, -0.0513,  0.1439, -0.5016,\n",
      "          0.0724, -0.1476],\n",
      "        [ 0.3509, -0.1694,  0.3861,  0.2594, -0.1662, -0.4163, -0.0885,\n",
      "          0.3407,  0.6411, -0.0377, -0.2181,  0.4241,  0.6128, -0.3431,\n",
      "         -0.2390, -0.0309]])\n",
      "torch.Size([10, 16])\n"
     ]
    }
   ],
   "source": [
    "#2. define CNN network with pytorch\n",
    "class CNN_FCL_Net(nn.Module): \n",
    "    def __init__(self,inChannels=3):\n",
    "        super(CNN_FCL_Net, self).__init__()\n",
    "        #(channels, Height, Width)\n",
    "        #layer1: Convolution, (3,1024,1024)->(16,512,512)\n",
    "        self.conv1 = nn.Conv2d(in_channels=inChannels, out_channels=16, kernel_size=3, padding=1, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        #layer2: max pooling,(16,512,512)->(16,256,256)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, padding=1, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        #layer3: Convolution, (16,256,256)->(8,128,128)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3, padding=1, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(8)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        #layer4: mean pooling, (8,128,128)->(8,64,64)\n",
    "        self.avgpool1 = nn.AvgPool2d(kernel_size=3, padding=1, stride=2)\n",
    "        self.bn4 = nn.BatchNorm2d(8)\n",
    "        #layer5: Convolution, (8,64,64)->(4*32*32)\n",
    "        self.conv3 = nn.Conv2d(in_channels=8, out_channels=4, kernel_size=3, padding=1, stride=2)\n",
    "        self.bn5 = nn.BatchNorm2d(4)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        #layer6: mean pooling, (4,32,32)->(4,16,16)\n",
    "        self.avgpool2 = nn.AvgPool2d(kernel_size=3, padding=1, stride=2)\n",
    "        self.bn6 = nn.BatchNorm2d(4)\n",
    "        #layer7: fully connected, 4*16*16->512\n",
    "        self.fcl1 = nn.Linear(4*16*16,512)\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "        #layer8: Hashing layer, 512->16\n",
    "        self.fcl2 = nn.Linear(512,16)#\n",
    "        self.tanh = nn.Tanh()\n",
    "        #layer9: fully connected, 16->5\n",
    "        self.fcl3 = nn.Linear(16,5)#type:5\n",
    "              \n",
    "    def forward(self,x):\n",
    "        #input: (batch_size, in_channels, Height, Width)\n",
    "        #output: (batch_size, out_channels, Height, Width)\n",
    "        #layer1: convolution\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        #layer2: max pooling\n",
    "        x = self.maxpool(x)\n",
    "        x = self.bn2(x)\n",
    "        #layer3: Convolution\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu2(x)\n",
    "        #layer4: mean pooling\n",
    "        x = self.avgpool1(x)\n",
    "        x = self.bn4(x)\n",
    "        #layer5: Convolution\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu3(x)\n",
    "        #layer6: mean pooling\n",
    "        x = self.avgpool2(x)\n",
    "        x = self.bn6(x)\n",
    "        #layer7:fully connected\n",
    "        x = x.view(x.size(0),-1) #transfer three dims to one dim\n",
    "        x = self.fcl1(x)\n",
    "        x = self.relu4(x)\n",
    "        #layer8: fully connected\n",
    "        x = self.fcl2(x)\n",
    "        x = self.tanh(x)#[-1,1]\n",
    "        #layer9: fully connected\n",
    "        out = self.fcl3(x)\n",
    "                \n",
    "        return x,out\n",
    "#test network: valid\n",
    "x = torch.rand(10,3,1024,1024)\n",
    "y = torch.LongTensor([0,1,2,3,4,3,2,4,0,1])\n",
    "model = CNN_FCL_Net()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    _,out = model(x)\n",
    "    out = F.log_softmax(out)\n",
    "    loss = F.nll_loss(out, y)\n",
    "    print (loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #observe the variant of model.parameters\n",
    "    for i in model.named_parameters():\n",
    "        print(i[0])\n",
    "        print(i[1][0][0][0])\n",
    "        break\n",
    "#output\n",
    "x2 = torch.rand(10,3,1024,1024)#.cuda()\n",
    "x2,_ = model(x2)\n",
    "print (x2)\n",
    "print (x2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 / 271 : loss = 1.238058"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 270 / 271 : loss = 0.666214Eopch:     1 mean_loss = 1.406450\n",
      " 270 / 271 : loss = 0.613051Eopch:     2 mean_loss = 1.731901\n",
      " 29 / 30 1 mHR@5=0.242667, mAP@5=0.241122, mRR@5=0.980856\n",
      "mHR@10=0.241667, mAP@10=0.240656, mRR@10=0.980856\n",
      "mHR@15=0.241111, mAP@15=0.240438, mRR@15=0.980856\n",
      "mHR@20=0.241333, mAP@20=0.240433, mRR@20=0.980856\n"
     ]
    }
   ],
   "source": [
    "#3. Train and evaluate model \n",
    "#define model\n",
    "model = CNN_FCL_Net().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "#train model\n",
    "batchSize = 10\n",
    "num_batches = len(trY) // batchSize+1\n",
    "for epoch in range(2):#iteration\n",
    "    #train model \n",
    "    losses = []\n",
    "    for i in range(num_batches):\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY), (i+1)*batchSize])\n",
    "        I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "        Y_batch = torch.from_numpy(np.array(trY[min_idx: max_idx])).type(torch.LongTensor).cuda()\n",
    "        optimizer.zero_grad()\n",
    "        #forward\n",
    "        _, out = model(I_batch.permute(0, 3, 1, 2))#adjust channel to the second\n",
    "        out = F.log_softmax(out)\n",
    "        loss = F.nll_loss(out, Y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    \n",
    "#release gpu memory\n",
    "#model = model.cpu()\n",
    "#torch.cuda.empty_cache()\n",
    "#hash code of train data from model\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize+1\n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch,_ = model(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#hash code of test data from model\n",
    "teF = []\n",
    "num_batches = len(teI) // batchSize\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(teI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch,_ = model(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    teF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#Evaluate model\n",
    "#train data with list: trData, trI, trF, trY\n",
    "#test data with list: teData, teI, teF, teY\n",
    "for topk in [5,10,15,20]:\n",
    "    MHR = [] #mean Hit ratio \n",
    "    MAP = [] #mean average precision\n",
    "    MRR = [] #mean reciprocal rank\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        map_item_score = {}\n",
    "        for j, trVal in enumerate(trF):\n",
    "            map_item_score[j] = pdist(np.vstack([teVal,trVal]),'cosine')\n",
    "        ranklist = heapq.nsmallest(topk, map_item_score, key=map_item_score.get)\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        mrr_flag = 0\n",
    "        for j in ranklist:\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                MHR.append(1)\n",
    "                pos_len = pos_len +1\n",
    "                MAP.append(pos_len/rank_len) \n",
    "                if mrr_flag==0: \n",
    "                    MRR.append(pos_len/rank_len)\n",
    "                    mrr_flag =1\n",
    "            else: \n",
    "                MHR.append(0)\n",
    "                MAP.append(0)   \n",
    "    print(\"mHR@{}={:.6f}, mAP@{}={:.6f}, mRR@{}={:.6f}\".format(topk,np.mean(MHR),topk,np.mean(MAP), topk, np.mean(MRR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:99: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6286647319793701\n",
      "conv1.weight\n",
      "tensor([ 0.0681,  0.0753, -0.1499])\n",
      "0.9922958612442017\n",
      "conv1.weight\n",
      "tensor([ 0.0688,  0.0762, -0.1497])\n",
      "0.7420358657836914\n",
      "conv1.weight\n",
      "tensor([ 0.0695,  0.0771, -0.1497])\n",
      "0.6227890253067017\n",
      "conv1.weight\n",
      "tensor([ 0.0700,  0.0779, -0.1498])\n",
      "0.5594567060470581\n",
      "conv1.weight\n",
      "tensor([ 0.0702,  0.0786, -0.1500])\n",
      "0.5235650539398193\n",
      "conv1.weight\n",
      "tensor([ 0.0704,  0.0792, -0.1502])\n",
      "0.5012494325637817\n",
      "conv1.weight\n",
      "tensor([ 0.0706,  0.0798, -0.1505])\n",
      "0.4861129820346832\n",
      "conv1.weight\n",
      "tensor([ 0.0707,  0.0802, -0.1507])\n",
      "0.47518372535705566\n",
      "conv1.weight\n",
      "tensor([ 0.0708,  0.0807, -0.1508])\n",
      "0.4666842818260193\n",
      "conv1.weight\n",
      "tensor([ 0.0709,  0.0810, -0.1510])\n",
      "torch.Size([10, 16])\n",
      "tensor([[-0.3691,  0.0007, -0.1708,  0.1649, -0.0504, -0.6654, -0.0322,\n",
      "          0.2987,  0.2620, -0.4826, -0.0104, -0.4075,  0.0734, -0.3656,\n",
      "          0.5830,  0.4572],\n",
      "        [-0.1422,  0.0243, -0.2885,  0.4359, -0.4094, -0.6607, -0.4221,\n",
      "          0.2962,  0.1323,  0.0828, -0.4885, -0.7189,  0.0485, -0.3262,\n",
      "          0.3713,  0.3278],\n",
      "        [-0.5102,  0.1854, -0.7308,  0.6096, -0.2320, -0.9058,  0.3863,\n",
      "          0.8154,  0.4117,  0.3002, -0.5901, -0.9269,  0.2783, -0.5810,\n",
      "          0.3719,  0.8642],\n",
      "        [-0.4316, -0.0706, -0.0529,  0.2203, -0.1128, -0.6502, -0.3648,\n",
      "          0.2813,  0.4348,  0.0395, -0.3088, -0.6489,  0.1809, -0.2234,\n",
      "          0.5483,  0.0241],\n",
      "        [ 0.2030,  0.2374,  0.4482,  0.3356, -0.5738, -0.5677, -0.7090,\n",
      "          0.0976,  0.5088, -0.1887, -0.6404, -0.4308,  0.6271, -0.3961,\n",
      "          0.5170,  0.2783],\n",
      "        [-0.4686, -0.3063, -0.2278,  0.3020,  0.2014, -0.5727, -0.2924,\n",
      "          0.3763,  0.2618, -0.3403, -0.6391, -0.6292,  0.4592,  0.1391,\n",
      "          0.0365,  0.4080],\n",
      "        [-0.4021, -0.0796, -0.0881,  0.2279, -0.1761, -0.5014, -0.2838,\n",
      "          0.1231,  0.3221,  0.0296,  0.0288, -0.4567,  0.4295, -0.0871,\n",
      "          0.3130,  0.3917],\n",
      "        [-0.7076, -0.1716, -0.3579, -0.1650,  0.3112, -0.7572,  0.4037,\n",
      "          0.0068, -0.0846,  0.0145,  0.1374, -0.6381,  0.0691, -0.0106,\n",
      "          0.0838,  0.3129],\n",
      "        [-0.2765,  0.1273,  0.0903,  0.4934,  0.2331, -0.5487, -0.4148,\n",
      "         -0.2757, -0.4141,  0.2653, -0.6074, -0.1939,  0.5412, -0.1348,\n",
      "          0.1514,  0.3096],\n",
      "        [ 0.0059,  0.1098, -0.0841,  0.4845, -0.2912, -0.2337, -0.1591,\n",
      "          0.1304, -0.0908,  0.1974, -0.6235, -0.4886,  0.4495, -0.2764,\n",
      "          0.0375, -0.0433]])\n"
     ]
    }
   ],
   "source": [
    "#3. define Attention-CNN network with pytorch\n",
    "class SpatialAttention(nn.Module):#spatial attention layer\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "class ATT_FCL_Net(nn.Module): \n",
    "    def __init__(self,inChannels=3):\n",
    "        super(ATT_FCL_Net, self).__init__()\n",
    "        #(channels, Height, Width)\n",
    "        #layer1: Convolution, (3,1024,1024)->(16,512,512)\n",
    "        self.conv1 = nn.Conv2d(in_channels=inChannels, out_channels=16, kernel_size=3, padding=1, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        #layer2: max pooling,(16,512,512)->(16,256,256)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, padding=1, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        #layer3: Spatial Attention Layer, (16,256,256)->(16,256,256)\n",
    "        self.sa = SpatialAttention()\n",
    "        #layer4: Convolution, (16,256,256)->(8,128,128)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3, padding=1, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(8)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        #layer5: mean pooling, (8,128,128)->(8,64,64)\n",
    "        self.avgpool1 = nn.AvgPool2d(kernel_size=3, padding=1, stride=2)\n",
    "        self.bn4 = nn.BatchNorm2d(8)\n",
    "        #layer6: Convolution, (8,64,64)->(4*32*32)\n",
    "        self.conv3 = nn.Conv2d(in_channels=8, out_channels=4, kernel_size=3, padding=1, stride=2)\n",
    "        self.bn5 = nn.BatchNorm2d(4)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        #layer7: mean pooling, (4,32,32)->(4,16,16)\n",
    "        self.avgpool2 = nn.AvgPool2d(kernel_size=3, padding=1, stride=2)\n",
    "        self.bn6 = nn.BatchNorm2d(4)\n",
    "        #layer8: fully connected, 4*16*16->512\n",
    "        self.fcl1 = nn.Linear(4*16*16,512)\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "        #layer9: Hashing layer, 512->16\n",
    "        self.fcl2 = nn.Linear(512,16)#\n",
    "        self.tanh = nn.Tanh()\n",
    "        #layer10: fully connected, 16->5\n",
    "        self.fcl3 = nn.Linear(16,5)#type:5\n",
    "              \n",
    "    def forward(self,x):\n",
    "        #input: (batch_size, in_channels, Height, Width)\n",
    "        #output: (batch_size, out_channels, Height, Width)\n",
    "        #layer1: convolution\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        #layer2: max pooling\n",
    "        x = self.maxpool(x)\n",
    "        x = self.bn2(x)\n",
    "        #layer3: Spatial Attention\n",
    "        x = self.sa(x)*x\n",
    "        #layer4: Convolution\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu2(x)\n",
    "        #layer5: mean pooling\n",
    "        x = self.avgpool1(x)\n",
    "        x = self.bn4(x)\n",
    "        #layer6: Convolution\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu3(x)\n",
    "        #layer7: mean pooling\n",
    "        x = self.avgpool2(x)\n",
    "        x = self.bn6(x)\n",
    "        #layer7:fully connected\n",
    "        x = x.view(x.size(0),-1) #transfer three dims to one dim\n",
    "        x = self.fcl1(x)\n",
    "        x = self.relu4(x)\n",
    "        #layer8: fully connected\n",
    "        x = self.fcl2(x)\n",
    "        x = self.tanh(x)#[-1,1]\n",
    "        #layer9: fully connected\n",
    "        out = self.fcl3(x)\n",
    "                \n",
    "        return x,out\n",
    "    \n",
    "#test network: valid\n",
    "x = torch.rand(10,3,1024,1024)\n",
    "y = torch.LongTensor([0,1,2,3,4,3,2,4,0,1])\n",
    "model = ATT_FCL_Net()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    _,out = model(x)\n",
    "    out = F.log_softmax(out)\n",
    "    loss = F.nll_loss(out, y)\n",
    "    print (loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #observe the variant of model.parameters\n",
    "    for i in model.named_parameters():\n",
    "        print(i[0])\n",
    "        print(i[1][0][0][0])\n",
    "        break\n",
    "#output\n",
    "x2 = torch.rand(10,3,1024,1024)#.cuda()\n",
    "x2,_ = model(x2)\n",
    "print (x2.size())\n",
    "print (x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 / 271 : loss = 0.945197"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 270 / 271 : loss = 1.491649Eopch:     1 mean_loss = 2.066111\n",
      " 270 / 271 : loss = 0.721831Eopch:     2 mean_loss = 1.548523\n",
      " 29 / 30 1 mHR@5=0.244000, mAP@5=0.242489, mRR@5=0.970175\n",
      "mHR@10=0.246000, mAP@10=0.242817, mRR@10=0.948962\n",
      "mHR@15=0.246889, mAP@15=0.243340, mRR@15=0.948962\n",
      "mHR@20=0.246167, mAP@20=0.242868, mRR@20=0.948962\n"
     ]
    }
   ],
   "source": [
    "#4.train and evaluate model\n",
    "#define model\n",
    "model = ATT_FCL_Net().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "#train model\n",
    "batchSize = 10\n",
    "num_batches = len(trY) // batchSize+1\n",
    "for epoch in range(2):#iteration\n",
    "    #train model \n",
    "    losses = []\n",
    "    for i in range(num_batches):\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY), (i+1)*batchSize])\n",
    "        I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "        Y_batch = torch.from_numpy(np.array(trY[min_idx: max_idx])).type(torch.LongTensor).cuda()\n",
    "        optimizer.zero_grad()\n",
    "        #forward\n",
    "        _, out = model(I_batch.permute(0, 3, 1, 2))#adjust channel to the second\n",
    "        out = F.log_softmax(out)\n",
    "        loss = F.nll_loss(out, Y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "#release gpu memory\n",
    "#model = model.cpu()\n",
    "#torch.cuda.empty_cache()\n",
    "#hash code of train data from model\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize+1\n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch,_ = model(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#hash code of test data from model\n",
    "teF = []\n",
    "num_batches = len(teI) // batchSize\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(teI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch,_ = model(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    teF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "#train data with list: trData, trI, trF, trY\n",
    "#test data with list: teData, teI, teF, teY\n",
    "for topk in [5,10,15,20]:\n",
    "    MHR = [] #mean Hit ratio \n",
    "    MAP = [] #mean average precision\n",
    "    MRR = [] #mean reciprocal rank\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        map_item_score = {}\n",
    "        for j, trVal in enumerate(trF):\n",
    "            map_item_score[j] = pdist(np.vstack([teVal,trVal]),'cosine')\n",
    "        ranklist = heapq.nsmallest(topk, map_item_score, key=map_item_score.get)\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        mrr_flag = 0\n",
    "        for j in ranklist:\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                MHR.append(1)\n",
    "                pos_len = pos_len +1\n",
    "                MAP.append(pos_len/rank_len) \n",
    "                if mrr_flag==0: \n",
    "                    MRR.append(pos_len/rank_len)\n",
    "                    mrr_flag =1\n",
    "            else: \n",
    "                MHR.append(0)\n",
    "                MAP.append(0)   \n",
    "    print(\"mHR@{}={:.6f}, mAP@{}={:.6f}, mRR@{}={:.6f}\".format(topk,np.mean(MHR),topk,np.mean(MAP), topk, np.mean(MRR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
