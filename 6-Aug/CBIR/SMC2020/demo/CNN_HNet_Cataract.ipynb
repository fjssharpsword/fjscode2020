{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.Develop Env: linux+cuda9+python3+opencv+pytorch\n",
    "2.Dataset: ASOCT-Cataract with 32560 images, Dataset Statistics: \n",
    "        1)OD:oculus dextrus, OS: oculus sinister\n",
    "           OD    18901\n",
    "           OS    13659\n",
    "        2)Structure: N, C, P\n",
    "           N-Level: 1.0-6.0\n",
    "           C-Level: 1.0-5.0 if C=0.0(562) denotes this sample with no label \n",
    "           P-Level: 1.0-6.0 if C=0.0(7354) denotes this sample with no label\n",
    "        3)train set and test set: mean distribution of id\n",
    "           train set: (29297, 6)\n",
    "           test set: (3255, 6)\n",
    "3.Performance Metric: \n",
    "  1)MHR(Mean Hit Ratio):  for evaluating the precison of relevance retrieval;\n",
    "  2)MAP(Mean Average Precision): for evaluation the rank of relevance retrieval;\n",
    "  3)MRR(Mean Reciprocal Rank): for evaluation the first hit rank of relevance retrieval;\n",
    "  4)Memory consumption and Retrieval Speed.\n",
    "4.Algorithm: \n",
    "  1)Baseline: HNet\n",
    "  2)Attention: AHNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from scipy.spatial.distance import pdist\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "#import faiss\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.cuda.set_device(5)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1349 / 29304 C020_20180514_100234_R_CASIA2_LGC_010.jpg:/data/fjsdata/ASOCT/Cataract/C_8bit_Crop_New/C020_20180514_100234_R_CASIA2_LGC_010.jpg\n",
      "11175 / 29304 C020_20180514_100234_R_CASIA2_LGC_008.jpg:/data/fjsdata/ASOCT/Cataract/C_8bit_Crop_New/C020_20180514_100234_R_CASIA2_LGC_008.jpg\n",
      "11426 / 29304 C020_20180514_100234_R_CASIA2_LGC_002.jpg:/data/fjsdata/ASOCT/Cataract/C_8bit_Crop_New/C020_20180514_100234_R_CASIA2_LGC_002.jpg\n",
      "17059 / 29304 C020_20180514_100234_R_CASIA2_LGC_004.jpg:/data/fjsdata/ASOCT/Cataract/C_8bit_Crop_New/C020_20180514_100234_R_CASIA2_LGC_004.jpg\n",
      "19051 / 29304 C020_20180514_100234_R_CASIA2_LGC_000.jpg:/data/fjsdata/ASOCT/Cataract/C_8bit_Crop_New/C020_20180514_100234_R_CASIA2_LGC_000.jpg\n",
      "19279 / 29304 C020_20180514_100234_R_CASIA2_LGC_016.jpg:/data/fjsdata/ASOCT/Cataract/C_8bit_Crop_New/C020_20180514_100234_R_CASIA2_LGC_016.jpg\n",
      "22192 / 29304 c0151_20181119_110748_L_CASIA2_LGC_030.jpg:/data/fjsdata/ASOCT/Cataract/C_8bit_Crop_New/c0151_20181119_110748_L_CASIA2_LGC_030.jpg\n",
      "29297 / 29304 The length of train set is 29297\n",
      "2365 / 3256 C020_20180514_100234_R_CASIA2_LGC_032.jpg:/data/fjsdata/ASOCT/Cataract/C_8bit_Crop_New/C020_20180514_100234_R_CASIA2_LGC_032.jpg\n",
      "3255 / 3256 The length of train set is 3255\n"
     ]
    }
   ],
   "source": [
    "#1. Read data with List storage Data:[name],I:[img],Y[type]\n",
    "image_dir = '/data/fjsdata/ASOCT/Cataract/C_8bit_Crop_New' #the path of images\n",
    "trainset = pd.read_csv(\"/data/fjsdata/ASOCT/Cataract/CBIR_Cataract_ncp_train.csv\" , sep=',')#load dataset\n",
    "#print('The length of test set is %d'%trainset.shape[0])\n",
    "testset = pd.read_csv(\"/data/fjsdata/ASOCT/Cataract/CBIR_Cataract_ncp_test.csv\" , sep=',')#load testset\n",
    "#print('The length of test set is %d'%testset.shape[0])\n",
    "\n",
    "#read train image with CV\n",
    "trData, trI, trYN, trYC, trYP = [],[],[],[],[]\n",
    "for index, row in trainset.iterrows():#column: name,id,lr,N,C,P  \n",
    "    if row['name'].endswith(\".jpg\"):\n",
    "        try:\n",
    "            image_path = os.path.join(image_dir, row['name'])\n",
    "            img = cv2.resize(cv2.imread(image_path).astype(np.float32), (1024, 1024))\n",
    "            trData.append(row['name'])\n",
    "            trI.append(img)\n",
    "            trYN.append(row['N'])\n",
    "            trYC.append(row['C'])\n",
    "            trYP.append(row['P'])\n",
    "        except:\n",
    "            print(row['name']+\":\"+str(image_path))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(trData),trainset.shape[0]))\n",
    "        sys.stdout.flush()\n",
    "print('The length of train set is %d'%len(trData))\n",
    "#read test image with CV\n",
    "teData, teI, teYN, teYC, teYP = [],[],[],[],[]\n",
    "for index, row in testset.iterrows():#column: name,id,lr,N,C,P  \n",
    "    if row['name'].endswith(\".jpg\"):\n",
    "        try:\n",
    "            image_path = os.path.join(image_dir, row['name'])\n",
    "            img = cv2.resize(cv2.imread(image_path).astype(np.float32), (1024, 1024))\n",
    "            teData.append(row['name'])\n",
    "            teI.append(img)\n",
    "            teYN.append(row['N'])\n",
    "            teYC.append(row['C'])\n",
    "            teYP.append(row['P'])\n",
    "        except:\n",
    "            print(row['name']+\":\"+str(image_path))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(teData),testset.shape[0]))\n",
    "        sys.stdout.flush()\n",
    "print('The length of train set is %d'%len(teData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.03159523010254\n",
      "conv1.weight\n",
      "tensor([ 0.1704, -0.1849,  0.1505])\n",
      "14.555537223815918\n",
      "conv1.weight\n",
      "tensor([ 0.1694, -0.1852,  0.1502])\n",
      "11.206185340881348\n",
      "conv1.weight\n",
      "tensor([ 0.1690, -0.1857,  0.1505])\n",
      "7.917587757110596\n",
      "conv1.weight\n",
      "tensor([ 0.1690, -0.1864,  0.1511])\n",
      "6.534246444702148\n",
      "conv1.weight\n",
      "tensor([ 0.1694, -0.1864,  0.1514])\n",
      "5.623223304748535\n",
      "conv1.weight\n",
      "tensor([ 0.1700, -0.1862,  0.1516])\n",
      "4.265881061553955\n",
      "conv1.weight\n",
      "tensor([ 0.1707, -0.1863,  0.1520])\n",
      "2.8265511989593506\n",
      "conv1.weight\n",
      "tensor([ 0.1711, -0.1865,  0.1524])\n",
      "2.5538811683654785\n",
      "conv1.weight\n",
      "tensor([ 0.1713, -0.1869,  0.1529])\n",
      "2.1924242973327637\n",
      "conv1.weight\n",
      "tensor([ 0.1717, -0.1875,  0.1530])\n",
      "tensor([[ 0.2517, -0.6320,  0.0867, -0.2645,  0.1796,  0.1508,  0.3877,\n",
      "          0.2545,  0.5201,  0.0066,  0.4533,  0.5320,  0.3209, -0.2749,\n",
      "         -0.4564, -0.3753],\n",
      "        [-0.0125,  0.2979, -0.0201,  0.1015, -0.1684, -0.5525, -0.4656,\n",
      "         -0.3066, -0.4149,  0.2464, -0.3827, -0.3939, -0.3632,  0.0782,\n",
      "          0.3039,  0.3378],\n",
      "        [-0.1389,  0.0023, -0.0604,  0.0706, -0.1356, -0.1167,  0.2349,\n",
      "          0.1890, -0.0782, -0.1605,  0.1892,  0.0415,  0.0385,  0.1958,\n",
      "          0.3522, -0.0570],\n",
      "        [ 0.2141, -0.0859, -0.0161, -0.3314,  0.0178,  0.1319, -0.0353,\n",
      "          0.0584, -0.0225, -0.0780, -0.0924,  0.0055,  0.0620, -0.0478,\n",
      "         -0.1380,  0.1563],\n",
      "        [-0.0253, -0.1687,  0.2733,  0.2637,  0.3501, -0.2199, -0.1494,\n",
      "         -0.2438,  0.1410,  0.3783, -0.1268, -0.1344, -0.0211,  0.1421,\n",
      "         -0.1206, -0.3554],\n",
      "        [ 0.1391, -0.1038,  0.0475, -0.0591, -0.2477,  0.0775,  0.0265,\n",
      "          0.2223,  0.4281,  0.1340,  0.2796,  0.6169,  0.0918, -0.1393,\n",
      "         -0.3521,  0.1030],\n",
      "        [ 0.1255,  0.1962, -0.2286, -0.0775, -0.1835, -0.1677,  0.0162,\n",
      "          0.0321, -0.1517,  0.1448, -0.2675, -0.0772, -0.3723,  0.3624,\n",
      "          0.2745,  0.0905],\n",
      "        [ 0.1666, -0.0482, -0.2157, -0.1949, -0.1037,  0.0163, -0.1979,\n",
      "         -0.0570, -0.2688,  0.0829, -0.5186, -0.0155, -0.3560,  0.2233,\n",
      "          0.2233,  0.0233],\n",
      "        [ 0.3119,  0.0290,  0.2976, -0.2093, -0.0585, -0.2277,  0.0211,\n",
      "          0.3977,  0.2179, -0.0874, -0.0448, -0.0281, -0.0027,  0.0245,\n",
      "         -0.2657, -0.0455],\n",
      "        [-0.1327, -0.1326, -0.0730, -0.0216,  0.2877, -0.1071,  0.0752,\n",
      "         -0.1475, -0.0254, -0.0974,  0.3503,  0.1042, -0.1532,  0.0205,\n",
      "         -0.3437, -0.0112]])\n",
      "tensor([[ 1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "          1., -1., -1., -1.],\n",
      "        [-1.,  1., -1.,  1., -1., -1., -1., -1., -1.,  1., -1., -1.,\n",
      "         -1.,  1.,  1.,  1.],\n",
      "        [-1.,  1., -1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,  1.,\n",
      "          1.,  1.,  1., -1.],\n",
      "        [ 1., -1., -1., -1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,\n",
      "          1., -1., -1.,  1.],\n",
      "        [-1., -1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,\n",
      "         -1.,  1., -1., -1.],\n",
      "        [ 1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "          1., -1., -1.,  1.],\n",
      "        [ 1.,  1., -1., -1., -1., -1.,  1.,  1., -1.,  1., -1., -1.,\n",
      "         -1.,  1.,  1.,  1.],\n",
      "        [ 1., -1., -1., -1., -1.,  1., -1., -1., -1.,  1., -1., -1.,\n",
      "         -1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1., -1., -1., -1.,\n",
      "         -1.,  1., -1., -1.],\n",
      "        [-1., -1., -1., -1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,\n",
      "         -1.,  1., -1., -1.]])\n",
      "torch.Size([10, 16])\n"
     ]
    }
   ],
   "source": [
    "#2. define Attention-based Hashing network with pytorch\n",
    "class HNet(nn.Module): #deep Hashint Network:DHNet\n",
    "    def __init__(self,inChannels=3):\n",
    "        super(HNet, self).__init__()\n",
    "        #(channels, Height, Width)\n",
    "        #layer1: Convolution, (3,1024,1024)->(16,512,512)\n",
    "        self.conv1 = nn.Conv2d(in_channels=inChannels, out_channels=16, kernel_size=3, padding=1, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        #layer2: max pooling,(16,512,512)->(16,256,256)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, padding=1, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        #layer3: Convolution, (16,256,256)->(8,128,128)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3, padding=1, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(8)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        #layer4: mean pooling, (8,128,128)->(8,64,64)\n",
    "        self.avgpool1 = nn.AvgPool2d(kernel_size=3, padding=1, stride=2)\n",
    "        self.bn4 = nn.BatchNorm2d(8)\n",
    "        #layer5: Convolution, (8,64,64)->(4,32,32)\n",
    "        self.conv3 = nn.Conv2d(in_channels=8, out_channels=4, kernel_size=3, padding=1, stride=2)\n",
    "        self.bn5 = nn.BatchNorm2d(4)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        #layer6: mean pooling, (4,32,32)->(4,16,16)\n",
    "        self.avgpool2 = nn.AvgPool2d(kernel_size=3, padding=1, stride=2)\n",
    "        self.bn6 = nn.BatchNorm2d(4)\n",
    "        #layer7: fully connected, 4*16*16->512\n",
    "        self.fcl1 = nn.Linear(4*16*16,512)\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "        #layer8: Hashing layer, 512->16\n",
    "        self.fcl2 = nn.Linear(512,16)#\n",
    "        self.tanh = nn.Tanh() #{-1,1}\n",
    "              \n",
    "    def forward(self,x):\n",
    "        #input: (batch_size, in_channels, Height, Width)\n",
    "        #output: (batch_size, out_channels, Height, Width)\n",
    "        #layer1: convolution\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        #layer2: max pooling\n",
    "        x = self.maxpool(x)\n",
    "        x = self.bn2(x)\n",
    "        #layer3: Convolution\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu2(x)\n",
    "        #layer4: mean pooling\n",
    "        x = self.avgpool1(x)\n",
    "        x = self.bn4(x)\n",
    "        #layer5: Convolution\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu3(x)\n",
    "        #layer6: mean pooling\n",
    "        x = self.avgpool2(x)\n",
    "        x = self.bn6(x)\n",
    "        #layer7:fully connected\n",
    "        x = x.view(x.size(0),-1) #transfer three dims to one dim\n",
    "        x = self.fcl1(x)\n",
    "        x = self.relu4(x)\n",
    "        #layer8: Hashing layer\n",
    "        x = self.fcl2(x)\n",
    "        x = self.tanh(x)\n",
    "                \n",
    "        return x\n",
    "    \n",
    "#https://pytorch-cn.readthedocs.io/zh/latest/    \n",
    "#https://github.com/filipradenovic/cnnimageretrieval-pytorch/blob/master/cirtorch/layers/functional.py\n",
    "class HashLossFunc(nn.Module):\n",
    "    def __init__(self, margin=0.5, alpha=0.01):\n",
    "        super(HashLossFunc, self).__init__()\n",
    "        self.alpha = alpha #regularization\n",
    "        self.margin = margin #margin threshold\n",
    "    \n",
    "    def forward(self,h1,h2,y): \n",
    "        #h1=h2:NxD,y:N\n",
    "        dim = h1.shape[1]\n",
    "        euc_dist = F.pairwise_distance(h1, h2, p=2, eps=1e-06) # Calcualte Euclidean Distance\n",
    "        sim_term = 0.5*(1-y)*euc_dist #penalize the similar iamge pairs when y=0\n",
    "        unsim_term = 0.5*y*torch.clamp(self.margin*dim-euc_dist,0)#penalize the unsimlar image pairs when y =1\n",
    "        reg_term = self.alpha * ( torch.sum((torch.abs(h1)-1),dim=1) + torch.sum((torch.abs(h2)-1),dim=1) ) #regularization term\n",
    "        #loss = torch.mean(sim_term + unsim_term + reg_term) \n",
    "        loss = torch.sum(sim_term + unsim_term+ reg_term) \n",
    "        return loss\n",
    "\n",
    "#test network: valid\n",
    "x1 = torch.rand(10,3,1024,1024)#.cuda()\n",
    "x2 = torch.rand(10,3,1024,1024)#.cuda()\n",
    "y = torch.FloatTensor([0,1,1,0,1,0,0,0,1,1])#.cuda()\n",
    "model = HNet()#.cuda()\n",
    "criterion  = HashLossFunc(margin=0.5)#.cuda() #define loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    out1 = model(x1)#out.grad_fn\n",
    "    out2 = model(x2)\n",
    "    loss = criterion(out1,out2,y)\n",
    "    print (loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #observe the variant of model.parameters\n",
    "    for i in model.named_parameters():\n",
    "        print(i[0])\n",
    "        print(i[1][0][0][0])\n",
    "        break\n",
    "#output\n",
    "x3 = torch.rand(10,3,1024,1024)#.cuda()\n",
    "out3 = model(x3)\n",
    "print (out3)\n",
    "out3 = torch.sign(out3) #Binarization,[-1,1]->{-1,1}\n",
    "print (out3)\n",
    "print (out3.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 182 / 5860 : loss = 18.463573"
     ]
    }
   ],
   "source": [
    "#3.train and evaluate model\n",
    "def onlineGenImgPairs(batchSize):\n",
    "    idx_sf = random.sample(range(0, len(trYN)),2*batchSize)\n",
    "    trI1_sf, trI2_sf, trY1_sf, trY2_sf = [],[],[],[]\n",
    "    flag = 0\n",
    "    for i in idx_sf:\n",
    "        if flag==0:\n",
    "            trI1_sf.append(trI[i])\n",
    "            trY1_sf.append(trYN[i])\n",
    "            flag =1\n",
    "        else:\n",
    "            trI2_sf.append(trI[i])\n",
    "            trY2_sf.append(trYN[i])\n",
    "            flag =0\n",
    "    trY_sf = np.where((np.array(trY1_sf)-np.array(trY2_sf))!=0,1,0)\n",
    "    return np.array(trI1_sf),np.array(trI2_sf),trY_sf\n",
    "        \n",
    "#define model\n",
    "model = HNet().cuda()\n",
    "criterion  = HashLossFunc(margin=0.5).cuda() #define loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "#train model\n",
    "batchSize = 10\n",
    "epochSize = len(trYN)//batchSize+1\n",
    "losses = []\n",
    "for epoch in range(2*epochSize):#iteration\n",
    "    #grad vanish\n",
    "    optimizer.zero_grad() \n",
    "    #genenate training images pair\n",
    "    trI1_sf, trI2_sf, trY_sf = onlineGenImgPairs(batchSize)\n",
    "    I1_batch = torch.from_numpy(trI1_sf).type(torch.FloatTensor).cuda()\n",
    "    I2_batch = torch.from_numpy(trI2_sf).type(torch.FloatTensor).cuda()\n",
    "    Y_batch = torch.from_numpy(trY_sf).type(torch.FloatTensor).cuda()\n",
    "    #forword\n",
    "    X1_batch = model(I1_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "    X2_batch = model(I2_batch.permute(0, 3, 1, 2))\n",
    "    #binary-like loss\n",
    "    loss = criterion(X1_batch,X2_batch,Y_batch)\n",
    "    #backward\n",
    "    loss.backward()\n",
    "    #update parameters\n",
    "    optimizer.step()\n",
    "    #show loss\n",
    "    sys.stdout.write('\\r {} / {} : loss = {}'.format(epoch, 2*epochSize, float('%0.6f'%loss.item())))\n",
    "    sys.stdout.flush()     \n",
    "    losses.append(loss.item())\n",
    "print(\"mean_loss = %.6f\" % (np.mean(losses)))\n",
    "\n",
    "#release gpu memory\n",
    "#model = model.cpu()\n",
    "#torch.cuda.empty_cache()\n",
    "#hash code of train data from model\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize+1\n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch = torch.sign(model(I_batch.permute(0, 3, 1, 2)))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#hash code of test data from model\n",
    "teF = []\n",
    "num_batches = len(teI) // batchSize\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(teI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch = torch.sign(model(I_batch.permute(0, 3, 1, 2)))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    teF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#train data with list: trData, trI, trF, trY\n",
    "#test data with list: teData, teI, teF, teY\n",
    "for topk in [5,10,15,20]:\n",
    "    MHR = [] #mean Hit ratio \n",
    "    MAP = [] #mean average precision\n",
    "    MRR = [] #mean reciprocal rank\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teYN[i]\n",
    "        map_item_score = {}\n",
    "        for j, trVal in enumerate(trF):\n",
    "            map_item_score[j] = pdist(np.vstack([teVal,trVal]),'hamming')\n",
    "        ranklist = heapq.nsmallest(topk, map_item_score, key=map_item_score.get)\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        mrr_flag = 0\n",
    "        for j in ranklist:\n",
    "            dtype = trYN[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                MHR.append(1)\n",
    "                pos_len = pos_len +1\n",
    "                MAP.append(pos_len/rank_len) \n",
    "                if mrr_flag==0: \n",
    "                    MRR.append(pos_len/rank_len)\n",
    "                    mrr_flag =1\n",
    "            else: \n",
    "                MHR.append(0)\n",
    "                MAP.append(0)   \n",
    "    print(\"mHR@{}={:.6f}, mAP@{}={:.6f}, mRR@{}={:.6f}\".format(topk,np.mean(MHR),topk,np.mean(MAP), topk, np.mean(MRR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
