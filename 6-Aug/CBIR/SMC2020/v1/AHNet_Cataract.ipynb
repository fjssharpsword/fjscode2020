{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.Develop Env: linux+cuda9+python3+opencv+pytorch\n",
    "2.Dataset: ASOCT-Cataract with 32560 images, Dataset Statistics: \n",
    "        1)OD:oculus dextrus, OS: oculus sinister\n",
    "           OD    18901\n",
    "           OS    13659\n",
    "        2)Structure: N, C, P train set: (29297, 6) test set: (3255, 6)\n",
    "           N-Level: 1.0-6.0 \n",
    "           C-Level: 1.0-5.0 if C=0.0(562) denotes this sample with no label \n",
    "           P-Level: 1.0-6.0 if C=0.0(7354) denotes this sample with no label\n",
    "        3)train set and test set:  OD, P-Level(Micro ROI) \n",
    "           1.0(2381),2.0(1407),3.0(1677),4.0(1494),5.0(781)-7000 for train ,700 for test \n",
    "3.Performance Metric: \n",
    "  1)MHR(Mean Hit Ratio):  for evaluating the precison of relevance retrieval;\n",
    "  2)MAP(Mean Average Precision): for evaluation the rank of relevance retrieval;\n",
    "  3)MRR(Mean Reciprocal Rank): for evaluation the first hit rank of relevance retrieval;\n",
    "  4)Memory consumption and Retrieval Speed.\n",
    "4.Algorithm: \n",
    "  1)Baseline: HNet\n",
    "  2)Attention: AHNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from scipy.spatial.distance import pdist\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "#import faiss\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.cuda.set_device(7)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468 / 7000 C020_20180514_100234_R_CASIA2_LGC_004.jpg:/data/fjsdata/ASOCT/Cataract/C_8bit_Crop_New/C020_20180514_100234_R_CASIA2_LGC_004.jpg\n",
      "568 / 7000 C020_20180514_100234_R_CASIA2_LGC_000.jpg:/data/fjsdata/ASOCT/Cataract/C_8bit_Crop_New/C020_20180514_100234_R_CASIA2_LGC_000.jpg\n",
      "1871 / 7000 C020_20180514_100234_R_CASIA2_LGC_002.jpg:/data/fjsdata/ASOCT/Cataract/C_8bit_Crop_New/C020_20180514_100234_R_CASIA2_LGC_002.jpg\n",
      "1929 / 7000 C020_20180514_100234_R_CASIA2_LGC_008.jpg:/data/fjsdata/ASOCT/Cataract/C_8bit_Crop_New/C020_20180514_100234_R_CASIA2_LGC_008.jpg\n",
      "6996 / 7000 The length of train set is 6996\n",
      "700 / 700 The length of train set is 700\n"
     ]
    }
   ],
   "source": [
    "#1. Read data with List storage Data:[name],I:[img],Y[type]\n",
    "image_dir = '/data/fjsdata/ASOCT/Cataract/C_8bit_Crop_New' #the path of images\n",
    "trainset = pd.read_csv(\"/data/fjsdata/ASOCT/Cataract/CBIR_MICCAI_train.csv\" , sep=',')#load dataset\n",
    "testset = pd.read_csv(\"/data/fjsdata/ASOCT/Cataract/CBIR_MICCAI_test.csv\" , sep=',')#load testset\n",
    "\n",
    "#read train image with CV\n",
    "trData, trI, trY = [],[],[]\n",
    "for iname, itype in np.array(trainset).tolist():#column: name,id,lr,N,C,P  \n",
    "    if iname.endswith(\".jpg\"):\n",
    "        try:\n",
    "            image_path = os.path.join(image_dir, iname)\n",
    "            img = cv2.resize(cv2.imread(image_path).astype(np.float32), (512, 512))\n",
    "            trData.append([iname, itype])\n",
    "            trI.append(img)\n",
    "            trY.append(itype)\n",
    "        except:\n",
    "            print(iname+\":\"+str(image_path))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(trData),len(trainset)))\n",
    "        sys.stdout.flush()\n",
    "print('The length of train set is %d'%len(trData))\n",
    "#read test image with CV\n",
    "teData, teI, teY = [],[],[]\n",
    "for iname, itype in np.array(testset).tolist():#column: name,id,lr,N,C,P  \n",
    "    if iname.endswith(\".jpg\"):\n",
    "        try:\n",
    "            image_path = os.path.join(image_dir, iname)\n",
    "            img = cv2.resize(cv2.imread(image_path).astype(np.float32), (512, 512))\n",
    "            teData.append([iname, itype])\n",
    "            teI.append(img)\n",
    "            teY.append(itype)\n",
    "        except:\n",
    "            print(iname+\":\"+str(image_path))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(teData),len(testset)))\n",
    "        sys.stdout.flush()\n",
    "print('The length of train set is %d'%len(teData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.79018783569336\n",
      "conv1.weight\n",
      "tensor([ 0.1762,  0.0183, -0.1426])\n",
      "15.591217994689941\n",
      "conv1.weight\n",
      "tensor([ 0.1770,  0.0178, -0.1417])\n",
      "11.198603630065918\n",
      "conv1.weight\n",
      "tensor([ 0.1779,  0.0176, -0.1407])\n",
      "6.940100193023682\n",
      "conv1.weight\n",
      "tensor([ 0.1784,  0.0175, -0.1397])\n",
      "3.9047999382019043\n",
      "conv1.weight\n",
      "tensor([ 0.1781,  0.0175, -0.1391])\n",
      "3.276855707168579\n",
      "conv1.weight\n",
      "tensor([ 0.1782,  0.0178, -0.1383])\n",
      "2.5485496520996094\n",
      "conv1.weight\n",
      "tensor([ 0.1783,  0.0178, -0.1376])\n",
      "1.407162070274353\n",
      "conv1.weight\n",
      "tensor([ 0.1781,  0.0175, -0.1369])\n",
      "0.4547092318534851\n",
      "conv1.weight\n",
      "tensor([ 0.1780,  0.0173, -0.1366])\n",
      "0.22658812999725342\n",
      "conv1.weight\n",
      "tensor([ 0.1777,  0.0173, -0.1361])\n",
      "tensor([[ 0.2744, -0.0170, -0.1306,  0.0603,  0.2706, -0.2192, -0.1687,\n",
      "         -0.3207, -0.2111, -0.4491, -0.0719, -0.0476, -0.5325,  0.2009,\n",
      "         -0.3792,  0.3386],\n",
      "        [-0.2105,  0.3633,  0.1055,  0.4417,  0.0690, -0.2778,  0.4220,\n",
      "         -0.2100,  0.5080, -0.1959, -0.0454,  0.4005,  0.2815, -0.1228,\n",
      "          0.3709, -0.3197],\n",
      "        [ 0.2874,  0.0637,  0.2720,  0.5278,  0.2428, -0.1650,  0.4501,\n",
      "         -0.5677, -0.0918, -0.3640, -0.1981,  0.0907, -0.1207, -0.2631,\n",
      "         -0.0610, -0.2382],\n",
      "        [-0.4036,  0.3313, -0.1750,  0.4215,  0.2865, -0.3755, -0.0226,\n",
      "         -0.1675,  0.0960, -0.0233, -0.2414,  0.4040, -0.0401, -0.2467,\n",
      "          0.2009, -0.0169],\n",
      "        [-0.4076,  0.3078, -0.1587,  0.3426, -0.0312, -0.5455,  0.0752,\n",
      "          0.1691,  0.4278,  0.2818, -0.1408,  0.4475,  0.5202, -0.0339,\n",
      "          0.5536, -0.0951],\n",
      "        [ 0.3179, -0.1337,  0.2889, -0.2266, -0.2540, -0.2199,  0.1856,\n",
      "          0.3091,  0.2153, -0.2420, -0.2293, -0.1798, -0.1762,  0.1557,\n",
      "          0.0020, -0.0012],\n",
      "        [-0.0113, -0.2052,  0.1279,  0.1516,  0.1748,  0.0508, -0.1155,\n",
      "         -0.0727,  0.0883, -0.0248,  0.2342,  0.0757,  0.1952, -0.4002,\n",
      "          0.1766,  0.0301],\n",
      "        [-0.1951,  0.1264,  0.1938,  0.1260, -0.2479, -0.3677,  0.4242,\n",
      "          0.3391,  0.5339,  0.3124, -0.1581,  0.3045,  0.5089,  0.0415,\n",
      "          0.3290, -0.3103],\n",
      "        [ 0.2208, -0.0141,  0.2065,  0.1025, -0.3030,  0.3420,  0.1176,\n",
      "         -0.0659,  0.2104,  0.1142,  0.0211, -0.1926,  0.0826, -0.1643,\n",
      "          0.0908, -0.0046],\n",
      "        [-0.0570,  0.1955, -0.3761,  0.2562,  0.5103, -0.1630, -0.3283,\n",
      "         -0.5792, -0.2373, -0.2288,  0.2342,  0.1978, -0.1117, -0.2146,\n",
      "         -0.1908,  0.1179]])\n",
      "tensor([[ 1., -1., -1.,  1.,  1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "         -1.,  1., -1.,  1.],\n",
      "        [-1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1., -1.,  1.,\n",
      "          1., -1.,  1., -1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1., -1., -1.,  1.,\n",
      "         -1., -1., -1., -1.],\n",
      "        [-1.,  1., -1.,  1.,  1., -1., -1., -1.,  1., -1., -1.,  1.,\n",
      "         -1., -1.,  1., -1.],\n",
      "        [-1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
      "          1., -1.,  1., -1.],\n",
      "        [ 1., -1.,  1., -1., -1., -1.,  1.,  1.,  1., -1., -1., -1.,\n",
      "         -1.,  1.,  1., -1.],\n",
      "        [-1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1.,\n",
      "          1., -1.,  1.,  1.],\n",
      "        [-1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
      "          1.,  1.,  1., -1.],\n",
      "        [ 1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1.,\n",
      "          1., -1.,  1., -1.],\n",
      "        [-1.,  1., -1.,  1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,\n",
      "         -1., -1., -1.,  1.]])\n",
      "torch.Size([10, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. define Attention-based Hashing network with pytorch\n",
    "class SpatialAttention(nn.Module):#spatial attention layer\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "class AHNet(nn.Module): #deep Hashint Network:DHNet\n",
    "    def __init__(self,inChannels=3):\n",
    "        super(AHNet, self).__init__()\n",
    "        #(channels, Height, Width)\n",
    "        #layer1: Convolution, (3,512,512)->(8,256,256)\n",
    "        self.conv1 = nn.Conv2d(in_channels=inChannels, out_channels=8, kernel_size=3, padding=1, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        #layer2: max pooling,(8,256,256)->(8,128,128)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, padding=1, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(8)\n",
    "        #layer3: Spatial Attention Layer, (8,256,256)->(8,256,256)\n",
    "        self.sa = SpatialAttention()\n",
    "        #layer4: Convolution, (8,128,128)->(2,64,64)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=2, kernel_size=3, padding=1, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(2)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        #layer5: mean pooling, (2,64,64)->(2,32,32)\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=3, padding=1, stride=2)\n",
    "        self.bn4 = nn.BatchNorm2d(2)\n",
    "        #layer6: fully connected, 2*32*32->512\n",
    "        self.fcl1 = nn.Linear(2*32*32,512)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        #layer7: Hashing layer, 512->16\n",
    "        self.fcl2 = nn.Linear(512,16)#\n",
    "        self.tanh = nn.Tanh() #{-1,1}\n",
    "              \n",
    "    def forward(self,x):\n",
    "        #input: (batch_size, in_channels, Height, Width)\n",
    "        #output: (batch_size, out_channels, Height, Width)\n",
    "        #layer1: convolution\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        #layer2: max pooling\n",
    "        x = self.maxpool(x)\n",
    "        x = self.bn2(x)\n",
    "        #layer3: Attention\n",
    "        x = self.sa(x)*x\n",
    "        #layer4: Convolution\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu2(x)\n",
    "        #layer5: mean pooling\n",
    "        x = self.avgpool(x)\n",
    "        x = self.bn4(x)\n",
    "        #layer6:fully connected\n",
    "        x = x.view(x.size(0),-1) #transfer three dims to one dim\n",
    "        x = self.fcl1(x)\n",
    "        x = self.relu3(x)\n",
    "        #layer7: Hashing layer\n",
    "        x = self.fcl2(x)\n",
    "        x = self.tanh(x)\n",
    "                \n",
    "        return x\n",
    "    \n",
    "#https://pytorch-cn.readthedocs.io/zh/latest/    \n",
    "#https://github.com/filipradenovic/cnnimageretrieval-pytorch/blob/master/cirtorch/layers/functional.py\n",
    "class HashLossFunc(nn.Module):\n",
    "    def __init__(self, margin=0.5, alpha=0.01):\n",
    "        super(HashLossFunc, self).__init__()\n",
    "        self.alpha = alpha #regularization\n",
    "        self.margin = margin #margin threshold\n",
    "    \n",
    "    def forward(self,h1,h2,y): \n",
    "        #h1=h2:NxD,y:N\n",
    "        dim = h1.shape[1]\n",
    "        euc_dist = F.pairwise_distance(h1, h2, p=2, eps=1e-06) # Calcualte Euclidean Distance\n",
    "        sim_term = 0.5*(1-y)*euc_dist #penalize the similar iamge pairs when y=0\n",
    "        unsim_term = 0.5*y*torch.clamp(self.margin*dim-euc_dist,0)#penalize the unsimlar image pairs when y =1\n",
    "        reg_term = self.alpha * ( torch.sum((torch.abs(h1)-1),dim=1) + torch.sum((torch.abs(h2)-1),dim=1) ) #regularization term\n",
    "        #loss = torch.mean(sim_term + unsim_term + reg_term) \n",
    "        loss = torch.sum(sim_term + unsim_term+ reg_term) \n",
    "        return loss\n",
    "\n",
    "#test network: valid\n",
    "x1 = torch.rand(10,3,512,512)#.cuda()\n",
    "x2 = torch.rand(10,3,512,512)#.cuda()\n",
    "y = torch.FloatTensor([0,1,1,0,1,0,0,0,1,1])#.cuda()\n",
    "model = AHNet()#.cuda()\n",
    "criterion  = HashLossFunc(margin=0.5)#.cuda() #define loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    out1 = model(x1)#out.grad_fn\n",
    "    out2 = model(x2)\n",
    "    loss = criterion(out1,out2,y)\n",
    "    print (loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #observe the variant of model.parameters\n",
    "    for i in model.named_parameters():\n",
    "        print(i[0])\n",
    "        print(i[1][0][0][0])\n",
    "        break\n",
    "#output\n",
    "x3 = torch.rand(10,3,512,512)#.cuda()\n",
    "out3 = model(x3)\n",
    "print (out3)\n",
    "out3 = torch.sign(out3) #Binarization,[-1,1]->{-1,1}\n",
    "print (out3)\n",
    "print (out3.size())\n",
    "del x1,x2,x3,out1,out2,out3,model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 699 / 699 : loss = 24.581563Eopch:     1 mean_loss = 16.068793\n",
      " 699 / 699 : loss = 12.568348Eopch:     2 mean_loss = 15.851292\n",
      "best_loss = 15.851292\n",
      " 69 / 70 0 mHR@5=0.511429, mAP@5=0.503210, mRR@5=0.969867\n",
      "mHR@10=0.510143, mAP@10=0.499710, mRR@10=0.952008\n",
      "mHR@15=0.511238, mAP@15=0.497424, mRR@15=0.938608\n",
      "mHR@20=0.515143, mAP@20=0.497713, mRR@20=0.912153\n"
     ]
    }
   ],
   "source": [
    "#3.train and evaluate model\n",
    "def onlineGenImgPairs(batchSize):\n",
    "    idx_sf = random.sample(range(0, len(trY)),2*batchSize)\n",
    "    trI1_sf, trI2_sf, trY1_sf, trY2_sf = [],[],[],[]\n",
    "    flag = 0\n",
    "    for i in idx_sf:\n",
    "        if flag==0:\n",
    "            trI1_sf.append(trI[i])\n",
    "            trY1_sf.append(trY[i])\n",
    "            flag =1\n",
    "        else:\n",
    "            trI2_sf.append(trI[i])\n",
    "            trY2_sf.append(trY[i])\n",
    "            flag =0\n",
    "    trY_sf = np.where(abs((np.array(trY1_sf)-np.array(trY2_sf)))<=1.0,0,1)\n",
    "    return np.array(trI1_sf),np.array(trI2_sf),trY_sf\n",
    "        \n",
    "#define model\n",
    "model = AHNet().cuda()\n",
    "criterion  = HashLossFunc(margin=0.5).cuda() #define loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "for epoch in range(2):#iteration:len(trY)/2\n",
    "    batchSize = 10\n",
    "    batches = len(trY)//batchSize\n",
    "    losses = []\n",
    "    for batch in range(batches):\n",
    "        #grad vanish\n",
    "        optimizer.zero_grad() \n",
    "        #genenate training images pair\n",
    "        trI1_sf, trI2_sf, trY_sf = onlineGenImgPairs(batchSize)\n",
    "        I1_batch = torch.from_numpy(trI1_sf).type(torch.FloatTensor).cuda()\n",
    "        I2_batch = torch.from_numpy(trI2_sf).type(torch.FloatTensor).cuda()\n",
    "        Y_batch = torch.from_numpy(trY_sf).type(torch.FloatTensor).cuda()\n",
    "        #forword\n",
    "        X1_batch = model(I1_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        X2_batch = model(I2_batch.permute(0, 3, 1, 2))\n",
    "        #binary-like loss\n",
    "        loss = criterion(X1_batch,X2_batch,Y_batch)\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(batch+1, batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "#hash code of train data from model\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize+1\n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch = torch.sign(best_net(I_batch.permute(0, 3, 1, 2)))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#hash code of test data from model\n",
    "teF = []\n",
    "num_batches = len(teI) // batchSize\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(teI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch = torch.sign(best_net(I_batch.permute(0, 3, 1, 2)))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    teF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#train data with list: trData, trI, trF, trY\n",
    "#test data with list: teData, teI, teF, teY\n",
    "for topk in [5,10,15,20]:\n",
    "    MHR = [] #mean Hit ratio \n",
    "    MAP = [] #mean average precision\n",
    "    MRR = [] #mean reciprocal rank\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        map_item_score = {}\n",
    "        for j, trVal in enumerate(trF):\n",
    "            map_item_score[j] = pdist(np.vstack([teVal,trVal]),'hamming')\n",
    "        ranklist = heapq.nsmallest(topk, map_item_score, key=map_item_score.get)\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        mrr_flag = 0\n",
    "        for j in ranklist:\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if abs(stype-dtype)<=1.0:  #hit\n",
    "                MHR.append(1)\n",
    "                pos_len = pos_len +1\n",
    "                MAP.append(pos_len/rank_len) \n",
    "                if mrr_flag==0: \n",
    "                    MRR.append(pos_len/rank_len)\n",
    "                    mrr_flag =1\n",
    "            else: \n",
    "                MHR.append(0)\n",
    "                MAP.append(0)   \n",
    "    print(\"mHR@{}={:.6f}, mAP@{}={:.6f}, mRR@{}={:.6f}\".format(topk,np.mean(MHR),topk,np.mean(MAP), topk, np.mean(MRR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
