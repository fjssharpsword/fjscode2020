{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.Develop Env: linux+cuda9+python3+opencv+pytorch\n",
    "2.Dataset: ASOCT-Cataract with 32560 images, Dataset Statistics: \n",
    "        1)OD:oculus dextrus, OS: oculus sinister\n",
    "           OD    18901\n",
    "           OS    13659\n",
    "        2)Structure: N, C, P train set: (29297, 6) test set: (3255, 6)\n",
    "           N-Level: 1.0-6.0 \n",
    "           C-Level: 1.0-5.0 if C=0.0(562) denotes this sample with no label \n",
    "           P-Level: 1.0-6.0 if C=0.0(7354) denotes this sample with no label\n",
    "        3)train set and test set:  OD, P-Level(Micro ROI) \n",
    "           1.0(2381),2.0(1407),3.0(1677),4.0(1494),5.0(781)-7000 for train ,700 for test\n",
    "3.Performance Metric: \n",
    "  1)Accuracy(Acc):  for evaluating the precison of top 1 in the returned list;\n",
    "  2)Specificity(Spe): for evaluating the misdiagnosis rate of normal\n",
    "  3)Sensitivity(Sen): for evaluating the missed diagnosis rate of abnorml(S,V,F)\n",
    "4.Algorithm: Attention-based Triplet Hashing Network(ATH), Cross-loss(Focal+Triplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading faiss with AVX2 support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "from PIL import Image\n",
    "from io import StringIO,BytesIO \n",
    "from scipy.spatial.distance import pdist\n",
    "import cv2\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc \n",
    "from functools import reduce\n",
    "import wfdb#https://github.com/MIT-LCP/wfdb-python\n",
    "from wfdb import processing\n",
    "import faiss \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "torch.cuda.set_device(1)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468 / 7000 C020_20180514_100234_R_CASIA2_LGC_004.jpg:/data/fjsdata/ASOCT/Cataract/C_8bit_Crop_New/C020_20180514_100234_R_CASIA2_LGC_004.jpg\n",
      "568 / 7000 C020_20180514_100234_R_CASIA2_LGC_000.jpg:/data/fjsdata/ASOCT/Cataract/C_8bit_Crop_New/C020_20180514_100234_R_CASIA2_LGC_000.jpg\n",
      "1871 / 7000 C020_20180514_100234_R_CASIA2_LGC_002.jpg:/data/fjsdata/ASOCT/Cataract/C_8bit_Crop_New/C020_20180514_100234_R_CASIA2_LGC_002.jpg\n",
      "1929 / 7000 C020_20180514_100234_R_CASIA2_LGC_008.jpg:/data/fjsdata/ASOCT/Cataract/C_8bit_Crop_New/C020_20180514_100234_R_CASIA2_LGC_008.jpg\n",
      "6996 / 7000 The length of train set is 6996\n",
      "700 / 700 The length of train set is 700\n"
     ]
    }
   ],
   "source": [
    "#Read data with List storage N:[name],I:[img],Y[type]\n",
    "image_dir = '/data/fjsdata/ASOCT/Cataract/C_8bit_Crop_New/' #the path of images\n",
    "trainset = pd.read_csv(\"/data/fjsdata/ASOCT/Cataract/CBIR_MICCAI_train.csv\" , sep=',')#load dataset\n",
    "testset = pd.read_csv(\"/data/fjsdata/ASOCT/Cataract/CBIR_MICCAI_test.csv\" , sep=',')#load testset\n",
    "\n",
    "#read train image with CV\n",
    "trN, trI, trY = [],[],[]\n",
    "for iname, itype in np.array(trainset).tolist():#column: name,id,lr,N,C,P  \n",
    "    if iname.endswith(\".jpg\"):\n",
    "        try:\n",
    "            image_path = os.path.join(image_dir, iname)\n",
    "            img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))\n",
    "            trN.append(iname)\n",
    "            trI.append(img)\n",
    "            trY.append(itype-1)\n",
    "        except:\n",
    "            print(iname+\":\"+str(image_path))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(trN),len(trainset)))\n",
    "        sys.stdout.flush()\n",
    "print('The length of train set is %d'%len(trN))\n",
    "#read test image with CV\n",
    "teN, teI, teY = [],[],[]\n",
    "for iname, itype in np.array(testset).tolist():#column: name,id,lr,N,C,P  \n",
    "    if iname.endswith(\".jpg\"):\n",
    "        try:\n",
    "            image_path = os.path.join(image_dir, iname)\n",
    "            img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))\n",
    "            teN.append(iname)\n",
    "            teI.append(img)\n",
    "            teY.append(itype-1)\n",
    "        except:\n",
    "            print(iname+\":\"+str(image_path))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(teN),len(testset)))\n",
    "        sys.stdout.flush()\n",
    "print('The length of train set is %d'%len(teN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 700 / 700 : loss = 18.226952Eopch:     1 mean_loss = 16.597284\n",
      " 700 / 700 : loss = 10.210654Eopch:     2 mean_loss = 13.091690\n",
      " 700 / 700 : loss = 6.2457483Eopch:     3 mean_loss = 10.616536\n",
      " 700 / 700 : loss = 6.9127204Eopch:     4 mean_loss = 8.445382\n",
      " 700 / 700 : loss = 10.574819Eopch:     5 mean_loss = 6.627485\n",
      " 700 / 700 : loss = 14.457724Eopch:     6 mean_loss = 5.080488\n",
      " 700 / 700 : loss = 0.0253454Eopch:     7 mean_loss = 3.723782\n",
      " 700 / 700 : loss = 0.0671164Eopch:     8 mean_loss = 2.618566\n",
      " 700 / 700 : loss = 0.0540033Eopch:     9 mean_loss = 1.969935\n",
      " 700 / 700 : loss = 0.0780229Eopch:    10 mean_loss = 1.699470\n",
      "best_loss = 1.699470\n",
      " 69 / 70 0 Completed buliding index in 24 seconds\n",
      "mHR@10=0.736714, mAP@10=0.673692, mRR@10=0.937101\n",
      "Accuracy: 0.892857\n",
      "[[164   9  17   6   2]\n",
      " [  6 124   0   6   0]\n",
      " [ 11   3 152   1   0]\n",
      " [  4   6   2 136   1]\n",
      " [  1   0   0   0  49]]\n",
      "Sensitivity of Level 0: 0.828283\n",
      "Sensitivity of Level 1: 0.911765\n",
      "Sensitivity of Level 2: 0.910180\n",
      "Sensitivity of Level 3: 0.912752\n",
      "Sensitivity of Level 4: 0.980000\n"
     ]
    }
   ],
   "source": [
    "#ATH model with Tripet loss\n",
    "class SpatialAttention(nn.Module):#spatial attention layer\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels, out_channels=out_channels,\n",
    "                kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        self.downsample_layer = None\n",
    "        self.do_downsample = False\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.do_downsample = True\n",
    "            self.downsample_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.net(x)\n",
    "\n",
    "        if self.do_downsample:\n",
    "            identity = self.downsample_layer(x)\n",
    "\n",
    "        return F.relu(out + identity, inplace=True) #resnet\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            \n",
    "class ATHNet(nn.Module):\n",
    "    def __init__(self, code_size: int):\n",
    "        super().__init__()\n",
    "        #resnet and maxpool\n",
    "        self.net1 = nn.Sequential(#(3,256,256)->(16,128,128)\n",
    "            ResBlock(in_channels=3, out_channels=16, stride=2), \n",
    "            nn.MaxPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        )\n",
    "        \n",
    "        #Attention (16,128,128)->(16,128,128)\n",
    "        self.sa = SpatialAttention()\n",
    "        \n",
    "        #resnet and meanpool\n",
    "        self.net2 =nn.Sequential( #(16,128,128)->(8,64,64)\n",
    "            ResBlock(in_channels=16, out_channels=8, stride=2),\n",
    "            nn.AvgPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        ) \n",
    "         \n",
    "        #fully connected with conv (8,64,64)->(1,32,32)\n",
    "        self.dense=ResBlock(in_channels=8, out_channels=1, stride=2)\n",
    "        #fully connected (1,32,32)->class_size\n",
    "        self.linear = nn.Linear(1*32*32, code_size)\n",
    "    \n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net1(x)\n",
    "        x = self.sa(x)*x\n",
    "        x = self.net2(x)\n",
    "        x = self.dense(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "#https://github.com/luyajie/triplet-deep-hash-pytorch#triplet-deep-hash-pytorch            \n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=0.5):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin #margin threshold\n",
    "        self.mse_loss = nn.MSELoss(reduction='none')\n",
    "    \n",
    "    def forward(self,H_q,H_p,H_n):    \n",
    "        margin_val = self.margin * H_q.shape[1]\n",
    "        squared_loss_pos = torch.mean(self.mse_loss(H_q, H_p), dim=1)\n",
    "        squared_loss_neg = torch.mean(self.mse_loss(H_q, H_n), dim=1)\n",
    "        zeros = torch.zeros_like(squared_loss_neg)\n",
    "        loss  = torch.max(zeros, margin_val - squared_loss_neg + squared_loss_pos)\n",
    "        return torch.mean(loss)\n",
    "\n",
    "#Generate image pairs for model\n",
    "def onlineGenImgPairs( ):\n",
    "    idx_sf = []\n",
    "    idx_0 = np.where( np.array(trY) == 0 ) #class 0\n",
    "    idx_0 = list(idx_0[0])\n",
    "    idx_sf.extend(idx_0)\n",
    "    idx_1 = np.where( np.array(trY) == 1 ) #class 1\n",
    "    idx_1 = list(idx_1[0])\n",
    "    idx_sf.extend(idx_1)\n",
    "    idx_2 = np.where( np.array(trY) == 2 ) #class 2\n",
    "    idx_2 = list(idx_2[0])\n",
    "    idx_sf.extend(idx_2)\n",
    "    idx_3 = np.where( np.array(trY) == 3 ) #class 3\n",
    "    idx_3 = list(idx_3[0])\n",
    "    idx_sf.extend(idx_3)\n",
    "    idx_4 = np.where( np.array(trY) == 4 ) #class 4\n",
    "    idx_4 = list(idx_4[0])\n",
    "    idx_sf.extend(idx_4)\n",
    "    random.shuffle(idx_sf)   \n",
    "    trQ_sf, trP_sf, trN_sf = [], [], []\n",
    "    for iQ in idx_sf:\n",
    "        trQ_sf.append(trI[iQ])\n",
    "        if trY[iQ] == 0:\n",
    "            idx_tmp = idx_0.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_0))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "        elif trY[iQ] == 1:\n",
    "            idx_tmp = idx_1.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_1))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "        elif trY[iQ] == 2:\n",
    "            idx_tmp = idx_2.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_2))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "        elif trY[iQ] == 3:\n",
    "            idx_tmp = idx_3.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_3))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "        elif trY[iQ] == 4:\n",
    "            idx_tmp = idx_4.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_4))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "        else: pass\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(trQ_sf),len(idx_sf)))\n",
    "        sys.stdout.flush()\n",
    "    return np.array(trQ_sf),np.array(trP_sf),np.array(trN_sf)\n",
    "trQ_sf, trP_sf, trN_sf = onlineGenImgPairs() #sample \n",
    "assert (trQ_sf.shape==trP_sf.shape)\n",
    "assert (trQ_sf.shape==trN_sf.shape)\n",
    "\n",
    "#define model\n",
    "model = ATHNet(code_size=36).cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "criterion  = TripletLoss(margin=0.5).cuda() #define TripletLoss \n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(10):#iteration\n",
    "    losses = []\n",
    "    shuffled_idx = np.random.permutation(np.arange(len(trQ_sf)))\n",
    "    train_q = trQ_sf[shuffled_idx]\n",
    "    train_p = trP_sf[shuffled_idx]\n",
    "    train_n = trN_sf[shuffled_idx]\n",
    "    num_batches = len(trQ_sf) // batchSize +1\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trQ_sf), (i+1)*batchSize])\n",
    "        Q_batch = torch.from_numpy(train_q[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        P_batch = torch.from_numpy(train_p[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        N_batch = torch.from_numpy(train_n[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        #forword\n",
    "        Q_hash = model(Q_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        P_hash = model(P_batch.permute(0, 3, 1, 2))\n",
    "        N_hash = model(N_batch.permute(0, 3, 1, 2))\n",
    "        #binary-like loss\n",
    "        loss = criterion(Q_hash,P_hash,N_hash)\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "criterion=criterion.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "#hash code of train data from model\n",
    "#torch.cuda.synchronize()\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize +1\n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#hash code of test data from model\n",
    "#torch.cuda.synchronize()\n",
    "teF = []\n",
    "num_batches = len(teI) // batchSize \n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(teI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    teF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(36) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "for topk in [10]:#[5,10,15,20]:\n",
    "    MHR = [] #mean Hit ratio \n",
    "    MAP = [] #mean average precision\n",
    "    MRR = [] #mean reciprocal rank\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        scores, neighbors = gpu_index.search(np.array(teF)[i:i+1].astype('float32'), k=topk)\n",
    "        #map_item_score = {}\n",
    "        #for j, trVal in enumerate(trF):\n",
    "        #    map_item_score[j] = pdist(np.vstack([teVal,trVal]),'hamming')\n",
    "        #ranklist = heapq.nsmallest(topk, map_item_score, key=map_item_score.get)\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        mrr_flag = 0\n",
    "        #for j in ranklist:\n",
    "        for j in neighbors.flatten():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                MHR.append(1)\n",
    "                pos_len = pos_len +1\n",
    "                MAP.append(pos_len/rank_len) \n",
    "                if mrr_flag==0: \n",
    "                    MRR.append(pos_len/rank_len)\n",
    "                    mrr_flag =1\n",
    "            else: \n",
    "                MHR.append(0)\n",
    "                MAP.append(0)   \n",
    "    print(\"mHR@{}={:.6f}, mAP@{}={:.6f}, mRR@{}={:.6f}\".format(topk,np.mean(MHR),topk,np.mean(MAP), topk, np.mean(MRR)))\n",
    "#performance\n",
    "scores, neighbors = gpu_index.search(np.ascontiguousarray(teF, dtype=np.float32), k=1) #return top1\n",
    "y_pred = []\n",
    "for i in neighbors.flatten():\n",
    "    y_pred.append(np.array(trY)[i]) #label of top1\n",
    "print ( 'Accuracy: %.6f'%accuracy_score(teY, y_pred))\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, y_pred, labels=labels ) #labels=['0','1','2','3','4']\n",
    "print (cm)\n",
    "print ('Sensitivity of Level 0: %.6f'%float(cm[0][0]/np.sum(cm[0])))\n",
    "print ('Sensitivity of Level 1: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity of Level 2: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity of Level 3: %.6f'%float(cm[3][3]/np.sum(cm[3])))\n",
    "print ('Sensitivity of Level 4: %.6f'%float(cm[4][4]/np.sum(cm[4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 350 / 350 : loss = 4.992043Eopch:     1 mean_loss = 4.011516\n",
      " 350 / 350 : loss = 5.940256Eopch:     2 mean_loss = 3.081914\n",
      " 350 / 350 : loss = 2.591778Eopch:     3 mean_loss = 2.991618\n",
      " 350 / 350 : loss = 2.406147Eopch:     4 mean_loss = 2.776023\n",
      " 350 / 350 : loss = 2.090609Eopch:     5 mean_loss = 2.809472\n",
      " 350 / 350 : loss = 1.957647Eopch:     6 mean_loss = 2.773422\n",
      " 350 / 350 : loss = 4.076516Eopch:     7 mean_loss = 2.703397\n",
      " 350 / 350 : loss = 3.442056Eopch:     8 mean_loss = 2.664989\n",
      " 350 / 350 : loss = 1.545562Eopch:     9 mean_loss = 2.625064\n",
      " 350 / 350 : loss = 2.119313Eopch:    10 mean_loss = 2.557716\n",
      "best_loss = 2.557716\n",
      " 69 / 70 0 Completed buliding index in 1 seconds\n",
      "mHR@10=0.862714, mAP@10=0.830593, mRR@10=0.989713\n",
      "Accuracy: 0.981429\n",
      "[[190   1   5   2   0]\n",
      " [  1 135   0   0   0]\n",
      " [  3   0 164   0   0]\n",
      " [  1   0   0 148   0]\n",
      " [  0   0   0   0  50]]\n",
      "Sensitivity of Level 0: 0.959596\n",
      "Sensitivity of Level 1: 0.992647\n",
      "Sensitivity of Level 2: 0.982036\n",
      "Sensitivity of Level 3: 0.993289\n",
      "Sensitivity of Level 4: 1.000000\n"
     ]
    }
   ],
   "source": [
    "#ATH model with pairwise loss\n",
    "class SpatialAttention(nn.Module):#spatial attention layer\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels, out_channels=out_channels,\n",
    "                kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        self.downsample_layer = None\n",
    "        self.do_downsample = False\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.do_downsample = True\n",
    "            self.downsample_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.net(x)\n",
    "\n",
    "        if self.do_downsample:\n",
    "            identity = self.downsample_layer(x)\n",
    "\n",
    "        return F.relu(out + identity, inplace=True) #resnet\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            \n",
    "class ATHNet(nn.Module):\n",
    "    def __init__(self, code_size: int):\n",
    "        super().__init__()\n",
    "        #resnet and maxpool\n",
    "        self.net1 = nn.Sequential(#(3,256,256)->(16,128,128)\n",
    "            ResBlock(in_channels=3, out_channels=16, stride=2), \n",
    "            nn.MaxPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        )\n",
    "        \n",
    "        #Attention (16,128,128)->(16,128,128)\n",
    "        self.sa = SpatialAttention()\n",
    "        \n",
    "        #resnet and meanpool\n",
    "        self.net2 =nn.Sequential( #(16,128,128)->(8,64,64)\n",
    "            ResBlock(in_channels=16, out_channels=8, stride=2),\n",
    "            nn.AvgPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        ) \n",
    "         \n",
    "        #fully connected with conv (8,64,64)->(1,32,32)\n",
    "        self.dense=ResBlock(in_channels=8, out_channels=1, stride=2)\n",
    "        #fully connected (1,32,32)->class_size\n",
    "        self.linear = nn.Linear(1*32*32, code_size)\n",
    "    \n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net1(x)\n",
    "        x = self.sa(x)*x\n",
    "        x = self.net2(x)\n",
    "        x = self.dense(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "#define loss function:pairwise loss            \n",
    "class PairwiseLoss(nn.Module):\n",
    "    def __init__(self, margin=0.5, alpha=0.01):\n",
    "        super(PairwiseLoss, self).__init__()\n",
    "        self.alpha = alpha #regularization\n",
    "        self.margin = margin #margin threshold\n",
    "        self.mse_loss = nn.MSELoss(reduction='none')\n",
    "        self.l1_loss = nn.L1Loss(reduction='mean')\n",
    "    \n",
    "    def forward(self,h1,h2,y):    \n",
    "        margin_val = self.margin * h1.shape[1]\n",
    "        squared_loss = torch.mean(self.mse_loss(h1, h2), dim=1)\n",
    "        # T1: 0.5 * (1 - y) * dist(x1, x2)\n",
    "        positive_pair_loss = (0.5 * (1 - y) * squared_loss)\n",
    "        mean_positive_pair_loss = torch.mean(positive_pair_loss)\n",
    "        # T2: 0.5 * y * max(margin - dist(x1, x2), 0)\n",
    "        zeros = torch.zeros_like(squared_loss)\n",
    "        marginMat = margin_val * torch.ones_like(squared_loss)\n",
    "        negative_pair_loss = 0.5 * y * torch.max(zeros, marginMat - squared_loss)\n",
    "        mean_negative_pair_loss = torch.mean(negative_pair_loss)\n",
    "\n",
    "        # T3: alpha(dst_l1(abs(x1), 1)) + dist_l1(abs(x2), 1)))\n",
    "        mean_value_regularization = self.alpha * (\n",
    "                self.l1_loss(torch.abs(h1), torch.ones_like(h1)) +\n",
    "                self.l1_loss(torch.abs(h2), torch.ones_like(h2)))\n",
    "\n",
    "        loss = mean_positive_pair_loss + mean_negative_pair_loss + mean_value_regularization\n",
    "        return loss\n",
    "\n",
    "#Generate image pairs for model\n",
    "def onlineGenImgPairs():\n",
    "    if (len(trY) % 2) == 0: spls = len(trY)\n",
    "    else:  spls = len(trY)-1\n",
    "    idx_sf = random.sample(range(0, spls),spls)\n",
    "    trI1_sf, trI2_sf, trY1_sf, trY2_sf = [],[],[],[]\n",
    "    flag = 0\n",
    "    for i in idx_sf:\n",
    "        if flag==0:\n",
    "            trI1_sf.append(trI[i])\n",
    "            trY1_sf.append(trY[i])\n",
    "            flag =1\n",
    "        else:\n",
    "            trI2_sf.append(trI[i])\n",
    "            trY2_sf.append(trY[i])\n",
    "            flag =0\n",
    "    trY_sf = np.where((np.array(trY1_sf)-np.array(trY2_sf))!=0,1,0)\n",
    "    return np.array(trI1_sf),np.array(trI2_sf),trY_sf\n",
    "\n",
    "#define model\n",
    "model = ATHNet(code_size=36).cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "criterion  = PairwiseLoss(margin=0.5).cuda() #define PairwiseLoss \n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(10):#iteration\n",
    "    trI1_sf, trI2_sf, trY_sf = onlineGenImgPairs()\n",
    "    losses = []\n",
    "    num_batches = len(trY_sf) // batchSize +1\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY_sf), (i+1)*batchSize])\n",
    "        I1_batch = torch.from_numpy(trI1_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        I2_batch = torch.from_numpy(trI2_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        Y_batch = torch.from_numpy(trY_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        #forword\n",
    "        X1_batch = model(I1_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        X2_batch = model(I2_batch.permute(0, 3, 1, 2))\n",
    "        #binary-like loss\n",
    "        loss = criterion(X1_batch,X2_batch,Y_batch)\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "criterion=criterion.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "#hash code of train data from model\n",
    "#torch.cuda.synchronize()\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize +1\n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#hash code of test data from model\n",
    "#torch.cuda.synchronize()\n",
    "teF = []\n",
    "num_batches = len(teI) // batchSize \n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(teI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    teF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(36) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "for topk in [10]:#[5,10,15,20]:\n",
    "    MHR = [] #mean Hit ratio \n",
    "    MAP = [] #mean average precision\n",
    "    MRR = [] #mean reciprocal rank\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        scores, neighbors = gpu_index.search(np.array(teF)[i:i+1].astype('float32'), k=topk)\n",
    "        #map_item_score = {}\n",
    "        #for j, trVal in enumerate(trF):\n",
    "        #    map_item_score[j] = pdist(np.vstack([teVal,trVal]),'hamming')\n",
    "        #ranklist = heapq.nsmallest(topk, map_item_score, key=map_item_score.get)\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        mrr_flag = 0\n",
    "        #for j in ranklist:\n",
    "        for j in neighbors.flatten():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                MHR.append(1)\n",
    "                pos_len = pos_len +1\n",
    "                MAP.append(pos_len/rank_len) \n",
    "                if mrr_flag==0: \n",
    "                    MRR.append(pos_len/rank_len)\n",
    "                    mrr_flag =1\n",
    "            else: \n",
    "                MHR.append(0)\n",
    "                MAP.append(0)   \n",
    "    print(\"mHR@{}={:.6f}, mAP@{}={:.6f}, mRR@{}={:.6f}\".format(topk,np.mean(MHR),topk,np.mean(MAP), topk, np.mean(MRR)))\n",
    "#performance\n",
    "scores, neighbors = gpu_index.search(np.ascontiguousarray(teF, dtype=np.float32), k=1) #return top1\n",
    "y_pred = []\n",
    "for i in neighbors.flatten():\n",
    "    y_pred.append(np.array(trY)[i]) #label of top1\n",
    "print ( 'Accuracy: %.6f'%accuracy_score(teY, y_pred))\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, y_pred, labels=labels ) #labels=['0','1','2','3','4']\n",
    "print (cm)\n",
    "print ('Sensitivity of Level 0: %.6f'%float(cm[0][0]/np.sum(cm[0])))\n",
    "print ('Sensitivity of Level 1: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity of Level 2: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity of Level 3: %.6f'%float(cm[3][3]/np.sum(cm[3])))\n",
    "print ('Sensitivity of Level 4: %.6f'%float(cm[4][4]/np.sum(cm[4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 700 / 700 : loss = 0.120042Eopch:     1 mean_loss = 0.182220\n",
      " 700 / 700 : loss = 0.191352Eopch:     2 mean_loss = 0.107954\n",
      " 700 / 700 : loss = 0.098527Eopch:     3 mean_loss = 0.074431\n",
      " 700 / 700 : loss = 0.030611Eopch:     4 mean_loss = 0.058185\n",
      " 700 / 700 : loss = 0.073638Eopch:     5 mean_loss = 0.048744\n",
      " 700 / 700 : loss = 0.034875Eopch:     6 mean_loss = 0.043287\n",
      " 700 / 700 : loss = 0.111056Eopch:     7 mean_loss = 0.037282\n",
      " 700 / 700 : loss = 0.027236Eopch:     8 mean_loss = 0.031604\n",
      " 700 / 700 : loss = 0.026439Eopch:     9 mean_loss = 0.030225\n",
      " 700 / 700 : loss = 0.006712Eopch:    10 mean_loss = 0.026635\n",
      "best_loss = 0.026635\n",
      " 69 / 70 0 Completed buliding index in 2 seconds\n",
      "mHR@10=0.925714, mAP@10=0.917287, mRR@10=0.997258\n",
      "Accuracy: 0.788571\n",
      "[[155  22  16   5   0]\n",
      " [ 17 106   5   7   1]\n",
      " [ 32   1 130   3   1]\n",
      " [ 17   7   3 117   5]\n",
      " [  6   0   0   0  44]]\n",
      "Sensitivity of Level 0: 0.782828\n",
      "Sensitivity of Level 1: 0.779412\n",
      "Sensitivity of Level 2: 0.778443\n",
      "Sensitivity of Level 3: 0.785235\n",
      "Sensitivity of Level 4: 0.880000\n"
     ]
    }
   ],
   "source": [
    "#ATH model with focal loss\n",
    "class SpatialAttention(nn.Module):#spatial attention layer\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels, out_channels=out_channels,\n",
    "                kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        self.downsample_layer = None\n",
    "        self.do_downsample = False\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.do_downsample = True\n",
    "            self.downsample_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.net(x)\n",
    "\n",
    "        if self.do_downsample:\n",
    "            identity = self.downsample_layer(x)\n",
    "\n",
    "        return F.relu(out + identity, inplace=True) #resnet\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            \n",
    "class ATHNet(nn.Module):\n",
    "    def __init__(self, class_size: int):\n",
    "        super().__init__()\n",
    "        #resnet and maxpool\n",
    "        self.net1 = nn.Sequential(#(3,256,256)->(16,128,128)\n",
    "            ResBlock(in_channels=3, out_channels=16, stride=2), \n",
    "            nn.MaxPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        )\n",
    "        \n",
    "        #Attention (16,128,128)->(16,128,128)\n",
    "        self.sa = SpatialAttention()\n",
    "        \n",
    "        #resnet and meanpool\n",
    "        self.net2 =nn.Sequential( #(16,128,128)->(8,64,64)\n",
    "            ResBlock(in_channels=16, out_channels=8, stride=2),\n",
    "            nn.AvgPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        ) \n",
    "         \n",
    "        #fully connected with conv (8,64,64)->(1,32,32)\n",
    "        self.dense=ResBlock(in_channels=8, out_channels=1, stride=2)\n",
    "        #fully connected (1,32,32)->class_size\n",
    "        self.linear = nn.Linear(1*32*32, class_size)\n",
    "    \n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net1(x)\n",
    "        x = self.sa(x)*x\n",
    "        x = self.net2(x)\n",
    "        x = self.dense(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        out = self.linear(x)\n",
    "        return x,out\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "#https://github.com/marvis/pytorch-yolo2/blob/master/FocalLoss.py\n",
    "#https://github.com/clcarwin/focal_loss_pytorch/blob/master/focalloss.py\n",
    "class FocalLoss(nn.Module):\n",
    "    #Loss(x, class) = - \\alpha (1-softmax(x)[class])^gamma \\log(softmax(x)[class])\n",
    "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n",
    "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, out, y):\n",
    "        y = y.view(-1,1)\n",
    "        logpt = F.log_softmax(out,dim=1)#default ,dim=1\n",
    "        logpt = logpt.gather(1,y)# dim=1, index=y, max\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = Variable(logpt.data.exp())\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type()!=out.data.type():\n",
    "                self.alpha = self.alpha.type_as(out.data)\n",
    "            at = self.alpha.gather(0,y.data.view(-1))\n",
    "            logpt = logpt * Variable(at)\n",
    "\n",
    "        loss = -1 * (1-pt)**self.gamma * logpt\n",
    "        if self.size_average: return loss.mean()\n",
    "        else: return loss.sum()\n",
    "        \n",
    "#define model\n",
    "model = ATHNet(class_size=5).cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "criterion  = FocalLoss(gamma=2,alpha=[0.25,0.25,0.25,0.25,0.25]).cuda() #define ce mutli-classes, \n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "trI = np.array(trI)\n",
    "trY = np.array(trY)\n",
    "for epoch in range(10):#iteration\n",
    "    losses = []\n",
    "    shuffled_idx = np.random.permutation(np.arange(len(trY)))\n",
    "    train_x = trI[shuffled_idx]\n",
    "    train_y = trY[shuffled_idx]\n",
    "    num_batches = len(trY) // batchSize +1\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY), (i+1)*batchSize])\n",
    "        x_batch = torch.from_numpy(train_x[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        y_batch = torch.from_numpy(train_y[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        #forword\n",
    "        _, out_batch = model(x_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        loss = criterion(out_batch,y_batch) #F.log_softmax+F.nll_loss\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "criterion = criterion.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "#torch.cuda.synchronize()\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize +1\n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    feature, _ = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    feature = feature.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(feature.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "teY_pred = []\n",
    "teF = [] \n",
    "num_batches = len(teY) // batchSize \n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    feature, out_batch = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    teF.extend(feature.cpu().data.numpy().tolist()) #record feature\n",
    "    out_batch = F.log_softmax(out_batch,dim=1) \n",
    "    pred = out_batch.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(pred.cpu().data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(32*32) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "for topk in [10]:#[5,10,15,20]:\n",
    "    MHR = [] #mean Hit ratio \n",
    "    MAP = [] #mean average precision\n",
    "    MRR = [] #mean reciprocal rank\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        scores, neighbors = gpu_index.search(np.array(teF)[i:i+1].astype('float32'), k=topk)\n",
    "        #map_item_score = {}\n",
    "        #for j, trVal in enumerate(trF):\n",
    "        #    map_item_score[j] = pdist(np.vstack([teVal,trVal]),'hamming')\n",
    "        #ranklist = heapq.nsmallest(topk, map_item_score, key=map_item_score.get)\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        mrr_flag = 0\n",
    "        #for j in ranklist:\n",
    "        for j in neighbors.flatten():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                MHR.append(1)\n",
    "                pos_len = pos_len +1\n",
    "                MAP.append(pos_len/rank_len) \n",
    "                if mrr_flag==0: \n",
    "                    MRR.append(pos_len/rank_len)\n",
    "                    mrr_flag =1\n",
    "            else: \n",
    "                MHR.append(0)\n",
    "                MAP.append(0)   \n",
    "    print(\"mHR@{}={:.6f}, mAP@{}={:.6f}, mRR@{}={:.6f}\".format(topk,np.mean(MHR),topk,np.mean(MAP), topk, np.mean(MRR)))\n",
    "\n",
    "#confusion matrix\n",
    "print ( 'Accuracy: %.6f'%accuracy_score(teY, teY_pred))\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, teY_pred, labels=labels ) #labels=['0','1','2','3','4']\n",
    "print (cm)\n",
    "print ('Sensitivity of Level 0: %.6f'%float(cm[0][0]/np.sum(cm[0])))\n",
    "print ('Sensitivity of Level 1: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity of Level 2: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity of Level 3: %.6f'%float(cm[3][3]/np.sum(cm[3])))\n",
    "print ('Sensitivity of Level 4: %.6f'%float(cm[4][4]/np.sum(cm[4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 700 / 700 : loss = 0.739072Eopch:     1 mean_loss = 1.187998\n",
      " 700 / 700 : loss = 1.318123Eopch:     2 mean_loss = 0.784576\n",
      " 700 / 700 : loss = 1.165577Eopch:     3 mean_loss = 0.632328\n",
      " 700 / 700 : loss = 0.217673Eopch:     4 mean_loss = 0.542153\n",
      " 700 / 700 : loss = 1.114526Eopch:     5 mean_loss = 0.474634\n",
      " 700 / 700 : loss = 0.207522Eopch:     6 mean_loss = 0.415868\n",
      " 700 / 700 : loss = 0.348246Eopch:     7 mean_loss = 0.380798\n",
      " 700 / 700 : loss = 0.255347Eopch:     8 mean_loss = 0.338175\n",
      " 700 / 700 : loss = 0.096127Eopch:     9 mean_loss = 0.303433\n",
      " 700 / 700 : loss = 0.445111Eopch:    10 mean_loss = 0.276612\n",
      "best_loss = 0.276612\n",
      " 69 / 70 0 Completed buliding index in 2 seconds\n",
      "mHR@10=0.939000, mAP@10=0.931118, mRR@10=0.997377\n",
      "Accuracy: 0.767143\n",
      "[[148  10  14  23   3]\n",
      " [ 18  90  13  15   0]\n",
      " [ 21   4 127  14   1]\n",
      " [  8   4   1 135   1]\n",
      " [  7   0   3   3  37]]\n",
      "Sensitivity of Level 0: 0.747475\n",
      "Sensitivity of Level 1: 0.661765\n",
      "Sensitivity of Level 2: 0.760479\n",
      "Sensitivity of Level 3: 0.906040\n",
      "Sensitivity of Level 4: 0.740000\n"
     ]
    }
   ],
   "source": [
    "#ATH model with cross entropy loss\n",
    "class SpatialAttention(nn.Module):#spatial attention layer\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels, out_channels=out_channels,\n",
    "                kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        self.downsample_layer = None\n",
    "        self.do_downsample = False\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.do_downsample = True\n",
    "            self.downsample_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.net(x)\n",
    "\n",
    "        if self.do_downsample:\n",
    "            identity = self.downsample_layer(x)\n",
    "\n",
    "        return F.relu(out + identity, inplace=True) #resnet\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            \n",
    "class ATHNet(nn.Module):\n",
    "    def __init__(self, class_size: int):\n",
    "        super().__init__()\n",
    "        #resnet and maxpool\n",
    "        self.net1 = nn.Sequential(#(3,256,256)->(16,128,128)\n",
    "            ResBlock(in_channels=3, out_channels=16, stride=2), \n",
    "            nn.MaxPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        )\n",
    "        \n",
    "        #Attention (16,128,128)->(16,128,128)\n",
    "        self.sa = SpatialAttention()\n",
    "        \n",
    "        #resnet and meanpool\n",
    "        self.net2 =nn.Sequential( #(16,128,128)->(8,64,64)\n",
    "            ResBlock(in_channels=16, out_channels=8, stride=2),\n",
    "            nn.AvgPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        ) \n",
    "         \n",
    "        #fully connected with conv (8,64,64)->(1,32,32)\n",
    "        self.dense=ResBlock(in_channels=8, out_channels=1, stride=2)\n",
    "        #fully connected (1,32,32)->class_size\n",
    "        self.linear = nn.Linear(1*32*32, class_size)\n",
    "    \n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net1(x)\n",
    "        x = self.sa(x)*x\n",
    "        x = self.net2(x)\n",
    "        x = self.dense(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        out = self.linear(x)\n",
    "        return x,out\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "#define model\n",
    "model = ATHNet(class_size=5).cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "criterion  = nn.CrossEntropyLoss().cuda() #define ce mutli-classes\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "trI = np.array(trI)\n",
    "trY = np.array(trY)\n",
    "for epoch in range(10):#iteration\n",
    "    losses = []\n",
    "    shuffled_idx = np.random.permutation(np.arange(len(trY)))\n",
    "    train_x = trI[shuffled_idx]\n",
    "    train_y = trY[shuffled_idx]\n",
    "    num_batches = len(trY) // batchSize + 1\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY), (i+1)*batchSize])\n",
    "        x_batch = torch.from_numpy(train_x[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        y_batch = torch.from_numpy(train_y[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        #forword\n",
    "        _,out_batch = model(x_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        loss = criterion(out_batch,y_batch) #F.log_softmax+F.nll_loss\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "criterion = criterion.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "#torch.cuda.synchronize()\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize+1\n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    feature, _ = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    feature = feature.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(feature.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "teY_pred = []\n",
    "teF = [] \n",
    "num_batches = len(teY) // batchSize \n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    feature, out_batch = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    teF.extend(feature.cpu().data.numpy().tolist()) #record feature\n",
    "    out_batch = F.log_softmax(out_batch,dim=1) \n",
    "    pred = out_batch.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(pred.cpu().data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(32*32) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "for topk in [10]:#[5,10,15,20]:\n",
    "    MHR = [] #mean Hit ratio \n",
    "    MAP = [] #mean average precision\n",
    "    MRR = [] #mean reciprocal rank\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        scores, neighbors = gpu_index.search(np.array(teF)[i:i+1].astype('float32'), k=topk)\n",
    "        #map_item_score = {}\n",
    "        #for j, trVal in enumerate(trF):\n",
    "        #    map_item_score[j] = pdist(np.vstack([teVal,trVal]),'hamming')\n",
    "        #ranklist = heapq.nsmallest(topk, map_item_score, key=map_item_score.get)\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        mrr_flag = 0\n",
    "        #for j in ranklist:\n",
    "        for j in neighbors.flatten():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                MHR.append(1)\n",
    "                pos_len = pos_len +1\n",
    "                MAP.append(pos_len/rank_len) \n",
    "                if mrr_flag==0: \n",
    "                    MRR.append(pos_len/rank_len)\n",
    "                    mrr_flag =1\n",
    "            else: \n",
    "                MHR.append(0)\n",
    "                MAP.append(0)   \n",
    "    print(\"mHR@{}={:.6f}, mAP@{}={:.6f}, mRR@{}={:.6f}\".format(topk,np.mean(MHR),topk,np.mean(MAP), topk, np.mean(MRR)))\n",
    "\n",
    "#confusion matrix\n",
    "print ( 'Accuracy: %.6f'%accuracy_score(teY, teY_pred))\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, teY_pred, labels=labels ) #labels=['0','1','2','3','4']\n",
    "print (cm)\n",
    "print ('Sensitivity of Level 0: %.6f'%float(cm[0][0]/np.sum(cm[0])))\n",
    "print ('Sensitivity of Level 1: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity of Level 2: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity of Level 3: %.6f'%float(cm[3][3]/np.sum(cm[3])))\n",
    "print ('Sensitivity of Level 4: %.6f'%float(cm[4][4]/np.sum(cm[4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Org data dimension is 1024.Embedded data dimension is 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize : t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import random\n",
    "def scatter(X, y):\n",
    "    #X,y:numpy-array\n",
    "    classes = len(list(set(y.tolist())))#get number of classes\n",
    "    #palette = np.array(sns.color_palette(\"hls\", classes))# choose a color palette with seaborn.\n",
    "    color = ['c','y','m','b','g','r']\n",
    "    marker = ['o','x','+','*','s']\n",
    "    plt.figure(figsize=(8,8))#create a plot\n",
    "    for i in range(classes):\n",
    "        plt.scatter(X[y == i,0], X[y == i,1], c=color[i], marker=marker[i], label=str(i))\n",
    "    plt.axis('off')\n",
    "    plt.legend(loc='upper left')\n",
    "    #plt.savefig('digits_tsne-generated.png', dpi=100)\n",
    "    plt.show()\n",
    "\n",
    "#prepare data，classes=5\n",
    "#idx= random.sample(np.where(np.array(teY)==0)[0].tolist(),100)\n",
    "idx= np.where(np.array(teY)==0)[0].tolist()\n",
    "X0= np.array(teF)[idx]\n",
    "y0= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==1)[0].tolist()\n",
    "X1= np.array(teF)[idx]\n",
    "y1= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==2)[0].tolist()\n",
    "X2= np.array(teF)[idx]\n",
    "y2= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==3)[0].tolist()\n",
    "X3= np.array(teF)[idx]\n",
    "y3= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==4)[0].tolist()\n",
    "X4= np.array(teF)[idx]\n",
    "y4= np.array(teY)[idx]\n",
    "\n",
    "y = np.append(y0,y1)\n",
    "y = np.append(y,y2)\n",
    "y = np.append(y,y3)\n",
    "y = np.append(y,y4)\n",
    "X = np.vstack((X0,X1))\n",
    "X = np.vstack((X,X2))\n",
    "X = np.vstack((X,X3))\n",
    "X = np.vstack((X,X4))\n",
    "#training t-sne \n",
    "tsne = TSNE(n_components=2, init='pca', random_state=501)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "print(\"Org data dimension is {}.Embedded data dimension is {}\".format(X.shape[-1], X_tsne.shape[-1]))\n",
    "\n",
    "#visualize\n",
    "scatter(X_tsne, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real label:0\n",
      "0.861 -> Level 1\n",
      "0.125 -> Leve 2\n",
      "0.012 -> Level 3\n",
      "0.001 -> Level 4\n",
      "0.000 -> Level 5\n",
      "output CAM.jpg for the top1 prediction: Level 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate class activation mapping for the top1 prediction\n",
    "def returnCAM(feature_conv, weight_softmax, class_idx):\n",
    "    # generate the class activation maps upsample to 256x256\n",
    "    size_upsample = (256, 256)\n",
    "    bz, nc, h, w = feature_conv.shape\n",
    "    \n",
    "    output_cam = []\n",
    "    for idx in class_idx:\n",
    "        #cam = weight_softmax[class_idx].dot(feature_conv.reshape((nc,h*w)))\n",
    "        cam = weight_softmax[class_idx]*(feature_conv.reshape((nc,h*w)))\n",
    "        cam = cam.reshape(h, w)\n",
    "        cam = cam - np.min(cam)\n",
    "        cam_img = cam / np.max(cam)\n",
    "        cam_img = np.uint8(255 * cam_img)\n",
    "        output_cam.append(cv2.resize(cam_img, size_upsample))\n",
    "    return output_cam\n",
    "\n",
    "\n",
    "# hook the feature extractor\n",
    "features_blobs = []\n",
    "def hook_feature(module, input, output):\n",
    "    features_blobs.append(output.data.cpu().numpy())\n",
    "#last conv layer followed with one channel by last fully connected layer\n",
    "final_conv = 'dense' \n",
    "best_net._modules.get(final_conv).register_forward_hook(hook_feature)\n",
    "#get weights parameters\n",
    "params = list(best_net.parameters())\n",
    "#get the last and second last weights, like [classes, hiden nodes]\n",
    "weight_softmax = np.squeeze(params[-2].data.cpu().numpy()) \n",
    "# define class type\n",
    "classes = {0: 'Level 1', 1: 'Leve 2', 2:'Level 3', 3:'Level 4', 4:'Level 5'}\n",
    "#read image\n",
    "root = os.path.join(image_dir, teN[0])\n",
    "print('real label:%d'%(teY[0]))\n",
    "img = []\n",
    "img.append( cv2.resize(cv2.imread(root).astype(np.float32), (256, 256)))#(256, 256) is the model input size\n",
    "data = torch.from_numpy(np.array(img)).type(torch.FloatTensor).cuda()\n",
    "_,logit = best_net(data.permute(0, 3, 1, 2))#forword\n",
    "h_x = F.softmax(logit, dim=1).data.squeeze()#softmax\n",
    "probs, idx = h_x.sort(0, True) #probabilities of classes\n",
    "\n",
    "# output: the prediction\n",
    "for i in range(0, len(classes)):\n",
    "    line = '{:.3f} -> {}'.format(probs[i], classes[idx[i].item()])\n",
    "    print(line)\n",
    "#get the class activation maps\n",
    "CAMs = returnCAM(features_blobs[0], weight_softmax, [idx[0].item()])\n",
    "\n",
    "# render the CAM and show\n",
    "print('output CAM.jpg for the top1 prediction: %s' % classes[idx[0].item()])\n",
    "img = cv2.imread(root)\n",
    "height, width, _ = img.shape\n",
    "CAM = cv2.resize(CAMs[0], (width, height))\n",
    "heatmap = cv2.applyColorMap(CAM, cv2.COLORMAP_JET)\n",
    "result = heatmap * 0.3 + img * 0.5\n",
    "cv2.imwrite('Cataract_cam.jpg', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
