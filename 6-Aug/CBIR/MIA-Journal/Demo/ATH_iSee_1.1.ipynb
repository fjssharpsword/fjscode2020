{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.Develop Env: linux+cuda9+python3+opencv+pytorch\n",
    "2.Dataset: Fundus-iSee with 10000 images(AMD-720, DR-270, glaucoma-450,myopia-790,norm-7770)\n",
    "        trainset(9000): AMD-648, DR-243, glaucoma-405, myopia-711, norm-6993, \n",
    "        testset(1000): AMD-72, DR-27, glaucoma-45, myopia-79, norm=777\n",
    "3.Performance Metric: \n",
    "  1)Accuracy(Acc):  for evaluating the precison of top 1 in the returned list;\n",
    "  2)Specificity(Spe): for evaluating the misdiagnosis rate of normal\n",
    "  3)Sensitivity(Sen): for evaluating the missed diagnosis rate of abnorml(S,V,F)\n",
    "4.Algorithm: Attention-based Triplet Hashing Network(ATH), Cross-loss(Focal+Triplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading faiss with AVX2 support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "from PIL import Image\n",
    "from io import StringIO,BytesIO \n",
    "from scipy.spatial.distance import pdist\n",
    "import cv2\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc \n",
    "from functools import reduce\n",
    "import wfdb#https://github.com/MIT-LCP/wfdb-python\n",
    "from wfdb import processing\n",
    "import faiss \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "torch.cuda.set_device(1)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000 / 9000 The length of train set is 9000\n",
      "1000 / 1000 The length of test set is 1000\n",
      "Completed data handle in 773 seconds\n"
     ]
    }
   ],
   "source": [
    "#Read data with List storage Name:[name],I:[img],Y[type]\n",
    "def TypetoNum(itype): #map the type into number.\n",
    "    if itype =='AMD': return 0\n",
    "    elif itype =='DR': return 1\n",
    "    elif itype =='glaucoma': return 2\n",
    "    elif itype =='myopia': return 3\n",
    "    else: return 4 #norm\n",
    "    \n",
    "root_dir = '/data/fjsdata/fundus/iSee/iSee_multi_dataset/' #the path of images\n",
    "trainset = pd.read_csv(\"/data/fjsdata/fundus/iSee/iSee_multi_dataset/CBIR_iSee_train.csv\" , sep=',')#load trainset\n",
    "testset = pd.read_csv(\"/data/fjsdata/fundus/iSee/iSee_multi_dataset/CBIR_iSee_test.csv\" , sep=',')#load testset\n",
    "tstart = time.time()\n",
    "#read train image with CV\n",
    "trN, trI, trY = [],[],[]\n",
    "norm = 6993\n",
    "for iname, itype in np.array(trainset).tolist():\n",
    "    if iname.endswith(\".jpg\"):\n",
    "        try:\n",
    "            image_dir = root_dir+'img_data_%s'%itype\n",
    "            image_path = os.path.join(image_dir, iname)\n",
    "            if itype == 'norm':\n",
    "                if norm>0:\n",
    "                    img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(1920,1920,3)->(256,256,3)\n",
    "                    trN.append(iname)\n",
    "                    trI.append(img)\n",
    "                    trY.append(TypetoNum(itype))\n",
    "                    norm = norm - 1\n",
    "            else:\n",
    "                img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(1920,1920,3)->(256,256,3)\n",
    "                trN.append(iname)\n",
    "                trI.append(img)\n",
    "                trY.append(TypetoNum(itype))    \n",
    "        except:\n",
    "            print(iname+\":\"+str(image_path))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(trN),trainset.shape[0]))\n",
    "        sys.stdout.flush()\n",
    "print('The length of train set is %d'%len(trN))\n",
    "#read test image with CV\n",
    "teN, teI, teY = [],[],[]\n",
    "norm = 777\n",
    "for iname, itype in np.array(testset).tolist():\n",
    "    if iname.endswith(\".jpg\"):\n",
    "        try:\n",
    "            image_dir = root_dir+'img_data_%s'%itype\n",
    "            image_path = os.path.join(image_dir, iname)\n",
    "            if itype == 'norm':\n",
    "                if norm>0:\n",
    "                    img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(1920,1920,3)->(256,256,3)\n",
    "                    teN.append(iname)\n",
    "                    teI.append(img)\n",
    "                    teY.append(TypetoNum(itype))\n",
    "                    norm = norm - 1\n",
    "            else:\n",
    "                img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(1920,1920,3)->(256,256,3)\n",
    "                teN.append(iname)\n",
    "                teI.append(img)\n",
    "                teY.append(TypetoNum(itype)) \n",
    "        except:\n",
    "            print(iname+\":\"+str(image_path))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(teN),testset.shape[0]))\n",
    "        sys.stdout.flush()\n",
    "print('The length of test set is %d'%len(teN))\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed data handle in %d seconds' % int(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 900 / 900 : loss = 20.701817Eopch:     1 mean_loss = 17.098784\n",
      " 900 / 900 : loss = 16.607653Eopch:     2 mean_loss = 16.167664\n",
      " 900 / 900 : loss = 15.191724Eopch:     3 mean_loss = 15.619937\n",
      " 900 / 900 : loss = 16.948387Eopch:     4 mean_loss = 14.689277\n",
      " 900 / 900 : loss = 14.159218Eopch:     5 mean_loss = 13.306673\n",
      " 900 / 900 : loss = 11.576347Eopch:     6 mean_loss = 11.370548\n",
      " 900 / 900 : loss = 0.1148246Eopch:     7 mean_loss = 9.443250\n",
      " 900 / 900 : loss = 9.8200762Eopch:     8 mean_loss = 7.888464\n",
      " 900 / 900 : loss = 8.8942259Eopch:     9 mean_loss = 6.407361\n",
      " 900 / 900 : loss = 5.4244741Eopch:    10 mean_loss = 5.439723\n",
      "best_loss = 5.439723\n",
      " 99 / 100  Completed buliding index in 23 seconds\n",
      "mHR@10=0.737400, mAP@10=0.687811, mRR@10=0.901891\n",
      "Accuracy: 0.746000\n",
      "[[  3   1   7   4  57]\n",
      " [  3   0   0   1  23]\n",
      " [  4   2   1   2  36]\n",
      " [ 11   2   3  21  42]\n",
      " [ 24   6  15  11 721]]\n",
      "Specificity of normal: 0.927928\n",
      "Sensitivity of AMD: 0.041667\n",
      "Sensitivity of DR: 0.000000\n",
      "Sensitivity of glaucoma: 0.022222\n",
      "Sensitivity of myopia: 0.265823\n"
     ]
    }
   ],
   "source": [
    "#ATH model with Tripet loss\n",
    "class SpatialAttention(nn.Module):#spatial attention layer\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels, out_channels=out_channels,\n",
    "                kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        self.downsample_layer = None\n",
    "        self.do_downsample = False\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.do_downsample = True\n",
    "            self.downsample_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.net(x)\n",
    "\n",
    "        if self.do_downsample:\n",
    "            identity = self.downsample_layer(x)\n",
    "\n",
    "        return F.relu(out + identity, inplace=True) #resnet\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            \n",
    "class ATHNet(nn.Module):\n",
    "    def __init__(self, code_size: int):\n",
    "        super().__init__()\n",
    "        #resnet and maxpool\n",
    "        self.net1 = nn.Sequential(#(3,256,256)->(16,128,128)\n",
    "            ResBlock(in_channels=3, out_channels=16, stride=2), \n",
    "            nn.MaxPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        )\n",
    "        \n",
    "        #Attention (16,128,128)->(16,128,128)\n",
    "        self.sa = SpatialAttention()\n",
    "        \n",
    "        #resnet and meanpool\n",
    "        self.net2 =nn.Sequential( #(16,128,128)->(8,64,64)\n",
    "            ResBlock(in_channels=16, out_channels=8, stride=2),\n",
    "            nn.AvgPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        ) \n",
    "         \n",
    "        #fully connected with conv (8,64,64)->(1,32,32)\n",
    "        self.dense=ResBlock(in_channels=8, out_channels=1, stride=2)\n",
    "        #fully connected (1,32,32)->class_size\n",
    "        self.linear = nn.Linear(1*32*32, code_size)\n",
    "    \n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net1(x)\n",
    "        x = self.sa(x)*x\n",
    "        x = self.net2(x)\n",
    "        x = self.dense(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "#https://github.com/luyajie/triplet-deep-hash-pytorch#triplet-deep-hash-pytorch            \n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=0.5):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin #margin threshold\n",
    "        self.mse_loss = nn.MSELoss(reduction='none')\n",
    "    \n",
    "    def forward(self,H_q,H_p,H_n):    \n",
    "        margin_val = self.margin * H_q.shape[1]\n",
    "        squared_loss_pos = torch.mean(self.mse_loss(H_q, H_p), dim=1)\n",
    "        squared_loss_neg = torch.mean(self.mse_loss(H_q, H_n), dim=1)\n",
    "        zeros = torch.zeros_like(squared_loss_neg)\n",
    "        loss  = torch.max(zeros, margin_val - squared_loss_neg + squared_loss_pos)\n",
    "        return torch.mean(loss)\n",
    "\n",
    "#Generate image pairs for model\n",
    "def onlineGenImgPairs( ):\n",
    "    idx_sf = []\n",
    "    idx_0 = np.where( np.array(trY) == 0 ) #class 0\n",
    "    idx_0 = list(idx_0[0])\n",
    "    idx_sf.extend(idx_0)\n",
    "    idx_1 = np.where( np.array(trY) == 1 ) #class 1\n",
    "    idx_1 = list(idx_1[0])\n",
    "    idx_sf.extend(idx_1)\n",
    "    idx_2 = np.where( np.array(trY) == 2 ) #class 2\n",
    "    idx_2 = list(idx_2[0])\n",
    "    idx_sf.extend(idx_2)\n",
    "    idx_3 = np.where( np.array(trY) == 3 ) #class 3\n",
    "    idx_3 = list(idx_3[0])\n",
    "    idx_sf.extend(idx_3)\n",
    "    idx_4 = np.where( np.array(trY) == 4 ) #class 4\n",
    "    idx_4 = list(idx_4[0])\n",
    "    idx_sf.extend(idx_4)\n",
    "    random.shuffle(idx_sf)   \n",
    "    trQ_sf, trP_sf, trN_sf = [], [], []\n",
    "    for iQ in idx_sf:\n",
    "        trQ_sf.append(trI[iQ])\n",
    "        if trY[iQ] == 0:\n",
    "            idx_tmp = idx_0.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_0))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "        elif trY[iQ] == 1:\n",
    "            idx_tmp = idx_1.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_1))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "        elif trY[iQ] == 2:\n",
    "            idx_tmp = idx_2.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_2))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "        elif trY[iQ] == 3:\n",
    "            idx_tmp = idx_3.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_3))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "        elif trY[iQ] == 4:\n",
    "            idx_tmp = idx_4.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_4))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "        else: pass\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(trQ_sf),len(idx_sf)))\n",
    "        sys.stdout.flush()\n",
    "    return np.array(trQ_sf),np.array(trP_sf),np.array(trN_sf)\n",
    "trQ_sf, trP_sf, trN_sf = onlineGenImgPairs() #sample \n",
    "assert (trQ_sf.shape==trP_sf.shape)\n",
    "assert (trQ_sf.shape==trN_sf.shape)\n",
    "\n",
    "#define model\n",
    "model = ATHNet(code_size=36).cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "criterion  = TripletLoss(margin=0.5).cuda() #define TripletLoss \n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(10):#iteration\n",
    "    losses = []\n",
    "    shuffled_idx = np.random.permutation(np.arange(len(trQ_sf)))\n",
    "    train_q = trQ_sf[shuffled_idx]\n",
    "    train_p = trP_sf[shuffled_idx]\n",
    "    train_n = trN_sf[shuffled_idx]\n",
    "    num_batches = len(trQ_sf) // batchSize\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trQ_sf), (i+1)*batchSize])\n",
    "        Q_batch = torch.from_numpy(train_q[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        P_batch = torch.from_numpy(train_p[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        N_batch = torch.from_numpy(train_n[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        #forword\n",
    "        Q_hash = model(Q_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        P_hash = model(P_batch.permute(0, 3, 1, 2))\n",
    "        N_hash = model(N_batch.permute(0, 3, 1, 2))\n",
    "        #binary-like loss\n",
    "        loss = criterion(Q_hash,P_hash,N_hash)\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "criterion=criterion.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "#hash code of train data from model\n",
    "#torch.cuda.synchronize()\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize\n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#hash code of test data from model\n",
    "#torch.cuda.synchronize()\n",
    "teF = []\n",
    "num_batches = len(teI) // batchSize \n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(teI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    teF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(36) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "for topk in [10]:#[5,10,15,20]:\n",
    "    MHR = [] #mean Hit ratio \n",
    "    MAP = [] #mean average precision\n",
    "    MRR = [] #mean reciprocal rank\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        scores, neighbors = gpu_index.search(np.array(teF)[i:i+1].astype('float32'), k=topk)\n",
    "        #map_item_score = {}\n",
    "        #for j, trVal in enumerate(trF):\n",
    "        #    map_item_score[j] = pdist(np.vstack([teVal,trVal]),'hamming')\n",
    "        #ranklist = heapq.nsmallest(topk, map_item_score, key=map_item_score.get)\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        mrr_flag = 0\n",
    "        #for j in ranklist:\n",
    "        for j in neighbors.flatten():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                MHR.append(1)\n",
    "                pos_len = pos_len +1\n",
    "                MAP.append(pos_len/rank_len) \n",
    "                if mrr_flag==0: \n",
    "                    MRR.append(pos_len/rank_len)\n",
    "                    mrr_flag =1\n",
    "            else: \n",
    "                MHR.append(0)\n",
    "                MAP.append(0)   \n",
    "    print(\"mHR@{}={:.6f}, mAP@{}={:.6f}, mRR@{}={:.6f}\".format(topk,np.mean(MHR),topk,np.mean(MAP), topk, np.mean(MRR)))\n",
    "    \n",
    "#performance\n",
    "scores, neighbors = gpu_index.search(np.ascontiguousarray(teF, dtype=np.float32), k=1) #return top1\n",
    "y_pred = []\n",
    "for i in neighbors.flatten():\n",
    "    y_pred.append(np.array(trY)[i]) #label of top1\n",
    "print ( 'Accuracy: %.6f'%accuracy_score(teY, y_pred))\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, y_pred, labels=labels ) #labels=['AMD','DR','glaucoma','myopia','norm']\n",
    "print (cm)\n",
    "print ('Specificity of normal: %.6f'%float(cm[4][4]/np.sum(cm[4])))\n",
    "print ('Sensitivity of AMD: %.6f'%float(cm[0][0]/np.sum(cm[0])))\n",
    "print ('Sensitivity of DR: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity of glaucoma: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity of myopia: %.6f'%float(cm[3][3]/np.sum(cm[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 450 / 450 : loss = 4.460619Eopch:     1 mean_loss = 3.497393\n",
      " 450 / 450 : loss = 2.862026Eopch:     2 mean_loss = 3.465407\n",
      " 450 / 450 : loss = 2.963078Eopch:     3 mean_loss = 3.309732\n",
      " 450 / 450 : loss = 4.067571Eopch:     4 mean_loss = 3.270898\n",
      " 450 / 450 : loss = 2.703939Eopch:     5 mean_loss = 3.300474\n",
      " 450 / 450 : loss = 2.101919Eopch:     6 mean_loss = 3.264904\n",
      " 450 / 450 : loss = 1.802994Eopch:     7 mean_loss = 3.199393\n",
      " 450 / 450 : loss = 3.393795Eopch:     8 mean_loss = 3.324095\n",
      " 450 / 450 : loss = 2.944171Eopch:     9 mean_loss = 3.202616\n",
      " 450 / 450 : loss = 4.130229Eopch:    10 mean_loss = 3.286979\n",
      "best_loss = 3.199393\n",
      " 99 / 100  Completed buliding index in 1 seconds\n",
      "mHR@10=0.640900, mAP@10=0.540794, mRR@10=0.828881\n",
      "Accuracy: 0.661000\n",
      "[[ 13   1   4   2  52]\n",
      " [  1   2   1   0  23]\n",
      " [  8   2   0   2  33]\n",
      " [  3   1   5  22  48]\n",
      " [ 57  22  28  46 624]]\n",
      "Specificity of normal: 0.803089\n",
      "Sensitivity of AMD: 0.180556\n",
      "Sensitivity of DR: 0.074074\n",
      "Sensitivity of glaucoma: 0.000000\n",
      "Sensitivity of myopia: 0.278481\n"
     ]
    }
   ],
   "source": [
    "#ATH model with pairwise loss\n",
    "class SpatialAttention(nn.Module):#spatial attention layer\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels, out_channels=out_channels,\n",
    "                kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        self.downsample_layer = None\n",
    "        self.do_downsample = False\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.do_downsample = True\n",
    "            self.downsample_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.net(x)\n",
    "\n",
    "        if self.do_downsample:\n",
    "            identity = self.downsample_layer(x)\n",
    "\n",
    "        return F.relu(out + identity, inplace=True) #resnet\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            \n",
    "class ATHNet(nn.Module):\n",
    "    def __init__(self, code_size: int):\n",
    "        super().__init__()\n",
    "        #resnet and maxpool\n",
    "        self.net1 = nn.Sequential(#(3,256,256)->(16,128,128)\n",
    "            ResBlock(in_channels=3, out_channels=16, stride=2), \n",
    "            nn.MaxPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        )\n",
    "        \n",
    "        #Attention (16,128,128)->(16,128,128)\n",
    "        self.sa = SpatialAttention()\n",
    "        \n",
    "        #resnet and meanpool\n",
    "        self.net2 =nn.Sequential( #(16,128,128)->(8,64,64)\n",
    "            ResBlock(in_channels=16, out_channels=8, stride=2),\n",
    "            nn.AvgPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        ) \n",
    "         \n",
    "        #fully connected with conv (8,64,64)->(1,32,32)\n",
    "        self.dense=ResBlock(in_channels=8, out_channels=1, stride=2)\n",
    "        #fully connected (1,32,32)->class_size\n",
    "        self.linear = nn.Linear(1*32*32, code_size)\n",
    "    \n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net1(x)\n",
    "        x = self.sa(x)*x\n",
    "        x = self.net2(x)\n",
    "        x = self.dense(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "#define loss function:pairwise loss            \n",
    "class PairwiseLoss(nn.Module):\n",
    "    def __init__(self, margin=0.5, alpha=0.01):\n",
    "        super(PairwiseLoss, self).__init__()\n",
    "        self.alpha = alpha #regularization\n",
    "        self.margin = margin #margin threshold\n",
    "        self.mse_loss = nn.MSELoss(reduction='none')\n",
    "        self.l1_loss = nn.L1Loss(reduction='mean')\n",
    "    \n",
    "    def forward(self,h1,h2,y):    \n",
    "        margin_val = self.margin * h1.shape[1]\n",
    "        squared_loss = torch.mean(self.mse_loss(h1, h2), dim=1)\n",
    "        # T1: 0.5 * (1 - y) * dist(x1, x2)\n",
    "        positive_pair_loss = (0.5 * (1 - y) * squared_loss)\n",
    "        mean_positive_pair_loss = torch.mean(positive_pair_loss)\n",
    "        # T2: 0.5 * y * max(margin - dist(x1, x2), 0)\n",
    "        zeros = torch.zeros_like(squared_loss)\n",
    "        marginMat = margin_val * torch.ones_like(squared_loss)\n",
    "        negative_pair_loss = 0.5 * y * torch.max(zeros, marginMat - squared_loss)\n",
    "        mean_negative_pair_loss = torch.mean(negative_pair_loss)\n",
    "\n",
    "        # T3: alpha(dst_l1(abs(x1), 1)) + dist_l1(abs(x2), 1)))\n",
    "        mean_value_regularization = self.alpha * (\n",
    "                self.l1_loss(torch.abs(h1), torch.ones_like(h1)) +\n",
    "                self.l1_loss(torch.abs(h2), torch.ones_like(h2)))\n",
    "\n",
    "        loss = mean_positive_pair_loss + mean_negative_pair_loss + mean_value_regularization\n",
    "        return loss\n",
    "\n",
    "#Generate image pairs for model\n",
    "def onlineGenImgPairs():\n",
    "    if (len(trY) % 2) == 0: spls = len(trY)\n",
    "    else:  spls = len(trY)-1\n",
    "    idx_sf = random.sample(range(0, spls),spls)\n",
    "    trI1_sf, trI2_sf, trY1_sf, trY2_sf = [],[],[],[]\n",
    "    flag = 0\n",
    "    for i in idx_sf:\n",
    "        if flag==0:\n",
    "            trI1_sf.append(trI[i])\n",
    "            trY1_sf.append(trY[i])\n",
    "            flag =1\n",
    "        else:\n",
    "            trI2_sf.append(trI[i])\n",
    "            trY2_sf.append(trY[i])\n",
    "            flag =0\n",
    "    trY_sf = np.where((np.array(trY1_sf)-np.array(trY2_sf))!=0,1,0)\n",
    "    return np.array(trI1_sf),np.array(trI2_sf),trY_sf\n",
    "\n",
    "#define model\n",
    "model = ATHNet(code_size=36).cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "criterion  = PairwiseLoss(margin=0.5).cuda() #define PairwiseLoss \n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(10):#iteration\n",
    "    trI1_sf, trI2_sf, trY_sf = onlineGenImgPairs()\n",
    "    losses = []\n",
    "    num_batches = len(trY_sf) // batchSize \n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY_sf), (i+1)*batchSize])\n",
    "        I1_batch = torch.from_numpy(trI1_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        I2_batch = torch.from_numpy(trI2_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        Y_batch = torch.from_numpy(trY_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        #forword\n",
    "        X1_batch = model(I1_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        X2_batch = model(I2_batch.permute(0, 3, 1, 2))\n",
    "        #binary-like loss\n",
    "        loss = criterion(X1_batch,X2_batch,Y_batch)\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "criterion=criterion.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "#hash code of train data from model\n",
    "#torch.cuda.synchronize()\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize\n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#hash code of test data from model\n",
    "#torch.cuda.synchronize()\n",
    "teF = []\n",
    "num_batches = len(teI) // batchSize \n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(teI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    teF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(36) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "for topk in [10]:#[5,10,15,20]:\n",
    "    MHR = [] #mean Hit ratio \n",
    "    MAP = [] #mean average precision\n",
    "    MRR = [] #mean reciprocal rank\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        scores, neighbors = gpu_index.search(np.array(teF)[i:i+1].astype('float32'), k=topk)\n",
    "        #map_item_score = {}\n",
    "        #for j, trVal in enumerate(trF):\n",
    "        #    map_item_score[j] = pdist(np.vstack([teVal,trVal]),'hamming')\n",
    "        #ranklist = heapq.nsmallest(topk, map_item_score, key=map_item_score.get)\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        mrr_flag = 0\n",
    "        #for j in ranklist:\n",
    "        for j in neighbors.flatten():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                MHR.append(1)\n",
    "                pos_len = pos_len +1\n",
    "                MAP.append(pos_len/rank_len) \n",
    "                if mrr_flag==0: \n",
    "                    MRR.append(pos_len/rank_len)\n",
    "                    mrr_flag =1\n",
    "            else: \n",
    "                MHR.append(0)\n",
    "                MAP.append(0)   \n",
    "    print(\"mHR@{}={:.6f}, mAP@{}={:.6f}, mRR@{}={:.6f}\".format(topk,np.mean(MHR),topk,np.mean(MAP), topk, np.mean(MRR)))\n",
    "#performance\n",
    "scores, neighbors = gpu_index.search(np.ascontiguousarray(teF, dtype=np.float32), k=1) #return top1\n",
    "y_pred = []\n",
    "for i in neighbors.flatten():\n",
    "    y_pred.append(np.array(trY)[i]) #label of top1\n",
    "print ( 'Accuracy: %.6f'%accuracy_score(teY, y_pred))\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, y_pred, labels=labels ) #labels=['AMD','DR','glaucoma','myopia','norm']\n",
    "print (cm)\n",
    "print ('Specificity of normal: %.6f'%float(cm[4][4]/np.sum(cm[4])))\n",
    "print ('Sensitivity of AMD: %.6f'%float(cm[0][0]/np.sum(cm[0])))\n",
    "print ('Sensitivity of DR: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity of glaucoma: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity of myopia: %.6f'%float(cm[3][3]/np.sum(cm[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 900 / 900 : loss = 0.025827Eopch:     1 mean_loss = 0.075194\n",
      " 900 / 900 : loss = 0.067827Eopch:     2 mean_loss = 0.071478\n",
      " 900 / 900 : loss = 0.085572Eopch:     3 mean_loss = 0.069584\n",
      " 900 / 900 : loss = 0.085841Eopch:     4 mean_loss = 0.066611\n",
      " 900 / 900 : loss = 0.130229Eopch:     5 mean_loss = 0.063935\n",
      " 900 / 900 : loss = 0.015422Eopch:     6 mean_loss = 0.061875\n",
      " 900 / 900 : loss = 0.115747Eopch:     7 mean_loss = 0.060433\n",
      " 900 / 900 : loss = 0.078121Eopch:     8 mean_loss = 0.058288\n",
      " 900 / 900 : loss = 0.023583Eopch:     9 mean_loss = 0.056304\n",
      " 900 / 900 : loss = 0.131926Eopch:    10 mean_loss = 0.054898\n",
      "best_loss = 0.054898\n",
      " 99 / 100  Completed buliding index in 2 seconds\n",
      "mHR@10=0.639300, mAP@10=0.541441, mRR@10=0.829425\n",
      "Accuracy: 0.715000\n",
      "[[ 11   0   3   6  52]\n",
      " [  2   0   0   3  22]\n",
      " [  3   2   7   2  31]\n",
      " [ 11   0   3  30  35]\n",
      " [ 46   7  29  28 667]]\n",
      "Specificity of normal: 0.858430\n",
      "Sensitivity of AMD: 0.152778\n",
      "Sensitivity of DR: 0.000000\n",
      "Sensitivity of glaucoma: 0.155556\n",
      "Sensitivity of myopia: 0.379747\n"
     ]
    }
   ],
   "source": [
    "#ATH model with focal loss\n",
    "class SpatialAttention(nn.Module):#spatial attention layer\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels, out_channels=out_channels,\n",
    "                kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        self.downsample_layer = None\n",
    "        self.do_downsample = False\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.do_downsample = True\n",
    "            self.downsample_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.net(x)\n",
    "\n",
    "        if self.do_downsample:\n",
    "            identity = self.downsample_layer(x)\n",
    "\n",
    "        return F.relu(out + identity, inplace=True) #resnet\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            \n",
    "class ATHNet(nn.Module):\n",
    "    def __init__(self, class_size: int):\n",
    "        super().__init__()\n",
    "        #resnet and maxpool\n",
    "        self.net1 = nn.Sequential(#(3,256,256)->(16,128,128)\n",
    "            ResBlock(in_channels=3, out_channels=16, stride=2), \n",
    "            nn.MaxPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        )\n",
    "        \n",
    "        #Attention (16,128,128)->(16,128,128)\n",
    "        self.sa = SpatialAttention()\n",
    "        \n",
    "        #resnet and meanpool\n",
    "        self.net2 =nn.Sequential( #(16,128,128)->(8,64,64)\n",
    "            ResBlock(in_channels=16, out_channels=8, stride=2),\n",
    "            nn.AvgPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        ) \n",
    "         \n",
    "        #fully connected with conv (8,64,64)->(1,32,32)\n",
    "        self.dense=ResBlock(in_channels=8, out_channels=1, stride=2)\n",
    "        #fully connected (1,32,32)->class_size\n",
    "        self.linear = nn.Linear(1*32*32, class_size)\n",
    "    \n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net1(x)\n",
    "        x = self.sa(x)*x\n",
    "        x = self.net2(x)\n",
    "        x = self.dense(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        out = self.linear(x)\n",
    "        return x,out\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "#https://github.com/marvis/pytorch-yolo2/blob/master/FocalLoss.py\n",
    "#https://github.com/clcarwin/focal_loss_pytorch/blob/master/focalloss.py\n",
    "class FocalLoss(nn.Module):\n",
    "    #Loss(x, class) = - \\alpha (1-softmax(x)[class])^gamma \\log(softmax(x)[class])\n",
    "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n",
    "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, out, y):\n",
    "        y = y.view(-1,1)\n",
    "        logpt = F.log_softmax(out,dim=1)#default ,dim=1\n",
    "        logpt = logpt.gather(1,y)# dim=1, index=y, max\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = Variable(logpt.data.exp())\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type()!=out.data.type():\n",
    "                self.alpha = self.alpha.type_as(out.data)\n",
    "            at = self.alpha.gather(0,y.data.view(-1))\n",
    "            logpt = logpt * Variable(at)\n",
    "\n",
    "        loss = -1 * (1-pt)**self.gamma * logpt\n",
    "        if self.size_average: return loss.mean()\n",
    "        else: return loss.sum()\n",
    "        \n",
    "#define model\n",
    "model = ATHNet(class_size=5).cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "criterion  = FocalLoss(gamma=2,alpha=[0.2,0.4,0.2,0.15,0.05]).cuda() #define ce mutli-classes, \n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "trI = np.array(trI)\n",
    "trY = np.array(trY)\n",
    "for epoch in range(10):#iteration\n",
    "    losses = []\n",
    "    shuffled_idx = np.random.permutation(np.arange(len(trY)))\n",
    "    train_x = trI[shuffled_idx]\n",
    "    train_y = trY[shuffled_idx]\n",
    "    num_batches = len(trY) // batchSize\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY), (i+1)*batchSize])\n",
    "        x_batch = torch.from_numpy(train_x[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        y_batch = torch.from_numpy(train_y[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        #forword\n",
    "        _, out_batch = model(x_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        loss = criterion(out_batch,y_batch) #F.log_softmax+F.nll_loss\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "criterion = criterion.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "#torch.cuda.synchronize()\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize\n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    feature, _ = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    feature = feature.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(feature.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "teY_pred = []\n",
    "teF = [] \n",
    "num_batches = len(teY) // batchSize \n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    feature, out_batch = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    teF.extend(feature.cpu().data.numpy().tolist()) #record feature\n",
    "    out_batch = F.log_softmax(out_batch,dim=1) \n",
    "    pred = out_batch.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(pred.cpu().data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(32*32) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "for topk in [10]:#[5,10,15,20]:\n",
    "    MHR = [] #mean Hit ratio \n",
    "    MAP = [] #mean average precision\n",
    "    MRR = [] #mean reciprocal rank\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        scores, neighbors = gpu_index.search(np.array(teF)[i:i+1].astype('float32'), k=topk)\n",
    "        #map_item_score = {}\n",
    "        #for j, trVal in enumerate(trF):\n",
    "        #    map_item_score[j] = pdist(np.vstack([teVal,trVal]),'hamming')\n",
    "        #ranklist = heapq.nsmallest(topk, map_item_score, key=map_item_score.get)\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        mrr_flag = 0\n",
    "        #for j in ranklist:\n",
    "        for j in neighbors.flatten():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                MHR.append(1)\n",
    "                pos_len = pos_len +1\n",
    "                MAP.append(pos_len/rank_len) \n",
    "                if mrr_flag==0: \n",
    "                    MRR.append(pos_len/rank_len)\n",
    "                    mrr_flag =1\n",
    "            else: \n",
    "                MHR.append(0)\n",
    "                MAP.append(0)   \n",
    "    print(\"mHR@{}={:.6f}, mAP@{}={:.6f}, mRR@{}={:.6f}\".format(topk,np.mean(MHR),topk,np.mean(MAP), topk, np.mean(MRR)))\n",
    "\n",
    "#confusion matrix\n",
    "print ( 'Accuracy: %.6f'%accuracy_score(teY, teY_pred))\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, teY_pred, labels=labels ) #labels=['AMD','DR','glaucoma','myopia','norm']\n",
    "print (cm)\n",
    "print ('Specificity of normal: %.6f'%float(cm[4][4]/np.sum(cm[4])))\n",
    "print ('Sensitivity of AMD: %.6f'%float(cm[0][0]/np.sum(cm[0])))\n",
    "print ('Sensitivity of DR: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity of glaucoma: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity of myopia: %.6f'%float(cm[3][3]/np.sum(cm[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 900 / 900 : loss = 0.473502Eopch:     1 mean_loss = 0.818080\n",
      " 900 / 900 : loss = 0.604596Eopch:     2 mean_loss = 0.773206\n",
      " 900 / 900 : loss = 0.412981Eopch:     3 mean_loss = 0.760208\n",
      " 900 / 900 : loss = 1.241025Eopch:     4 mean_loss = 0.750548\n",
      " 900 / 900 : loss = 0.338364Eopch:     5 mean_loss = 0.748032\n",
      " 900 / 900 : loss = 1.065161Eopch:     6 mean_loss = 0.740972\n",
      " 900 / 900 : loss = 0.696076Eopch:     7 mean_loss = 0.732908\n",
      " 900 / 900 : loss = 1.295812Eopch:     8 mean_loss = 0.726191\n",
      " 900 / 900 : loss = 1.512881Eopch:     9 mean_loss = 0.720169\n",
      " 900 / 900 : loss = 1.168957Eopch:    10 mean_loss = 0.715275\n",
      "best_loss = 0.715275\n",
      " 99 / 100  Completed buliding index in 2 seconds\n",
      "mHR@10=0.655800, mAP@10=0.569686, mRR@10=0.844168\n",
      "Accuracy: 0.783000\n",
      "[[  0   0   0   3  69]\n",
      " [  0   0   0   2  25]\n",
      " [  0   0   0   1  44]\n",
      " [  0   0   0  13  66]\n",
      " [  0   0   0   7 770]]\n",
      "Specificity of normal: 0.990991\n",
      "Sensitivity of AMD: 0.000000\n",
      "Sensitivity of DR: 0.000000\n",
      "Sensitivity of glaucoma: 0.000000\n",
      "Sensitivity of myopia: 0.164557\n"
     ]
    }
   ],
   "source": [
    "#ATH model with cross entropy loss\n",
    "class SpatialAttention(nn.Module):#spatial attention layer\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels, out_channels=out_channels,\n",
    "                kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        self.downsample_layer = None\n",
    "        self.do_downsample = False\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.do_downsample = True\n",
    "            self.downsample_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.net(x)\n",
    "\n",
    "        if self.do_downsample:\n",
    "            identity = self.downsample_layer(x)\n",
    "\n",
    "        return F.relu(out + identity, inplace=True) #resnet\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            \n",
    "class ATHNet(nn.Module):\n",
    "    def __init__(self, class_size: int):\n",
    "        super().__init__()\n",
    "        #resnet and maxpool\n",
    "        self.net1 = nn.Sequential(#(3,256,256)->(16,128,128)\n",
    "            ResBlock(in_channels=3, out_channels=16, stride=2), \n",
    "            nn.MaxPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        )\n",
    "        \n",
    "        #Attention (16,128,128)->(16,128,128)\n",
    "        self.sa = SpatialAttention()\n",
    "        \n",
    "        #resnet and meanpool\n",
    "        self.net2 =nn.Sequential( #(16,128,128)->(8,64,64)\n",
    "            ResBlock(in_channels=16, out_channels=8, stride=2),\n",
    "            nn.AvgPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        ) \n",
    "         \n",
    "        #fully connected with conv (8,64,64)->(1,32,32)\n",
    "        self.dense=ResBlock(in_channels=8, out_channels=1, stride=2)\n",
    "        #fully connected (1,32,32)->class_size\n",
    "        self.linear = nn.Linear(1*32*32, class_size)\n",
    "    \n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net1(x)\n",
    "        x = self.sa(x)*x\n",
    "        x = self.net2(x)\n",
    "        x = self.dense(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        out = self.linear(x)\n",
    "        return x,out\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "#define model\n",
    "model = ATHNet(class_size=5).cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "criterion  = nn.CrossEntropyLoss().cuda() #define ce mutli-classes\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "trI = np.array(trI)\n",
    "trY = np.array(trY)\n",
    "for epoch in range(10):#iteration\n",
    "    losses = []\n",
    "    shuffled_idx = np.random.permutation(np.arange(len(trY)))\n",
    "    train_x = trI[shuffled_idx]\n",
    "    train_y = trY[shuffled_idx]\n",
    "    num_batches = len(trY) // batchSize\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY), (i+1)*batchSize])\n",
    "        x_batch = torch.from_numpy(train_x[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        y_batch = torch.from_numpy(train_y[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        #forword\n",
    "        _,out_batch = model(x_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        loss = criterion(out_batch,y_batch) #F.log_softmax+F.nll_loss\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "criterion = criterion.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "#torch.cuda.synchronize()\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize\n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    feature, _ = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    feature = feature.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(feature.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "teY_pred = []\n",
    "teF = [] \n",
    "num_batches = len(teY) // batchSize \n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    feature, out_batch = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    teF.extend(feature.cpu().data.numpy().tolist()) #record feature\n",
    "    out_batch = F.log_softmax(out_batch,dim=1) \n",
    "    pred = out_batch.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(pred.cpu().data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(32*32) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "for topk in [10]:#[5,10,15,20]:\n",
    "    MHR = [] #mean Hit ratio \n",
    "    MAP = [] #mean average precision\n",
    "    MRR = [] #mean reciprocal rank\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        scores, neighbors = gpu_index.search(np.array(teF)[i:i+1].astype('float32'), k=topk)\n",
    "        #map_item_score = {}\n",
    "        #for j, trVal in enumerate(trF):\n",
    "        #    map_item_score[j] = pdist(np.vstack([teVal,trVal]),'hamming')\n",
    "        #ranklist = heapq.nsmallest(topk, map_item_score, key=map_item_score.get)\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        mrr_flag = 0\n",
    "        #for j in ranklist:\n",
    "        for j in neighbors.flatten():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                MHR.append(1)\n",
    "                pos_len = pos_len +1\n",
    "                MAP.append(pos_len/rank_len) \n",
    "                if mrr_flag==0: \n",
    "                    MRR.append(pos_len/rank_len)\n",
    "                    mrr_flag =1\n",
    "            else: \n",
    "                MHR.append(0)\n",
    "                MAP.append(0)   \n",
    "    print(\"mHR@{}={:.6f}, mAP@{}={:.6f}, mRR@{}={:.6f}\".format(topk,np.mean(MHR),topk,np.mean(MAP), topk, np.mean(MRR)))\n",
    "#confusion matrix\n",
    "print ( 'Accuracy: %.6f'%accuracy_score(teY, teY_pred))\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, teY_pred, labels=labels ) #labels=['AMD','DR','glaucoma','myopia','norm']\n",
    "print (cm)\n",
    "print ('Specificity of normal: %.6f'%float(cm[4][4]/np.sum(cm[4])))\n",
    "print ('Sensitivity of AMD: %.6f'%float(cm[0][0]/np.sum(cm[0])))\n",
    "print ('Sensitivity of DR: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity of glaucoma: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity of myopia: %.6f'%float(cm[3][3]/np.sum(cm[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Org data dimension is 1024.Embedded data dimension is 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize : t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import random\n",
    "def scatter(X, y):\n",
    "    #X,y:numpy-array\n",
    "    classes = len(list(set(y.tolist())))#get number of classes\n",
    "    #palette = np.array(sns.color_palette(\"hls\", classes))# choose a color palette with seaborn.\n",
    "    color = ['c','y','m','b','g','r']\n",
    "    marker = ['o','x','+','*','s']\n",
    "    plt.figure(figsize=(8,8))#create a plot\n",
    "    for i in range(classes):\n",
    "        plt.scatter(X[y == i,0], X[y == i,1], c=color[i], marker=marker[i], label=str(i))\n",
    "    plt.axis('off')\n",
    "    plt.legend(loc='upper left')\n",
    "    #plt.savefig('digits_tsne-generated.png', dpi=100)\n",
    "    plt.show()\n",
    "\n",
    "#prepare data，classes=5\n",
    "#idx= random.sample(np.where(np.array(teY)==0)[0].tolist(),100)\n",
    "idx= np.where(np.array(teY)==0)[0].tolist()\n",
    "X0= np.array(teF)[idx]\n",
    "y0= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==1)[0].tolist()\n",
    "X1= np.array(teF)[idx]\n",
    "y1= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==2)[0].tolist()\n",
    "X2= np.array(teF)[idx]\n",
    "y2= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==3)[0].tolist()\n",
    "X3= np.array(teF)[idx]\n",
    "y3= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==4)[0].tolist()\n",
    "X4= np.array(teF)[idx]\n",
    "y4= np.array(teY)[idx]\n",
    "\n",
    "y = np.append(y0,y1)\n",
    "y = np.append(y,y2)\n",
    "y = np.append(y,y3)\n",
    "y = np.append(y,y4)\n",
    "X = np.vstack((X0,X1))\n",
    "X = np.vstack((X,X2))\n",
    "X = np.vstack((X,X3))\n",
    "X = np.vstack((X,X4))\n",
    "#training t-sne \n",
    "tsne = TSNE(n_components=2, init='pca', random_state=501)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "print(\"Org data dimension is {}.Embedded data dimension is {}\".format(X.shape[-1], X_tsne.shape[-1]))\n",
    "\n",
    "#visualize\n",
    "scatter(X_tsne, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.855 -> norm\n",
      "0.070 -> AMD\n",
      "0.045 -> glaucoma\n",
      "0.018 -> DR\n",
      "0.012 -> myopia\n",
      "output CAM.jpg for the top1 prediction: norm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate class activation mapping for the top1 prediction\n",
    "def returnCAM(feature_conv, weight_softmax, class_idx):\n",
    "    # generate the class activation maps upsample to 256x256\n",
    "    size_upsample = (256, 256)\n",
    "    bz, nc, h, w = feature_conv.shape\n",
    "    \n",
    "    output_cam = []\n",
    "    for idx in class_idx:\n",
    "        #cam = weight_softmax[class_idx].dot(feature_conv.reshape((nc,h*w)))\n",
    "        cam = weight_softmax[class_idx]*(feature_conv.reshape((nc,h*w)))\n",
    "        cam = cam.reshape(h, w)\n",
    "        cam = cam - np.min(cam)\n",
    "        cam_img = cam / np.max(cam)\n",
    "        cam_img = np.uint8(255 * cam_img)\n",
    "        output_cam.append(cv2.resize(cam_img, size_upsample))\n",
    "    return output_cam\n",
    "\n",
    "\n",
    "# hook the feature extractor\n",
    "features_blobs = []\n",
    "def hook_feature(module, input, output):\n",
    "    features_blobs.append(output.data.cpu().numpy())\n",
    "#last conv layer followed with one channel by last fully connected layer\n",
    "final_conv = 'dense' \n",
    "best_net._modules.get(final_conv).register_forward_hook(hook_feature)\n",
    "#get weights parameters\n",
    "params = list(best_net.parameters())\n",
    "#get the last and second last weights, like [classes, hiden nodes]\n",
    "weight_softmax = np.squeeze(params[-2].data.cpu().numpy()) \n",
    "# define class type\n",
    "classes = {0: 'AMD', 1: 'DR', 2:'glaucoma', 3:'myopia', 4:'norm'}\n",
    "#read image\n",
    "root='/data/fjsdata/fundus/iSee/iSee_multi_dataset/img_data_AMD/99971.jpg'\n",
    "img = []\n",
    "img.append( cv2.resize(cv2.imread(root).astype(np.float32), (256, 256)))#(256, 256) is the model input size\n",
    "data = torch.from_numpy(np.array(img)).type(torch.FloatTensor).cuda()\n",
    "_,logit = best_net(data.permute(0, 3, 1, 2))#forword\n",
    "h_x = F.softmax(logit, dim=1).data.squeeze()#softmax\n",
    "probs, idx = h_x.sort(0, True) #probabilities of classes\n",
    "\n",
    "# output: the prediction\n",
    "for i in range(0, len(classes)):\n",
    "    line = '{:.3f} -> {}'.format(probs[i], classes[idx[i].item()])\n",
    "    print(line)\n",
    "#get the class activation maps\n",
    "CAMs = returnCAM(features_blobs[0], weight_softmax, [idx[0].item()])\n",
    "\n",
    "# render the CAM and show\n",
    "print('output CAM.jpg for the top1 prediction: %s' % classes[idx[0].item()])\n",
    "img = cv2.imread(root)\n",
    "height, width, _ = img.shape\n",
    "CAM = cv2.resize(CAMs[0], (width, height))\n",
    "heatmap = cv2.applyColorMap(CAM, cv2.COLORMAP_JET)\n",
    "result = heatmap * 0.3 + img * 0.5\n",
    "cv2.imwrite('iSee_cam.jpg', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_items([('net1', Sequential(\n",
      "  (0): ResBlock(\n",
      "    (net): Sequential(\n",
      "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (downsample_layer): Sequential(\n",
      "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      ")), ('sa', SpatialAttention(\n",
      "  (conv1): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (sigmoid): Sigmoid()\n",
      ")), ('net2', Sequential(\n",
      "  (0): ResBlock(\n",
      "    (net): Sequential(\n",
      "      (0): Conv2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "      (3): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (downsample_layer): Sequential(\n",
      "      (0): Conv2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      ")), ('dense', ResBlock(\n",
      "  (net): Sequential(\n",
      "    (0): Conv2d(8, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (downsample_layer): Sequential(\n",
      "    (0): Conv2d(8, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")), ('linear', Linear(in_features=1024, out_features=5, bias=True))])\n"
     ]
    }
   ],
   "source": [
    "print (best_net._modules.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
