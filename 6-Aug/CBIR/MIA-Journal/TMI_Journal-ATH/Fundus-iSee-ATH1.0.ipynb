{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.Develop Env: linux+cuda9+python3+opencv+pytorch\n",
    "2.Dataset: Fundus-iSee with 10000 images(AMD-720, DR-270, glaucoma-450,myopia-790,norm-7770)\n",
    "        trainset(9000): AMD-648, DR-243, glaucoma-405, myopia-711, norm-6993, \n",
    "        testset(1000): AMD-72, DR-27, glaucoma-45, myopia-79, norm=777\n",
    "3.Performance Metric for unbalanced sample(triplet loss): \n",
    "  1)AUC (Area Under Curve);\n",
    "  2)Sensitivity(Sen): for evaluating the missed diagnosis rate of abnorml\n",
    "4.Performance Metric for retrieval (Spatial Attention Mechanism):\n",
    "  1)MHR(Mean Hit Ratio):  for evaluating the precison of relevance retrieval;\n",
    "  2)MAP(Mean Average Precision): for evaluation the rank of relevance retrieval;\n",
    "  3)MRR(Mean Reciprocal Rank): for evaluation the first hit rank of relevance retrieval;\n",
    "5.Algorithm: Attention-based Triplet Hashing Network(ATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading faiss with AVX2 support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "import gc\n",
    "from PIL import Image\n",
    "from io import StringIO,BytesIO \n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc,roc_auc_score  \n",
    "from functools import reduce\n",
    "import faiss \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "torch.cuda.set_device(0)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttention(nn.Module):#spatial attention layer\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels, out_channels=out_channels,\n",
    "                kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        self.downsample_layer = None\n",
    "        self.do_downsample = False\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.do_downsample = True\n",
    "            self.downsample_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.net(x)\n",
    "\n",
    "        if self.do_downsample:\n",
    "            identity = self.downsample_layer(x)\n",
    "\n",
    "        return F.relu(out + identity, inplace=True) #resnet\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            \n",
    "class ATHNet(nn.Module):\n",
    "    def __init__(self, hash_size: int, type_size: int):\n",
    "        super().__init__()\n",
    "        #resnet and maxpool\n",
    "        self.net1 = nn.Sequential(#(3,256,256)->(16,128,128)\n",
    "            ResBlock(in_channels=3, out_channels=16, stride=2), \n",
    "            nn.MaxPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        )\n",
    "        \n",
    "        #Attention (16,128,128)->(16,128,128)\n",
    "        self.sa = SpatialAttention()\n",
    "        \n",
    "        #resnet and meanpool\n",
    "        self.net2 =nn.Sequential( #(16,128,128)->(8,64,64)\n",
    "            ResBlock(in_channels=16, out_channels=8, stride=2),\n",
    "            nn.AvgPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        ) \n",
    "         \n",
    "        #fully connected with conv (8,64,64)->(1,32,32)\n",
    "        self.dense=ResBlock(in_channels=8, out_channels=1, stride=2)\n",
    "        #fully connected (1,32,32)->class_size\n",
    "        self.hashlayer = nn.Linear(1*32*32, hash_size)\n",
    "        self.typelayer = nn.Linear(1*32*32, type_size)\n",
    "    \n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net1(x)\n",
    "        x = self.sa(x)*x\n",
    "        x = self.net2(x)\n",
    "        x = self.dense(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x_hash = self.hashlayer(x)\n",
    "        x_type = self.typelayer(x)\n",
    "        return x_hash, x_type\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "#https://github.com/luyajie/triplet-deep-hash-pytorch#triplet-deep-hash-pytorch            \n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=0.5):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin #margin threshold\n",
    "        self.mse_loss = nn.MSELoss(reduction='none')\n",
    "    \n",
    "    def forward(self,H_q,H_p,H_n):    \n",
    "        margin_val = self.margin * H_q.shape[1]\n",
    "        squared_loss_pos = torch.mean(self.mse_loss(H_q, H_p), dim=1)\n",
    "        squared_loss_neg = torch.mean(self.mse_loss(H_q, H_n), dim=1)\n",
    "        zeros = torch.zeros_like(squared_loss_neg)\n",
    "        loss  = torch.max(zeros, margin_val - squared_loss_neg + squared_loss_pos)\n",
    "        return torch.mean(loss)\n",
    "    \n",
    "#https://github.com/marvis/pytorch-yolo2/blob/master/FocalLoss.py\n",
    "#https://github.com/clcarwin/focal_loss_pytorch/blob/master/focalloss.py  \n",
    "class FocalLoss(nn.Module):\n",
    "    #Loss(x, class) = - \\alpha (1-softmax(x)[class])^gamma \\log(softmax(x)[class])\n",
    "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n",
    "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, out, y):\n",
    "        y = y.view(-1,1)\n",
    "        logpt = F.log_softmax(out,dim=1)#default ,dim=1\n",
    "        logpt = logpt.gather(1,y)# dim=1, index=y, max\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = Variable(logpt.data.exp())\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type()!=out.data.type():\n",
    "                self.alpha = self.alpha.type_as(out.data)\n",
    "            at = self.alpha.gather(0,y.data.view(-1))\n",
    "            logpt = logpt * Variable(at)\n",
    "\n",
    "        loss = -1 * (1-pt)**self.gamma * logpt\n",
    "        if self.size_average: return loss.mean()\n",
    "        else: return loss.sum()\n",
    "#https://github.com/qianjinhao/circle-loss\n",
    "class CircleLoss(nn.Module):\n",
    "    def __init__(self, scale=32, margin=0.25, similarity='cos', **kwargs):\n",
    "        super(CircleLoss, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.margin = margin\n",
    "        self.similarity = similarity\n",
    "\n",
    "    def forward(self, feats, labels):\n",
    "        assert feats.size(0) == labels.size(0), \\\n",
    "            f\"feats.size(0): {feats.size(0)} is not equal to labels.size(0): {labels.size(0)}\"\n",
    "        batch_size = feats.size(0)\n",
    "        if self.similarity == 'dot':\n",
    "            sim_mat = torch.matmul(feats, torch.t(feats))\n",
    "        elif self.similarity == 'cos':\n",
    "            feats = F.normalize(feats)\n",
    "            sim_mat = feats.mm(feats.t())\n",
    "        else:\n",
    "            raise ValueError('This similarity is not implemented.')\n",
    "        loss = list()\n",
    "        for i in range(batch_size):\n",
    "            pos_index = labels == labels[i]\n",
    "            pos_index[i] = 0\n",
    "            neg_index = labels != labels[i]\n",
    "            pos_pair_ = sim_mat[i][pos_index]\n",
    "            neg_pair_ = sim_mat[i][neg_index]\n",
    "\n",
    "            alpha_p = torch.relu(-pos_pair_ + 1 + self.margin)\n",
    "            alpha_n = torch.relu(neg_pair_ + self.margin)\n",
    "            margin_p = 1 - self.margin\n",
    "            margin_n = self.margin\n",
    "            loss_p = torch.sum(torch.exp(-self.scale * alpha_p * (pos_pair_ - margin_p)))\n",
    "            loss_n = torch.sum(torch.exp(self.scale * alpha_n * (neg_pair_ - margin_n)))\n",
    "            loss.append(torch.log(1 + loss_p * loss_n))\n",
    "\n",
    "        loss = sum(loss) / batch_size\n",
    "        return loss    \n",
    "\n",
    "#define loss function:pairwise loss            \n",
    "class PairwiseLoss(nn.Module):\n",
    "    def __init__(self, margin=0.5, alpha=0.01):\n",
    "        super(PairwiseLoss, self).__init__()\n",
    "        self.alpha = alpha #regularization\n",
    "        self.margin = margin #margin threshold\n",
    "        self.mse_loss = nn.MSELoss(reduction='none')\n",
    "        self.l1_loss = nn.L1Loss(reduction='mean')\n",
    "    \n",
    "    def forward(self,h1,h2,y):    \n",
    "        margin_val = self.margin * h1.shape[1]\n",
    "        squared_loss = torch.mean(self.mse_loss(h1, h2), dim=1)\n",
    "        # T1: 0.5 * (1 - y) * dist(x1, x2)\n",
    "        positive_pair_loss = (0.5 * (1 - y) * squared_loss)\n",
    "        mean_positive_pair_loss = torch.mean(positive_pair_loss)\n",
    "        # T2: 0.5 * y * max(margin - dist(x1, x2), 0)\n",
    "        zeros = torch.zeros_like(squared_loss)\n",
    "        marginMat = margin_val * torch.ones_like(squared_loss)\n",
    "        negative_pair_loss = 0.5 * y * torch.max(zeros, marginMat - squared_loss)\n",
    "        mean_negative_pair_loss = torch.mean(negative_pair_loss)\n",
    "\n",
    "        # T3: alpha(dst_l1(abs(x1), 1)) + dist_l1(abs(x2), 1)))\n",
    "        mean_value_regularization = self.alpha * (\n",
    "                self.l1_loss(torch.abs(h1), torch.ones_like(h1)) +\n",
    "                self.l1_loss(torch.abs(h2), torch.ones_like(h2)))\n",
    "\n",
    "        loss = mean_positive_pair_loss + mean_negative_pair_loss + mean_value_regularization\n",
    "        return loss\n",
    "    \n",
    "#Generate image pairs for model\n",
    "def onlineGenImgPairs( ):\n",
    "    idx_sf = []\n",
    "    idx_0 = np.where( np.array(trY) == 0 ) #class 0\n",
    "    idx_0 = list(idx_0[0])#[0:4555]\n",
    "    idx_sf.extend(idx_0)\n",
    "    idx_1 = np.where( np.array(trY) == 1 ) #class 1\n",
    "    idx_1 = list(idx_1[0])\n",
    "    idx_sf.extend(idx_1)\n",
    "    idx_2 = np.where( np.array(trY) == 2 ) #class 2\n",
    "    idx_2 = list(idx_2[0])\n",
    "    idx_sf.extend(idx_2)\n",
    "    idx_3 = np.where( np.array(trY) == 3 ) #class 3\n",
    "    idx_3 = list(idx_3[0])\n",
    "    idx_sf.extend(idx_3)\n",
    "    idx_4 = np.where( np.array(trY) == 4 ) #class 4\n",
    "    idx_4 = list(idx_4[0])#[0:993]\n",
    "    idx_sf.extend(idx_4)\n",
    "    random.shuffle(idx_sf)   \n",
    "    trQ_sf, trP_sf, trN_sf = [], [], []\n",
    "    trQ_y, trP_y, trN_y = [], [], []\n",
    "    for iQ in idx_sf:\n",
    "        trQ_sf.append(trI[iQ])\n",
    "        trQ_y.append(trY[iQ])\n",
    "        if trY[iQ] == 0:\n",
    "            idx_tmp = idx_0.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            trP_y.append(trY[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_0))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "            trN_y.append(trY[iN[0]])\n",
    "        elif trY[iQ] == 1:\n",
    "            idx_tmp = idx_1.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            trP_y.append(trY[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_1))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "            trN_y.append(trY[iN[0]])\n",
    "        elif trY[iQ] == 2:\n",
    "            idx_tmp = idx_2.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            trP_y.append(trY[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_2))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "            trN_y.append(trY[iN[0]])\n",
    "        elif trY[iQ] == 3:\n",
    "            idx_tmp = idx_3.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            trP_y.append(trY[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_3))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "            trN_y.append(trY[iN[0]])\n",
    "        elif trY[iQ] == 4:\n",
    "            idx_tmp = idx_4.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            trP_y.append(trY[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_4))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "            trN_y.append(trY[iN[0]])\n",
    "        else: pass\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(trQ_sf),len(idx_sf)))\n",
    "        sys.stdout.flush()\n",
    "    return np.array(trQ_sf),np.array(trP_sf),np.array(trN_sf), np.array(trQ_y), np.array(trP_y), np.array(trN_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000 / 9000 The length of train set is 9000\n",
      "1000 / 1000 The length of test set is 1000\n",
      "Completed data handle in 795 seconds\n"
     ]
    }
   ],
   "source": [
    "#Read data with List storage Name:[name],I:[img],Y[type]\n",
    "def TypetoNum(itype): #map the type into number.\n",
    "    if itype =='AMD': return 1\n",
    "    elif itype =='DR': return 2\n",
    "    elif itype =='glaucoma': return 3\n",
    "    elif itype =='myopia': return 4\n",
    "    else: return 0 #norm\n",
    "    \n",
    "root_dir = '/data/fjsdata/fundus/iSee/iSee_multi_dataset/' #the path of images\n",
    "trainset = pd.read_csv(\"/data/fjsdata/fundus/iSee/iSee_multi_dataset/CBIR_iSee_train.csv\" , sep=',')#load trainset\n",
    "testset = pd.read_csv(\"/data/fjsdata/fundus/iSee/iSee_multi_dataset/CBIR_iSee_test.csv\" , sep=',')#load testset\n",
    "tstart = time.time()\n",
    "#read train image with CV\n",
    "trN, trI, trY = [],[],[]\n",
    "norm = 6993\n",
    "for iname, itype in np.array(trainset).tolist():\n",
    "    if iname.endswith(\".jpg\"):\n",
    "        try:\n",
    "            image_dir = root_dir+'img_data_%s'%itype\n",
    "            image_path = os.path.join(image_dir, iname)\n",
    "            if itype == 'norm':\n",
    "                if norm>0:\n",
    "                    img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(1920,1920,3)->(256,256,3)\n",
    "                    trN.append(iname)\n",
    "                    trI.append(img)\n",
    "                    trY.append(TypetoNum(itype))\n",
    "                    norm = norm - 1\n",
    "            else:\n",
    "                img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(1920,1920,3)->(256,256,3)\n",
    "                trN.append(iname)\n",
    "                trI.append(img)\n",
    "                trY.append(TypetoNum(itype))    \n",
    "        except:\n",
    "            print(iname+\":\"+str(image_path))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(trN),trainset.shape[0]))\n",
    "        sys.stdout.flush()\n",
    "print('The length of train set is %d'%len(trN))\n",
    "#read test image with CV\n",
    "teN, teI, teY = [],[],[]\n",
    "norm = 777\n",
    "for iname, itype in np.array(testset).tolist():\n",
    "    if iname.endswith(\".jpg\"):\n",
    "        try:\n",
    "            image_dir = root_dir+'img_data_%s'%itype\n",
    "            image_path = os.path.join(image_dir, iname)\n",
    "            if itype == 'norm':\n",
    "                if norm>0:\n",
    "                    img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(1920,1920,3)->(256,256,3)\n",
    "                    teN.append(iname)\n",
    "                    teI.append(img)\n",
    "                    teY.append(TypetoNum(itype))\n",
    "                    norm = norm - 1\n",
    "            else:\n",
    "                img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(1920,1920,3)->(256,256,3)\n",
    "                teN.append(iname)\n",
    "                teI.append(img)\n",
    "                teY.append(TypetoNum(itype)) \n",
    "        except:\n",
    "            print(iname+\":\"+str(image_path))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(teN),testset.shape[0]))\n",
    "        sys.stdout.flush()\n",
    "print('The length of test set is %d'%len(teN))\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed data handle in %d seconds' % int(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 900 / 900 : loss = 24.794512Eopch:     1 mean_loss = 20.643592\n",
      " 900 / 900 : loss = 14.300351Eopch:     2 mean_loss = 19.329779\n",
      " 900 / 900 : loss = 16.699152Eopch:     3 mean_loss = 18.330257\n",
      " 900 / 900 : loss = 19.828735Eopch:     4 mean_loss = 16.497529\n",
      " 900 / 900 : loss = 12.671606Eopch:     5 mean_loss = 15.294242\n",
      " 900 / 900 : loss = 21.026741Eopch:     6 mean_loss = 13.669827\n",
      " 900 / 900 : loss = 14.323267Eopch:     7 mean_loss = 12.439150\n",
      " 900 / 900 : loss = 15.980244Eopch:     8 mean_loss = 11.492320\n",
      " 900 / 900 : loss = 8.5032146Eopch:     9 mean_loss = 10.266158\n",
      " 900 / 900 : loss = 10.470182Eopch:    10 mean_loss = 9.288874\n",
      " 900 / 900 : loss = 7.4146175Eopch:    11 mean_loss = 8.387284\n",
      " 900 / 900 : loss = 4.1651472Eopch:    12 mean_loss = 7.557140\n",
      " 900 / 900 : loss = 7.6977146Eopch:    13 mean_loss = 6.756209\n",
      " 900 / 900 : loss = 5.4493688Eopch:    14 mean_loss = 6.120780\n",
      " 900 / 900 : loss = 10.763062Eopch:    15 mean_loss = 5.460130\n",
      " 900 / 900 : loss = 7.0827071Eopch:    16 mean_loss = 5.080590\n",
      " 900 / 900 : loss = 2.6739017Eopch:    17 mean_loss = 4.493764\n",
      " 900 / 900 : loss = 2.2211462Eopch:    18 mean_loss = 4.262483\n",
      " 900 / 900 : loss = 8.6124315Eopch:    19 mean_loss = 4.076572\n",
      " 900 / 900 : loss = 4.5768128Eopch:    20 mean_loss = 3.694928\n",
      " 900 / 900 : loss = 3.0289886Eopch:    21 mean_loss = 3.564421\n",
      " 900 / 900 : loss = 1.7455312Eopch:    22 mean_loss = 3.505311\n",
      " 900 / 900 : loss = 3.5116546Eopch:    23 mean_loss = 3.253437\n",
      " 900 / 900 : loss = 2.4844113Eopch:    24 mean_loss = 3.261482\n",
      " 900 / 900 : loss = 2.8120243Eopch:    25 mean_loss = 3.159962\n",
      " 900 / 900 : loss = 1.9419838Eopch:    26 mean_loss = 3.063870\n",
      " 900 / 900 : loss = 2.0034432Eopch:    27 mean_loss = 3.035770\n",
      " 900 / 900 : loss = 6.2018384Eopch:    28 mean_loss = 2.947234\n",
      " 900 / 900 : loss = 2.8532747Eopch:    29 mean_loss = 2.906193\n",
      " 900 / 900 : loss = 7.7940765Eopch:    30 mean_loss = 2.840000\n",
      " 900 / 900 : loss = 2.4249515Eopch:    31 mean_loss = 2.743595\n",
      " 900 / 900 : loss = 1.6556376Eopch:    32 mean_loss = 2.805043\n",
      " 900 / 900 : loss = 4.7582082Eopch:    33 mean_loss = 2.784161\n",
      " 900 / 900 : loss = 5.8984997Eopch:    34 mean_loss = 2.785458\n",
      " 900 / 900 : loss = 2.5494079Eopch:    35 mean_loss = 2.711626\n",
      " 900 / 900 : loss = 2.7519759Eopch:    36 mean_loss = 2.605991\n",
      " 900 / 900 : loss = 2.6784993Eopch:    37 mean_loss = 2.626816\n",
      " 900 / 900 : loss = 2.223871Eopch:    38 mean_loss = 2.482345\n",
      " 900 / 900 : loss = 1.6686783Eopch:    39 mean_loss = 2.585106\n",
      " 900 / 900 : loss = 1.9654851Eopch:    40 mean_loss = 2.524140\n",
      " 900 / 900 : loss = 1.6460328Eopch:    41 mean_loss = 2.556750\n",
      " 900 / 900 : loss = 5.7270695Eopch:    42 mean_loss = 2.529989\n",
      " 900 / 900 : loss = 1.362716Eopch:    43 mean_loss = 2.497195\n",
      " 900 / 900 : loss = 2.0217827Eopch:    44 mean_loss = 2.374772\n",
      " 900 / 900 : loss = 2.2198558Eopch:    45 mean_loss = 2.503653\n",
      " 900 / 900 : loss = 2.267069Eopch:    46 mean_loss = 2.453651\n",
      " 900 / 900 : loss = 1.8379744Eopch:    47 mean_loss = 2.390626\n",
      " 900 / 900 : loss = 2.3523922Eopch:    48 mean_loss = 2.420216\n",
      " 900 / 900 : loss = 3.0471473Eopch:    49 mean_loss = 2.372728\n",
      " 900 / 900 : loss = 1.3258123Eopch:    50 mean_loss = 2.386099\n",
      "best_loss = 2.372728\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------\n",
    "#ATH-Triplet+CE\n",
    "#--------------------------------------------------------\n",
    "#sample  triplet labels\n",
    "#trQ_sf, trP_sf, trN_sf, trQ_y, trP_y, trN_y = onlineGenImgPairs() \n",
    "assert (trQ_sf.shape==trP_sf.shape and trQ_sf.shape==trN_sf.shape)\n",
    "assert (trQ_y.shape==trP_y.shape and trQ_y.shape==trN_y.shape)\n",
    "assert (np.mean(np.where((np.array(trQ_y)-np.array(trP_y))!=0,1,0))==0.0)\n",
    "assert (np.mean(np.where((np.array(trQ_y)-np.array(trN_y))!=0,1,0))==1.0)\n",
    "\n",
    "#define model\n",
    "model = ATHNet(hash_size=36, type_size=5).cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "tl_loss  = TripletLoss(margin=0.5).cuda() #define TripletLoss \n",
    "ce_loss  = nn.CrossEntropyLoss().cuda() #define cross-entropy loss\n",
    "\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "plot_tripletloss = []\n",
    "for epoch in range(50):#iteration\n",
    "    losses, hash_losses, class_loss = [], [], []\n",
    "    shuffled_idx = np.random.permutation(np.arange(len(trQ_sf)))\n",
    "    train_q = trQ_sf[shuffled_idx]\n",
    "    train_q_y = trQ_y[shuffled_idx]\n",
    "    train_p = trP_sf[shuffled_idx]\n",
    "    train_p_y = trP_y[shuffled_idx]\n",
    "    train_n = trN_sf[shuffled_idx]\n",
    "    train_n_y = trN_y[shuffled_idx]\n",
    "    num_batches = len(trQ_sf) // batchSize\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trQ_sf), (i+1)*batchSize])\n",
    "        Q_batch = torch.from_numpy(train_q[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        Q_y_batch = torch.from_numpy(train_q_y[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        P_batch = torch.from_numpy(train_p[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        P_y_batch = torch.from_numpy(train_p_y[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        N_batch = torch.from_numpy(train_n[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        N_y_batch = torch.from_numpy(train_n_y[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        #forword\n",
    "        Q_hash, Q_type = model(Q_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        P_hash, P_type = model(P_batch.permute(0, 3, 1, 2))\n",
    "        N_hash, N_type = model(N_batch.permute(0, 3, 1, 2))\n",
    "        #loss,#F.log_softmax+F.nll_loss\n",
    "        hash_loss = tl_loss(Q_hash,P_hash,N_hash)\n",
    "        type_loss = ce_loss(Q_type,Q_y_batch) + ce_loss(P_type,P_y_batch) + ce_loss(N_type,N_y_batch) \n",
    "        loss = hash_loss+type_loss\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "        hash_losses.append(hash_loss.item())\n",
    "        class_loss.append(type_loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    plot_tripletloss.append(np.mean(hash_losses))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "tl_loss=tl_loss.cpu()\n",
    "ce_loss=ce_loss.cpu()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17.19490905019972, 16.138523411220973, 15.27953808678521, 13.567265672849285, 12.465564910808785, 10.974376009044548, 9.805674698294865, 8.898501250710753, 7.708006849521771, 6.789166804036746, 5.884611516456223, 5.090200038852377, 4.2893484655519325, 3.68937084286215, 3.107978306371305, 2.6667100233774788, 2.1364617234385674, 1.8807740409548084, 1.717733720787801, 1.362559432153228, 1.230248041275061, 1.1818840779179138, 0.9682118869324525, 0.9991373343186246, 0.8873830052923101, 0.8090240444874184, 0.7773097575642168, 0.6743753006329967, 0.6557964225392788, 0.6316299202882996, 0.5265758212298776, 0.5676938693592739, 0.551706732277655, 0.5991558107857903, 0.5347910418247597, 0.44688135346397756, 0.47425651371375555, 0.3340531005468155, 0.4555749459554338, 0.39682673548115416, 0.40412271675498534, 0.3948044294470714, 0.3693438702511291, 0.280456232022908, 0.3737329430774682, 0.3663472735116051, 0.32769884179074626, 0.3507867917358979, 0.30510521583879985, 0.3230860122521537]\n"
     ]
    }
   ],
   "source": [
    "print (plot_tripletloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99 / 100  Completed buliding index in 22 seconds\n",
      "mHR@10=0.749700, mAP@10=0.715217, mRR@10=0.934236\n",
      "[[687  25  21  29  15]\n",
      " [ 52   4   7   2   7]\n",
      " [ 14   5   4   3   1]\n",
      " [ 38   2   4   0   1]\n",
      " [ 26  10   4  13  26]]\n",
      "Sensitivity(TPR) of Normal: 0.884170\n",
      "Sensitivity(TPR) of AMD: 0.055556\n",
      "Sensitivity(TPR) of DR: 0.148148\n",
      "Sensitivity(TPR) of Glaucoma: 0.000000\n",
      "Sensitivity(TPR) of Myopia: 0.329114\n",
      "AUC (Area Under Curve) of Micro: 0.897840\n"
     ]
    }
   ],
   "source": [
    "#hash code of train data from model\n",
    "#torch.cuda.synchronize()\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize \n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch,_ = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#hash code of test data from model\n",
    "#torch.cuda.synchronize()\n",
    "teY_pred = []\n",
    "teY_prob = []\n",
    "teF = [] \n",
    "num_batches = len(teY) // batchSize \n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    x_hash, x_type = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    teF.extend(x_hash.cpu().data.numpy().tolist()) #record feature\n",
    "    x_type = F.log_softmax(x_type,dim=1) \n",
    "    teY_prob.extend(x_type.cpu().data.numpy().tolist())\n",
    "    pred = x_type.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(pred.cpu().data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "#performance of retrieval\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(36) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "for topk in [10]:\n",
    "    MHR = [] #mean Hit ratio \n",
    "    MAP = [] #mean average precision\n",
    "    MRR = [] #mean reciprocal rank\n",
    "    scores, neighbors = gpu_index.search(np.array(teF).astype('float32'), k=topk)\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        mrr_flag = 0\n",
    "        #for j in ranklist:\n",
    "        for j in neighbors[i].tolist():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                MHR.append(1)\n",
    "                pos_len = pos_len +1\n",
    "                MAP.append(pos_len/rank_len) \n",
    "                if mrr_flag==0: \n",
    "                    MRR.append(pos_len/rank_len)\n",
    "                    mrr_flag =1\n",
    "            else: \n",
    "                MHR.append(0)\n",
    "                MAP.append(0)   \n",
    "    print(\"mHR@{}={:.6f}, mAP@{}={:.6f}, mRR@{}={:.6f}\".format(topk,np.mean(MHR),topk,np.mean(MAP), topk, np.mean(MRR)))\n",
    "#performance of classification\n",
    "#https://blog.csdn.net/hlang8160/article/details/78040311\n",
    "#https://www.jianshu.com/p/7919ef304b19\n",
    "#https://www.jianshu.com/p/c61ae11cc5f6\n",
    "#https://www.cnblogs.com/yanshw/p/12691329.html\n",
    "#TNR= TN / (FP + TN) ->low misdiagnosis rate->Specificity\n",
    "#TPR=TP / (TP+ FN) -> low missed diagnosis rate->Sensitivity\n",
    "#ROC: x axis = 1-TNR, y asis=TPR\n",
    "#print ( 'Accuracy: %.6f'%accuracy_score(teY, teY_pred))\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, teY_pred, labels=labels) \n",
    "print (cm)\n",
    "print ('Sensitivity(TPR) of Normal: %.6f'%float(cm[0][0]/np.sum(cm[0]))) \n",
    "print ('Sensitivity(TPR) of AMD: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity(TPR) of DR: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity(TPR) of Glaucoma: %.6f'%float(cm[3][3]/np.sum(cm[3])))\n",
    "print ('Sensitivity(TPR) of Myopia: %.6f'%float(cm[4][4]/np.sum(cm[4])))\n",
    "#auc and roc\n",
    "teY_one_hot = label_binarize(np.array(teY), np.arange(len(labels)))\n",
    "auc_score = roc_auc_score(teY_one_hot, np.array(teY_prob), average='micro')#macro\n",
    "print ('AUC (Area Under Curve) of Micro: %.6f'% auc_score)\n",
    "fpr_tce, tpr_tce, thresholds = roc_curve(teY_one_hot.ravel(),np.array(teY_prob).ravel()) #for roc curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481483.jpg:2-Distance:0.021004\n",
      "496278.jpg:0-Distance:0.281160\n",
      "488091.jpg:0-Distance:0.305985\n",
      "488939.jpg:1-Distance:0.318543\n",
      "481590.jpg:0-Distance:0.321325\n",
      "484703.jpg:0-Distance:0.322712\n",
      "92659.jpg:1-Distance:0.335201\n",
      "908668.jpg:0-Distance:0.340074\n",
      "910369.jpg:0-Distance:0.343832\n",
      "486933.jpg:0-Distance:0.344289\n",
      "488225.jpg:0-Distance:0.348042\n",
      "98815.jpg:0-Distance:0.353763\n",
      "909999.jpg:0-Distance:0.354402\n",
      "82791.jpg:0-Distance:0.355593\n",
      "99384.jpg:4-Distance:0.356089\n",
      "98272.jpg:1-Distance:0.356324\n",
      "89977.jpg:0-Distance:0.356890\n",
      "496065.jpg:0-Distance:0.359909\n",
      "488388.jpg:0-Distance:0.363795\n",
      "913078.jpg:0-Distance:0.365187\n"
     ]
    }
   ],
   "source": [
    "#figure 1 for problem introduction\n",
    "image_dir = '/data/fjsdata/fundus/iSee/iSee_multi_dataset/img_data_DR/481483.jpg' #DR\n",
    "Input_feature = []\n",
    "Input_feature.append( cv2.resize(cv2.imread(image_dir).astype(np.float32), (256, 256)))\n",
    "data = torch.from_numpy(np.array(Input_feature)).type(torch.FloatTensor).cuda()\n",
    "Output_feature,logit = best_net(data.permute(0, 3, 1, 2))#forword\n",
    "Output_feature=np.array(Output_feature.cpu().data.numpy().tolist())\n",
    "map_item_score = {}\n",
    "for j, trVal in enumerate(trF):\n",
    "    map_item_score[j] = pdist(np.vstack([Output_feature[0],trVal]),'cosine')#hamming\n",
    "ranklist = heapq.nsmallest(20, map_item_score, key=map_item_score.get)\n",
    "for j in ranklist:\n",
    "    print ('%s:%d-Distance:%.6f'%(trN[j],trY[j],map_item_score[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495656.jpg:2-481483.jpg:2-Distance:0.290702\n"
     ]
    }
   ],
   "source": [
    "#figure 1 for problem introduction\n",
    "for i in range(len(teY)):\n",
    "    if teY[i]==2 :#DR\n",
    "    #if teN[i] in ['28901_right','19414_right']: \n",
    "        itype = teY[i]\n",
    "        teVal = teF[i]\n",
    "        image_path = os.path.join(root_dir, teN[i])\n",
    "        map_item_score = {}\n",
    "        for j, trVal in enumerate(trF):\n",
    "            map_item_score[j] = pdist(np.vstack([teVal,trVal]),'cosine')#hamming\n",
    "        ranklist = heapq.nsmallest(5, map_item_score, key=map_item_score.get)\n",
    "        for j in ranklist:\n",
    "            if trY[j]==2:\n",
    "                print ('%s:%d-%s:%d-Distance:%.6f'%(teN[i],teY[i],trN[j],trY[j],map_item_score[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.841 -> DR\n",
      "0.072 -> Norm\n",
      "0.067 -> Glaucoma\n",
      "0.017 -> AMD\n",
      "0.002 -> Myopia\n",
      "(1, 1, 128, 128)\n",
      "output CAM.jpg for the top1 prediction: DR\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate class activation mapping for the top1 prediction\n",
    "def returnCAM(feature_conv, weight_softmax, class_idx):\n",
    "    # generate the class activation maps upsample to 256x256\n",
    "    size_upsample = (256, 256)\n",
    "    bz, nc, h, w = 1,1,32,32#feature_conv.shape\n",
    "    \n",
    "    output_cam = []\n",
    "    for idx in class_idx:\n",
    "        #cam = weight_softmax[class_idx].dot(feature_conv.reshape((nc,h*w)))\n",
    "        cam = weight_softmax[class_idx]*(feature_conv.reshape((nc,h*w)))\n",
    "        cam = cam.reshape(h, w)\n",
    "        cam = cam - np.min(cam)\n",
    "        cam_img = cam / np.max(cam)\n",
    "        cam_img = np.uint8(255 * cam_img)\n",
    "        output_cam.append(cv2.resize(cam_img, size_upsample))\n",
    "    return output_cam\n",
    "\n",
    "\n",
    "# hook the feature extractor\n",
    "features_blobs = []\n",
    "def hook_feature(module, input, output):\n",
    "    features_blobs.append(output.data.cpu().numpy())\n",
    "#last conv layer followed with one channel by last fully connected layer\n",
    "final_conv = 'sa' \n",
    "best_net._modules.get(final_conv).register_forward_hook(hook_feature)\n",
    "#get weights parameters\n",
    "params = list(best_net.parameters())\n",
    "#get the last and second last weights, like [classes, hiden nodes]\n",
    "weight_softmax = np.squeeze(params[-2].data.cpu().numpy()) \n",
    "# define class type\n",
    "classes = {0:'Norm', 1: 'AMD', 2: 'DR', 3:'Glaucoma', 4:'Myopia', }\n",
    "#read image\n",
    "root='/data/fjsdata/fundus/iSee/iSee_multi_dataset/img_data_DR/100217.jpg'\n",
    "img = []\n",
    "img.append( cv2.resize(cv2.imread(root).astype(np.float32), (256, 256)))#(256, 256) is the model input size\n",
    "data = torch.from_numpy(np.array(img)).type(torch.FloatTensor).cuda()\n",
    "_,logit = best_net(data.permute(0, 3, 1, 2))#forword\n",
    "h_x = F.softmax(logit, dim=1).data.squeeze()#softmax\n",
    "probs, idx = h_x.sort(0, True) #probabilities of classes\n",
    "\n",
    "# output: the prediction\n",
    "for i in range(0, len(classes)):\n",
    "    line = '{:.3f} -> {}'.format(probs[i], classes[idx[i].item()])\n",
    "    print(line)\n",
    "#get the class activation maps\n",
    "print (features_blobs[-1].shape)\n",
    "feature_layer = features_blobs[-1].squeeze()[0]\n",
    "feature_layer = cv2.resize(feature_layer, (32, 32))\n",
    "CAMs = returnCAM(feature_layer, weight_softmax, [idx[0].item()])\n",
    "\n",
    "# render the CAM and show\n",
    "print('output CAM.jpg for the top1 prediction: %s' % classes[idx[0].item()])\n",
    "img = cv2.imread(root)\n",
    "height, width, _ = img.shape\n",
    "CAM = cv2.resize(CAMs[0], (width, height))\n",
    "heatmap = cv2.applyColorMap(CAM, cv2.COLORMAP_JET)\n",
    "#result = heatmap * 0.3 + img * 0.5\n",
    "result = heatmap \n",
    "cv2.imwrite('iSee_cam.jpg', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 16, 128, 128)\n",
      "(16, 128, 128)\n",
      "(128, 128)\n",
      "output CAM.jpg for the top1 prediction: DR\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (features_blobs[0].shape)\n",
    "feature_layer = features_blobs[0].squeeze()\n",
    "print (feature_layer.shape)\n",
    "#feature_layer = np.mean(feature_layer, axis=0)\n",
    "feature_layer = np.max(feature_layer, axis=0)\n",
    "print (feature_layer.shape)\n",
    "feature_layer = cv2.resize(feature_layer, (32, 32))\n",
    "CAMs = returnCAM(feature_layer, weight_softmax, [idx[0].item()])\n",
    "\n",
    "# render the CAM and show\n",
    "print('output CAM.jpg for the top1 prediction: %s' % classes[idx[0].item()])\n",
    "img = cv2.imread(root)\n",
    "height, width, _ = img.shape\n",
    "CAM = cv2.resize(CAMs[0], (width, height))\n",
    "heatmap = cv2.applyColorMap(CAM, cv2.COLORMAP_JET)\n",
    "#result = heatmap * 0.3 + img * 0.5\n",
    "result = heatmap \n",
    "cv2.imwrite('iSee_cam.jpg', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 900 / 900 : loss = 17.614923Eopch:     1 mean_loss = 17.269549\n",
      " 900 / 900 : loss = 15.560282Eopch:     2 mean_loss = 16.117119\n",
      " 900 / 900 : loss = 19.702757Eopch:     3 mean_loss = 15.425354\n",
      " 900 / 900 : loss = 7.6883012Eopch:     4 mean_loss = 14.387825\n",
      " 900 / 900 : loss = 10.221549Eopch:     5 mean_loss = 13.455571\n",
      " 900 / 900 : loss = 12.598732Eopch:     6 mean_loss = 12.175616\n",
      " 900 / 900 : loss = 7.2787132Eopch:     7 mean_loss = 10.908250\n",
      " 900 / 900 : loss = 19.430489Eopch:     8 mean_loss = 9.592487\n",
      " 900 / 900 : loss = 0.7529739Eopch:     9 mean_loss = 8.074116\n",
      " 900 / 900 : loss = 4.8095846Eopch:    10 mean_loss = 6.752805\n",
      " 900 / 900 : loss = 3.0550255Eopch:    11 mean_loss = 5.895860\n",
      " 900 / 900 : loss = 2.9965866Eopch:    12 mean_loss = 5.071240\n",
      " 900 / 900 : loss = 6.6479396Eopch:    13 mean_loss = 4.504203\n",
      " 900 / 900 : loss = 0.1788295Eopch:    14 mean_loss = 3.790285\n",
      " 900 / 900 : loss = 14.437225Eopch:    15 mean_loss = 3.255619\n",
      " 900 / 900 : loss = 0.0696288Eopch:    16 mean_loss = 2.695951\n",
      " 900 / 900 : loss = 0.0396984Eopch:    17 mean_loss = 2.412342\n",
      " 900 / 900 : loss = 3.4730855Eopch:    18 mean_loss = 2.032758\n",
      " 900 / 900 : loss = 1.5817936Eopch:    19 mean_loss = 1.693014\n",
      " 900 / 900 : loss = 4.7010385Eopch:    20 mean_loss = 1.496082\n",
      " 900 / 900 : loss = 0.0925845Eopch:    21 mean_loss = 1.431367\n",
      " 900 / 900 : loss = 0.4498187Eopch:    22 mean_loss = 1.357257\n",
      " 900 / 900 : loss = 0.0035617Eopch:    23 mean_loss = 1.149351\n",
      " 900 / 900 : loss = 0.0609128Eopch:    24 mean_loss = 1.040227\n",
      " 900 / 900 : loss = 0.0654344Eopch:    25 mean_loss = 0.982140\n",
      " 900 / 900 : loss = 0.0010629Eopch:    26 mean_loss = 0.983634\n",
      " 900 / 900 : loss = 0.0167691Eopch:    27 mean_loss = 0.947165\n",
      " 900 / 900 : loss = 0.0281916Eopch:    28 mean_loss = 0.734287\n",
      " 900 / 900 : loss = 0.0816044Eopch:    29 mean_loss = 0.787073\n",
      " 900 / 900 : loss = 0.0190067Eopch:    30 mean_loss = 0.757559\n",
      " 900 / 900 : loss = 0.0468498Eopch:    31 mean_loss = 0.785223\n",
      " 900 / 900 : loss = 1.488332Eopch:    32 mean_loss = 0.677016\n",
      " 900 / 900 : loss = 0.0050438Eopch:    33 mean_loss = 0.693865\n",
      " 900 / 900 : loss = 0.0827061Eopch:    34 mean_loss = 0.670557\n",
      " 900 / 900 : loss = 0.3326354Eopch:    35 mean_loss = 0.619723\n",
      " 900 / 900 : loss = 0.0088291Eopch:    36 mean_loss = 0.737207\n",
      " 900 / 900 : loss = 2.2831127Eopch:    37 mean_loss = 0.676527\n",
      " 900 / 900 : loss = 0.0500989Eopch:    38 mean_loss = 0.528205\n",
      " 900 / 900 : loss = 0.0485385Eopch:    39 mean_loss = 0.551756\n",
      " 900 / 900 : loss = 0.9195162Eopch:    40 mean_loss = 0.541503\n",
      " 900 / 900 : loss = 0.9418951Eopch:    41 mean_loss = 0.572283\n",
      " 900 / 900 : loss = 0.9082931Eopch:    42 mean_loss = 0.564959\n",
      " 900 / 900 : loss = 0.018979Eopch:    43 mean_loss = 0.410805\n",
      " 900 / 900 : loss = 0.7027711Eopch:    44 mean_loss = 0.468469\n",
      " 900 / 900 : loss = 0.0206338Eopch:    45 mean_loss = 0.582417\n",
      " 900 / 900 : loss = 0.030265Eopch:    46 mean_loss = 0.442485\n",
      " 900 / 900 : loss = 0.0135015Eopch:    47 mean_loss = 0.369664\n",
      " 900 / 900 : loss = 0.042947Eopch:    48 mean_loss = 0.418194\n",
      " 900 / 900 : loss = 0.0644094Eopch:    49 mean_loss = 0.531095\n",
      " 900 / 900 : loss = 0.0437133Eopch:    50 mean_loss = 0.498718\n",
      "best_loss = 0.369664\n",
      " 99 / 100  Completed buliding index in 1 seconds\n",
      "mHR@10=0.739600, mAP@10=0.704638, mRR@10=0.933241\n",
      "[[479  81 201   0  16]\n",
      " [ 40   8  23   0   1]\n",
      " [ 18   1   6   1   1]\n",
      " [ 29   5   8   0   3]\n",
      " [ 40   6  29   0   4]]\n",
      "Sensitivity(TPR) of Normal: 0.616474\n",
      "Sensitivity(TPR) of AMD: 0.111111\n",
      "Sensitivity(TPR) of DR: 0.222222\n",
      "Sensitivity(TPR) of Glaucoma: 0.000000\n",
      "Sensitivity(TPR) of Myopia: 0.050633\n",
      "AUC (Area Under Curve) of Micro: 0.773486\n"
     ]
    }
   ],
   "source": [
    "#define model\n",
    "model = ATHNet(hash_size=36, type_size=5).cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "tl_loss  = TripletLoss(margin=0.5).cuda() #define TripletLoss \n",
    "\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "pl_t_i = []\n",
    "for epoch in range(50):#iteration\n",
    "    losses = []\n",
    "    shuffled_idx = np.random.permutation(np.arange(len(trQ_sf)))\n",
    "    train_q = trQ_sf[shuffled_idx]\n",
    "    train_p = trP_sf[shuffled_idx]\n",
    "    train_n = trN_sf[shuffled_idx]\n",
    "    num_batches = len(trQ_sf) // batchSize\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trQ_sf), (i+1)*batchSize])\n",
    "        Q_batch = torch.from_numpy(train_q[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        P_batch = torch.from_numpy(train_p[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        N_batch = torch.from_numpy(train_n[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        #forword\n",
    "        Q_hash, _ = model(Q_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        P_hash, _ = model(P_batch.permute(0, 3, 1, 2))\n",
    "        N_hash, _ = model(N_batch.permute(0, 3, 1, 2))\n",
    "        #loss\n",
    "        loss = tl_loss(Q_hash,P_hash,N_hash)\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    pl_t_i.append(np.mean(losses))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "tl_loss=tl_loss.cpu()\n",
    "ce_loss=ce_loss.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#hash code of train data from model\n",
    "#torch.cuda.synchronize()\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize \n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch,_ = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#hash code of test data from model\n",
    "#torch.cuda.synchronize()\n",
    "teY_pred = []\n",
    "teY_prob = []\n",
    "teF = [] \n",
    "num_batches = len(teY) // batchSize \n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    x_hash, x_type = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    teF.extend(x_hash.cpu().data.numpy().tolist()) #record feature\n",
    "    x_type = F.log_softmax(x_type,dim=1) \n",
    "    teY_prob.extend(x_type.cpu().data.numpy().tolist())\n",
    "    pred = x_type.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(pred.cpu().data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "#performance of retrieval\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(36) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "for topk in [10]:\n",
    "    MHR = [] #mean Hit ratio \n",
    "    MAP = [] #mean average precision\n",
    "    MRR = [] #mean reciprocal rank\n",
    "    scores, neighbors = gpu_index.search(np.array(teF).astype('float32'), k=topk)\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        mrr_flag = 0\n",
    "        #for j in ranklist:\n",
    "        for j in neighbors[i].tolist():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                MHR.append(1)\n",
    "                pos_len = pos_len +1\n",
    "                MAP.append(pos_len/rank_len) \n",
    "                if mrr_flag==0: \n",
    "                    MRR.append(pos_len/rank_len)\n",
    "                    mrr_flag =1\n",
    "            else: \n",
    "                MHR.append(0)\n",
    "                MAP.append(0)   \n",
    "    print(\"mHR@{}={:.6f}, mAP@{}={:.6f}, mRR@{}={:.6f}\".format(topk,np.mean(MHR),topk,np.mean(MAP), topk, np.mean(MRR)))\n",
    "#performance of classification\n",
    "#https://blog.csdn.net/hlang8160/article/details/78040311\n",
    "#https://www.jianshu.com/p/7919ef304b19\n",
    "#https://www.jianshu.com/p/c61ae11cc5f6\n",
    "#https://www.cnblogs.com/yanshw/p/12691329.html\n",
    "#TNR= TN / (FP + TN) ->low misdiagnosis rate->Specificity\n",
    "#TPR=TP / (TP+ FN) -> low missed diagnosis rate->Sensitivity\n",
    "#ROC: x axis = 1-TNR, y asis=TPR\n",
    "#print ( 'Accuracy: %.6f'%accuracy_score(teY, teY_pred))\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, teY_pred, labels=labels) \n",
    "print (cm)\n",
    "print ('Sensitivity(TPR) of Normal: %.6f'%float(cm[0][0]/np.sum(cm[0]))) \n",
    "print ('Sensitivity(TPR) of AMD: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity(TPR) of DR: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity(TPR) of Glaucoma: %.6f'%float(cm[3][3]/np.sum(cm[3])))\n",
    "print ('Sensitivity(TPR) of Myopia: %.6f'%float(cm[4][4]/np.sum(cm[4])))\n",
    "#auc and roc\n",
    "teY_one_hot = label_binarize(np.array(teY), np.arange(len(labels)))\n",
    "auc_score = roc_auc_score(teY_one_hot, np.array(teY_prob), average='micro')#macro\n",
    "print ('AUC (Area Under Curve) of Micro: %.6f'% auc_score)\n",
    "fpr_tl, tpr_tl, thresholds = roc_curve(teY_one_hot.ravel(),np.array(teY_prob).ravel()) #for roc curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 450 / 450 : loss = 1.804384Eopch:     1 mean_loss = 3.437861\n",
      " 450 / 450 : loss = 2.701309Eopch:     2 mean_loss = 3.499912\n",
      " 450 / 450 : loss = 1.801613Eopch:     3 mean_loss = 3.469247\n",
      " 450 / 450 : loss = 3.600728Eopch:     4 mean_loss = 3.476900\n",
      " 450 / 450 : loss = 4.500449Eopch:     5 mean_loss = 3.434739\n",
      " 450 / 450 : loss = 4.500545Eopch:     6 mean_loss = 3.430594\n",
      " 450 / 450 : loss = 4.500203Eopch:     7 mean_loss = 3.406621\n",
      " 450 / 450 : loss = 4.500449Eopch:     8 mean_loss = 3.440555\n",
      " 450 / 450 : loss = 5.400171Eopch:     9 mean_loss = 3.372390\n",
      " 450 / 450 : loss = 1.800466Eopch:    10 mean_loss = 3.416363\n",
      " 450 / 450 : loss = 2.700316Eopch:    11 mean_loss = 3.470363\n",
      " 450 / 450 : loss = 5.400331Eopch:    12 mean_loss = 3.434344\n",
      " 450 / 450 : loss = 4.500446Eopch:    13 mean_loss = 3.420465\n",
      " 450 / 450 : loss = 3.600176Eopch:    14 mean_loss = 3.484007\n",
      " 450 / 450 : loss = 5.400224Eopch:    15 mean_loss = 3.414373\n",
      " 450 / 450 : loss = 2.700342Eopch:    16 mean_loss = 3.486264\n",
      " 450 / 450 : loss = 4.500844Eopch:    17 mean_loss = 3.393466\n",
      " 450 / 450 : loss = 3.600618Eopch:    18 mean_loss = 3.451136\n",
      " 450 / 450 : loss = 2.689686Eopch:    19 mean_loss = 3.477299\n",
      " 450 / 450 : loss = 3.598883Eopch:    20 mean_loss = 3.456606\n",
      " 450 / 450 : loss = 2.707122Eopch:    21 mean_loss = 3.398370\n",
      " 450 / 450 : loss = 3.600172Eopch:    22 mean_loss = 3.392441\n",
      " 450 / 450 : loss = 5.400071Eopch:    23 mean_loss = 3.390325\n",
      " 450 / 450 : loss = 3.600411Eopch:    24 mean_loss = 3.436254\n",
      " 450 / 450 : loss = 4.500169Eopch:    25 mean_loss = 3.456259\n",
      " 450 / 450 : loss = 0.900217Eopch:    26 mean_loss = 3.504187\n",
      " 450 / 450 : loss = 2.700124Eopch:    27 mean_loss = 3.438174\n",
      " 450 / 450 : loss = 2.700495Eopch:    28 mean_loss = 3.416368\n",
      " 450 / 450 : loss = 4.500181Eopch:    29 mean_loss = 3.418567\n",
      " 450 / 450 : loss = 3.599862Eopch:    30 mean_loss = 3.422189\n",
      " 450 / 450 : loss = 2.703991Eopch:    31 mean_loss = 3.455547\n",
      " 450 / 450 : loss = 4.500497Eopch:    32 mean_loss = 3.435210\n",
      " 450 / 450 : loss = 0.900176Eopch:    33 mean_loss = 3.420057\n",
      " 450 / 450 : loss = 1.800175Eopch:    34 mean_loss = 3.447941\n",
      " 450 / 450 : loss = 2.710323Eopch:    35 mean_loss = 3.431270\n",
      " 450 / 450 : loss = 3.600248Eopch:    36 mean_loss = 3.460677\n",
      " 450 / 450 : loss = 1.800133Eopch:    37 mean_loss = 3.478195\n",
      " 450 / 450 : loss = 4.500059Eopch:    38 mean_loss = 3.446109\n",
      " 450 / 450 : loss = 1.800037Eopch:    39 mean_loss = 3.420060\n",
      " 450 / 450 : loss = 5.400021Eopch:    40 mean_loss = 3.406033\n",
      " 450 / 450 : loss = 3.600009Eopch:    41 mean_loss = 3.450023\n",
      " 450 / 450 : loss = 2.700789Eopch:    42 mean_loss = 3.423160\n",
      " 450 / 450 : loss = 1.800283Eopch:    43 mean_loss = 3.428484\n",
      " 450 / 450 : loss = 5.400116Eopch:    44 mean_loss = 3.382184\n",
      " 450 / 450 : loss = 2.700077Eopch:    45 mean_loss = 3.454143\n",
      " 450 / 450 : loss = 3.600095Eopch:    46 mean_loss = 3.404100\n",
      " 450 / 450 : loss = 1.800043Eopch:    47 mean_loss = 3.450076\n",
      " 450 / 450 : loss = 5.400043Eopch:    48 mean_loss = 3.404063\n",
      " 450 / 450 : loss = 3.600029Eopch:    49 mean_loss = 3.444055\n",
      " 450 / 450 : loss = 6.300036Eopch:    50 mean_loss = 3.442039\n",
      "best_loss = 3.372390\n",
      " 99 / 100  Completed buliding index in 1 seconds\n",
      "mHR@10=0.637800, mAP@10=0.538415, mRR@10=0.817677\n",
      "[[  0 541   1 234   1]\n",
      " [  0  49   0  23   0]\n",
      " [  0  18   0   9   0]\n",
      " [  0  36   0   9   0]\n",
      " [  0  42   1  36   0]]\n",
      "Sensitivity(TPR) of Normal: 0.000000\n",
      "Sensitivity(TPR) of AMD: 0.680556\n",
      "Sensitivity(TPR) of DR: 0.000000\n",
      "Sensitivity(TPR) of Glaucoma: 0.200000\n",
      "Sensitivity(TPR) of Myopia: 0.000000\n",
      "AUC (Area Under Curve) of Micro: 0.415050\n"
     ]
    }
   ],
   "source": [
    "#Generate image pairs for model\n",
    "def onlineGenImgPairs():\n",
    "    if (len(trY) % 2) == 0: spls = len(trY)\n",
    "    else:  spls = len(trY)-1\n",
    "    idx_sf = random.sample(range(0, spls),spls)\n",
    "    trI1_sf, trI2_sf, trY1_sf, trY2_sf = [],[],[],[]\n",
    "    flag = 0\n",
    "    for i in idx_sf:\n",
    "        if flag==0:\n",
    "            trI1_sf.append(trI[i])\n",
    "            trY1_sf.append(trY[i])\n",
    "            flag =1\n",
    "        else:\n",
    "            trI2_sf.append(trI[i])\n",
    "            trY2_sf.append(trY[i])\n",
    "            flag =0\n",
    "    trY_sf = np.where((np.array(trY1_sf)-np.array(trY2_sf))!=0,1,0)\n",
    "    return np.array(trI1_sf),np.array(trI2_sf),trY_sf\n",
    "\n",
    "#define model\n",
    "model = ATHNet(hash_size=36, type_size=5).cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "criterion  = PairwiseLoss(margin=0.5).cuda() #define PairwiseLoss \n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(50):#iteration\n",
    "    trI1_sf, trI2_sf, trY_sf = onlineGenImgPairs()\n",
    "    losses = []\n",
    "    num_batches = len(trY_sf) // batchSize \n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY_sf), (i+1)*batchSize])\n",
    "        I1_batch = torch.from_numpy(trI1_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        I2_batch = torch.from_numpy(trI2_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        Y_batch = torch.from_numpy(trY_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        #forword\n",
    "        X1_batch,_ = model(I1_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        X2_batch,_ = model(I2_batch.permute(0, 3, 1, 2))\n",
    "        #binary-like loss\n",
    "        loss = criterion(X1_batch,X2_batch,Y_batch)\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "tl_loss=tl_loss.cpu()\n",
    "ce_loss=ce_loss.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "#hash code of train data from model\n",
    "#torch.cuda.synchronize()\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize \n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch,_ = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#hash code of test data from model\n",
    "#torch.cuda.synchronize()\n",
    "teY_pred = []\n",
    "teY_prob = []\n",
    "teF = [] \n",
    "num_batches = len(teY) // batchSize \n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    x_hash, x_type = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    teF.extend(x_hash.cpu().data.numpy().tolist()) #record feature\n",
    "    x_type = F.log_softmax(x_type,dim=1) \n",
    "    teY_prob.extend(x_type.cpu().data.numpy().tolist())\n",
    "    pred = x_type.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(pred.cpu().data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#performance of retrieval\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(36) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "for topk in [10]:\n",
    "    MHR = [] #mean Hit ratio \n",
    "    MAP = [] #mean average precision\n",
    "    MRR = [] #mean reciprocal rank\n",
    "    scores, neighbors = gpu_index.search(np.array(teF).astype('float32'), k=topk)\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        mrr_flag = 0\n",
    "        #for j in ranklist:\n",
    "        for j in neighbors[i].tolist():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                MHR.append(1)\n",
    "                pos_len = pos_len +1\n",
    "                MAP.append(pos_len/rank_len) \n",
    "                if mrr_flag==0: \n",
    "                    MRR.append(pos_len/rank_len)\n",
    "                    mrr_flag =1\n",
    "            else: \n",
    "                MHR.append(0)\n",
    "                MAP.append(0)   \n",
    "    print(\"mHR@{}={:.6f}, mAP@{}={:.6f}, mRR@{}={:.6f}\".format(topk,np.mean(MHR),topk,np.mean(MAP), topk, np.mean(MRR)))\n",
    "#performance of classification\n",
    "#https://blog.csdn.net/hlang8160/article/details/78040311\n",
    "#https://www.jianshu.com/p/7919ef304b19\n",
    "#https://www.jianshu.com/p/c61ae11cc5f6\n",
    "#https://www.cnblogs.com/yanshw/p/12691329.html\n",
    "#TNR= TN / (FP + TN) ->low misdiagnosis rate->Specificity\n",
    "#TPR=TP / (TP+ FN) -> low missed diagnosis rate->Sensitivity\n",
    "#ROC: x axis = 1-TNR, y asis=TPR\n",
    "#print ( 'Accuracy: %.6f'%accuracy_score(teY, teY_pred))\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, teY_pred, labels=labels) \n",
    "print (cm)\n",
    "print ('Sensitivity(TPR) of Normal: %.6f'%float(cm[0][0]/np.sum(cm[0]))) \n",
    "print ('Sensitivity(TPR) of AMD: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity(TPR) of DR: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity(TPR) of Glaucoma: %.6f'%float(cm[3][3]/np.sum(cm[3])))\n",
    "print ('Sensitivity(TPR) of Myopia: %.6f'%float(cm[4][4]/np.sum(cm[4])))\n",
    "#auc and roc\n",
    "teY_one_hot = label_binarize(np.array(teY), np.arange(len(labels)))\n",
    "auc_score = roc_auc_score(teY_one_hot, np.array(teY_prob), average='micro')#macro\n",
    "print ('AUC (Area Under Curve) of Micro: %.6f'% auc_score)\n",
    "fpr_pl, tpr_pl, thresholds = roc_curve(teY_one_hot.ravel(),np.array(teY_prob).ravel()) #for roc curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr_tce, tpr_tce, c = 'r', ls = '--', label = u'ATH(our) AUC=%.4f' % 0.8978)\n",
    "plt.plot(fpr_tl, tpr_tl, c = 'b', ls = '--', label = u'ATH-pairwise AUC=%.4f' % 0.8034)\n",
    "#plt.plot(fpr_pl, tpr_pl, c = 'b', ls = '--', label = u'ATH-pairwise AUC=%.4f' % 0.7734)\n",
    "plt.plot((0, 1), (0, 1), c = '#808080', lw = 1, ls = '--', alpha = 0.7)\n",
    "plt.xlim((-0.01, 1.02))\n",
    "plt.ylim((-0.01, 1.02))\n",
    "plt.xticks(np.arange(0, 1.1, 0.2))\n",
    "plt.yticks(np.arange(0, 1.1, 0.2))\n",
    "plt.xlabel('1-Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.grid(b=True, ls=':')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Fundus-DR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize : t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import random\n",
    "def scatter(X, y):\n",
    "    #X,y:numpy-array\n",
    "    classes = len(list(set(y.tolist())))#get number of classes\n",
    "    #palette = np.array(sns.color_palette(\"hls\", classes))# choose a color palette with seaborn.\n",
    "    color = ['c','y','m','b','g','r']\n",
    "    marker = ['o','x','s','*','+']\n",
    "    label = ['AMD','DR','glaucoma','myopia','normal']\n",
    "    plt.figure(figsize=(8,8))#create a plot\n",
    "    for i in range(classes):\n",
    "        plt.scatter(X[y == i,0], X[y == i,1], c=color[i], marker=marker[i], label=label[i])\n",
    "    plt.axis('off')\n",
    "    plt.legend(loc='lower left')\n",
    "    #plt.savefig('digits_tsne-generated.png', dpi=100)\n",
    "    plt.show()\n",
    "\n",
    "#prepare dataclasses=5\n",
    "#idx= random.sample(np.where(np.array(teY)==0)[0].tolist(),100)\n",
    "idx= np.where(np.array(teY)==0)[0].tolist()\n",
    "X0= np.array(teF)[idx]\n",
    "y0= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==1)[0].tolist()\n",
    "X1= np.array(teF)[idx]\n",
    "y1= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==2)[0].tolist()\n",
    "X2= np.array(teF)[idx]\n",
    "y2= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==3)[0].tolist()\n",
    "X3= np.array(teF)[idx]\n",
    "y3= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==4)[0].tolist()\n",
    "X4= np.array(teF)[idx]\n",
    "y4= np.array(teY)[idx]\n",
    "\n",
    "y = np.append(y0,y1)\n",
    "y = np.append(y,y2)\n",
    "y = np.append(y,y3)\n",
    "y = np.append(y,y4)\n",
    "X = np.vstack((X0,X1))\n",
    "X = np.vstack((X,X2))\n",
    "X = np.vstack((X,X3))\n",
    "X = np.vstack((X,X4))\n",
    "#training t-sne \n",
    "tsne = TSNE(n_components=2, init='pca', random_state=501)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "print(\"Org data dimension is {}.Embedded data dimension is {}\".format(X.shape[-1], X_tsne.shape[-1]))\n",
    "\n",
    "#visualize\n",
    "scatter(X_tsne, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
