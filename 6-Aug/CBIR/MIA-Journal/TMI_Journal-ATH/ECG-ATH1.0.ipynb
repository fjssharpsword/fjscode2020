{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.Develop Env: linux+cuda9+python3+opencv+pytorch\n",
    "2.Dataset: Fundus-iSee with 10000 images(AMD-720, DR-270, glaucoma-450,myopia-790,norm-7770)\n",
    "        trainset(9000): AMD-648, DR-243, glaucoma-405, myopia-711, norm-6993, \n",
    "        testset(1000): AMD-72, DR-27, glaucoma-45, myopia-79, norm=777\n",
    "3.Performance Metric for unbalanced sample(triplet loss): \n",
    "  1)AUC (Area Under Curve);\n",
    "  2)Sensitivity(Sen): for evaluating the missed diagnosis rate of abnorml\n",
    "4.Performance Metric for retrieval (Spatial Attention Mechanism):\n",
    "  1)MHR(Mean Hit Ratio):  for evaluating the precison of relevance retrieval;\n",
    "  2)MAP(Mean Average Precision): for evaluation the rank of relevance retrieval;\n",
    "  3)MRR(Mean Reciprocal Rank): for evaluation the first hit rank of relevance retrieval;\n",
    "5.Algorithm: Attention-based Triplet Hashing Network(ATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading faiss with AVX2 support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "import gc\n",
    "from PIL import Image\n",
    "from io import StringIO,BytesIO \n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc,roc_auc_score  \n",
    "from functools import reduce\n",
    "import faiss \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "torch.cuda.set_device(0)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttention(nn.Module):#spatial attention layer\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels, out_channels=out_channels,\n",
    "                kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        self.downsample_layer = None\n",
    "        self.do_downsample = False\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.do_downsample = True\n",
    "            self.downsample_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.net(x)\n",
    "\n",
    "        if self.do_downsample:\n",
    "            identity = self.downsample_layer(x)\n",
    "\n",
    "        return F.relu(out + identity, inplace=True) #resnet\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            \n",
    "class ATHNet(nn.Module):\n",
    "    def __init__(self, hash_size: int, type_size: int):\n",
    "        super().__init__()\n",
    "        #resnet and maxpool\n",
    "        self.net1 = nn.Sequential(#(3,256,256)->(16,128,128)\n",
    "            ResBlock(in_channels=3, out_channels=16, stride=2), \n",
    "            nn.MaxPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        )\n",
    "        \n",
    "        #Attention (16,128,128)->(16,128,128)\n",
    "        self.sa = SpatialAttention()\n",
    "        \n",
    "        #resnet and meanpool\n",
    "        self.net2 =nn.Sequential( #(16,128,128)->(8,64,64)\n",
    "            ResBlock(in_channels=16, out_channels=8, stride=2),\n",
    "            nn.AvgPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        ) \n",
    "         \n",
    "        #fully connected with conv (8,64,64)->(1,32,32)\n",
    "        self.dense=ResBlock(in_channels=8, out_channels=1, stride=2)\n",
    "        #fully connected (1,32,32)->class_size\n",
    "        self.hashlayer = nn.Linear(1*32*32, hash_size)\n",
    "        self.typelayer = nn.Linear(1*32*32, type_size)\n",
    "    \n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net1(x)\n",
    "        x = self.sa(x)*x\n",
    "        x = self.net2(x)\n",
    "        x = self.dense(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x_hash = self.hashlayer(x)\n",
    "        x_type = self.typelayer(x)\n",
    "        return x_hash, x_type\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "#https://github.com/luyajie/triplet-deep-hash-pytorch#triplet-deep-hash-pytorch            \n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=0.5):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin #margin threshold\n",
    "        self.mse_loss = nn.MSELoss(reduction='none')\n",
    "    \n",
    "    def forward(self,H_q,H_p,H_n):    \n",
    "        margin_val = self.margin * H_q.shape[1]\n",
    "        squared_loss_pos = torch.mean(self.mse_loss(H_q, H_p), dim=1)\n",
    "        squared_loss_neg = torch.mean(self.mse_loss(H_q, H_n), dim=1)\n",
    "        zeros = torch.zeros_like(squared_loss_neg)\n",
    "        loss  = torch.max(zeros, margin_val - squared_loss_neg + squared_loss_pos)\n",
    "        return torch.mean(loss)\n",
    "    \n",
    "#https://github.com/marvis/pytorch-yolo2/blob/master/FocalLoss.py\n",
    "#https://github.com/clcarwin/focal_loss_pytorch/blob/master/focalloss.py  \n",
    "class FocalLoss(nn.Module):\n",
    "    #Loss(x, class) = - \\alpha (1-softmax(x)[class])^gamma \\log(softmax(x)[class])\n",
    "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n",
    "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, out, y):\n",
    "        y = y.view(-1,1)\n",
    "        logpt = F.log_softmax(out,dim=1)#default ,dim=1\n",
    "        logpt = logpt.gather(1,y)# dim=1, index=y, max\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = Variable(logpt.data.exp())\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type()!=out.data.type():\n",
    "                self.alpha = self.alpha.type_as(out.data)\n",
    "            at = self.alpha.gather(0,y.data.view(-1))\n",
    "            logpt = logpt * Variable(at)\n",
    "\n",
    "        loss = -1 * (1-pt)**self.gamma * logpt\n",
    "        if self.size_average: return loss.mean()\n",
    "        else: return loss.sum()\n",
    "#https://github.com/qianjinhao/circle-loss\n",
    "class CircleLoss(nn.Module):\n",
    "    def __init__(self, scale=32, margin=0.25, similarity='cos', **kwargs):\n",
    "        super(CircleLoss, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.margin = margin\n",
    "        self.similarity = similarity\n",
    "\n",
    "    def forward(self, feats, labels):\n",
    "        assert feats.size(0) == labels.size(0), \\\n",
    "            f\"feats.size(0): {feats.size(0)} is not equal to labels.size(0): {labels.size(0)}\"\n",
    "        batch_size = feats.size(0)\n",
    "        if self.similarity == 'dot':\n",
    "            sim_mat = torch.matmul(feats, torch.t(feats))\n",
    "        elif self.similarity == 'cos':\n",
    "            feats = F.normalize(feats)\n",
    "            sim_mat = feats.mm(feats.t())\n",
    "        else:\n",
    "            raise ValueError('This similarity is not implemented.')\n",
    "        loss = list()\n",
    "        for i in range(batch_size):\n",
    "            pos_index = labels == labels[i]\n",
    "            pos_index[i] = 0\n",
    "            neg_index = labels != labels[i]\n",
    "            pos_pair_ = sim_mat[i][pos_index]\n",
    "            neg_pair_ = sim_mat[i][neg_index]\n",
    "\n",
    "            alpha_p = torch.relu(-pos_pair_ + 1 + self.margin)\n",
    "            alpha_n = torch.relu(neg_pair_ + self.margin)\n",
    "            margin_p = 1 - self.margin\n",
    "            margin_n = self.margin\n",
    "            loss_p = torch.sum(torch.exp(-self.scale * alpha_p * (pos_pair_ - margin_p)))\n",
    "            loss_n = torch.sum(torch.exp(self.scale * alpha_n * (neg_pair_ - margin_n)))\n",
    "            loss.append(torch.log(1 + loss_p * loss_n))\n",
    "\n",
    "        loss = sum(loss) / batch_size\n",
    "        return loss    \n",
    "\n",
    "#define loss function:pairwise loss            \n",
    "class PairwiseLoss(nn.Module):\n",
    "    def __init__(self, margin=0.5, alpha=0.01):\n",
    "        super(PairwiseLoss, self).__init__()\n",
    "        self.alpha = alpha #regularization\n",
    "        self.margin = margin #margin threshold\n",
    "        self.mse_loss = nn.MSELoss(reduction='none')\n",
    "        self.l1_loss = nn.L1Loss(reduction='mean')\n",
    "    \n",
    "    def forward(self,h1,h2,y):    \n",
    "        margin_val = self.margin * h1.shape[1]\n",
    "        squared_loss = torch.mean(self.mse_loss(h1, h2), dim=1)\n",
    "        # T1: 0.5 * (1 - y) * dist(x1, x2)\n",
    "        positive_pair_loss = (0.5 * (1 - y) * squared_loss)\n",
    "        mean_positive_pair_loss = torch.mean(positive_pair_loss)\n",
    "        # T2: 0.5 * y * max(margin - dist(x1, x2), 0)\n",
    "        zeros = torch.zeros_like(squared_loss)\n",
    "        marginMat = margin_val * torch.ones_like(squared_loss)\n",
    "        negative_pair_loss = 0.5 * y * torch.max(zeros, marginMat - squared_loss)\n",
    "        mean_negative_pair_loss = torch.mean(negative_pair_loss)\n",
    "\n",
    "        # T3: alpha(dst_l1(abs(x1), 1)) + dist_l1(abs(x2), 1)))\n",
    "        mean_value_regularization = self.alpha * (\n",
    "                self.l1_loss(torch.abs(h1), torch.ones_like(h1)) +\n",
    "                self.l1_loss(torch.abs(h2), torch.ones_like(h2)))\n",
    "\n",
    "        loss = mean_positive_pair_loss + mean_negative_pair_loss + mean_value_regularization\n",
    "        return loss\n",
    "    \n",
    "#Generate image pairs for model\n",
    "def onlineGenImgPairs( ):\n",
    "    idx_sf = []\n",
    "    idx_0 = np.where( np.array(trY) == 0 ) #class 0\n",
    "    idx_0 = list(idx_0[0])[0:4555]\n",
    "    idx_sf.extend(idx_0)\n",
    "    idx_1 = np.where( np.array(trY) == 1 ) #class 1\n",
    "    idx_1 = list(idx_1[0])\n",
    "    idx_sf.extend(idx_1)\n",
    "    idx_2 = np.where( np.array(trY) == 2 ) #class 2\n",
    "    idx_2 = list(idx_2[0])\n",
    "    idx_sf.extend(idx_2)\n",
    "    idx_3 = np.where( np.array(trY) == 3 ) #class 3\n",
    "    idx_3 = list(idx_3[0])\n",
    "    idx_sf.extend(idx_3)\n",
    "    random.shuffle(idx_sf)   \n",
    "    trQ_sf, trP_sf, trN_sf = [], [], []\n",
    "    trQ_y, trP_y, trN_y = [], [], []\n",
    "    for iQ in idx_sf:\n",
    "        trQ_sf.append(trI[iQ])\n",
    "        trQ_y.append(trY[iQ])\n",
    "        if trY[iQ] == 0:\n",
    "            idx_tmp = idx_0.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            trP_y.append(trY[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_0))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "            trN_y.append(trY[iN[0]])\n",
    "        elif trY[iQ] == 1:\n",
    "            idx_tmp = idx_1.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            trP_y.append(trY[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_1))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "            trN_y.append(trY[iN[0]])\n",
    "        elif trY[iQ] == 2:\n",
    "            idx_tmp = idx_2.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            trP_y.append(trY[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_2))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "            trN_y.append(trY[iN[0]])\n",
    "        elif trY[iQ] == 3:\n",
    "            idx_tmp = idx_3.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            trP_y.append(trY[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_3))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "            trN_y.append(trY[iN[0]])\n",
    "        else: pass\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(trQ_sf),len(idx_sf)))\n",
    "        sys.stdout.flush()\n",
    "    return np.array(trQ_sf),np.array(trP_sf),np.array(trN_sf), np.array(trQ_y), np.array(trP_y), np.array(trN_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 / 20000 The length of train set is 20000\n",
      "20000 / 20000 The length of test set is 20000\n"
     ]
    }
   ],
   "source": [
    "#read train image with CV\n",
    "train_dir = '/data/fjsdata/ECG/MIT-BIH/train' #the path of images\n",
    "trN, trI, trY = [],[],[]\n",
    "for iname in os.listdir(train_dir):\n",
    "    if iname.endswith(\".png\"):\n",
    "        try:\n",
    "            image_path = os.path.join(train_dir, iname)\n",
    "            itype = int(os.path.splitext(iname)[0].split(\"-\")[1])\n",
    "            img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(500,300,3)->(256,256,3)\n",
    "            trN.append(iname)\n",
    "            trI.append(img)\n",
    "            trY.append(itype)\n",
    "        except:\n",
    "            print(iname+\":\"+str(image_path))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(trY),20000))\n",
    "        sys.stdout.flush()\n",
    "print('The length of train set is %d'%len(trY))\n",
    "#read test image with CV\n",
    "test_dir = '/data/fjsdata/ECG/MIT-BIH/test' #the path of images\n",
    "teN, teI, teY = [],[],[]\n",
    "for iname in os.listdir(test_dir):\n",
    "    if iname.endswith(\".png\"):\n",
    "        try:\n",
    "            image_path = os.path.join(test_dir, iname)\n",
    "            itype = int(os.path.splitext(iname)[0].split(\"-\")[1])\n",
    "            img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(500,300,3)->(256,256,3)\n",
    "            teN.append(iname)\n",
    "            teI.append(img)\n",
    "            teY.append(itype)\n",
    "        except:\n",
    "            print(iname+\":\"+str(image_path))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(teY),20000))\n",
    "        sys.stdout.flush()\n",
    "print('The length of test set is %d'%len(teY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1000 / 1000 : loss = 0.101469Eopch:     1 mean_loss = 4.630832\n",
      " 1000 / 1000 : loss = 0.177148Eopch:     2 mean_loss = 2.446012\n",
      " 1000 / 1000 : loss = 1.044084Eopch:     3 mean_loss = 1.959064\n",
      " 1000 / 1000 : loss = 0.103176Eopch:     4 mean_loss = 1.567014\n",
      " 1000 / 1000 : loss = 0.146945Eopch:     5 mean_loss = 1.316604\n",
      " 1000 / 1000 : loss = 0.069636Eopch:     6 mean_loss = 1.139023\n",
      " 1000 / 1000 : loss = 2.196618Eopch:     7 mean_loss = 0.892951\n",
      " 1000 / 1000 : loss = 0.073056Eopch:     8 mean_loss = 0.803528\n",
      " 1000 / 1000 : loss = 0.148098Eopch:     9 mean_loss = 0.643870\n",
      " 1000 / 1000 : loss = 0.185109Eopch:    10 mean_loss = 0.586953\n",
      " 1000 / 1000 : loss = 0.444317Eopch:    11 mean_loss = 0.518026\n",
      " 1000 / 1000 : loss = 0.585326Eopch:    12 mean_loss = 0.464748\n",
      " 1000 / 1000 : loss = 0.00019Eopch:    13 mean_loss = 0.433287\n",
      " 1000 / 1000 : loss = 0.015106Eopch:    14 mean_loss = 0.352949\n",
      " 1000 / 1000 : loss = 0.440287Eopch:    15 mean_loss = 0.362134\n",
      " 1000 / 1000 : loss = 0.029813Eopch:    16 mean_loss = 0.293839\n",
      " 1000 / 1000 : loss = 0.233492Eopch:    17 mean_loss = 0.315321\n",
      " 1000 / 1000 : loss = 0.015995Eopch:    18 mean_loss = 0.293541\n",
      " 1000 / 1000 : loss = 0.009809Eopch:    19 mean_loss = 0.260320\n",
      " 1000 / 1000 : loss = 0.441417Eopch:    20 mean_loss = 0.292504\n",
      " 1000 / 1000 : loss = 0.011044Eopch:    21 mean_loss = 0.284882\n",
      " 1000 / 1000 : loss = 0.176025Eopch:    22 mean_loss = 0.206540\n",
      " 1000 / 1000 : loss = 0.079054Eopch:    23 mean_loss = 0.224608\n",
      " 1000 / 1000 : loss = 0.236632Eopch:    24 mean_loss = 0.257305\n",
      " 1000 / 1000 : loss = 0.015383Eopch:    25 mean_loss = 0.223005\n",
      " 1000 / 1000 : loss = 0.017726Eopch:    26 mean_loss = 0.244945\n",
      " 1000 / 1000 : loss = 0.040872Eopch:    27 mean_loss = 0.174424\n",
      " 1000 / 1000 : loss = 0.014431Eopch:    28 mean_loss = 0.228913\n",
      " 1000 / 1000 : loss = 0.006543Eopch:    29 mean_loss = 0.208043\n",
      " 1000 / 1000 : loss = 0.048209Eopch:    30 mean_loss = 0.212003\n",
      " 1000 / 1000 : loss = 0.214807Eopch:    31 mean_loss = 0.143658\n",
      " 1000 / 1000 : loss = 0.252057Eopch:    32 mean_loss = 0.166110\n",
      " 1000 / 1000 : loss = 0.279609Eopch:    33 mean_loss = 0.198104\n",
      " 1000 / 1000 : loss = 0.011263Eopch:    34 mean_loss = 0.160855\n",
      " 1000 / 1000 : loss = 0.013116Eopch:    35 mean_loss = 0.163608\n",
      " 1000 / 1000 : loss = 0.000805Eopch:    36 mean_loss = 0.128949\n",
      " 1000 / 1000 : loss = 0.012461Eopch:    37 mean_loss = 0.208593\n",
      " 1000 / 1000 : loss = 0.018835Eopch:    38 mean_loss = 0.156064\n",
      " 1000 / 1000 : loss = 0.006778Eopch:    39 mean_loss = 0.097359\n",
      " 1000 / 1000 : loss = 0.022825Eopch:    40 mean_loss = 0.126954\n",
      " 1000 / 1000 : loss = 0.004872Eopch:    41 mean_loss = 0.164749\n",
      " 1000 / 1000 : loss = 0.025649Eopch:    42 mean_loss = 0.163503\n",
      " 1000 / 1000 : loss = 0.020044Eopch:    43 mean_loss = 0.146476\n",
      " 1000 / 1000 : loss = 0.163991Eopch:    44 mean_loss = 0.143655\n",
      " 1000 / 1000 : loss = 0.011858Eopch:    45 mean_loss = 0.102462\n",
      " 1000 / 1000 : loss = 0.315407Eopch:    46 mean_loss = 0.130460\n",
      " 1000 / 1000 : loss = 0.010366Eopch:    47 mean_loss = 0.090158\n",
      " 1000 / 1000 : loss = 0.004663Eopch:    48 mean_loss = 0.140324\n",
      " 1000 / 1000 : loss = 0.016335Eopch:    49 mean_loss = 0.135042\n",
      " 1000 / 1000 : loss = 0.994556Eopch:    50 mean_loss = 0.130436\n",
      "best_loss = 0.090158\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------\n",
    "#ATH-Triplet+CE\n",
    "#--------------------------------------------------------\n",
    "#sample  triplet labels\n",
    "#trQ_sf, trP_sf, trN_sf, trQ_y, trP_y, trN_y = onlineGenImgPairs() \n",
    "assert (trQ_sf.shape==trP_sf.shape and trQ_sf.shape==trN_sf.shape)\n",
    "assert (trQ_y.shape==trP_y.shape and trQ_y.shape==trN_y.shape)\n",
    "assert (np.mean(np.where((np.array(trQ_y)-np.array(trP_y))!=0,1,0))==0.0)\n",
    "assert (np.mean(np.where((np.array(trQ_y)-np.array(trN_y))!=0,1,0))==1.0)\n",
    "\n",
    "#define model\n",
    "model = ATHNet(hash_size=36, type_size=4).cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "tl_loss  = TripletLoss(margin=0.5).cuda() #define TripletLoss \n",
    "ce_loss  = nn.CrossEntropyLoss().cuda() #define cross-entropy loss\n",
    "\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "plot_tripletloss = []\n",
    "for epoch in range(50):#iteration\n",
    "    losses, hash_losses, class_loss = [], [], []\n",
    "    shuffled_idx = np.random.permutation(np.arange(len(trQ_sf)))\n",
    "    train_q = trQ_sf[shuffled_idx]\n",
    "    train_q_y = trQ_y[shuffled_idx]\n",
    "    train_p = trP_sf[shuffled_idx]\n",
    "    train_p_y = trP_y[shuffled_idx]\n",
    "    train_n = trN_sf[shuffled_idx]\n",
    "    train_n_y = trN_y[shuffled_idx]\n",
    "    num_batches = len(trQ_sf) // batchSize\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trQ_sf), (i+1)*batchSize])\n",
    "        Q_batch = torch.from_numpy(train_q[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        Q_y_batch = torch.from_numpy(train_q_y[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        P_batch = torch.from_numpy(train_p[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        P_y_batch = torch.from_numpy(train_p_y[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        N_batch = torch.from_numpy(train_n[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        N_y_batch = torch.from_numpy(train_n_y[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        #forword\n",
    "        Q_hash, Q_type = model(Q_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        P_hash, P_type = model(P_batch.permute(0, 3, 1, 2))\n",
    "        N_hash, N_type = model(N_batch.permute(0, 3, 1, 2))\n",
    "        #loss,#F.log_softmax+F.nll_loss\n",
    "        hash_loss = tl_loss(Q_hash,P_hash,N_hash)\n",
    "        type_loss = ce_loss(Q_type,Q_y_batch) + ce_loss(P_type,P_y_batch) + ce_loss(N_type,N_y_batch) \n",
    "        loss = hash_loss+type_loss\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "        hash_losses.append(hash_loss.item())\n",
    "        class_loss.append(type_loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    plot_tripletloss.append(np.mean(hash_losses))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "tl_loss=tl_loss.cpu()\n",
    "ce_loss=ce_loss.cpu()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1999 / 2000 Completed buliding index in 2 seconds\n",
      "mHR@10=0.765145, mAP@10=0.736485, mRR@10=0.929116\n",
      "[[10541   832  2933   548]\n",
      " [  259   380   279    26]\n",
      " [  167    96  3420   105]\n",
      " [  233     1    58   122]]\n",
      "Sensitivity(TPR) of N: 0.709641\n",
      "Sensitivity(TPR) of S: 0.402542\n",
      "Sensitivity(TPR) of V: 0.902851\n",
      "Sensitivity(TPR) of F: 0.294686\n",
      "AUC (Area Under Curve) of Micro: 0.884323\n"
     ]
    }
   ],
   "source": [
    "#hash code of train data from model\n",
    "#torch.cuda.synchronize()\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize \n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch,_ = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#hash code of test data from model\n",
    "#torch.cuda.synchronize()\n",
    "teY_pred = []\n",
    "teY_prob = []\n",
    "teF = [] \n",
    "num_batches = len(teY) // batchSize \n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    x_hash, x_type = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    teF.extend(x_hash.cpu().data.numpy().tolist()) #record feature\n",
    "    x_type = F.log_softmax(x_type,dim=1) \n",
    "    teY_prob.extend(x_type.cpu().data.numpy().tolist())\n",
    "    pred = x_type.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(pred.cpu().data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "#performance of retrieval\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(36) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "for topk in [10]:\n",
    "    MHR = [] #mean Hit ratio \n",
    "    MAP = [] #mean average precision\n",
    "    MRR = [] #mean reciprocal rank\n",
    "    scores, neighbors = gpu_index.search(np.array(teF).astype('float32'), k=topk)\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        mrr_flag = 0\n",
    "        #for j in ranklist:\n",
    "        for j in neighbors[i].tolist():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                MHR.append(1)\n",
    "                pos_len = pos_len +1\n",
    "                MAP.append(pos_len/rank_len) \n",
    "                if mrr_flag==0: \n",
    "                    MRR.append(pos_len/rank_len)\n",
    "                    mrr_flag =1\n",
    "            else: \n",
    "                MHR.append(0)\n",
    "                MAP.append(0)   \n",
    "    print(\"mHR@{}={:.6f}, mAP@{}={:.6f}, mRR@{}={:.6f}\".format(topk,np.mean(MHR),topk,np.mean(MAP), topk, np.mean(MRR)))\n",
    "#performance of classification\n",
    "#https://blog.csdn.net/hlang8160/article/details/78040311\n",
    "#https://www.jianshu.com/p/7919ef304b19\n",
    "#https://www.jianshu.com/p/c61ae11cc5f6\n",
    "#https://www.cnblogs.com/yanshw/p/12691329.html\n",
    "#TNR= TN / (FP + TN) ->low misdiagnosis rate->Specificity\n",
    "#TPR=TP / (TP+ FN) -> low missed diagnosis rate->Sensitivity\n",
    "#ROC: x axis = 1-TNR, y asis=TPR\n",
    "#print ( 'Accuracy: %.6f'%accuracy_score(teY, teY_pred))\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, teY_pred, labels=labels) \n",
    "print (cm)\n",
    "print ('Sensitivity(TPR) of N: %.6f'%float(cm[0][0]/np.sum(cm[0]))) \n",
    "print ('Sensitivity(TPR) of S: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity(TPR) of V: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity(TPR) of F: %.6f'%float(cm[3][3]/np.sum(cm[3])))\n",
    "#auc and roc\n",
    "teY_one_hot = label_binarize(np.array(teY), np.arange(len(labels)))\n",
    "auc_score = roc_auc_score(teY_one_hot, np.array(teY_prob), average='micro')#macro\n",
    "print ('AUC (Area Under Curve) of Micro: %.6f'% auc_score)\n",
    "fpr_tce, tpr_tce, thresholds = roc_curve(teY_one_hot.ravel(),np.array(teY_prob).ravel()) #for roc curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.841 -> DR\n",
      "0.072 -> Norm\n",
      "0.067 -> Glaucoma\n",
      "0.017 -> AMD\n",
      "0.002 -> Myopia\n",
      "(1, 1, 128, 128)\n",
      "output CAM.jpg for the top1 prediction: DR\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate class activation mapping for the top1 prediction\n",
    "def returnCAM(feature_conv, weight_softmax, class_idx):\n",
    "    # generate the class activation maps upsample to 256x256\n",
    "    size_upsample = (256, 256)\n",
    "    bz, nc, h, w = 1,1,32,32#feature_conv.shape\n",
    "    \n",
    "    output_cam = []\n",
    "    for idx in class_idx:\n",
    "        #cam = weight_softmax[class_idx].dot(feature_conv.reshape((nc,h*w)))\n",
    "        cam = weight_softmax[class_idx]*(feature_conv.reshape((nc,h*w)))\n",
    "        cam = cam.reshape(h, w)\n",
    "        cam = cam - np.min(cam)\n",
    "        cam_img = cam / np.max(cam)\n",
    "        cam_img = np.uint8(255 * cam_img)\n",
    "        output_cam.append(cv2.resize(cam_img, size_upsample))\n",
    "    return output_cam\n",
    "\n",
    "\n",
    "# hook the feature extractor\n",
    "features_blobs = []\n",
    "def hook_feature(module, input, output):\n",
    "    features_blobs.append(output.data.cpu().numpy())\n",
    "#last conv layer followed with one channel by last fully connected layer\n",
    "final_conv = 'sa' \n",
    "best_net._modules.get(final_conv).register_forward_hook(hook_feature)\n",
    "#get weights parameters\n",
    "params = list(best_net.parameters())\n",
    "#get the last and second last weights, like [classes, hiden nodes]\n",
    "weight_softmax = np.squeeze(params[-2].data.cpu().numpy()) \n",
    "# define class type\n",
    "classes = {0:'Norm', 1: 'AMD', 2: 'DR', 3:'Glaucoma', 4:'Myopia', }\n",
    "#read image\n",
    "root='/data/fjsdata/fundus/iSee/iSee_multi_dataset/img_data_DR/100217.jpg'\n",
    "img = []\n",
    "img.append( cv2.resize(cv2.imread(root).astype(np.float32), (256, 256)))#(256, 256) is the model input size\n",
    "data = torch.from_numpy(np.array(img)).type(torch.FloatTensor).cuda()\n",
    "_,logit = best_net(data.permute(0, 3, 1, 2))#forword\n",
    "h_x = F.softmax(logit, dim=1).data.squeeze()#softmax\n",
    "probs, idx = h_x.sort(0, True) #probabilities of classes\n",
    "\n",
    "# output: the prediction\n",
    "for i in range(0, len(classes)):\n",
    "    line = '{:.3f} -> {}'.format(probs[i], classes[idx[i].item()])\n",
    "    print(line)\n",
    "#get the class activation maps\n",
    "print (features_blobs[-1].shape)\n",
    "feature_layer = features_blobs[-1].squeeze()[0]\n",
    "feature_layer = cv2.resize(feature_layer, (32, 32))\n",
    "CAMs = returnCAM(feature_layer, weight_softmax, [idx[0].item()])\n",
    "\n",
    "# render the CAM and show\n",
    "print('output CAM.jpg for the top1 prediction: %s' % classes[idx[0].item()])\n",
    "img = cv2.imread(root)\n",
    "height, width, _ = img.shape\n",
    "CAM = cv2.resize(CAMs[0], (width, height))\n",
    "heatmap = cv2.applyColorMap(CAM, cv2.COLORMAP_JET)\n",
    "#result = heatmap * 0.3 + img * 0.5\n",
    "result = heatmap \n",
    "cv2.imwrite('iSee_cam.jpg', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 16, 128, 128)\n",
      "(16, 128, 128)\n",
      "(128, 128)\n",
      "output CAM.jpg for the top1 prediction: DR\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (features_blobs[0].shape)\n",
    "feature_layer = features_blobs[0].squeeze()\n",
    "print (feature_layer.shape)\n",
    "#feature_layer = np.mean(feature_layer, axis=0)\n",
    "feature_layer = np.max(feature_layer, axis=0)\n",
    "print (feature_layer.shape)\n",
    "feature_layer = cv2.resize(feature_layer, (32, 32))\n",
    "CAMs = returnCAM(feature_layer, weight_softmax, [idx[0].item()])\n",
    "\n",
    "# render the CAM and show\n",
    "print('output CAM.jpg for the top1 prediction: %s' % classes[idx[0].item()])\n",
    "img = cv2.imread(root)\n",
    "height, width, _ = img.shape\n",
    "CAM = cv2.resize(CAMs[0], (width, height))\n",
    "heatmap = cv2.applyColorMap(CAM, cv2.COLORMAP_JET)\n",
    "#result = heatmap * 0.3 + img * 0.5\n",
    "result = heatmap \n",
    "cv2.imwrite('iSee_cam.jpg', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1000 / 1000 : loss = 0.079554Eopch:     1 mean_loss = 4.124642\n",
      " 1000 / 1000 : loss = 0.092885Eopch:     2 mean_loss = 2.125666\n",
      " 1000 / 1000 : loss = 0.703044Eopch:     3 mean_loss = 1.773538\n",
      " 1000 / 1000 : loss = 0.018187Eopch:     4 mean_loss = 1.513705\n",
      " 1000 / 1000 : loss = 0.062834Eopch:     5 mean_loss = 1.315106\n",
      " 1000 / 1000 : loss = 0.400215Eopch:     6 mean_loss = 1.048908\n",
      " 1000 / 1000 : loss = 0.060367Eopch:     7 mean_loss = 0.902662\n",
      " 1000 / 1000 : loss = 0.059067Eopch:     8 mean_loss = 0.718942\n",
      " 1000 / 1000 : loss = 0.04387Eopch:     9 mean_loss = 0.557316\n",
      " 1000 / 1000 : loss = 0.087575Eopch:    10 mean_loss = 0.452063\n",
      " 1000 / 1000 : loss = 0.092192Eopch:    11 mean_loss = 0.437227\n",
      " 1000 / 1000 : loss = 0.02979Eopch:    12 mean_loss = 0.355749\n",
      " 1000 / 1000 : loss = 0.014821Eopch:    13 mean_loss = 0.236814\n",
      " 1000 / 1000 : loss = 0.05301Eopch:    14 mean_loss = 0.326578\n",
      " 1000 / 1000 : loss = 0.06621Eopch:    15 mean_loss = 0.197600\n",
      " 1000 / 1000 : loss = 0.012366Eopch:    16 mean_loss = 0.240709\n",
      " 1000 / 1000 : loss = 5.314188Eopch:    17 mean_loss = 0.180446\n",
      " 1000 / 1000 : loss = 0.066582Eopch:    18 mean_loss = 0.180939\n",
      " 1000 / 1000 : loss = 0.085776Eopch:    19 mean_loss = 0.214516\n",
      " 1000 / 1000 : loss = 0.02309Eopch:    20 mean_loss = 0.163048\n",
      " 1000 / 1000 : loss = 0.04357Eopch:    21 mean_loss = 0.139843\n",
      " 1000 / 1000 : loss = 0.029717Eopch:    22 mean_loss = 0.131764\n",
      " 1000 / 1000 : loss = 0.01012Eopch:    23 mean_loss = 0.130388\n",
      " 1000 / 1000 : loss = 1.400101Eopch:    24 mean_loss = 0.114987\n",
      " 1000 / 1000 : loss = 0.00554Eopch:    25 mean_loss = 0.175593\n",
      " 1000 / 1000 : loss = 0.079238Eopch:    26 mean_loss = 0.118224\n",
      " 1000 / 1000 : loss = 0.03043Eopch:    27 mean_loss = 0.135710\n",
      " 1000 / 1000 : loss = 0.08142Eopch:    28 mean_loss = 0.126080\n",
      " 1000 / 1000 : loss = 0.06612Eopch:    29 mean_loss = 0.122787\n",
      " 1000 / 1000 : loss = 0.03253Eopch:    30 mean_loss = 0.067592\n",
      " 1000 / 1000 : loss = 0.048712Eopch:    31 mean_loss = 0.195966\n",
      " 1000 / 1000 : loss = 0.02514Eopch:    32 mean_loss = 0.109528\n",
      " 1000 / 1000 : loss = 0.05169Eopch:    33 mean_loss = 0.085936\n",
      " 1000 / 1000 : loss = 0.016489Eopch:    34 mean_loss = 0.075239\n",
      " 1000 / 1000 : loss = 0.081821Eopch:    35 mean_loss = 0.125193\n",
      " 1000 / 1000 : loss = 0.05916Eopch:    36 mean_loss = 0.092601\n",
      " 1000 / 1000 : loss = 0.01928Eopch:    37 mean_loss = 0.114053\n",
      " 1000 / 1000 : loss = 0.00369Eopch:    38 mean_loss = 0.097137\n",
      " 1000 / 1000 : loss = 0.01961Eopch:    39 mean_loss = 0.136097\n",
      " 1000 / 1000 : loss = 0.06513Eopch:    40 mean_loss = 0.077785\n",
      " 1000 / 1000 : loss = 0.08787Eopch:    41 mean_loss = 0.052665\n",
      " 1000 / 1000 : loss = 0.06913Eopch:    42 mean_loss = 0.075506\n",
      " 1000 / 1000 : loss = 0.02486Eopch:    43 mean_loss = 0.091890\n",
      " 1000 / 1000 : loss = 0.062272Eopch:    44 mean_loss = 0.090237\n",
      " 1000 / 1000 : loss = 0.07335Eopch:    45 mean_loss = 0.080997\n",
      " 1000 / 1000 : loss = 0.02078Eopch:    46 mean_loss = 0.067865\n",
      " 1000 / 1000 : loss = 0.03647Eopch:    47 mean_loss = 0.081599\n",
      " 1000 / 1000 : loss = 0.06658Eopch:    48 mean_loss = 0.051965\n",
      " 1000 / 1000 : loss = 0.04886Eopch:    49 mean_loss = 0.103369\n",
      " 1000 / 1000 : loss = 0.09351Eopch:    50 mean_loss = 0.059327\n",
      "best_loss = 0.051965\n",
      " 1999 / 2000 Completed buliding index in 1 seconds\n",
      "mHR@10=0.752200, mAP@10=0.720813, mRR@10=0.915753\n",
      "[[ 973 2075 7915 3891]\n",
      " [  58   65  547  274]\n",
      " [ 175  347 2064 1202]\n",
      " [  38  139  151   86]]\n",
      "Sensitivity(TPR) of N: 0.065504\n",
      "Sensitivity(TPR) of S: 0.068856\n",
      "Sensitivity(TPR) of V: 0.544879\n",
      "Sensitivity(TPR) of F: 0.207729\n",
      "AUC (Area Under Curve) of Micro: 0.410998\n"
     ]
    }
   ],
   "source": [
    "#define model\n",
    "model = ATHNet(hash_size=36, type_size=4).cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "tl_loss  = TripletLoss(margin=0.5).cuda() #define TripletLoss \n",
    "\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "pl_t_i = []\n",
    "for epoch in range(50):#iteration\n",
    "    losses = []\n",
    "    shuffled_idx = np.random.permutation(np.arange(len(trQ_sf)))\n",
    "    train_q = trQ_sf[shuffled_idx]\n",
    "    train_p = trP_sf[shuffled_idx]\n",
    "    train_n = trN_sf[shuffled_idx]\n",
    "    num_batches = len(trQ_sf) // batchSize\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trQ_sf), (i+1)*batchSize])\n",
    "        Q_batch = torch.from_numpy(train_q[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        P_batch = torch.from_numpy(train_p[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        N_batch = torch.from_numpy(train_n[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        #forword\n",
    "        Q_hash, _ = model(Q_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        P_hash, _ = model(P_batch.permute(0, 3, 1, 2))\n",
    "        N_hash, _ = model(N_batch.permute(0, 3, 1, 2))\n",
    "        #loss\n",
    "        loss = tl_loss(Q_hash,P_hash,N_hash)\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    pl_t_i.append(np.mean(losses))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "tl_loss=tl_loss.cpu()\n",
    "ce_loss=ce_loss.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#hash code of train data from model\n",
    "#torch.cuda.synchronize()\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize \n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch,_ = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#hash code of test data from model\n",
    "#torch.cuda.synchronize()\n",
    "teY_pred = []\n",
    "teY_prob = []\n",
    "teF = [] \n",
    "num_batches = len(teY) // batchSize \n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    x_hash, x_type = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    teF.extend(x_hash.cpu().data.numpy().tolist()) #record feature\n",
    "    x_type = F.log_softmax(x_type,dim=1) \n",
    "    teY_prob.extend(x_type.cpu().data.numpy().tolist())\n",
    "    pred = x_type.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(pred.cpu().data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "#performance of retrieval\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(36) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "for topk in [10]:\n",
    "    MHR = [] #mean Hit ratio \n",
    "    MAP = [] #mean average precision\n",
    "    MRR = [] #mean reciprocal rank\n",
    "    scores, neighbors = gpu_index.search(np.array(teF).astype('float32'), k=topk)\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        mrr_flag = 0\n",
    "        #for j in ranklist:\n",
    "        for j in neighbors[i].tolist():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                MHR.append(1)\n",
    "                pos_len = pos_len +1\n",
    "                MAP.append(pos_len/rank_len) \n",
    "                if mrr_flag==0: \n",
    "                    MRR.append(pos_len/rank_len)\n",
    "                    mrr_flag =1\n",
    "            else: \n",
    "                MHR.append(0)\n",
    "                MAP.append(0)   \n",
    "    print(\"mHR@{}={:.6f}, mAP@{}={:.6f}, mRR@{}={:.6f}\".format(topk,np.mean(MHR),topk,np.mean(MAP), topk, np.mean(MRR)))\n",
    "#performance of classification\n",
    "#https://blog.csdn.net/hlang8160/article/details/78040311\n",
    "#https://www.jianshu.com/p/7919ef304b19\n",
    "#https://www.jianshu.com/p/c61ae11cc5f6\n",
    "#https://www.cnblogs.com/yanshw/p/12691329.html\n",
    "#TNR= TN / (FP + TN) ->low misdiagnosis rate->Specificity\n",
    "#TPR=TP / (TP+ FN) -> low missed diagnosis rate->Sensitivity\n",
    "#ROC: x axis = 1-TNR, y asis=TPR\n",
    "#print ( 'Accuracy: %.6f'%accuracy_score(teY, teY_pred))\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, teY_pred, labels=labels) \n",
    "print (cm)\n",
    "print ('Sensitivity(TPR) of N: %.6f'%float(cm[0][0]/np.sum(cm[0]))) \n",
    "print ('Sensitivity(TPR) of S: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity(TPR) of V: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity(TPR) of F: %.6f'%float(cm[3][3]/np.sum(cm[3])))\n",
    "#auc and roc\n",
    "teY_one_hot = label_binarize(np.array(teY), np.arange(len(labels)))\n",
    "auc_score = roc_auc_score(teY_one_hot, np.array(teY_prob), average='micro')#macro\n",
    "print ('AUC (Area Under Curve) of Micro: %.6f'% auc_score)\n",
    "fpr_tl, tpr_tl, thresholds = roc_curve(teY_one_hot.ravel(),np.array(teY_prob).ravel()) #for roc curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1000 / 1000 : loss = 0.755503Eopch:     1 mean_loss = 1.297846\n",
      " 1000 / 1000 : loss = 1.478089Eopch:     2 mean_loss = 0.901388\n",
      " 1000 / 1000 : loss = 1.718168Eopch:     3 mean_loss = 0.808178\n",
      " 1000 / 1000 : loss = 0.424097Eopch:     4 mean_loss = 0.798458\n",
      " 1000 / 1000 : loss = 0.412887Eopch:     5 mean_loss = 0.753448\n",
      " 1000 / 1000 : loss = 0.880708Eopch:     6 mean_loss = 0.737915\n",
      " 1000 / 1000 : loss = 0.152149Eopch:     7 mean_loss = 0.708520\n",
      " 1000 / 1000 : loss = 1.401464Eopch:     8 mean_loss = 0.704942\n",
      " 1000 / 1000 : loss = 0.936747Eopch:     9 mean_loss = 0.699134\n",
      " 1000 / 1000 : loss = 0.779636Eopch:    10 mean_loss = 0.681416\n",
      " 1000 / 1000 : loss = 0.195381Eopch:    11 mean_loss = 0.684720\n",
      " 1000 / 1000 : loss = 0.37511Eopch:    12 mean_loss = 0.657041\n",
      " 1000 / 1000 : loss = 0.071109Eopch:    13 mean_loss = 0.654873\n",
      " 1000 / 1000 : loss = 0.256513Eopch:    14 mean_loss = 0.646153\n",
      " 1000 / 1000 : loss = 0.185392Eopch:    15 mean_loss = 0.637556\n",
      " 1000 / 1000 : loss = 1.014438Eopch:    16 mean_loss = 0.615465\n",
      " 1000 / 1000 : loss = 0.806155Eopch:    17 mean_loss = 0.624846\n",
      " 1000 / 1000 : loss = 0.070397Eopch:    18 mean_loss = 0.607878\n",
      " 1000 / 1000 : loss = 1.717754Eopch:    19 mean_loss = 0.602057\n",
      " 1000 / 1000 : loss = 0.128622Eopch:    20 mean_loss = 0.600963\n",
      " 1000 / 1000 : loss = 1.963355Eopch:    21 mean_loss = 0.611204\n",
      " 1000 / 1000 : loss = 1.11907Eopch:    22 mean_loss = 0.603449\n",
      " 1000 / 1000 : loss = 0.697188Eopch:    23 mean_loss = 0.607234\n",
      " 1000 / 1000 : loss = 1.014325Eopch:    24 mean_loss = 0.580711\n",
      " 1000 / 1000 : loss = 0.544322Eopch:    25 mean_loss = 0.580442\n",
      " 1000 / 1000 : loss = 1.055037Eopch:    26 mean_loss = 0.583213\n",
      " 1000 / 1000 : loss = 0.774623Eopch:    27 mean_loss = 0.559022\n",
      " 1000 / 1000 : loss = 0.178599Eopch:    28 mean_loss = 0.583346\n",
      " 1000 / 1000 : loss = 1.005881Eopch:    29 mean_loss = 0.536880\n",
      " 1000 / 1000 : loss = 0.17517Eopch:    30 mean_loss = 0.555478\n",
      " 1000 / 1000 : loss = 0.767308Eopch:    31 mean_loss = 0.573980\n",
      " 1000 / 1000 : loss = 1.14325Eopch:    32 mean_loss = 0.565891\n",
      " 1000 / 1000 : loss = 0.110682Eopch:    33 mean_loss = 0.553655\n",
      " 1000 / 1000 : loss = 0.655807Eopch:    34 mean_loss = 0.539081\n",
      " 1000 / 1000 : loss = 0.323603Eopch:    35 mean_loss = 0.537405\n",
      " 1000 / 1000 : loss = 1.985666Eopch:    36 mean_loss = 0.549922\n",
      " 1000 / 1000 : loss = 0.197526Eopch:    37 mean_loss = 0.538133\n",
      " 1000 / 1000 : loss = 0.141736Eopch:    38 mean_loss = 0.541114\n",
      " 1000 / 1000 : loss = 0.953355Eopch:    39 mean_loss = 0.560313\n",
      " 1000 / 1000 : loss = 0.192281Eopch:    40 mean_loss = 0.528274\n",
      " 1000 / 1000 : loss = 0.645953Eopch:    41 mean_loss = 0.529638\n",
      " 1000 / 1000 : loss = 0.314089Eopch:    42 mean_loss = 0.524157\n",
      " 1000 / 1000 : loss = 0.145332Eopch:    43 mean_loss = 0.519700\n",
      " 1000 / 1000 : loss = 0.655711Eopch:    44 mean_loss = 0.528576\n",
      " 1000 / 1000 : loss = 1.063569Eopch:    45 mean_loss = 0.536684\n",
      " 1000 / 1000 : loss = 0.113171Eopch:    46 mean_loss = 0.505886\n",
      " 1000 / 1000 : loss = 1.34465Eopch:    47 mean_loss = 0.510935\n",
      " 1000 / 1000 : loss = 0.415297Eopch:    48 mean_loss = 0.532298\n",
      " 1000 / 1000 : loss = 0.337823Eopch:    49 mean_loss = 0.502769\n",
      " 1000 / 1000 : loss = 0.383443Eopch:    50 mean_loss = 0.534159\n",
      "best_loss = 0.502769\n",
      " 1999 / 2000 Completed buliding index in 1 seconds\n",
      "mHR@10=0.698610, mAP@10=0.660541, mRR@10=0.910009\n",
      "[[ 685 8300  446 5423]\n",
      " [ 104  461   15  364]\n",
      " [ 433 1454   60 1841]\n",
      " [  43  207    8  156]]\n",
      "Sensitivity(TPR) of N: 0.046116\n",
      "Sensitivity(TPR) of S: 0.488347\n",
      "Sensitivity(TPR) of V: 0.015839\n",
      "Sensitivity(TPR) of F: 0.376812\n",
      "AUC (Area Under Curve) of Micro: 0.257955\n"
     ]
    }
   ],
   "source": [
    "#Generate image pairs for model\n",
    "def onlineGenImgPairs():\n",
    "    if (len(trY) % 2) == 0: spls = len(trY)\n",
    "    else:  spls = len(trY)-1\n",
    "    idx_sf = random.sample(range(0, spls),spls)\n",
    "    trI1_sf, trI2_sf, trY1_sf, trY2_sf = [],[],[],[]\n",
    "    flag = 0\n",
    "    for i in idx_sf:\n",
    "        if flag==0:\n",
    "            trI1_sf.append(trI[i])\n",
    "            trY1_sf.append(trY[i])\n",
    "            flag =1\n",
    "        else:\n",
    "            trI2_sf.append(trI[i])\n",
    "            trY2_sf.append(trY[i])\n",
    "            flag =0\n",
    "    trY_sf = np.where((np.array(trY1_sf)-np.array(trY2_sf))!=0,1,0)\n",
    "    return np.array(trI1_sf),np.array(trI2_sf),trY_sf\n",
    "\n",
    "#define model\n",
    "model = ATHNet(hash_size=36, type_size=4).cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "criterion  = PairwiseLoss(margin=0.5).cuda() #define PairwiseLoss \n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(50):#iteration\n",
    "    trI1_sf, trI2_sf, trY_sf = onlineGenImgPairs()\n",
    "    losses = []\n",
    "    num_batches = len(trY_sf) // batchSize \n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY_sf), (i+1)*batchSize])\n",
    "        I1_batch = torch.from_numpy(trI1_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        I2_batch = torch.from_numpy(trI2_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        Y_batch = torch.from_numpy(trY_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        #forword\n",
    "        X1_batch,_ = model(I1_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        X2_batch,_ = model(I2_batch.permute(0, 3, 1, 2))\n",
    "        #binary-like loss\n",
    "        loss = criterion(X1_batch,X2_batch,Y_batch)\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "tl_loss=tl_loss.cpu()\n",
    "ce_loss=ce_loss.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "#hash code of train data from model\n",
    "#torch.cuda.synchronize()\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize \n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch,_ = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#hash code of test data from model\n",
    "#torch.cuda.synchronize()\n",
    "teY_pred = []\n",
    "teY_prob = []\n",
    "teF = [] \n",
    "num_batches = len(teY) // batchSize \n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    x_hash, x_type = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    teF.extend(x_hash.cpu().data.numpy().tolist()) #record feature\n",
    "    x_type = F.log_softmax(x_type,dim=1) \n",
    "    teY_prob.extend(x_type.cpu().data.numpy().tolist())\n",
    "    pred = x_type.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(pred.cpu().data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#performance of retrieval\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(36) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "for topk in [10]:\n",
    "    MHR = [] #mean Hit ratio \n",
    "    MAP = [] #mean average precision\n",
    "    MRR = [] #mean reciprocal rank\n",
    "    scores, neighbors = gpu_index.search(np.array(teF).astype('float32'), k=topk)\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        mrr_flag = 0\n",
    "        #for j in ranklist:\n",
    "        for j in neighbors[i].tolist():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                MHR.append(1)\n",
    "                pos_len = pos_len +1\n",
    "                MAP.append(pos_len/rank_len) \n",
    "                if mrr_flag==0: \n",
    "                    MRR.append(pos_len/rank_len)\n",
    "                    mrr_flag =1\n",
    "            else: \n",
    "                MHR.append(0)\n",
    "                MAP.append(0)   \n",
    "    print(\"mHR@{}={:.6f}, mAP@{}={:.6f}, mRR@{}={:.6f}\".format(topk,np.mean(MHR),topk,np.mean(MAP), topk, np.mean(MRR)))\n",
    "#performance of classification\n",
    "#https://blog.csdn.net/hlang8160/article/details/78040311\n",
    "#https://www.jianshu.com/p/7919ef304b19\n",
    "#https://www.jianshu.com/p/c61ae11cc5f6\n",
    "#https://www.cnblogs.com/yanshw/p/12691329.html\n",
    "#TNR= TN / (FP + TN) ->low misdiagnosis rate->Specificity\n",
    "#TPR=TP / (TP+ FN) -> low missed diagnosis rate->Sensitivity\n",
    "#ROC: x axis = 1-TNR, y asis=TPR\n",
    "#print ( 'Accuracy: %.6f'%accuracy_score(teY, teY_pred))\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, teY_pred, labels=labels) \n",
    "print (cm)\n",
    "print ('Sensitivity(TPR) of N: %.6f'%float(cm[0][0]/np.sum(cm[0]))) \n",
    "print ('Sensitivity(TPR) of S: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity(TPR) of V: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity(TPR) of F: %.6f'%float(cm[3][3]/np.sum(cm[3])))\n",
    "#auc and roc\n",
    "teY_one_hot = label_binarize(np.array(teY), np.arange(len(labels)))\n",
    "auc_score = roc_auc_score(teY_one_hot, np.array(teY_prob), average='micro')#macro\n",
    "print ('AUC (Area Under Curve) of Micro: %.6f'% auc_score)\n",
    "fpr_pl, tpr_pl, thresholds = roc_curve(teY_one_hot.ravel(),np.array(teY_prob).ravel()) #for roc curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2000 / 2000 : loss = 0.019041Eopch:     1 mean_loss = 0.208629\n",
      " 2000 / 2000 : loss = 0.028726Eopch:     2 mean_loss = 0.130455\n",
      " 2000 / 2000 : loss = 0.009701Eopch:     3 mean_loss = 0.114186\n",
      " 2000 / 2000 : loss = 0.018009Eopch:     4 mean_loss = 0.102722\n",
      " 2000 / 2000 : loss = 0.066974Eopch:     5 mean_loss = 0.094978\n",
      " 2000 / 2000 : loss = 0.035984Eopch:     6 mean_loss = 0.085338\n",
      " 2000 / 2000 : loss = 0.007596Eopch:     7 mean_loss = 0.080968\n",
      " 2000 / 2000 : loss = 0.146272Eopch:     8 mean_loss = 0.076655\n",
      " 2000 / 2000 : loss = 0.007152Eopch:     9 mean_loss = 0.072096\n",
      " 2000 / 2000 : loss = 0.001117Eopch:    10 mean_loss = 0.064960\n",
      "best_loss = 0.064960\n",
      " 1999 / 2000 Completed buliding index in 1 seconds\n",
      "mHR@10=0.692740, mAP@10=0.622557, mRR@10=0.845336\n",
      "[[11247   603  2971    33]\n",
      " [  477   183   272    12]\n",
      " [  414    52  3308    14]\n",
      " [  218     2   175    19]]\n",
      "Sensitivity(TPR) of N: 0.757170\n",
      "Sensitivity(TPR) of S: 0.193856\n",
      "Sensitivity(TPR) of V: 0.873284\n",
      "Sensitivity(TPR) of F: 0.045894\n",
      "AUC (Area Under Curve) of Micro: 0.931045\n"
     ]
    }
   ],
   "source": [
    "model = ATHNet(hash_size=36, type_size=4).cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "criterion  = nn.CrossEntropyLoss().cuda() #define ce mutli-classes\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "trI = np.array(trI)\n",
    "trY = np.array(trY)\n",
    "for epoch in range(10):#iteration\n",
    "    losses = []\n",
    "    shuffled_idx = np.random.permutation(np.arange(len(trY)))\n",
    "    train_x = trI[shuffled_idx]\n",
    "    train_y = trY[shuffled_idx]\n",
    "    num_batches = len(trY) // batchSize\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY), (i+1)*batchSize])\n",
    "        x_batch = torch.from_numpy(train_x[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        y_batch = torch.from_numpy(train_y[min_idx:max_idx]).type(torch.LongTensor).cuda()\n",
    "        #forword\n",
    "        _,out_batch = model(x_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        loss = criterion(out_batch,y_batch) #F.log_softmax+F.nll_loss\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "tl_loss=tl_loss.cpu()\n",
    "ce_loss=ce_loss.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "#hash code of train data from model\n",
    "#torch.cuda.synchronize()\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize \n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch,_ = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#hash code of test data from model\n",
    "#torch.cuda.synchronize()\n",
    "teY_pred = []\n",
    "teY_prob = []\n",
    "teF = [] \n",
    "num_batches = len(teY) // batchSize \n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "    x_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    x_hash, x_type = best_net(x_batch.permute(0, 3, 1, 2))#forword\n",
    "    teF.extend(x_hash.cpu().data.numpy().tolist()) #record feature\n",
    "    x_type = F.log_softmax(x_type,dim=1) \n",
    "    teY_prob.extend(x_type.cpu().data.numpy().tolist())\n",
    "    pred = x_type.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(pred.cpu().data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#performance of retrieval\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(36) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "for topk in [10]:\n",
    "    MHR = [] #mean Hit ratio \n",
    "    MAP = [] #mean average precision\n",
    "    MRR = [] #mean reciprocal rank\n",
    "    scores, neighbors = gpu_index.search(np.array(teF).astype('float32'), k=topk)\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        mrr_flag = 0\n",
    "        #for j in ranklist:\n",
    "        for j in neighbors[i].tolist():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                MHR.append(1)\n",
    "                pos_len = pos_len +1\n",
    "                MAP.append(pos_len/rank_len) \n",
    "                if mrr_flag==0: \n",
    "                    MRR.append(pos_len/rank_len)\n",
    "                    mrr_flag =1\n",
    "            else: \n",
    "                MHR.append(0)\n",
    "                MAP.append(0)   \n",
    "    print(\"mHR@{}={:.6f}, mAP@{}={:.6f}, mRR@{}={:.6f}\".format(topk,np.mean(MHR),topk,np.mean(MAP), topk, np.mean(MRR)))\n",
    "#performance of classification\n",
    "#https://blog.csdn.net/hlang8160/article/details/78040311\n",
    "#https://www.jianshu.com/p/7919ef304b19\n",
    "#https://www.jianshu.com/p/c61ae11cc5f6\n",
    "#https://www.cnblogs.com/yanshw/p/12691329.html\n",
    "#TNR= TN / (FP + TN) ->low misdiagnosis rate->Specificity\n",
    "#TPR=TP / (TP+ FN) -> low missed diagnosis rate->Sensitivity\n",
    "#ROC: x axis = 1-TNR, y asis=TPR\n",
    "#print ( 'Accuracy: %.6f'%accuracy_score(teY, teY_pred))\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, teY_pred, labels=labels) \n",
    "print (cm)\n",
    "print ('Sensitivity(TPR) of N: %.6f'%float(cm[0][0]/np.sum(cm[0]))) \n",
    "print ('Sensitivity(TPR) of S: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity(TPR) of V: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity(TPR) of F: %.6f'%float(cm[3][3]/np.sum(cm[3])))\n",
    "#auc and roc\n",
    "teY_one_hot = label_binarize(np.array(teY), np.arange(len(labels)))\n",
    "auc_score = roc_auc_score(teY_one_hot, np.array(teY_prob), average='micro')#macro\n",
    "print ('AUC (Area Under Curve) of Micro: %.6f'% auc_score)\n",
    "fpr_ce, tpr_ce, thresholds = roc_curve(teY_one_hot.ravel(),np.array(teY_prob).ravel()) #for roc curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr_ce, tpr_ce, c = 'r', ls = '--', label = u'ATH(our) AUC=%.4f' % 0.9310)\n",
    "plt.plot(fpr_tce, tpr_tce, c = 'b', ls = '--', label = u'ATH-pairwise AUC=%.4f' % 0.8843)\n",
    "#plt.plot(fpr_tl, tpr_tl, c = 'b', ls = '--', label = u'ATH-pairwise AUC=%.4f' % 0.8219)   \n",
    "plt.plot((0, 1), (0, 1), c = '#808080', lw = 1, ls = '--', alpha = 0.7)\n",
    "plt.xlim((-0.01, 1.02))\n",
    "plt.ylim((-0.01, 1.02))\n",
    "plt.xticks(np.arange(0, 1.1, 0.2))\n",
    "plt.yticks(np.arange(0, 1.1, 0.2))\n",
    "plt.xlabel('1-Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.grid(b=True, ls=':')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('MIMIC-CXR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize : t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import random\n",
    "def scatter(X, y):\n",
    "    #X,y:numpy-array\n",
    "    classes = len(list(set(y.tolist())))#get number of classes\n",
    "    #palette = np.array(sns.color_palette(\"hls\", classes))# choose a color palette with seaborn.\n",
    "    color = ['c','y','m','b','g','r']\n",
    "    marker = ['o','x','s','*','+']\n",
    "    label = ['AMD','DR','glaucoma','myopia','normal']\n",
    "    plt.figure(figsize=(8,8))#create a plot\n",
    "    for i in range(classes):\n",
    "        plt.scatter(X[y == i,0], X[y == i,1], c=color[i], marker=marker[i], label=label[i])\n",
    "    plt.axis('off')\n",
    "    plt.legend(loc='lower left')\n",
    "    #plt.savefig('digits_tsne-generated.png', dpi=100)\n",
    "    plt.show()\n",
    "\n",
    "#prepare dataclasses=5\n",
    "#idx= random.sample(np.where(np.array(teY)==0)[0].tolist(),100)\n",
    "idx= np.where(np.array(teY)==0)[0].tolist()\n",
    "X0= np.array(teF)[idx]\n",
    "y0= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==1)[0].tolist()\n",
    "X1= np.array(teF)[idx]\n",
    "y1= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==2)[0].tolist()\n",
    "X2= np.array(teF)[idx]\n",
    "y2= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==3)[0].tolist()\n",
    "X3= np.array(teF)[idx]\n",
    "y3= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==4)[0].tolist()\n",
    "X4= np.array(teF)[idx]\n",
    "y4= np.array(teY)[idx]\n",
    "\n",
    "y = np.append(y0,y1)\n",
    "y = np.append(y,y2)\n",
    "y = np.append(y,y3)\n",
    "y = np.append(y,y4)\n",
    "X = np.vstack((X0,X1))\n",
    "X = np.vstack((X,X2))\n",
    "X = np.vstack((X,X3))\n",
    "X = np.vstack((X,X4))\n",
    "#training t-sne \n",
    "tsne = TSNE(n_components=2, init='pca', random_state=501)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "print(\"Org data dimension is {}.Embedded data dimension is {}\".format(X.shape[-1], X_tsne.shape[-1]))\n",
    "\n",
    "#visualize\n",
    "scatter(X_tsne, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
