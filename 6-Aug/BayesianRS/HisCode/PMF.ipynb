{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics: Interaction = 2547452, User = 10216, Item = 96324, Sparsity = 249.3835\n",
      "  K               HR@10             NDCG@10\n",
      "Training RMSE: 0.401038, Val RMSE 0.800511\n",
      "Training RMSE: 0.401035, Val RMSE 0.800509\n",
      "Training RMSE: 0.401031, Val RMSE 0.800506\n",
      "Training RMSE: 0.401027, Val RMSE 0.800503\n",
      "Training RMSE: 0.401024, Val RMSE 0.800501\n",
      "Training RMSE: 0.401020, Val RMSE 0.800498\n",
      "Training RMSE: 0.401017, Val RMSE 0.800496\n",
      "Training RMSE: 0.401013, Val RMSE 0.800493\n",
      "Training RMSE: 0.401010, Val RMSE 0.800491\n",
      "Training RMSE: 0.401007, Val RMSE 0.800489\n",
      "Training RMSE: 0.401003, Val RMSE 0.800486\n",
      "Training RMSE: 0.401000, Val RMSE 0.800484\n",
      "Training RMSE: 0.400997, Val RMSE 0.800482\n",
      "Training RMSE: 0.400993, Val RMSE 0.800479\n",
      "Training RMSE: 0.400990, Val RMSE 0.800477\n",
      "Training RMSE: 0.400987, Val RMSE 0.800474\n",
      "Training RMSE: 0.400983, Val RMSE 0.800472\n",
      "Training RMSE: 0.400980, Val RMSE 0.800469\n",
      "Training RMSE: 0.400977, Val RMSE 0.800467\n",
      "Training RMSE: 0.400973, Val RMSE 0.800464\n",
      "  8            0.102388            0.046820\n",
      "Training RMSE: 0.402070, Val RMSE 0.800984\n",
      "Training RMSE: 0.402063, Val RMSE 0.800978\n",
      "Training RMSE: 0.402056, Val RMSE 0.800973\n",
      "Training RMSE: 0.402049, Val RMSE 0.800967\n",
      "Training RMSE: 0.402041, Val RMSE 0.800961\n",
      "Training RMSE: 0.402034, Val RMSE 0.800956\n",
      "Training RMSE: 0.402027, Val RMSE 0.800951\n",
      "Training RMSE: 0.402020, Val RMSE 0.800946\n",
      "Training RMSE: 0.402013, Val RMSE 0.800940\n",
      "Training RMSE: 0.402006, Val RMSE 0.800935\n",
      "Training RMSE: 0.402000, Val RMSE 0.800930\n",
      "Training RMSE: 0.401993, Val RMSE 0.800925\n",
      "Training RMSE: 0.401986, Val RMSE 0.800919\n",
      "Training RMSE: 0.401980, Val RMSE 0.800914\n",
      "Training RMSE: 0.401973, Val RMSE 0.800909\n",
      "Training RMSE: 0.401967, Val RMSE 0.800903\n",
      "Training RMSE: 0.401960, Val RMSE 0.800898\n",
      "Training RMSE: 0.401954, Val RMSE 0.800893\n",
      "Training RMSE: 0.401948, Val RMSE 0.800888\n",
      "Training RMSE: 0.401941, Val RMSE 0.800883\n",
      " 16            0.100039            0.044991\n",
      "Training RMSE: 0.404118, Val RMSE 0.801975\n",
      "Training RMSE: 0.404104, Val RMSE 0.801964\n",
      "Training RMSE: 0.404090, Val RMSE 0.801953\n",
      "Training RMSE: 0.404075, Val RMSE 0.801942\n",
      "Training RMSE: 0.404061, Val RMSE 0.801932\n",
      "Training RMSE: 0.404047, Val RMSE 0.801921\n",
      "Training RMSE: 0.404033, Val RMSE 0.801911\n",
      "Training RMSE: 0.404019, Val RMSE 0.801901\n",
      "Training RMSE: 0.404006, Val RMSE 0.801892\n",
      "Training RMSE: 0.403993, Val RMSE 0.801882\n",
      "Training RMSE: 0.403979, Val RMSE 0.801872\n",
      "Training RMSE: 0.403966, Val RMSE 0.801861\n",
      "Training RMSE: 0.403952, Val RMSE 0.801852\n",
      "Training RMSE: 0.403939, Val RMSE 0.801842\n",
      "Training RMSE: 0.403927, Val RMSE 0.801833\n",
      "Training RMSE: 0.403914, Val RMSE 0.801823\n",
      "Training RMSE: 0.403902, Val RMSE 0.801814\n",
      "Training RMSE: 0.403889, Val RMSE 0.801804\n",
      "Training RMSE: 0.403876, Val RMSE 0.801794\n",
      "Training RMSE: 0.403864, Val RMSE 0.801784\n",
      " 32            0.096026            0.043212\n",
      "Training RMSE: 0.408218, Val RMSE 0.804040\n",
      "Training RMSE: 0.408190, Val RMSE 0.804019\n",
      "Training RMSE: 0.408161, Val RMSE 0.803996\n",
      "Training RMSE: 0.408133, Val RMSE 0.803974\n",
      "Training RMSE: 0.408104, Val RMSE 0.803952\n",
      "Training RMSE: 0.408076, Val RMSE 0.803929\n",
      "Training RMSE: 0.408049, Val RMSE 0.803908\n",
      "Training RMSE: 0.408023, Val RMSE 0.803887\n",
      "Training RMSE: 0.407995, Val RMSE 0.803867\n",
      "Training RMSE: 0.407968, Val RMSE 0.803845\n",
      "Training RMSE: 0.407941, Val RMSE 0.803822\n",
      "Training RMSE: 0.407915, Val RMSE 0.803802\n",
      "Training RMSE: 0.407889, Val RMSE 0.803781\n",
      "Training RMSE: 0.407862, Val RMSE 0.803760\n",
      "Training RMSE: 0.407836, Val RMSE 0.803741\n",
      "Training RMSE: 0.407810, Val RMSE 0.803719\n",
      "Training RMSE: 0.407783, Val RMSE 0.803699\n",
      "Training RMSE: 0.407758, Val RMSE 0.803679\n",
      "Training RMSE: 0.407733, Val RMSE 0.803659\n",
      "Training RMSE: 0.407708, Val RMSE 0.803640\n",
      " 64            0.096026            0.043140\n"
     ]
    }
   ],
   "source": [
    "# -*- Encoding:UTF-8 -*-\n",
    "'''\n",
    "@author: Jason.F\n",
    "@data: 2019.07.18\n",
    "@function: Implementing PMF\n",
    "           Dataset: Knowledage-CC\n",
    "           Evaluating: hitradio,ndcg\n",
    "           https://papers.nips.cc/paper/3208-probabilistic-matrix-factorization.pdf\n",
    "           Matlab: http://www.utstat.toronto.edu/~rsalakhu/BPMF.html \n",
    "@reference: https://github.com/adamzjw/Probabilistic-matrix-factorization-in-Python\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import RandomState\n",
    "import copy\n",
    "import heapq\n",
    "import math\n",
    "from numpy import linalg as LA\n",
    "import random\n",
    "#define class PMF\n",
    "class PMF:\n",
    "    def __init__(self, num_feat=8, epsilon=1, _lambda=0.1, momentum=0.8, maxepoch=20, num_batches=10, batch_size=1000):\n",
    "        self.num_feat = num_feat\n",
    "        self.epsilon = epsilon\n",
    "        self._lambda = _lambda\n",
    "        self.momentum = momentum\n",
    "        self.maxepoch = maxepoch\n",
    "        self.num_batches = num_batches\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.w_C = None\n",
    "        self.w_I = None\n",
    "\n",
    "        self.err_train = []\n",
    "        self.err_val = []\n",
    "        \n",
    "    def fit(self, train_vec, val_vec):   \n",
    "        # mean subtraction\n",
    "        self.mean_inv = np.mean(train_vec[:,2])\n",
    "        \n",
    "        pairs_tr = train_vec.shape[0]\n",
    "        pairs_va = val_vec.shape[0]\n",
    "        \n",
    "        # 1-p-i, 2-m-c\n",
    "        num_inv = int(max(np.amax(train_vec[:,0]), np.amax(val_vec[:,0]))) + 1\n",
    "        num_com = int(max(np.amax(train_vec[:,1]), np.amax(val_vec[:,1]))) + 1\n",
    "\n",
    "        incremental = False\n",
    "        if ((not incremental) or (self.w_C is None)):\n",
    "            # initialize\n",
    "            self.epoch = 0\n",
    "            self.w_C = 0.1 * np.random.randn(num_com, self.num_feat)\n",
    "            self.w_I = 0.1 * np.random.randn(num_inv, self.num_feat)\n",
    "            \n",
    "            self.w_C_inc = np.zeros((num_com, self.num_feat))\n",
    "            self.w_I_inc = np.zeros((num_inv, self.num_feat))\n",
    "        \n",
    "        \n",
    "        while self.epoch < self.maxepoch:\n",
    "            self.epoch += 1\n",
    "\n",
    "            # Shuffle training truples\n",
    "            shuffled_order = np.arange(train_vec.shape[0])\n",
    "            np.random.shuffle(shuffled_order)\n",
    "\n",
    "            # Batch update\n",
    "            for batch in range(self.num_batches):\n",
    "                # print \"epoch %d batch %d\" % (self.epoch, batch+1)\n",
    "\n",
    "                batch_idx = np.mod(np.arange(self.batch_size * batch,\n",
    "                                             self.batch_size * (batch+1)),\n",
    "                                   shuffled_order.shape[0])\n",
    "\n",
    "                batch_invID = np.array(train_vec[shuffled_order[batch_idx], 0], dtype='int32')\n",
    "                batch_comID = np.array(train_vec[shuffled_order[batch_idx], 1], dtype='int32')\n",
    "\n",
    "                # Compute Objective Function\n",
    "                pred_out = np.sum(np.multiply(self.w_I[batch_invID,:], \n",
    "                                                self.w_C[batch_comID,:]),\n",
    "                                axis=1) # mean_inv subtracted\n",
    "\n",
    "                rawErr = pred_out - train_vec[shuffled_order[batch_idx], 2] + self.mean_inv\n",
    "\n",
    "                # Compute gradients\n",
    "                Ix_C = 2 * np.multiply(rawErr[:, np.newaxis], self.w_I[batch_invID,:]) \\\n",
    "                        + self._lambda * self.w_C[batch_comID,:]\n",
    "                Ix_I = 2 * np.multiply(rawErr[:, np.newaxis], self.w_C[batch_comID,:]) \\\n",
    "                        + self._lambda * self.w_I[batch_invID,:]\n",
    "            \n",
    "                dw_C = np.zeros((num_com, self.num_feat))\n",
    "                dw_I = np.zeros((num_inv, self.num_feat))\n",
    "\n",
    "                # loop to aggreate the gradients of the same element\n",
    "                for i in range(self.batch_size):\n",
    "                    dw_C[batch_comID[i],:] += Ix_C[i,:]\n",
    "                    dw_I[batch_invID[i],:] += Ix_I[i,:]\n",
    "\n",
    "\n",
    "                # Update with momentum\n",
    "                self.w_C_inc = self.momentum * self.w_C_inc + self.epsilon * dw_C / self.batch_size\n",
    "                self.w_I_inc = self.momentum * self.w_I_inc + self.epsilon * dw_I / self.batch_size\n",
    "\n",
    "\n",
    "                self.w_C = self.w_C - self.w_C_inc\n",
    "                self.w_I = self.w_I - self.w_I_inc\n",
    "\n",
    "                # Compute Objective Function after\n",
    "                if batch == self.num_batches - 1:\n",
    "                    pred_out = np.sum(np.multiply(self.w_I[np.array(train_vec[:,0], dtype='int32'),:],\n",
    "                                                    self.w_C[np.array(train_vec[:,1], dtype='int32'),:]),\n",
    "                                        axis=1) # mean_inv subtracted\n",
    "                    rawErr = pred_out - train_vec[:, 2] + self.mean_inv\n",
    "                    obj = LA.norm(rawErr) ** 2 \\\n",
    "                            + 0.5*self._lambda*(LA.norm(self.w_I) ** 2 + LA.norm(self.w_C) ** 2)\n",
    "\n",
    "                    self.err_train.append(np.sqrt(obj/pairs_tr))\n",
    "\n",
    "                # Compute validation error\n",
    "                if batch == self.num_batches - 1:\n",
    "                    pred_out = np.sum(np.multiply(self.w_I[np.array(val_vec[:,0], dtype='int32'),:],\n",
    "                                                    self.w_C[np.array(val_vec[:,1], dtype='int32'),:]),\n",
    "                                        axis=1) # mean_inv subtracted\n",
    "                    rawErr = pred_out - val_vec[:, 2] + self.mean_inv\n",
    "                    self.err_val.append(LA.norm(rawErr)/np.sqrt(pairs_va))\n",
    "\n",
    "                # Print info\n",
    "                if batch == self.num_batches - 1:\n",
    "                    print ('Training RMSE: %f, Val RMSE %f' % (self.err_train[-1], self.err_val[-1]))\n",
    "    \n",
    "    def predict(self, invID, comID): \n",
    "        return np.dot(self.w_C[comID,:], self.w_I[invID,:]) + self.mean_inv\n",
    "               \n",
    "    def evaluate(self, test_vec, k=10):\n",
    "        def getHitRatio(ranklist, gtItem):\n",
    "            for item in ranklist:\n",
    "                if item == gtItem:\n",
    "                    return 1\n",
    "            return 0\n",
    "\n",
    "        def getNDCG(ranklist, gtItem):\n",
    "            for i in range(len(ranklist)):\n",
    "                item = ranklist[i]\n",
    "                if item == gtItem:\n",
    "                    return math.log(2) / math.log(i+2)\n",
    "            return 0\n",
    "        \n",
    "        testset = pd.DataFrame(test_vec, columns=['u','i'])\n",
    "        hits = []\n",
    "        ndcgs = []\n",
    "        list_csr = list(set(np.array(testset['u']).tolist()))\n",
    "        for u in list_csr:\n",
    "            csrset = np.array(testset[testset['u']==u]).tolist()\n",
    "            scorelist = []\n",
    "            positem = csrset[0][1]#first item is positive\n",
    "            for _, i in csrset:\n",
    "                scorelist.append([i, self.predict(u,i)])\n",
    "            #get topk \n",
    "            map_item_score = {}\n",
    "            for item, rate in scorelist: #turn dict\n",
    "                map_item_score[item] = rate\n",
    "            ranklist = heapq.nlargest(10, map_item_score, key=map_item_score.get)#default Topn=10\n",
    "            hr = getHitRatio(ranklist, positem)\n",
    "            hits.append(hr)\n",
    "            ndcg = getNDCG(ranklist, positem)\n",
    "            ndcgs.append(ndcg)\n",
    "        hitratio,ndcg = np.array(hits).mean(), np.array(ndcgs).mean()\n",
    "        return hitratio,ndcg\n",
    "        \n",
    "#loading dataset\n",
    "def getTrainset(filePath):\n",
    "    kbdata = pd.read_csv(\"/data/fjsdata/ctKngBase/kbcc_trainset.csv\", sep='|', low_memory=False, dtype={'csr':int, 'ke':int, 'num':float})\n",
    "    kbdata['num']=kbdata['num'].apply(lambda x: 1 if float(x)>0.0 else 0)\n",
    "    trainset = np.array(kbdata).tolist()\n",
    "    maxu = kbdata['csr'].max()\n",
    "    maxi = kbdata['ke'].max()\n",
    "    maxr = kbdata['num'].max()\n",
    "    return trainset, maxr, maxu, maxi\n",
    "\n",
    "def getTestset(filePath):\n",
    "    kbdata = pd.read_csv(\"/data/fjsdata/ctKngBase/kbcc_testset.csv\", sep='|', low_memory=False, dtype={'csr':int, 'ke':int, 'num':float})\n",
    "    #testset['num']=testset['num'].apply(lambda x: 1 if float(x)>0.0 else 0)\n",
    "    testset = np.array(kbdata[['csr','ke']]).tolist()\n",
    "    return testset    \n",
    "\n",
    "def getTrainDict(data):\n",
    "        dataDict = {}\n",
    "        for i in data:\n",
    "            dataDict[(i[0], i[1])] = i[2]\n",
    "        return dataDict\n",
    "    \n",
    "def getNegTrain(data, maxi, negNum=4):\n",
    "        datadict = getTrainDict(data)\n",
    "        trainneg = []\n",
    "        for i in data:\n",
    "            trainneg.append([i[0],i[1],i[2]])\n",
    "            for t in range(negNum):\n",
    "                j = np.random.randint(maxi)\n",
    "                while (i[0], j) in datadict:\n",
    "                    j = np.random.randint(maxi)\n",
    "                trainneg.append([i[0], j, 0.0])\n",
    "        return trainneg\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    trainset, maxr, maxu, maxi = getTrainset(\"/data/fjsdata/ctKngBase/kbcc_trainset.csv\")\n",
    "    trainneg = getNegTrain(trainset, maxi)\n",
    "    testset = getTestset(\"/data/fjsdata/ctKngBase/kbcc_testset.csv\")\n",
    "    print('Dataset Statistics: Interaction = %d, User = %d, Item = %d, Sparsity = %.4f' % (len(trainset), maxu+1, maxi+1, len(trainset)/(maxu*maxr)))\n",
    "\n",
    "    print (\"%3s%20s%20s\" % ('K','HR@10', 'NDCG@10'))\n",
    "    for K in [8, 16, 32, 64]:\n",
    "        pmf = PMF(num_feat=K)\n",
    "        valtest = random.sample(trainset,int(0.2*len(trainset)))\n",
    "        pmf.fit(np.array(trainneg), np.array(valtest))\n",
    "        hit, ndcg = pmf.evaluate(testset)\n",
    "        print (\"%3d%20.6f%20.6f\" % (K, hit, ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics: Interaction = 1445622, User = 55187, Item = 9916, Sparsity = 26.1954\n",
      "  K               HR@10             NDCG@10\n",
      "Training RMSE: 0.401051, Val RMSE 0.800415\n",
      "Training RMSE: 0.401049, Val RMSE 0.800412\n",
      "Training RMSE: 0.401047, Val RMSE 0.800410\n",
      "Training RMSE: 0.401044, Val RMSE 0.800407\n",
      "Training RMSE: 0.401042, Val RMSE 0.800404\n",
      "Training RMSE: 0.401040, Val RMSE 0.800401\n",
      "Training RMSE: 0.401037, Val RMSE 0.800399\n",
      "Training RMSE: 0.401035, Val RMSE 0.800396\n",
      "Training RMSE: 0.401032, Val RMSE 0.800393\n",
      "Training RMSE: 0.401030, Val RMSE 0.800391\n",
      "Training RMSE: 0.401028, Val RMSE 0.800388\n",
      "Training RMSE: 0.401025, Val RMSE 0.800386\n",
      "Training RMSE: 0.401023, Val RMSE 0.800383\n",
      "Training RMSE: 0.401020, Val RMSE 0.800380\n",
      "Training RMSE: 0.401018, Val RMSE 0.800378\n",
      "Training RMSE: 0.401015, Val RMSE 0.800376\n",
      "Training RMSE: 0.401013, Val RMSE 0.800373\n",
      "Training RMSE: 0.401011, Val RMSE 0.800371\n",
      "Training RMSE: 0.401008, Val RMSE 0.800368\n",
      "Training RMSE: 0.401006, Val RMSE 0.800366\n",
      "  8            0.100404            0.045550\n",
      "Training RMSE: 0.402083, Val RMSE 0.801021\n",
      "Training RMSE: 0.402079, Val RMSE 0.801016\n",
      "Training RMSE: 0.402074, Val RMSE 0.801010\n",
      "Training RMSE: 0.402069, Val RMSE 0.801005\n",
      "Training RMSE: 0.402064, Val RMSE 0.800999\n",
      "Training RMSE: 0.402060, Val RMSE 0.800993\n",
      "Training RMSE: 0.402055, Val RMSE 0.800988\n",
      "Training RMSE: 0.402050, Val RMSE 0.800982\n",
      "Training RMSE: 0.402046, Val RMSE 0.800977\n",
      "Training RMSE: 0.402041, Val RMSE 0.800972\n",
      "Training RMSE: 0.402036, Val RMSE 0.800967\n",
      "Training RMSE: 0.402031, Val RMSE 0.800961\n",
      "Training RMSE: 0.402027, Val RMSE 0.800956\n",
      "Training RMSE: 0.402022, Val RMSE 0.800950\n",
      "Training RMSE: 0.402018, Val RMSE 0.800945\n",
      "Training RMSE: 0.402013, Val RMSE 0.800940\n",
      "Training RMSE: 0.402008, Val RMSE 0.800935\n",
      "Training RMSE: 0.402004, Val RMSE 0.800930\n",
      "Training RMSE: 0.401999, Val RMSE 0.800925\n",
      "Training RMSE: 0.401995, Val RMSE 0.800920\n",
      " 16            0.100060            0.045315\n",
      "Training RMSE: 0.404132, Val RMSE 0.801992\n",
      "Training RMSE: 0.404123, Val RMSE 0.801981\n",
      "Training RMSE: 0.404113, Val RMSE 0.801970\n",
      "Training RMSE: 0.404103, Val RMSE 0.801959\n",
      "Training RMSE: 0.404094, Val RMSE 0.801948\n",
      "Training RMSE: 0.404084, Val RMSE 0.801938\n",
      "Training RMSE: 0.404075, Val RMSE 0.801927\n",
      "Training RMSE: 0.404065, Val RMSE 0.801916\n",
      "Training RMSE: 0.404056, Val RMSE 0.801905\n",
      "Training RMSE: 0.404046, Val RMSE 0.801894\n",
      "Training RMSE: 0.404037, Val RMSE 0.801884\n",
      "Training RMSE: 0.404028, Val RMSE 0.801874\n",
      "Training RMSE: 0.404019, Val RMSE 0.801864\n",
      "Training RMSE: 0.404009, Val RMSE 0.801854\n",
      "Training RMSE: 0.404000, Val RMSE 0.801844\n",
      "Training RMSE: 0.403991, Val RMSE 0.801833\n",
      "Training RMSE: 0.403981, Val RMSE 0.801822\n",
      "Training RMSE: 0.403972, Val RMSE 0.801812\n",
      "Training RMSE: 0.403963, Val RMSE 0.801802\n",
      "Training RMSE: 0.403953, Val RMSE 0.801792\n",
      " 32            0.099154            0.044934\n",
      "Training RMSE: 0.408239, Val RMSE 0.804022\n",
      "Training RMSE: 0.408220, Val RMSE 0.804001\n",
      "Training RMSE: 0.408201, Val RMSE 0.803979\n",
      "Training RMSE: 0.408182, Val RMSE 0.803959\n",
      "Training RMSE: 0.408164, Val RMSE 0.803938\n",
      "Training RMSE: 0.408145, Val RMSE 0.803917\n",
      "Training RMSE: 0.408127, Val RMSE 0.803896\n",
      "Training RMSE: 0.408108, Val RMSE 0.803873\n",
      "Training RMSE: 0.408089, Val RMSE 0.803850\n",
      "Training RMSE: 0.408070, Val RMSE 0.803827\n",
      "Training RMSE: 0.408051, Val RMSE 0.803804\n",
      "Training RMSE: 0.408032, Val RMSE 0.803783\n",
      "Training RMSE: 0.408014, Val RMSE 0.803762\n",
      "Training RMSE: 0.407995, Val RMSE 0.803741\n",
      "Training RMSE: 0.407976, Val RMSE 0.803720\n",
      "Training RMSE: 0.407958, Val RMSE 0.803700\n",
      "Training RMSE: 0.407939, Val RMSE 0.803680\n",
      "Training RMSE: 0.407920, Val RMSE 0.803659\n",
      "Training RMSE: 0.407902, Val RMSE 0.803637\n",
      "Training RMSE: 0.407883, Val RMSE 0.803615\n",
      " 64            0.101238            0.045676\n"
     ]
    }
   ],
   "source": [
    "# -*- Encoding:UTF-8 -*-\n",
    "'''\n",
    "@author: Jason.F\n",
    "@data: 2019.07.18\n",
    "@function: Implementing PMF\n",
    "           Dataset: Pinterest-20\n",
    "           Evaluating: hitradio,ndcg\n",
    "           https://papers.nips.cc/paper/3208-probabilistic-matrix-factorization.pdf\n",
    "           Matlab: http://www.utstat.toronto.edu/~rsalakhu/BPMF.html \n",
    "@reference: https://github.com/adamzjw/Probabilistic-matrix-factorization-in-Python\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import RandomState\n",
    "import copy\n",
    "import heapq\n",
    "import math\n",
    "from numpy import linalg as LA\n",
    "import random\n",
    "#define class PMF\n",
    "class PMF:\n",
    "    def __init__(self, num_feat=8, epsilon=1, _lambda=0.1, momentum=0.8, maxepoch=20, num_batches=10, batch_size=1000):\n",
    "        self.num_feat = num_feat\n",
    "        self.epsilon = epsilon\n",
    "        self._lambda = _lambda\n",
    "        self.momentum = momentum\n",
    "        self.maxepoch = maxepoch\n",
    "        self.num_batches = num_batches\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.w_C = None\n",
    "        self.w_I = None\n",
    "\n",
    "        self.err_train = []\n",
    "        self.err_val = []\n",
    "        \n",
    "    def fit(self, train_vec, val_vec):   \n",
    "        # mean subtraction\n",
    "        self.mean_inv = np.mean(train_vec[:,2])\n",
    "        \n",
    "        pairs_tr = train_vec.shape[0]\n",
    "        pairs_va = val_vec.shape[0]\n",
    "        \n",
    "        # 1-p-i, 2-m-c\n",
    "        num_inv = int(max(np.amax(train_vec[:,0]), np.amax(val_vec[:,0]))) + 1\n",
    "        num_com = int(max(np.amax(train_vec[:,1]), np.amax(val_vec[:,1]))) + 1\n",
    "\n",
    "        incremental = False\n",
    "        if ((not incremental) or (self.w_C is None)):\n",
    "            # initialize\n",
    "            self.epoch = 0\n",
    "            self.w_C = 0.1 * np.random.randn(num_com, self.num_feat)\n",
    "            self.w_I = 0.1 * np.random.randn(num_inv, self.num_feat)\n",
    "            \n",
    "            self.w_C_inc = np.zeros((num_com, self.num_feat))\n",
    "            self.w_I_inc = np.zeros((num_inv, self.num_feat))\n",
    "        \n",
    "        \n",
    "        while self.epoch < self.maxepoch:\n",
    "            self.epoch += 1\n",
    "\n",
    "            # Shuffle training truples\n",
    "            shuffled_order = np.arange(train_vec.shape[0])\n",
    "            np.random.shuffle(shuffled_order)\n",
    "\n",
    "            # Batch update\n",
    "            for batch in range(self.num_batches):\n",
    "                # print \"epoch %d batch %d\" % (self.epoch, batch+1)\n",
    "\n",
    "                batch_idx = np.mod(np.arange(self.batch_size * batch,\n",
    "                                             self.batch_size * (batch+1)),\n",
    "                                   shuffled_order.shape[0])\n",
    "\n",
    "                batch_invID = np.array(train_vec[shuffled_order[batch_idx], 0], dtype='int32')\n",
    "                batch_comID = np.array(train_vec[shuffled_order[batch_idx], 1], dtype='int32')\n",
    "\n",
    "                # Compute Objective Function\n",
    "                pred_out = np.sum(np.multiply(self.w_I[batch_invID,:], \n",
    "                                                self.w_C[batch_comID,:]),\n",
    "                                axis=1) # mean_inv subtracted\n",
    "\n",
    "                rawErr = pred_out - train_vec[shuffled_order[batch_idx], 2] + self.mean_inv\n",
    "\n",
    "                # Compute gradients\n",
    "                Ix_C = 2 * np.multiply(rawErr[:, np.newaxis], self.w_I[batch_invID,:]) \\\n",
    "                        + self._lambda * self.w_C[batch_comID,:]\n",
    "                Ix_I = 2 * np.multiply(rawErr[:, np.newaxis], self.w_C[batch_comID,:]) \\\n",
    "                        + self._lambda * self.w_I[batch_invID,:]\n",
    "            \n",
    "                dw_C = np.zeros((num_com, self.num_feat))\n",
    "                dw_I = np.zeros((num_inv, self.num_feat))\n",
    "\n",
    "                # loop to aggreate the gradients of the same element\n",
    "                for i in range(self.batch_size):\n",
    "                    dw_C[batch_comID[i],:] += Ix_C[i,:]\n",
    "                    dw_I[batch_invID[i],:] += Ix_I[i,:]\n",
    "\n",
    "\n",
    "                # Update with momentum\n",
    "                self.w_C_inc = self.momentum * self.w_C_inc + self.epsilon * dw_C / self.batch_size\n",
    "                self.w_I_inc = self.momentum * self.w_I_inc + self.epsilon * dw_I / self.batch_size\n",
    "\n",
    "\n",
    "                self.w_C = self.w_C - self.w_C_inc\n",
    "                self.w_I = self.w_I - self.w_I_inc\n",
    "\n",
    "                # Compute Objective Function after\n",
    "                if batch == self.num_batches - 1:\n",
    "                    pred_out = np.sum(np.multiply(self.w_I[np.array(train_vec[:,0], dtype='int32'),:],\n",
    "                                                    self.w_C[np.array(train_vec[:,1], dtype='int32'),:]),\n",
    "                                        axis=1) # mean_inv subtracted\n",
    "                    rawErr = pred_out - train_vec[:, 2] + self.mean_inv\n",
    "                    obj = LA.norm(rawErr) ** 2 \\\n",
    "                            + 0.5*self._lambda*(LA.norm(self.w_I) ** 2 + LA.norm(self.w_C) ** 2)\n",
    "\n",
    "                    self.err_train.append(np.sqrt(obj/pairs_tr))\n",
    "\n",
    "                # Compute validation error\n",
    "                if batch == self.num_batches - 1:\n",
    "                    pred_out = np.sum(np.multiply(self.w_I[np.array(val_vec[:,0], dtype='int32'),:],\n",
    "                                                    self.w_C[np.array(val_vec[:,1], dtype='int32'),:]),\n",
    "                                        axis=1) # mean_inv subtracted\n",
    "                    rawErr = pred_out - val_vec[:, 2] + self.mean_inv\n",
    "                    self.err_val.append(LA.norm(rawErr)/np.sqrt(pairs_va))\n",
    "\n",
    "                # Print info\n",
    "                if batch == self.num_batches - 1:\n",
    "                    print ('Training RMSE: %f, Val RMSE %f' % (self.err_train[-1], self.err_val[-1]))\n",
    "    \n",
    "    def predict(self, invID, comID): \n",
    "        return np.dot(self.w_C[comID,:], self.w_I[invID,:]) + self.mean_inv\n",
    "               \n",
    "    def evaluate(self, test_vec, k=10):\n",
    "        def getHitRatio(ranklist, gtItem):\n",
    "            for item in ranklist:\n",
    "                if item == gtItem:\n",
    "                    return 1\n",
    "            return 0\n",
    "\n",
    "        def getNDCG(ranklist, gtItem):\n",
    "            for i in range(len(ranklist)):\n",
    "                item = ranklist[i]\n",
    "                if item == gtItem:\n",
    "                    return math.log(2) / math.log(i+2)\n",
    "            return 0\n",
    "        \n",
    "        testset = pd.DataFrame(test_vec, columns=['u','i'])\n",
    "        hits = []\n",
    "        ndcgs = []\n",
    "        list_csr = list(set(np.array(testset['u']).tolist()))\n",
    "        for u in list_csr:\n",
    "            csrset = np.array(testset[testset['u']==u]).tolist()\n",
    "            scorelist = []\n",
    "            positem = csrset[0][1]#first item is positive\n",
    "            for _, i in csrset:\n",
    "                scorelist.append([i, self.predict(u,i)])\n",
    "            #get topk \n",
    "            map_item_score = {}\n",
    "            for item, rate in scorelist: #turn dict\n",
    "                map_item_score[item] = rate\n",
    "            ranklist = heapq.nlargest(10, map_item_score, key=map_item_score.get)#default Topn=10\n",
    "            hr = getHitRatio(ranklist, positem)\n",
    "            hits.append(hr)\n",
    "            ndcg = getNDCG(ranklist, positem)\n",
    "            ndcgs.append(ndcg)\n",
    "        hitratio,ndcg = np.array(hits).mean(), np.array(ndcgs).mean()\n",
    "        return hitratio,ndcg\n",
    "        \n",
    "#loading dataset\n",
    "def getTrainset(filePath):\n",
    "    trainset = []\n",
    "    maxu = 0 \n",
    "    maxi = 0 \n",
    "    maxr = 0.0\n",
    "    with open(filePath, 'r') as fd:\n",
    "        line = fd.readline()\n",
    "        while line != None and line != \"\":\n",
    "            arr = line.split(\"\\t\")\n",
    "            u, i, rating = int(arr[0]), int(arr[1]), float(arr[2])\n",
    "            trainset.append([int(arr[0]), int(arr[1]), float(arr[2])])\n",
    "            if rating > maxr: maxr = rating\n",
    "            if u > maxu: maxu = u\n",
    "            if i > maxi: maxi = i\n",
    "            line = fd.readline()\n",
    "        return trainset, maxr, maxu, maxi\n",
    "\n",
    "def getTestset(filePath):\n",
    "    testset = []\n",
    "    with open(filePath, 'r') as fd:\n",
    "        line = fd.readline()\n",
    "        while line != None and line != '':\n",
    "            arr = line.split('\\t')\n",
    "            u = eval(arr[0])[0]\n",
    "            testset.append([u, eval(arr[0])[1]])#one postive item\n",
    "            for i in arr[1:]:\n",
    "                testset.append([u, int(i)]) #99 negative items\n",
    "            line = fd.readline()\n",
    "    return testset    \n",
    "\n",
    "def getTrainDict(data):\n",
    "        dataDict = {}\n",
    "        for i in data:\n",
    "            dataDict[(i[0], i[1])] = i[2]\n",
    "        return dataDict\n",
    "    \n",
    "def getNegTrain(data, maxi, negNum=4):\n",
    "        datadict = getTrainDict(data)\n",
    "        trainneg = []\n",
    "        for i in data:\n",
    "            trainneg.append([i[0],i[1],i[2]])\n",
    "            for t in range(negNum):\n",
    "                j = np.random.randint(maxi)\n",
    "                while (i[0], j) in datadict:\n",
    "                    j = np.random.randint(maxi)\n",
    "                trainneg.append([i[0], j, 0.0])\n",
    "        return trainneg\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    trainset, maxr, maxu, maxi = getTrainset(\"/data/fjsdata/ctKngBase/ml/pinterest-20.train.rating\")\n",
    "    trainneg = getNegTrain(trainset, maxi)\n",
    "    testset = getTestset(\"/data/fjsdata/ctKngBase/ml/pinterest-20.test.negative\")\n",
    "    print('Dataset Statistics: Interaction = %d, User = %d, Item = %d, Sparsity = %.4f' % (len(trainset), maxu+1, maxi+1, len(trainset)/(maxu*maxr)))\n",
    "\n",
    "    print (\"%3s%20s%20s\" % ('K','HR@10', 'NDCG@10'))\n",
    "    for K in [8, 16, 32, 64]:\n",
    "        pmf = PMF(num_feat=K)\n",
    "        valtest = random.sample(trainset,int(0.2*len(trainset)))\n",
    "        pmf.fit(np.array(trainneg), np.array(valtest))\n",
    "        hit, ndcg = pmf.evaluate(testset)\n",
    "        print (\"%3d%20.6f%20.6f\" % (K, hit, ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics: Interaction = 994169, User = 6040, Item = 3706, Sparsity = 32.9250\n",
      "  K               HR@10             NDCG@10\n",
      "Training RMSE: 1.517382, Val RMSE 3.076740\n",
      "Training RMSE: 1.517375, Val RMSE 3.076729\n",
      "Training RMSE: 1.517368, Val RMSE 3.076716\n",
      "Training RMSE: 1.517360, Val RMSE 3.076704\n",
      "Training RMSE: 1.517354, Val RMSE 3.076693\n",
      "Training RMSE: 1.517348, Val RMSE 3.076689\n",
      "Training RMSE: 1.517342, Val RMSE 3.076680\n",
      "Training RMSE: 1.517335, Val RMSE 3.076671\n",
      "Training RMSE: 1.517328, Val RMSE 3.076662\n",
      "Training RMSE: 1.517321, Val RMSE 3.076653\n",
      "Training RMSE: 1.517314, Val RMSE 3.076642\n",
      "Training RMSE: 1.517307, Val RMSE 3.076633\n",
      "Training RMSE: 1.517301, Val RMSE 3.076626\n",
      "Training RMSE: 1.517295, Val RMSE 3.076620\n",
      "Training RMSE: 1.517289, Val RMSE 3.076613\n",
      "Training RMSE: 1.517282, Val RMSE 3.076606\n",
      "Training RMSE: 1.517275, Val RMSE 3.076599\n",
      "Training RMSE: 1.517269, Val RMSE 3.076591\n",
      "Training RMSE: 1.517263, Val RMSE 3.076583\n",
      "Training RMSE: 1.517255, Val RMSE 3.076572\n",
      "  8            0.101325            0.045585\n",
      "Training RMSE: 1.517669, Val RMSE 3.077654\n",
      "Training RMSE: 1.517654, Val RMSE 3.077631\n",
      "Training RMSE: 1.517640, Val RMSE 3.077616\n",
      "Training RMSE: 1.517627, Val RMSE 3.077594\n",
      "Training RMSE: 1.517613, Val RMSE 3.077566\n",
      "Training RMSE: 1.517599, Val RMSE 3.077539\n",
      "Training RMSE: 1.517585, Val RMSE 3.077513\n",
      "Training RMSE: 1.517571, Val RMSE 3.077488\n",
      "Training RMSE: 1.517557, Val RMSE 3.077467\n",
      "Training RMSE: 1.517544, Val RMSE 3.077445\n",
      "Training RMSE: 1.517531, Val RMSE 3.077425\n",
      "Training RMSE: 1.517518, Val RMSE 3.077403\n",
      "Training RMSE: 1.517504, Val RMSE 3.077383\n",
      "Training RMSE: 1.517491, Val RMSE 3.077361\n",
      "Training RMSE: 1.517477, Val RMSE 3.077337\n",
      "Training RMSE: 1.517463, Val RMSE 3.077320\n",
      "Training RMSE: 1.517451, Val RMSE 3.077303\n",
      "Training RMSE: 1.517438, Val RMSE 3.077286\n",
      "Training RMSE: 1.517425, Val RMSE 3.077265\n",
      "Training RMSE: 1.517411, Val RMSE 3.077242\n",
      " 16            0.099338            0.046128\n",
      "Training RMSE: 1.518150, Val RMSE 3.079597\n",
      "Training RMSE: 1.518122, Val RMSE 3.079551\n",
      "Training RMSE: 1.518095, Val RMSE 3.079513\n",
      "Training RMSE: 1.518066, Val RMSE 3.079472\n",
      "Training RMSE: 1.518039, Val RMSE 3.079432\n",
      "Training RMSE: 1.518012, Val RMSE 3.079386\n",
      "Training RMSE: 1.517984, Val RMSE 3.079349\n",
      "Training RMSE: 1.517958, Val RMSE 3.079304\n",
      "Training RMSE: 1.517933, Val RMSE 3.079249\n",
      "Training RMSE: 1.517906, Val RMSE 3.079206\n",
      "Training RMSE: 1.517877, Val RMSE 3.079151\n",
      "Training RMSE: 1.517851, Val RMSE 3.079105\n",
      "Training RMSE: 1.517825, Val RMSE 3.079066\n",
      "Training RMSE: 1.517801, Val RMSE 3.079029\n",
      "Training RMSE: 1.517775, Val RMSE 3.078987\n",
      "Training RMSE: 1.517749, Val RMSE 3.078937\n",
      "Training RMSE: 1.517723, Val RMSE 3.078884\n",
      "Training RMSE: 1.517696, Val RMSE 3.078849\n",
      "Training RMSE: 1.517669, Val RMSE 3.078809\n",
      "Training RMSE: 1.517641, Val RMSE 3.078773\n",
      " 32            0.094371            0.042417\n",
      "Training RMSE: 1.519166, Val RMSE 3.076778\n",
      "Training RMSE: 1.519115, Val RMSE 3.076709\n",
      "Training RMSE: 1.519059, Val RMSE 3.076628\n",
      "Training RMSE: 1.519006, Val RMSE 3.076536\n",
      "Training RMSE: 1.518952, Val RMSE 3.076454\n",
      "Training RMSE: 1.518899, Val RMSE 3.076381\n",
      "Training RMSE: 1.518846, Val RMSE 3.076295\n",
      "Training RMSE: 1.518795, Val RMSE 3.076225\n",
      "Training RMSE: 1.518743, Val RMSE 3.076139\n",
      "Training RMSE: 1.518690, Val RMSE 3.076053\n",
      "Training RMSE: 1.518638, Val RMSE 3.075988\n",
      "Training RMSE: 1.518585, Val RMSE 3.075922\n",
      "Training RMSE: 1.518534, Val RMSE 3.075841\n",
      "Training RMSE: 1.518482, Val RMSE 3.075759\n",
      "Training RMSE: 1.518430, Val RMSE 3.075677\n",
      "Training RMSE: 1.518378, Val RMSE 3.075598\n",
      "Training RMSE: 1.518326, Val RMSE 3.075515\n",
      "Training RMSE: 1.518272, Val RMSE 3.075433\n",
      "Training RMSE: 1.518220, Val RMSE 3.075357\n",
      "Training RMSE: 1.518167, Val RMSE 3.075278\n",
      " 64            0.105795            0.047519\n"
     ]
    }
   ],
   "source": [
    "# -*- Encoding:UTF-8 -*-\n",
    "'''\n",
    "@author: Jason.F\n",
    "@data: 2019.07.18\n",
    "@function: Implementing PMF\n",
    "           Dataset: Movielen Dataset(ml-1m) \n",
    "           Evaluating: hitradio,ndcg\n",
    "           https://papers.nips.cc/paper/3208-probabilistic-matrix-factorization.pdf\n",
    "           Matlab: http://www.utstat.toronto.edu/~rsalakhu/BPMF.html \n",
    "@reference: https://github.com/adamzjw/Probabilistic-matrix-factorization-in-Python\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import RandomState\n",
    "import copy\n",
    "import heapq\n",
    "import math\n",
    "from numpy import linalg as LA\n",
    "import random\n",
    "#define class PMF\n",
    "class PMF:\n",
    "    def __init__(self, num_feat=8, epsilon=1, _lambda=0.1, momentum=0.8, maxepoch=20, num_batches=10, batch_size=1000):\n",
    "        self.num_feat = num_feat\n",
    "        self.epsilon = epsilon\n",
    "        self._lambda = _lambda\n",
    "        self.momentum = momentum\n",
    "        self.maxepoch = maxepoch\n",
    "        self.num_batches = num_batches\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.w_C = None\n",
    "        self.w_I = None\n",
    "\n",
    "        self.err_train = []\n",
    "        self.err_val = []\n",
    "        \n",
    "    def fit(self, train_vec, val_vec):   \n",
    "        # mean subtraction\n",
    "        self.mean_inv = np.mean(train_vec[:,2])\n",
    "        \n",
    "        pairs_tr = train_vec.shape[0]\n",
    "        pairs_va = val_vec.shape[0]\n",
    "        \n",
    "        # 1-p-i, 2-m-c\n",
    "        num_inv = int(max(np.amax(train_vec[:,0]), np.amax(val_vec[:,0]))) + 1\n",
    "        num_com = int(max(np.amax(train_vec[:,1]), np.amax(val_vec[:,1]))) + 1\n",
    "\n",
    "        incremental = False\n",
    "        if ((not incremental) or (self.w_C is None)):\n",
    "            # initialize\n",
    "            self.epoch = 0\n",
    "            self.w_C = 0.1 * np.random.randn(num_com, self.num_feat)\n",
    "            self.w_I = 0.1 * np.random.randn(num_inv, self.num_feat)\n",
    "            \n",
    "            self.w_C_inc = np.zeros((num_com, self.num_feat))\n",
    "            self.w_I_inc = np.zeros((num_inv, self.num_feat))\n",
    "        \n",
    "        \n",
    "        while self.epoch < self.maxepoch:\n",
    "            self.epoch += 1\n",
    "\n",
    "            # Shuffle training truples\n",
    "            shuffled_order = np.arange(train_vec.shape[0])\n",
    "            np.random.shuffle(shuffled_order)\n",
    "\n",
    "            # Batch update\n",
    "            for batch in range(self.num_batches):\n",
    "                # print \"epoch %d batch %d\" % (self.epoch, batch+1)\n",
    "\n",
    "                batch_idx = np.mod(np.arange(self.batch_size * batch,\n",
    "                                             self.batch_size * (batch+1)),\n",
    "                                   shuffled_order.shape[0])\n",
    "\n",
    "                batch_invID = np.array(train_vec[shuffled_order[batch_idx], 0], dtype='int32')\n",
    "                batch_comID = np.array(train_vec[shuffled_order[batch_idx], 1], dtype='int32')\n",
    "\n",
    "                # Compute Objective Function\n",
    "                pred_out = np.sum(np.multiply(self.w_I[batch_invID,:], \n",
    "                                                self.w_C[batch_comID,:]),\n",
    "                                axis=1) # mean_inv subtracted\n",
    "\n",
    "                rawErr = pred_out - train_vec[shuffled_order[batch_idx], 2] + self.mean_inv\n",
    "\n",
    "                # Compute gradients\n",
    "                Ix_C = 2 * np.multiply(rawErr[:, np.newaxis], self.w_I[batch_invID,:]) \\\n",
    "                        + self._lambda * self.w_C[batch_comID,:]\n",
    "                Ix_I = 2 * np.multiply(rawErr[:, np.newaxis], self.w_C[batch_comID,:]) \\\n",
    "                        + self._lambda * self.w_I[batch_invID,:]\n",
    "            \n",
    "                dw_C = np.zeros((num_com, self.num_feat))\n",
    "                dw_I = np.zeros((num_inv, self.num_feat))\n",
    "\n",
    "                # loop to aggreate the gradients of the same element\n",
    "                for i in range(self.batch_size):\n",
    "                    dw_C[batch_comID[i],:] += Ix_C[i,:]\n",
    "                    dw_I[batch_invID[i],:] += Ix_I[i,:]\n",
    "\n",
    "\n",
    "                # Update with momentum\n",
    "                self.w_C_inc = self.momentum * self.w_C_inc + self.epsilon * dw_C / self.batch_size\n",
    "                self.w_I_inc = self.momentum * self.w_I_inc + self.epsilon * dw_I / self.batch_size\n",
    "\n",
    "\n",
    "                self.w_C = self.w_C - self.w_C_inc\n",
    "                self.w_I = self.w_I - self.w_I_inc\n",
    "\n",
    "                # Compute Objective Function after\n",
    "                if batch == self.num_batches - 1:\n",
    "                    pred_out = np.sum(np.multiply(self.w_I[np.array(train_vec[:,0], dtype='int32'),:],\n",
    "                                                    self.w_C[np.array(train_vec[:,1], dtype='int32'),:]),\n",
    "                                        axis=1) # mean_inv subtracted\n",
    "                    rawErr = pred_out - train_vec[:, 2] + self.mean_inv\n",
    "                    obj = LA.norm(rawErr) ** 2 \\\n",
    "                            + 0.5*self._lambda*(LA.norm(self.w_I) ** 2 + LA.norm(self.w_C) ** 2)\n",
    "\n",
    "                    self.err_train.append(np.sqrt(obj/pairs_tr))\n",
    "\n",
    "                # Compute validation error\n",
    "                if batch == self.num_batches - 1:\n",
    "                    pred_out = np.sum(np.multiply(self.w_I[np.array(val_vec[:,0], dtype='int32'),:],\n",
    "                                                    self.w_C[np.array(val_vec[:,1], dtype='int32'),:]),\n",
    "                                        axis=1) # mean_inv subtracted\n",
    "                    rawErr = pred_out - val_vec[:, 2] + self.mean_inv\n",
    "                    self.err_val.append(LA.norm(rawErr)/np.sqrt(pairs_va))\n",
    "\n",
    "                # Print info\n",
    "                if batch == self.num_batches - 1:\n",
    "                    print ('Training RMSE: %f, Val RMSE %f' % (self.err_train[-1], self.err_val[-1]))\n",
    "    \n",
    "    def predict(self, invID, comID): \n",
    "        return np.dot(self.w_C[comID,:], self.w_I[invID,:]) + self.mean_inv\n",
    "               \n",
    "    def evaluate(self, test_vec, k=10):\n",
    "        def getHitRatio(ranklist, gtItem):\n",
    "            for item in ranklist:\n",
    "                if item == gtItem:\n",
    "                    return 1\n",
    "            return 0\n",
    "\n",
    "        def getNDCG(ranklist, gtItem):\n",
    "            for i in range(len(ranklist)):\n",
    "                item = ranklist[i]\n",
    "                if item == gtItem:\n",
    "                    return math.log(2) / math.log(i+2)\n",
    "            return 0\n",
    "        \n",
    "        testset = pd.DataFrame(test_vec, columns=['u','i'])\n",
    "        hits = []\n",
    "        ndcgs = []\n",
    "        list_csr = list(set(np.array(testset['u']).tolist()))\n",
    "        for u in list_csr:\n",
    "            csrset = np.array(testset[testset['u']==u]).tolist()\n",
    "            scorelist = []\n",
    "            positem = csrset[0][1]#first item is positive\n",
    "            for _, i in csrset:\n",
    "                scorelist.append([i, self.predict(u,i)])\n",
    "            #get topk \n",
    "            map_item_score = {}\n",
    "            for item, rate in scorelist: #turn dict\n",
    "                map_item_score[item] = rate\n",
    "            ranklist = heapq.nlargest(10, map_item_score, key=map_item_score.get)#default Topn=10\n",
    "            hr = getHitRatio(ranklist, positem)\n",
    "            hits.append(hr)\n",
    "            ndcg = getNDCG(ranklist, positem)\n",
    "            ndcgs.append(ndcg)\n",
    "        hitratio,ndcg = np.array(hits).mean(), np.array(ndcgs).mean()\n",
    "        return hitratio,ndcg\n",
    "        \n",
    "#loading dataset\n",
    "def getTrainset(filePath):\n",
    "    trainset = []\n",
    "    maxu = 0 \n",
    "    maxi = 0 \n",
    "    maxr = 0.0\n",
    "    with open(filePath, 'r') as fd:\n",
    "        line = fd.readline()\n",
    "        while line != None and line != \"\":\n",
    "            arr = line.split(\"\\t\")\n",
    "            u, i, rating = int(arr[0]), int(arr[1]), float(arr[2])\n",
    "            trainset.append([int(arr[0]), int(arr[1]), float(arr[2])])\n",
    "            if rating > maxr: maxr = rating\n",
    "            if u > maxu: maxu = u\n",
    "            if i > maxi: maxi = i\n",
    "            line = fd.readline()\n",
    "        return trainset, maxr, maxu, maxi\n",
    "\n",
    "def getTestset(filePath):\n",
    "    testset = []\n",
    "    with open(filePath, 'r') as fd:\n",
    "        line = fd.readline()\n",
    "        while line != None and line != '':\n",
    "            arr = line.split('\\t')\n",
    "            u = eval(arr[0])[0]\n",
    "            testset.append([u, eval(arr[0])[1]])#one postive item\n",
    "            for i in arr[1:]:\n",
    "                testset.append([u, int(i)]) #99 negative items\n",
    "            line = fd.readline()\n",
    "    return testset    \n",
    "\n",
    "def getTrainDict(data):\n",
    "        dataDict = {}\n",
    "        for i in data:\n",
    "            dataDict[(i[0], i[1])] = i[2]\n",
    "        return dataDict\n",
    "    \n",
    "def getNegTrain(data, maxi, negNum=4):\n",
    "        datadict = getTrainDict(data)\n",
    "        trainneg = []\n",
    "        for i in data:\n",
    "            trainneg.append([i[0],i[1],i[2]])\n",
    "            for t in range(negNum):\n",
    "                j = np.random.randint(maxi)\n",
    "                while (i[0], j) in datadict:\n",
    "                    j = np.random.randint(maxi)\n",
    "                trainneg.append([i[0], j, 0.0])\n",
    "        return trainneg\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    trainset, maxr, maxu, maxi = getTrainset(\"/data/fjsdata/ctKngBase/ml/ml-1m.train.rating\")\n",
    "    trainneg = getNegTrain(trainset, maxi)\n",
    "    testset = getTestset(\"/data/fjsdata/ctKngBase/ml/ml-1m.test.negative\")\n",
    "    print('Dataset Statistics: Interaction = %d, User = %d, Item = %d, Sparsity = %.4f' % (len(trainset), maxu+1, maxi+1, len(trainset)/(maxu*maxr)))\n",
    "\n",
    "    print (\"%3s%20s%20s\" % ('K','HR@10', 'NDCG@10'))\n",
    "    for K in [8, 16, 32, 64]:\n",
    "        pmf = PMF(num_feat=K)\n",
    "        valtest = random.sample(trainset,int(0.2*len(trainset)))\n",
    "        pmf.fit(np.array(trainneg), np.array(valtest))\n",
    "        hit, ndcg = pmf.evaluate(testset)\n",
    "        print (\"%3d%20.6f%20.6f\" % (K, hit, ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics: Interaction = 994169, User = 6040, Item = 3706, Sparsity = 32.9250\n",
      "  K               HR@10             NDCG@10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: RuntimeWarning: invalid value encountered in multiply\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:51: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8            1.000000            0.333333\n",
      " 16            1.000000            0.333333\n",
      " 32            1.000000            0.333333\n",
      " 64            1.000000            0.333333\n"
     ]
    }
   ],
   "source": [
    "# -*- Encoding:UTF-8 -*-\n",
    "'''\n",
    "@author: Jason.F\n",
    "@data: 2019.07.18\n",
    "@function: Implementing PMF\n",
    "           Dataset: Movielen Dataset(ml-1m) \n",
    "           Evaluating: hitradio,ndcg\n",
    "           https://papers.nips.cc/paper/3208-probabilistic-matrix-factorization.pdf\n",
    "           Matlab: http://www.utstat.toronto.edu/~rsalakhu/BPMF.html \n",
    "@reference: https://github.com/xuChenSJTU/PMF\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import RandomState\n",
    "import copy\n",
    "import heapq\n",
    "import math\n",
    "#define class PMF\n",
    "class PMF():\n",
    "    \n",
    "    def __init__(self, R, K=8):\n",
    "        # initialize some parameters\n",
    "        self.lambda_alpha = 1e-2\n",
    "        self.lambda_beta = 1e-2\n",
    "        self.momuntum = 0.9\n",
    "        self.lr = 0.001\n",
    "        self.iterations = 20\n",
    "        #handle data\n",
    "        self.R = R\n",
    "        self.random_state = RandomState(None)\n",
    "        self.I = copy.deepcopy(self.R)\n",
    "        self.I[self.I != 0] = 1\n",
    "        self.U = 0.1*self.random_state.rand(np.size(R, 0), K)# K is number of latent factors\n",
    "        self.V = 0.1*self.random_state.rand(np.size(R, 1), K)\n",
    "\n",
    "    def loss(self):\n",
    "        # the loss function of the model\n",
    "        loss = np.sum(self.I*(self.R-np.dot(self.U, self.V.T))**2) + self.lambda_alpha*np.sum(np.square(self.U)) + self.lambda_beta*np.sum(np.square(self.V))\n",
    "        return loss\n",
    "\n",
    "    def train(self):\n",
    "        # monemtum\n",
    "        momuntum_u = np.zeros(self.U.shape)\n",
    "        momuntum_v = np.zeros(self.V.shape)\n",
    "\n",
    "        for it in range(self.iterations):\n",
    "            # derivate of Vi\n",
    "            grads_u = np.dot(self.I*(self.R-np.dot(self.U, self.V.T)), -self.V) + self.lambda_alpha*self.U\n",
    "\n",
    "            # derivate of Tj\n",
    "            grads_v = np.dot((self.I*(self.R-np.dot(self.U, self.V.T))).T, -self.U) + self.lambda_beta*self.V\n",
    "\n",
    "            # update the parameters\n",
    "            momuntum_u = (self.momuntum * momuntum_u) + self.lr * grads_u\n",
    "            momuntum_v = (self.momuntum * momuntum_v) + self.lr * grads_v\n",
    "            self.U = self.U - momuntum_u\n",
    "            self.V = self.V - momuntum_v\n",
    "\n",
    "            # training evaluation\n",
    "            #train_loss = self.loss()\n",
    "            #print('traning iteration:{: d} ,loss:{: f}'.format(it, train_loss))\n",
    "\n",
    "        return self.U, self.V\n",
    "    \n",
    "    def predict(self, data):\n",
    "        index_data = np.array([[int(ele[0]), int(ele[1])] for ele in data], dtype=int)\n",
    "        u_features = self.U.take(index_data.take(0, axis=1), axis=0)\n",
    "        v_features = self.V.take(index_data.take(1, axis=1), axis=0)\n",
    "        preds_value_array = np.sum(u_features*v_features, 1)\n",
    "        return preds_value_array.tolist()\n",
    "    \n",
    "    \n",
    "    def evaluate(self, testset):\n",
    "        def getHitRatio(ranklist, gtItem):\n",
    "            for item in ranklist:\n",
    "                if item == gtItem:\n",
    "                    return 1\n",
    "            return 0\n",
    "\n",
    "        def getNDCG(ranklist, gtItem):\n",
    "            for i in range(len(ranklist)):\n",
    "                item = ranklist[i]\n",
    "                if item == gtItem:\n",
    "                    return math.log(2) / math.log(i+2)\n",
    "            return 0\n",
    "        testset = pd.DataFrame(testset, columns=['u','i'])\n",
    "        hits = []\n",
    "        ndcgs = []\n",
    "        list_csr = list(set(np.array(testset['u']).tolist()))\n",
    "        for u in list_csr:\n",
    "            csrset = np.array(testset[testset['u']==u]).tolist()\n",
    "            csrpred = self.predict(csrset)\n",
    "            scorelist = []\n",
    "            positem = csrset[0][1]#first item is positive\n",
    "            for j in range(len(csrset)):  \n",
    "                scorelist.append([csrset[j][1], csrpred[j]])\n",
    "            #get topk \n",
    "            map_item_score = {}\n",
    "            for item, rate in scorelist: #turn dict\n",
    "                map_item_score[item] = rate\n",
    "            ranklist = heapq.nlargest(10, map_item_score, key=map_item_score.get)#default Topn=10\n",
    "            hr = getHitRatio(ranklist, positem)\n",
    "            hits.append(hr)\n",
    "            ndcg = getNDCG(ranklist, positem)\n",
    "            ndcgs.append(ndcg)\n",
    "        hitratio,ndcg = np.array(hits).mean(), np.array(ndcgs).mean()\n",
    "        return hitratio,ndcg\n",
    "        \n",
    "        \n",
    "#loading dataset\n",
    "def getTrainset(filePath):\n",
    "    trainset = []\n",
    "    maxu = 0 \n",
    "    maxi = 0 \n",
    "    maxr = 0.0\n",
    "    with open(filePath, 'r') as fd:\n",
    "        line = fd.readline()\n",
    "        while line != None and line != \"\":\n",
    "            arr = line.split(\"\\t\")\n",
    "            u, i, rating = int(arr[0]), int(arr[1]), float(arr[2])\n",
    "            trainset.append([int(arr[0]), int(arr[1]), float(arr[2])])\n",
    "            if rating > maxr: maxr = rating\n",
    "            if u > maxu: maxu = u\n",
    "            if i > maxi: maxi = i\n",
    "            line = fd.readline()\n",
    "        return trainset, maxr, maxu, maxi\n",
    "\n",
    "def getTestset(filePath):\n",
    "    testset = []\n",
    "    with open(filePath, 'r') as fd:\n",
    "        line = fd.readline()\n",
    "        while line != None and line != '':\n",
    "            arr = line.split('\\t')\n",
    "            u = eval(arr[0])[0]\n",
    "            testset.append([u, eval(arr[0])[1]])#one postive item\n",
    "            for i in arr[1:]:\n",
    "                testset.append([u, int(i)]) #99 negative items\n",
    "            line = fd.readline()\n",
    "    return testset    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    trainset, maxr, maxu, maxi = getTrainset(\"/data/fjsdata/ctKngBase/ml/ml-1m.train.rating\")\n",
    "    testset = getTestset(\"/data/fjsdata/ctKngBase/ml/ml-1m.test.negative\")\n",
    "    print('Dataset Statistics: Interaction = %d, User = %d, Item = %d, Sparsity = %.4f' % (len(trainset), maxu+1, maxi+1, len(trainset)/(maxu*maxr)))\n",
    "    R = np.zeros([maxu+1, maxi+1], dtype=np.float32)\n",
    "    for i in trainset:\n",
    "        user = int(i[0])\n",
    "        item = int(i[1])\n",
    "        rating = float(i[2])\n",
    "        R[user][item] = rating\n",
    "    print (\"%3s%20s%20s\" % ('K','HR@10', 'NDCG@10'))\n",
    "    for K in [8, 16, 32, 64]:\n",
    "        pmf = PMF(R, K)\n",
    "        U, V = pmf.train()\n",
    "        hit, ndcg = pmf.evaluate(testset)\n",
    "        print (\"%3d%20.6f%20.6f\" % (K, hit, ndcg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
