{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Success!\n",
      "Data Info:\n",
      "\tUser Num: 10215\n",
      "\tItem Num: 96323\n",
      "\tData Size: 2547452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0723 00:15:15.402885 139830912517888 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:90: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 984045984 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training!\n",
      "====================Epoch  0 ====================\n",
      "270 / 49755 : loss = 39.979827880859375"
     ]
    }
   ],
   "source": [
    "# -*- Encoding:UTF-8 -*-\n",
    "'''\n",
    "@author: Jason.F\n",
    "@data: 2019.07.17\n",
    "@function: Implementing DMF with Tensorflow  \n",
    "           Dataset: KnowledgeBase-CC\n",
    "           Evaluating: hitradio,ndcg\n",
    "           https://www.ijcai.org/proceedings/2017/0447.pdf\n",
    "           https://github.com/RuidongZ/Deep_Matrix_Factorization_Models\n",
    "'''\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import heapq\n",
    "import math\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "class DMF:\n",
    "    def __init__(self, K, negNum=4, lr=0.001, maxEpochs=20, topK=10):\n",
    "        #prepare data\n",
    "        self.dataSet = DataSet()\n",
    "        self.shape = self.dataSet.shape\n",
    "        self.maxRate = self.dataSet.maxRate\n",
    "\n",
    "        self.train = self.dataSet.train\n",
    "        self.testNeg = self.dataSet.getTestNeg()\n",
    "        \n",
    "        #initiate model\n",
    "        self.negNum = negNum\n",
    "        self.add_embedding_matrix()\n",
    "        self.add_placeholders()\n",
    "\n",
    "        self.userLayer = [512, K]\n",
    "        self.itemLayer = [512, K]\n",
    "        self.add_model()\n",
    "\n",
    "        self.add_loss()\n",
    "\n",
    "        self.lr = lr\n",
    "        self.add_train_step()\n",
    "        self.init_sess()\n",
    "\n",
    "        self.maxEpochs = maxEpochs\n",
    "        self.batchSize = 256\n",
    "        self.topK = topK\n",
    "        self.earlyStop = 5\n",
    "\n",
    "\n",
    "    def add_placeholders(self):\n",
    "        self.user = tf.placeholder(tf.int32)\n",
    "        self.item = tf.placeholder(tf.int32)\n",
    "        self.rate = tf.placeholder(tf.float32)\n",
    "        self.drop = tf.placeholder(tf.float32)\n",
    "\n",
    "    def add_embedding_matrix(self):\n",
    "        self.matrix_init = tf.placeholder(tf.float32, shape=(self.shape[0], self.shape[1]))\n",
    "        matrix = tf.Variable(self.matrix_init)\n",
    "        self.user_item_embedding = tf.convert_to_tensor(matrix)\n",
    "        #self.user_item_embedding = tf.convert_to_tensor(self.dataSet.getEmbedding())\n",
    "        self.item_user_embedding = tf.transpose(self.user_item_embedding)\n",
    "\n",
    "    def add_model(self):\n",
    "        user_input = tf.nn.embedding_lookup(self.user_item_embedding, self.user)\n",
    "        item_input = tf.nn.embedding_lookup(self.item_user_embedding, self.item)\n",
    "\n",
    "        def init_variable(shape, name):\n",
    "            return tf.Variable(tf.truncated_normal(shape=shape, dtype=tf.float32, stddev=0.01), name=name)\n",
    "\n",
    "        with tf.name_scope(\"User_Layer\"):\n",
    "            user_W1 = init_variable([self.shape[1], self.userLayer[0]], \"user_W1\")\n",
    "            user_out = tf.matmul(user_input, user_W1)\n",
    "            for i in range(0, len(self.userLayer)-1):\n",
    "                W = init_variable([self.userLayer[i], self.userLayer[i+1]], \"user_W\"+str(i+2))\n",
    "                b = init_variable([self.userLayer[i+1]], \"user_b\"+str(i+2))\n",
    "                user_out = tf.nn.relu(tf.add(tf.matmul(user_out, W), b))\n",
    "\n",
    "        with tf.name_scope(\"Item_Layer\"):\n",
    "            item_W1 = init_variable([self.shape[0], self.itemLayer[0]], \"item_W1\")\n",
    "            item_out = tf.matmul(item_input, item_W1)\n",
    "            for i in range(0, len(self.itemLayer)-1):\n",
    "                W = init_variable([self.itemLayer[i], self.itemLayer[i+1]], \"item_W\"+str(i+2))\n",
    "                b = init_variable([self.itemLayer[i+1]], \"item_b\"+str(i+2))\n",
    "                item_out = tf.nn.relu(tf.add(tf.matmul(item_out, W), b))\n",
    "\n",
    "        norm_user_output = tf.sqrt(tf.reduce_sum(tf.square(user_out), axis=1))\n",
    "        norm_item_output = tf.sqrt(tf.reduce_sum(tf.square(item_out), axis=1))\n",
    "        self.y_ = tf.reduce_sum(tf.multiply(user_out, item_out), axis=1, keepdims=False) / (norm_item_output* norm_user_output)\n",
    "        self.y_ = tf.maximum(1e-6, self.y_)\n",
    "\n",
    "    def add_loss(self):\n",
    "        regRate = self.rate / self.maxRate\n",
    "        losses = regRate * tf.log(self.y_) + (1 - regRate) * tf.log(1 - self.y_)\n",
    "        loss = -tf.reduce_sum(losses)\n",
    "        # regLoss = tf.add_n([tf.nn.l2_loss(v) for v in tf.trainable_variables()])\n",
    "        # self.loss = loss + self.reg * regLoss\n",
    "        self.loss = loss\n",
    "\n",
    "    def add_train_step(self):\n",
    "        '''\n",
    "        global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "        self.lr = tf.train.exponential_decay(self.lr, global_step,\n",
    "                                             self.decay_steps, self.decay_rate, staircase=True)\n",
    "        '''\n",
    "        optimizer = tf.train.AdamOptimizer(self.lr)\n",
    "        self.train_step = optimizer.minimize(self.loss)\n",
    "\n",
    "    def init_sess(self):\n",
    "        self.config = tf.ConfigProto()\n",
    "        self.config.gpu_options.allow_growth = True\n",
    "        self.config.allow_soft_placement = True\n",
    "        self.sess = tf.Session(config=self.config)\n",
    "        #self.sess.run(tf.global_variables_initializer())\n",
    "        self.sess.run(tf.global_variables_initializer(), feed_dict={self.matrix_init: self.dataSet.getEmbedding()})\n",
    "\n",
    "    def run(self):\n",
    "        best_hr = -1\n",
    "        best_NDCG = -1\n",
    "        best_epoch = -1\n",
    "        print(\"Start Training!\")\n",
    "        for epoch in range(self.maxEpochs):\n",
    "            print(\"=\"*20+\"Epoch \", epoch, \"=\"*20)\n",
    "            self.run_epoch(self.sess)\n",
    "            print('='*50)\n",
    "            print(\"Start Evaluation!\")\n",
    "            hr, NDCG = self.evaluate(self.sess, self.topK)\n",
    "            print(\"Epoch \", epoch, \"HR: {}, NDCG: {}\".format(hr, NDCG))\n",
    "            if hr > best_hr or NDCG > best_NDCG:\n",
    "                best_hr = hr\n",
    "                best_NDCG = NDCG\n",
    "                best_epoch = epoch\n",
    "            if epoch - best_epoch > self.earlyStop:\n",
    "                print(\"Normal Early stop!\")\n",
    "                break\n",
    "            print(\"=\"*20+\"Epoch \", epoch, \"End\"+\"=\"*20)\n",
    "        print(\"Best hr: {}, NDCG: {}, At Epoch {}\".format(best_hr, best_NDCG, best_epoch))\n",
    "        print(\"Training complete!\")\n",
    "\n",
    "    def run_epoch(self, sess, verbose=10):\n",
    "        train_u, train_i, train_r = self.dataSet.getInstances(self.train, self.negNum)\n",
    "        train_len = len(train_u)\n",
    "        shuffled_idx = np.random.permutation(np.arange(train_len))\n",
    "        train_u = train_u[shuffled_idx]\n",
    "        train_i = train_i[shuffled_idx]\n",
    "        train_r = train_r[shuffled_idx]\n",
    "\n",
    "        num_batches = len(train_u) // self.batchSize + 1\n",
    "\n",
    "        losses = []\n",
    "        for i in range(num_batches):\n",
    "            min_idx = i * self.batchSize\n",
    "            max_idx = np.min([train_len, (i+1)*self.batchSize])\n",
    "            train_u_batch = train_u[min_idx: max_idx]\n",
    "            train_i_batch = train_i[min_idx: max_idx]\n",
    "            train_r_batch = train_r[min_idx: max_idx]\n",
    "            \n",
    "            feed_dict = self.create_feed_dict(train_u_batch, train_i_batch, train_r_batch)\n",
    "            _, tmp_loss = sess.run([self.train_step, self.loss], feed_dict=feed_dict)\n",
    "            losses.append(tmp_loss)\n",
    "            if verbose and i % verbose == 0:\n",
    "                sys.stdout.write('\\r{} / {} : loss = {}'.format(i, num_batches, np.mean(losses[-verbose:])))\n",
    "                sys.stdout.flush()\n",
    "        loss = np.mean(losses)\n",
    "        print(\"\\nMean loss in this epoch is: {}\".format(loss))\n",
    "        return loss\n",
    "\n",
    "    def create_feed_dict(self, u, i, r=None, drop=None):\n",
    "        return {self.user: u,\n",
    "                self.item: i,\n",
    "                self.rate: r,\n",
    "                self.drop: drop}\n",
    "\n",
    "    def evaluate(self, sess, topK):\n",
    "        def getHitRatio(ranklist, targetItem):\n",
    "            for item in ranklist:\n",
    "                if item == targetItem:\n",
    "                    return 1\n",
    "            return 0\n",
    "        def getNDCG(ranklist, targetItem):\n",
    "            for i in range(len(ranklist)):\n",
    "                item = ranklist[i]\n",
    "                if item == targetItem:\n",
    "                    return math.log(2) / math.log(i+2)\n",
    "            return 0\n",
    "\n",
    "\n",
    "        hr =[]\n",
    "        NDCG = []\n",
    "        testUser = self.testNeg[0]\n",
    "        testItem = self.testNeg[1]\n",
    "        for i in range(len(testUser)):\n",
    "            target = testItem[i][0]\n",
    "            feed_dict = self.create_feed_dict(testUser[i], testItem[i])\n",
    "            predict = sess.run(self.y_, feed_dict=feed_dict)\n",
    "\n",
    "            item_score_dict = {}\n",
    "\n",
    "            for j in range(len(testItem[i])):\n",
    "                item = testItem[i][j]\n",
    "                item_score_dict[item] = predict[j]\n",
    "\n",
    "            ranklist = heapq.nlargest(topK, item_score_dict, key=item_score_dict.get)\n",
    "\n",
    "            tmp_hr = getHitRatio(ranklist, target)\n",
    "            tmp_NDCG = getNDCG(ranklist, target)\n",
    "            hr.append(tmp_hr)\n",
    "            NDCG.append(tmp_NDCG)\n",
    "        return np.mean(hr), np.mean(NDCG)\n",
    "\n",
    "class DataSet(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.train, self.shape = self.getTrainData()\n",
    "        self.trainDict = self.getTrainDict()\n",
    "        \n",
    "    def getTrainData(self):\n",
    "        kbdata = pd.read_csv(\"/data/fjsdata/ctKngBase/kbcc_trainset.csv\", sep='|', low_memory=False, dtype={'csr':int, 'ke':int, 'num':float})\n",
    "        kbdata['num']=kbdata['num'].apply(lambda x: 1 if float(x)>0.0 else 0)\n",
    "        data = np.array(kbdata).tolist()\n",
    "        u = kbdata['csr'].max()\n",
    "        i = kbdata['ke'].max()\n",
    "        self.maxRate = kbdata['num'].max()\n",
    "        print(\"Loading Success!\\n\"\n",
    "                  \"Data Info:\\n\"\n",
    "                  \"\\tUser Num: {}\\n\"\n",
    "                  \"\\tItem Num: {}\\n\"\n",
    "                  \"\\tData Size: {}\".format(u, i, len(data)))\n",
    "        return data, [u+1, i+1]\n",
    "\n",
    "    def getTrainDict(self):\n",
    "        dataDict = {}\n",
    "        for i in self.train:\n",
    "            dataDict[(i[0], i[1])] = i[2]\n",
    "        return dataDict\n",
    "\n",
    "    def getEmbedding(self):\n",
    "        train_matrix = np.zeros([self.shape[0], self.shape[1]], dtype=np.float32)\n",
    "        for i in self.train:\n",
    "            user = i[0]\n",
    "            movie = i[1]\n",
    "            rating = i[2]\n",
    "            train_matrix[user][movie] = rating\n",
    "        return np.array(train_matrix)\n",
    "\n",
    "    def getInstances(self, data, negNum):\n",
    "        user = []\n",
    "        item = []\n",
    "        rate = []\n",
    "        for i in data:\n",
    "            user.append(i[0])\n",
    "            item.append(i[1])\n",
    "            rate.append(i[2])\n",
    "            for t in range(negNum):\n",
    "                j = np.random.randint(self.shape[1])\n",
    "                while (i[0], j) in self.trainDict:\n",
    "                    j = np.random.randint(self.shape[1])\n",
    "                user.append(i[0])\n",
    "                item.append(j)\n",
    "                rate.append(0.0)\n",
    "        return np.array(user), np.array(item), np.array(rate)\n",
    "\n",
    "    def getTestNeg(self):\n",
    "        #loading data\n",
    "        testset = []\n",
    "        kbdata = pd.read_csv(\"/data/fjsdata/ctKngBase/kbcc_testset.csv\", sep='|', low_memory=False, dtype={'csr':int, 'ke':int, 'num':float})\n",
    "        #testset['num']=testset['num'].apply(lambda x: 1 if float(x)>0.0 else 0)\n",
    "        testset = np.array(kbdata[['csr','ke']]).tolist()\n",
    "        #format    \n",
    "        user = []\n",
    "        item = []\n",
    "        u_prev = testset[0][0]\n",
    "        tmp_user = []\n",
    "        tmp_item = []\n",
    "        for u, i in testset:\n",
    "            if u_prev ==u:\n",
    "                tmp_user.append(u)\n",
    "                tmp_item.append(i)\n",
    "            else:\n",
    "                user.append(tmp_user)\n",
    "                item.append(tmp_item)\n",
    "                tmp_user = []\n",
    "                tmp_item = []\n",
    "                tmp_user.append(u)\n",
    "                tmp_item.append(i)\n",
    "            u_prev = u\n",
    "        return [np.array(user), np.array(item)]\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    for K in [64, 32, 16, 8]:\n",
    "        dmf = DMF(K, negNum=4, lr=0.001, maxEpochs=1, topK=10)\n",
    "        dmf.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
