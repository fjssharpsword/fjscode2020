{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading faiss with AVX2 support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "from PIL import Image\n",
    "from io import StringIO,BytesIO \n",
    "from scipy.spatial.distance import pdist\n",
    "import cv2\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc \n",
    "from functools import reduce\n",
    "import wfdb#https://github.com/MIT-LCP/wfdb-python\n",
    "from wfdb import processing\n",
    "import faiss \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "torch.cuda.set_device(0)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 / 20000 The length of train set is 20000\n",
      "20000 / 20000 The length of test set is 20000\n"
     ]
    }
   ],
   "source": [
    "#read train image with CV\n",
    "train_dir = '/data/tmpexec/ecg/train' #the path of images\n",
    "trI, trY = [],[]\n",
    "for iname in os.listdir(train_dir):\n",
    "    if iname.endswith(\".png\"):\n",
    "        try:\n",
    "            image_path = os.path.join(train_dir, iname)\n",
    "            itype = int(os.path.splitext(iname)[0].split(\"-\")[1])\n",
    "            img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(500,300,3)->(256,256,3)\n",
    "            trI.append(img)\n",
    "            trY.append(itype)\n",
    "        except:\n",
    "            print(iname+\":\"+str(image_path))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(trY),20000))\n",
    "        sys.stdout.flush()\n",
    "print('The length of train set is %d'%len(trY))\n",
    "#read test image with CV\n",
    "test_dir = '/data/tmpexec/ecg/test' #the path of images\n",
    "teI, teY = [],[]\n",
    "for iname in os.listdir(test_dir):\n",
    "    if iname.endswith(\".png\"):\n",
    "        try:\n",
    "            image_path = os.path.join(test_dir, iname)\n",
    "            itype = int(os.path.splitext(iname)[0].split(\"-\")[1])\n",
    "            img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(500,300,3)->(256,256,3)\n",
    "            teI.append(img)\n",
    "            teY.append(itype)\n",
    "        except:\n",
    "            print(iname+\":\"+str(image_path))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(teY),20000))\n",
    "        sys.stdout.flush()\n",
    "print('The length of test set is %d'%len(teY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttention(nn.Module):#spatial attention layer\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels, out_channels=out_channels,\n",
    "                kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        self.downsample_layer = None\n",
    "        self.do_downsample = False\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.do_downsample = True\n",
    "            self.downsample_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.net(x)\n",
    "\n",
    "        if self.do_downsample:\n",
    "            identity = self.downsample_layer(x)\n",
    "\n",
    "        return F.relu(out + identity, inplace=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            \n",
    "class ASHNet(nn.Module):\n",
    "    def __init__(self, hash_size: int, class_size:int):\n",
    "        super().__init__()\n",
    "        #Resnet\n",
    "        self.net = nn.Sequential(\n",
    "            ResBlock(in_channels=3, out_channels=16),\n",
    "            ResBlock(in_channels=16, out_channels=16),\n",
    "            ResBlock(in_channels=16, out_channels=16, stride=2),\n",
    "        ) \n",
    "        #Attention \n",
    "        self.sa = SpatialAttention() \n",
    "        #fully connected\n",
    "        self.hash = nn.Sequential(\n",
    "            nn.Linear(16*128*128, hash_size),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.classes = nn.Linear(hash_size, class_size)\n",
    "        \n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = self.sa(x)*x\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x_hash = self.hash(x)\n",
    "        x_class = self.classes(x_hash)\n",
    "        return x_hash,x_class\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "            \n",
    "class PairwiseLoss(nn.Module):\n",
    "    def __init__(self, margin=0.5, alpha=0.01):\n",
    "        super(PairwiseLoss, self).__init__()\n",
    "        self.alpha = alpha #regularization\n",
    "        self.margin = margin #margin threshold\n",
    "        self.mse_loss = nn.MSELoss(reduction='none')\n",
    "        self.l1_loss = nn.L1Loss(reduction='mean')\n",
    "    \n",
    "    def forward(self,h1,h2,y):    \n",
    "        margin_val = self.margin * h1.shape[1]\n",
    "        squared_loss = torch.mean(self.mse_loss(h1, h2), dim=1)\n",
    "        # T1: 0.5 * (1 - y) * dist(x1, x2)\n",
    "        positive_pair_loss = (0.5 * (1 - y) * squared_loss)\n",
    "        mean_positive_pair_loss = torch.mean(positive_pair_loss)\n",
    "        # T2: 0.5 * y * max(margin - dist(x1, x2), 0)\n",
    "        zeros = torch.zeros_like(squared_loss)\n",
    "        marginMat = margin_val * torch.ones_like(squared_loss)\n",
    "        negative_pair_loss = 0.5 * y * torch.max(zeros, marginMat - squared_loss)\n",
    "        mean_negative_pair_loss = torch.mean(negative_pair_loss)\n",
    "\n",
    "        # T3: alpha(dst_l1(abs(x1), 1)) + dist_l1(abs(x2), 1)))\n",
    "        mean_value_regularization = self.alpha * (\n",
    "                self.l1_loss(torch.abs(h1), torch.ones_like(h1)) +\n",
    "                self.l1_loss(torch.abs(h2), torch.ones_like(h2)))\n",
    "\n",
    "        loss = mean_positive_pair_loss + mean_negative_pair_loss + mean_value_regularization\n",
    "        return loss\n",
    "\n",
    "#https://github.com/clcarwin/focal_loss_pytorch/blob/master/focalloss.py   \n",
    "class FocalLoss(nn.Module):\n",
    "    #Loss(x, class) = - \\alpha (1-softmax(x)[class])^gamma \\log(softmax(x)[class])\n",
    "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n",
    "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, out, y):\n",
    "        y = y.view(-1,1)\n",
    "        logpt = F.log_softmax(out,dim=1)#default ,dim=1\n",
    "        logpt = logpt.gather(1,y)# dim=1, index=y, max\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = Variable(logpt.data.exp())\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type()!=out.data.type():\n",
    "                self.alpha = self.alpha.type_as(out.data)\n",
    "            at = self.alpha.gather(0,y.data.view(-1))\n",
    "            logpt = logpt * Variable(at)\n",
    "\n",
    "        loss = -1 * (1-pt)**self.gamma * logpt\n",
    "        if self.size_average: return loss.mean()\n",
    "        else: return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2000 / 2000 : loss = 0.001941Eopch:     1 mean_loss = 0.007782\n",
      " 2000 / 2000 : loss = 0.000431Eopch:     2 mean_loss = 0.002247\n",
      " 2000 / 2000 : loss = 0.000139Eopch:     3 mean_loss = 0.001064\n",
      " 2000 / 2000 : loss = 0.000895Eopch:     4 mean_loss = 0.000520\n",
      " 2000 / 2000 : loss = 0.000348Eopch:     5 mean_loss = 0.000408\n",
      " 2000 / 2000 : loss = 0.000192Eopch:     6 mean_loss = 0.000228\n",
      " 2000 / 2000 : loss = 0.000467Eopch:     7 mean_loss = 0.000349\n",
      " 2000 / 2000 : loss = 7e-05058Eopch:     8 mean_loss = 0.000370\n",
      " 2000 / 2000 : loss = 0.000698Eopch:     9 mean_loss = 0.000276\n",
      " 2000 / 2000 : loss = 0.000325Eopch:    10 mean_loss = 0.000167\n",
      "best_loss = 0.000167\n",
      " 546 / 546 : loss = 0.038578Eopch:     1 mean_loss = 0.832473\n",
      " 546 / 546 : loss = 0.034606Eopch:     2 mean_loss = 0.514196\n",
      " 546 / 546 : loss = 0.237115Eopch:     3 mean_loss = 0.446303\n",
      " 546 / 546 : loss = 0.043217Eopch:     4 mean_loss = 0.383217\n",
      " 546 / 546 : loss = 0.559744Eopch:     5 mean_loss = 0.326894\n",
      " 546 / 546 : loss = 0.192894Eopch:     6 mean_loss = 0.290028\n",
      " 546 / 546 : loss = 0.034256Eopch:     7 mean_loss = 0.270927\n",
      " 546 / 546 : loss = 0.035432Eopch:     8 mean_loss = 0.223102\n",
      " 546 / 546 : loss = 0.039425Eopch:     9 mean_loss = 0.204987\n",
      " 546 / 546 : loss = 0.037157Eopch:    10 mean_loss = 0.185700\n",
      "best_loss = 0.185700\n"
     ]
    }
   ],
   "source": [
    "#Cross train-Focal loss\n",
    "#define model\n",
    "model = ASHNet(hash_size=36, class_size=5).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "\n",
    "#define FocalLoss gamma=[0,0.5,1,2,5] alpha=[0.25,0.25,0.25,0.25,0.25]\n",
    "criterion  = FocalLoss(gamma=2, alpha=[0.01,0.10,0.09,0.20,0.60]).cuda() \n",
    "#train model with focal loss\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(10):#iteration\n",
    "    losses = []\n",
    "    num_batches = len(trY) // batchSize\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY), (i+1)*batchSize])\n",
    "        X_batch = torch.from_numpy(np.array(trI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "        y_batch = torch.from_numpy(np.array(trY[min_idx:max_idx])).type(torch.LongTensor).cuda()\n",
    "        #forword\n",
    "        _, out_class = model(X_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        #binary-like loss\n",
    "        loss = criterion(out_class, y_batch) #F.log_softmax+F.nll_loss\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "\n",
    "#train model with pairwise loss\n",
    "def onlineGenImgPairs(smlspl, bigspl):#Generate image pairs for model\n",
    "    idx_sf = random.sample(range(0, len(bigspl)),len(smlspl))\n",
    "    idx_sf.extend(list(smlspl))\n",
    "    random.shuffle(idx_sf)\n",
    "    trI1_sf, trI2_sf, trY1_sf, trY2_sf = [],[],[],[]\n",
    "    flag = 0\n",
    "    for i in idx_sf:\n",
    "        if flag==0:\n",
    "            trI1_sf.append(trI[i])\n",
    "            trY1_sf.append(trY[i])\n",
    "            flag =1\n",
    "        else:\n",
    "            trI2_sf.append(trI[i])\n",
    "            trY2_sf.append(trY[i])\n",
    "            flag =0\n",
    "    trY_sf = np.where((np.array(trY1_sf)-np.array(trY2_sf))!=0,1,0)\n",
    "    return np.array(trI1_sf),np.array(trI2_sf),trY_sf\n",
    "smlspl = np.where( np.array(trY) > 0 ) #samll sample\n",
    "bigspl = np.where( np.array(trY) == 0 ) #big sample\n",
    "#define pairwise loss\n",
    "criterion  = PairwiseLoss(margin=0.5).cuda() \n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(10):#iteration\n",
    "    trI1_sf, trI2_sf, trY_sf = onlineGenImgPairs(smlspl[0], bigspl[0]) #sample again\n",
    "    losses = []\n",
    "    num_batches = len(trY_sf) // batchSize + 1\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY_sf), (i+1)*batchSize])\n",
    "        I1_batch = torch.from_numpy(trI1_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        I2_batch = torch.from_numpy(trI2_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        Y_batch = torch.from_numpy(trY_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        #forword\n",
    "        X1_hash, _ = model(I1_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        X2_hash, _ = model(I2_batch.permute(0, 3, 1, 2))\n",
    "        #binary-like loss\n",
    "        loss = criterion(X1_hash,X2_hash,Y_batch)\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1999 / 2000 Completed buliding index in 1 seconds\n",
      "Accuracy: 0.787250\n",
      "[[12806   138  1885    15     2]\n",
      " [  630   143   171     0     0]\n",
      " [  968    26  2794     0     0]\n",
      " [  311     0   101     2     0]\n",
      " [    7     0     1     0     0]]\n",
      "Specificity: 0.862589\n",
      "Sensitivity of S: 0.151483\n",
      "Sensitivity of V: 0.737592\n",
      "Sensitivity of F: 0.004831\n",
      "Sensitivity of Q: 0.000000\n",
      " 1999 / 2000 Accuracy: 0.658650\n",
      "[[9057 1627 3159 1001    2]\n",
      " [ 202  436  242   63    1]\n",
      " [  48   16 3605  118    1]\n",
      " [ 183    5  151   75    0]\n",
      " [   3    0    5    0    0]]\n",
      "Specificity: 0.610063\n",
      "Sensitivity of S: 0.461864\n",
      "Sensitivity of V: 0.951690\n",
      "Sensitivity of F: 0.181159\n",
      "Sensitivity of Q: 0.000000\n"
     ]
    }
   ],
   "source": [
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "criterion=criterion.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "#hash code of train data from model\n",
    "#torch.cuda.synchronize()\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize\n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_hash, _ = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_hash = X_hash.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_hash.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#hash code of test data from model\n",
    "#torch.cuda.synchronize()\n",
    "teF = []\n",
    "num_batches = len(teI) // batchSize \n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(teI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_hash, _ = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_hash = X_hash.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    teF.extend(X_hash.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "#performance with hash\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(36) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "#performance\n",
    "scores, neighbors = gpu_index.search(np.ascontiguousarray(teF, dtype=np.float32), k=1) #return top1\n",
    "y_pred = []\n",
    "for i in neighbors.flatten():\n",
    "    y_pred.append(np.array(trY)[i]) #label of top1\n",
    "print ( 'Accuracy: %.6f'%accuracy_score(teY, y_pred))\n",
    "#confusion matrix\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, y_pred, labels=labels ) #labels=['N','S','V','F','Q']\n",
    "print (cm)\n",
    "print ('Specificity: %.6f'%float(cm[0][0]/np.sum(cm[0])))\n",
    "print ('Sensitivity of S: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity of V: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity of F: %.6f'%float(cm[3][3]/np.sum(cm[3])))\n",
    "print ('Sensitivity of Q: %.6f'%float(cm[4][4]/np.sum(cm[4])))\n",
    "\n",
    "#performance with class\n",
    "teY_pred = []\n",
    "teF = [] \n",
    "num_batches = len(teY) // batchSize \n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "    X_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    _, out_class = best_net(X_batch.permute(0, 3, 1, 2))#forword\n",
    "    teF.extend(out_class.cpu().data.numpy().tolist()) #record feature\n",
    "    out_class = F.log_softmax(out_class,dim=1) \n",
    "    pred = out_class.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(pred.cpu().data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "#confusion matrix\n",
    "print ( 'Accuracy: %.6f'%accuracy_score(teY, teY_pred))\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, teY_pred, labels=labels ) #labels=['N','S','V','F','Q']\n",
    "print (cm)\n",
    "print ('Specificity: %.6f'%float(cm[0][0]/np.sum(cm[0])))\n",
    "print ('Sensitivity of S: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity of V: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity of F: %.6f'%float(cm[3][3]/np.sum(cm[3])))\n",
    "print ('Sensitivity of Q: %.6f'%float(cm[4][4]/np.sum(cm[4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Org data dimension is 5.Embedded data dimension is 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize : t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import random\n",
    "def scatter(X, y):\n",
    "    #X,y:numpy-array\n",
    "    classes = len(list(set(y.tolist())))#get number of classes\n",
    "    #palette = np.array(sns.color_palette(\"hls\", classes))# choose a color palette with seaborn.\n",
    "    color = ['c','y','m','b','g','r']\n",
    "    marker = ['o','x','+','*','s']\n",
    "    plt.figure(figsize=(8,8))#create a plot\n",
    "    for i in range(classes):\n",
    "        plt.scatter(X[y == i,0], X[y == i,1], c=color[i], marker=marker[i], label=str(i))\n",
    "    plt.axis('off')\n",
    "    plt.legend(loc='upper left')\n",
    "    #plt.savefig('digits_tsne-generated.png', dpi=100)\n",
    "    plt.show()\n",
    "\n",
    "#prepare dataï¼Œclasses=5\n",
    "#idx= random.sample(np.where(np.array(teY)==0)[0].tolist(),100)\n",
    "idx= np.where(np.array(teY)==0)[0].tolist()[0:100]\n",
    "X0= np.array(teF)[idx]\n",
    "y0= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==1)[0].tolist()[0:100]\n",
    "X1= np.array(teF)[idx]\n",
    "y1= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==2)[0].tolist()[0:100]\n",
    "X2= np.array(teF)[idx]\n",
    "y2= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==3)[0].tolist()[0:100]\n",
    "X3= np.array(teF)[idx]\n",
    "y3= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==4)[0].tolist()\n",
    "X4= np.array(teF)[idx]\n",
    "y4= np.array(teY)[idx]\n",
    "\n",
    "y = np.append(y0,y1)\n",
    "y = np.append(y,y2)\n",
    "y = np.append(y,y3)\n",
    "y = np.append(y,y4)\n",
    "X = np.vstack((X0,X1))\n",
    "X = np.vstack((X,X2))\n",
    "X = np.vstack((X,X3))\n",
    "X = np.vstack((X,X4))\n",
    "#training t-sne \n",
    "tsne = TSNE(n_components=2, init='pca', random_state=501)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "print(\"Org data dimension is {}.Embedded data dimension is {}\".format(X.shape[-1], X_tsne.shape[-1]))\n",
    "\n",
    "#visualize\n",
    "scatter(X_tsne, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0040794510>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADXCAYAAAC51IK9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAADZUlEQVR4nO3bsU3EQBRFURttARQAgjo2IKQRitgaKILiECkh+dAAHslodZHwOelPXnSDkb2OMRYAGjd/PQDgSEQXICS6ACHRBQiJLkBIdAFCp+n1bfU9GcBeL2PdOs2j+3n1KQCHNo/uV7QC4CDm0b2NVgAcxDy68ysAO4kuQMgnYwAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqfp9bEZAXAU8+jeRSsADmIdY2weH5aP7SMAP3pf7tet2zS66+siugA7jcvyy+iur6ILsNMYl83oTt90z+Pp+msADmwa3ef1XO0A+D9mLwiz5wUArsvPEQAh0QUIiS5ASHQBQqILEBJdgNA3T2Ej2YBvy7QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#feature map\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    " \n",
    "# normalizing the output\n",
    "def normalize_output(img):\n",
    "    img = img - img.min()\n",
    "    img = img / img.max()\n",
    "    return img\n",
    "\n",
    "image_path = '/data/tmpexec/ecg/test/9929-2.png' #V:Ventricular ectopic beat\n",
    "oriImg = cv2.imread(image_path)\n",
    "height, width, _ = oriImg.shape\n",
    "#plt.axis('off')\n",
    "#plt.imshow(oriImg)\n",
    "data = []\n",
    "oriImg = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))\n",
    "data.append(oriImg)\n",
    "data = torch.from_numpy(np.array(data)).type(torch.FloatTensor).cuda() \n",
    "\n",
    "activation = {}\n",
    "best_net.sa.register_forward_hook(get_activation('sa'))#spatial attention\n",
    "output = best_net(data.permute(0, 3, 1, 2))\n",
    "feature = activation['sa'].squeeze()\n",
    "feature_0 = feature[0].cpu().numpy()\n",
    "feature_0 = normalize_output(feature_0)\n",
    "feature_0 = np.uint8(255 * feature_0)\n",
    "#plot\n",
    "featuremap = cv2.applyColorMap(cv2.resize(feature_0,(width, height)), cv2.COLORMAP_JET)\n",
    "plt.axis('off')\n",
    "plt.imshow(featuremap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
