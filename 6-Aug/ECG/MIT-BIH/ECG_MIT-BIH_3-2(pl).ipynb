{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading faiss with AVX2 support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "from PIL import Image\n",
    "from io import StringIO,BytesIO \n",
    "from scipy.spatial.distance import pdist\n",
    "import cv2\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc \n",
    "from functools import reduce\n",
    "import wfdb#https://github.com/MIT-LCP/wfdb-python\n",
    "from wfdb import processing\n",
    "import faiss \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "torch.cuda.set_device(0)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 / 20000 The length of train set is 20000\n",
      "20000 / 20000 The length of test set is 20000\n"
     ]
    }
   ],
   "source": [
    "#read train image with CV\n",
    "train_dir = '/data/tmpexec/ecg/train' #the path of images\n",
    "trI, trY = [],[]\n",
    "for iname in os.listdir(train_dir):\n",
    "    if iname.endswith(\".png\"):\n",
    "        try:\n",
    "            image_path = os.path.join(train_dir, iname)\n",
    "            itype = int(os.path.splitext(iname)[0].split(\"-\")[1])\n",
    "            img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(500,300,3)->(256,256,3)\n",
    "            trI.append(img)\n",
    "            trY.append(itype)\n",
    "        except:\n",
    "            print(iname+\":\"+str(image_path))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(trY),20000))\n",
    "        sys.stdout.flush()\n",
    "print('The length of train set is %d'%len(trY))\n",
    "#read test image with CV\n",
    "test_dir = '/data/tmpexec/ecg/test' #the path of images\n",
    "teI, teY = [],[]\n",
    "for iname in os.listdir(test_dir):\n",
    "    if iname.endswith(\".png\"):\n",
    "        try:\n",
    "            image_path = os.path.join(test_dir, iname)\n",
    "            itype = int(os.path.splitext(iname)[0].split(\"-\")[1])\n",
    "            img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(500,300,3)->(256,256,3)\n",
    "            teI.append(img)\n",
    "            teY.append(itype)\n",
    "        except:\n",
    "            print(iname+\":\"+str(image_path))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(teY),20000))\n",
    "        sys.stdout.flush()\n",
    "print('The length of test set is %d'%len(teY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 546 / 546 : loss = 0.294733Eopch:     1 mean_loss = 0.971631\n",
      " 546 / 546 : loss = 0.028961Eopch:     2 mean_loss = 0.675360\n",
      " 546 / 546 : loss = 0.047495Eopch:     3 mean_loss = 0.559917\n",
      " 546 / 546 : loss = 0.035413Eopch:     4 mean_loss = 0.512035\n",
      " 546 / 546 : loss = 0.033044Eopch:     5 mean_loss = 0.458218\n",
      " 546 / 546 : loss = 0.563144Eopch:     6 mean_loss = 0.434092\n",
      " 546 / 546 : loss = 0.027063Eopch:     7 mean_loss = 0.399067\n",
      " 546 / 546 : loss = 0.031128Eopch:     8 mean_loss = 0.376653\n",
      " 546 / 546 : loss = 0.724947Eopch:     9 mean_loss = 0.368996\n",
      " 546 / 546 : loss = 0.248426Eopch:    10 mean_loss = 0.352400\n",
      "best_loss = 0.352400\n",
      " 1999 / 2000 Completed buliding index in 1 seconds\n",
      "Accuracy: 0.790800\n",
      "[[12385   115  2123   223     0]\n",
      " [  605   150   185     4     0]\n",
      " [  438    26  3274    50     0]\n",
      " [  292     0   114     7     1]\n",
      " [    6     0     2     0     0]]\n",
      "Specificity: 0.834231\n",
      "Sensitivity of S: 0.158898\n",
      "Sensitivity of V: 0.864308\n",
      "Sensitivity of F: 0.016908\n",
      "Sensitivity of Q: 0.000000\n"
     ]
    }
   ],
   "source": [
    "class SpatialAttention(nn.Module):#spatial attention layer\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels, out_channels=out_channels,\n",
    "                kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        self.downsample_layer = None\n",
    "        self.do_downsample = False\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.do_downsample = True\n",
    "            self.downsample_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.net(x)\n",
    "\n",
    "        if self.do_downsample:\n",
    "            identity = self.downsample_layer(x)\n",
    "\n",
    "        return F.relu(out + identity, inplace=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            \n",
    "class ASHNet(nn.Module):\n",
    "    def __init__(self, code_size: int):\n",
    "        super().__init__()\n",
    "        #Resnet\n",
    "        self.net = nn.Sequential(\n",
    "            ResBlock(in_channels=3, out_channels=16),\n",
    "            ResBlock(in_channels=16, out_channels=16),\n",
    "            ResBlock(in_channels=16, out_channels=16, stride=2),\n",
    "        ) \n",
    "        #Attention \n",
    "        self.sa = SpatialAttention() \n",
    "        #fully connected\n",
    "        self.linear = nn.Sequential(\n",
    "            #nn.Linear(16*128*128, 4096),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            nn.Linear(16*128*128, code_size),\n",
    "            #nn.ReLU(inplace=True) #nn.Tanh()#[-1,1]\n",
    "        )\n",
    "        \n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = self.sa(x)*x\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "            \n",
    "class HashLossFunc(nn.Module):\n",
    "    def __init__(self, margin=0.5, alpha=0.01):\n",
    "        super(HashLossFunc, self).__init__()\n",
    "        self.alpha = alpha #regularization\n",
    "        self.margin = margin #margin threshold\n",
    "        self.mse_loss = nn.MSELoss(reduction='none')\n",
    "        self.l1_loss = nn.L1Loss(reduction='mean')\n",
    "    \n",
    "    def forward(self,h1,h2,y):    \n",
    "        margin_val = self.margin * h1.shape[1]\n",
    "        squared_loss = torch.mean(self.mse_loss(h1, h2), dim=1)\n",
    "        # T1: 0.5 * (1 - y) * dist(x1, x2)\n",
    "        positive_pair_loss = (0.5 * (1 - y) * squared_loss)\n",
    "        mean_positive_pair_loss = torch.mean(positive_pair_loss)\n",
    "        # T2: 0.5 * y * max(margin - dist(x1, x2), 0)\n",
    "        zeros = torch.zeros_like(squared_loss)\n",
    "        marginMat = margin_val * torch.ones_like(squared_loss)\n",
    "        negative_pair_loss = 0.5 * y * torch.max(zeros, marginMat - squared_loss)\n",
    "        mean_negative_pair_loss = torch.mean(negative_pair_loss)\n",
    "\n",
    "        # T3: alpha(dst_l1(abs(x1), 1)) + dist_l1(abs(x2), 1)))\n",
    "        mean_value_regularization = self.alpha * (\n",
    "                self.l1_loss(torch.abs(h1), torch.ones_like(h1)) +\n",
    "                self.l1_loss(torch.abs(h2), torch.ones_like(h2)))\n",
    "\n",
    "        loss = mean_positive_pair_loss + mean_negative_pair_loss + mean_value_regularization\n",
    "        return loss\n",
    "\n",
    "    \n",
    "#Generate image pairs for model\n",
    "def onlineGenImgPairs(smlspl, bigspl):\n",
    "    idx_sf = random.sample(range(0, len(bigspl)),len(smlspl))\n",
    "    idx_sf.extend(list(smlspl))\n",
    "    random.shuffle(idx_sf)\n",
    "    trI1_sf, trI2_sf, trY1_sf, trY2_sf = [],[],[],[]\n",
    "    flag = 0\n",
    "    for i in idx_sf:\n",
    "        if flag==0:\n",
    "            trI1_sf.append(trI[i])\n",
    "            trY1_sf.append(trY[i])\n",
    "            flag =1\n",
    "        else:\n",
    "            trI2_sf.append(trI[i])\n",
    "            trY2_sf.append(trY[i])\n",
    "            flag =0\n",
    "    trY_sf = np.where((np.array(trY1_sf)-np.array(trY2_sf))!=0,1,0)\n",
    "    return np.array(trI1_sf),np.array(trI2_sf),trY_sf\n",
    "smlspl = np.where( np.array(trY) > 0 ) #samll sample\n",
    "bigspl = np.where( np.array(trY) == 0 ) #big sample\n",
    "#trI1_sf, trI2_sf, trY_sf = onlineGenImgPairs(smlspl[0], bigspl[0]) #sample\n",
    "\n",
    "#define model\n",
    "hash_size=24\n",
    "model = ASHNet(code_size=hash_size).cuda()\n",
    "criterion  = HashLossFunc(margin=0.5).cuda() #define loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(10):#iteration\n",
    "    trI1_sf, trI2_sf, trY_sf = onlineGenImgPairs(smlspl[0], bigspl[0]) #sample again\n",
    "    losses = []\n",
    "    num_batches = len(trY_sf) // batchSize + 1\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY_sf), (i+1)*batchSize])\n",
    "        I1_batch = torch.from_numpy(trI1_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        I2_batch = torch.from_numpy(trI2_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        Y_batch = torch.from_numpy(trY_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        #forword\n",
    "        X1_batch = model(I1_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        X2_batch = model(I2_batch.permute(0, 3, 1, 2))\n",
    "        #binary-like loss\n",
    "        loss = criterion(X1_batch,X2_batch,Y_batch)\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "criterion=criterion.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "#hash code of train data from model\n",
    "#torch.cuda.synchronize()\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize\n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#hash code of test data from model\n",
    "#torch.cuda.synchronize()\n",
    "teF = []\n",
    "num_batches = len(teI) // batchSize \n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(teI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    teF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(hash_size) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "#performance\n",
    "scores, neighbors = gpu_index.search(np.ascontiguousarray(teF, dtype=np.float32), k=1) #return top1\n",
    "y_pred = []\n",
    "for i in neighbors.flatten():\n",
    "    y_pred.append(np.array(trY)[i]) #label of top1\n",
    "print ( 'Accuracy: %.6f'%accuracy_score(teY, y_pred))\n",
    "#confusion matrix\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, y_pred, labels=labels ) #labels=['N','S','V','F','Q']\n",
    "print (cm)\n",
    "print ('Specificity: %.6f'%float(cm[0][0]/np.sum(cm[0])))\n",
    "print ('Sensitivity of S: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity of V: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity of F: %.6f'%float(cm[3][3]/np.sum(cm[3])))\n",
    "print ('Sensitivity of Q: %.6f'%float(cm[4][4]/np.sum(cm[4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Org data dimension is 24.Embedded data dimension is 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize : t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import random\n",
    "def scatter(X, y):\n",
    "    #X,y:numpy-array\n",
    "    classes = len(list(set(y.tolist())))#get number of classes\n",
    "    #palette = np.array(sns.color_palette(\"hls\", classes))# choose a color palette with seaborn.\n",
    "    color = ['c','y','m','b','g','r']\n",
    "    marker = ['o','x','+','*','s']\n",
    "    plt.figure(figsize=(8,8))#create a plot\n",
    "    for i in range(classes):\n",
    "        plt.scatter(X[y == i,0], X[y == i,1], c=color[i], marker=marker[i], label=str(i))\n",
    "    plt.axis('off')\n",
    "    plt.legend(loc='upper left')\n",
    "    #plt.savefig('digits_tsne-generated.png', dpi=100)\n",
    "    plt.show()\n",
    "\n",
    "#prepare dataï¼Œclasses=5\n",
    "#idx= random.sample(np.where(np.array(teY)==0)[0].tolist(),100)\n",
    "idx= np.where(np.array(teY)==0)[0].tolist()[0:100]\n",
    "X0= np.array(teF)[idx]\n",
    "y0= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==1)[0].tolist()[0:100]\n",
    "X1= np.array(teF)[idx]\n",
    "y1= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==2)[0].tolist()[0:100]\n",
    "X2= np.array(teF)[idx]\n",
    "y2= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==3)[0].tolist()[0:100]\n",
    "X3= np.array(teF)[idx]\n",
    "y3= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==4)[0].tolist()\n",
    "X4= np.array(teF)[idx]\n",
    "y4= np.array(teY)[idx]\n",
    "\n",
    "y = np.append(y0,y1)\n",
    "y = np.append(y,y2)\n",
    "y = np.append(y,y3)\n",
    "y = np.append(y,y4)\n",
    "X = np.vstack((X0,X1))\n",
    "X = np.vstack((X,X2))\n",
    "X = np.vstack((X,X3))\n",
    "X = np.vstack((X,X4))\n",
    "#training t-sne \n",
    "tsne = TSNE(n_components=2, init='pca', random_state=501)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "print(\"Org data dimension is {}.Embedded data dimension is {}\".format(X.shape[-1], X_tsne.shape[-1]))\n",
    "\n",
    "#visualize\n",
    "scatter(X_tsne, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f86ac171c10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADXCAYAAAC51IK9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAADJklEQVR4nO3asWkEQRBFQc2xochWMJfQochbEezAiuMJtFXud9p6jDFrZj4AaDz++gCAOxFdgJDoAoREFyAkugAh0QUIHbvxey3/yQAues2ss81LFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIHb8eAbhMdAFC265+VlcA3MQ2uo95VncA3MI2us/1Vd0B8G/MnG9rdisAb+XLGEBIdAFCogsQEl2AkOgChEQXIPQDiocPsbxd7+4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#feature map\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    " \n",
    "# normalizing the output\n",
    "def normalize_output(img):\n",
    "    img = img - img.min()\n",
    "    img = img / img.max()\n",
    "    return img\n",
    "\n",
    "image_path = '/data/tmpexec/ecg/test/9929-2.png' #V:Ventricular ectopic beat\n",
    "oriImg = cv2.imread(image_path)\n",
    "height, width, _ = oriImg.shape\n",
    "#plt.axis('off')\n",
    "#plt.imshow(oriImg)\n",
    "data = []\n",
    "oriImg = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))\n",
    "data.append(oriImg)\n",
    "data = torch.from_numpy(np.array(data)).type(torch.FloatTensor).cuda() \n",
    "\n",
    "activation = {}\n",
    "best_net.sa.register_forward_hook(get_activation('sa'))#spatial attention\n",
    "output = best_net(data.permute(0, 3, 1, 2))\n",
    "feature = activation['sa'].squeeze()\n",
    "feature_0 = feature[0].cpu().numpy()\n",
    "feature_0 = normalize_output(feature_0)\n",
    "feature_0 = np.uint8(255 * feature_0)\n",
    "#plot\n",
    "featuremap = cv2.applyColorMap(cv2.resize(feature_0,(width, height)), cv2.COLORMAP_JET)\n",
    "plt.axis('off')\n",
    "plt.imshow(featuremap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 / 20000 The length of train set is 20000\n",
      "20000 / 20000 The length of test set is 20000\n",
      "Completed buliding index in 3 seconds\n",
      "Accuracy: 0.745600\n",
      "[[11900   133  2069   739     5]\n",
      " [  737    24   172    11     0]\n",
      " [  633    31  2977   144     3]\n",
      " [  215     5   183    11     0]\n",
      " [    5     0     3     0     0]]\n",
      "Specificity: 0.801563\n",
      "Sensitivity of S: 0.025424\n",
      "Sensitivity of V: 0.785903\n",
      "Sensitivity of F: 0.026570\n",
      "Sensitivity of Q: 0.000000\n"
     ]
    }
   ],
   "source": [
    "#PHA\n",
    "def avhash(im): #Perceptual hash algorithm\n",
    "    if not isinstance(im, Image.Image):\n",
    "        im = Image.open(im)\n",
    "    im = im.resize((16, 16), Image.ANTIALIAS).convert('L')\n",
    "    avg = reduce(lambda x, y: x + y, im.getdata()) / 64.\n",
    "    return reduce(lambda x, yz: x | (yz[1] << yz[0]),\n",
    "                  enumerate(map(lambda i: 0 if i < avg else 1, im.getdata())),\n",
    "                  0)\n",
    "#read train image with CV\n",
    "train_dir = '/data/tmpexec/ecg/train' #the path of images\n",
    "trI, trY = [],[]\n",
    "for iname in os.listdir(train_dir):\n",
    "    if iname.endswith(\".png\"):\n",
    "        try:\n",
    "            image_path = os.path.join(train_dir, iname)\n",
    "            itype = int(os.path.splitext(iname)[0].split(\"-\")[1])\n",
    "            img = cv2.resize(cv2.imread(image_path,cv2.IMREAD_GRAYSCALE).astype(np.float32), (128, 128))\n",
    "            trI.append(img.flatten())\n",
    "            trY.append(itype)\n",
    "        except:\n",
    "            print(iname+\":\"+str(image_path))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(trY),20000))\n",
    "        sys.stdout.flush()\n",
    "print('The length of train set is %d'%len(trY))\n",
    "#read test image with CV\n",
    "test_dir = '/data/tmpexec/ecg/test' #the path of images\n",
    "teI, teY = [],[]\n",
    "for iname in os.listdir(test_dir):\n",
    "    if iname.endswith(\".png\"):\n",
    "        try:\n",
    "            image_path = os.path.join(test_dir, iname)\n",
    "            itype = int(os.path.splitext(iname)[0].split(\"-\")[1])\n",
    "            img = cv2.resize(cv2.imread(image_path,cv2.IMREAD_GRAYSCALE).astype(np.float32), (128, 128))\n",
    "            teI.append(img.flatten())\n",
    "            teY.append(itype)\n",
    "        except:\n",
    "            print(iname+\":\"+str(image_path))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(teY),20000))\n",
    "        sys.stdout.flush()\n",
    "print('The length of test set is %d'%len(teY))\n",
    "\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(128*128) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trI, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "#performance\n",
    "scores, neighbors = gpu_index.search(np.ascontiguousarray(teI, dtype=np.float32), k=1) #return top1\n",
    "y_pred = []\n",
    "for i in neighbors.flatten():\n",
    "    y_pred.append(np.array(trY)[i]) #label of top1\n",
    "print ( 'Accuracy: %.6f'%accuracy_score(teY, y_pred))\n",
    "#confusion matrix\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, y_pred, labels=labels ) #labels=['N','S','V','F','Q']\n",
    "print (cm)\n",
    "print ('Specificity: %.6f'%float(cm[0][0]/np.sum(cm[0])))\n",
    "print ('Sensitivity of S: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity of V: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity of F: %.6f'%float(cm[3][3]/np.sum(cm[3])))\n",
    "print ('Sensitivity of Q: %.6f'%float(cm[4][4]/np.sum(cm[4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of DS1 is: (20000,360)\n",
      "0    14846\n",
      "2     3788\n",
      "1      944\n",
      "3      414\n",
      "4        8\n",
      "Name: 1, dtype: int64\n",
      "The shape of DS2 is: (20000,360)\n",
      "0    14548\n",
      "2     3220\n",
      "1     1837\n",
      "3      388\n",
      "4        7\n",
      "Name: 1, dtype: int64\n",
      "Completed buliding index in 1 seconds\n",
      "Accuracy: 0.807300\n",
      "[[12802   419  1340   285     0]\n",
      " [  638   148   151     7     0]\n",
      " [  518    79  3158    33     0]\n",
      " [  277     1    98    38     0]\n",
      " [    6     0     2     0     0]]\n",
      "Specificity: 0.862320\n",
      "Sensitivity of S: 0.156780\n",
      "Sensitivity of V: 0.833685\n",
      "Sensitivity of F: 0.091787\n",
      "Sensitivity of Q: 0.000000\n"
     ]
    }
   ],
   "source": [
    "#Beats generation,\n",
    "#we defined a single ECG beat image by centering the Q-wave peak signal while\n",
    "#excluding the first and the last 20 ECG signals from the previous and afterward Q-wave peak signal\n",
    "#https://github.com/MIT-LCP/wfdb-python/blob/master/demo.ipynb\n",
    "#https://archive.physionet.org/physiobank/database/html/mitdbdir/mitdbdir.htm\n",
    "#http://www.tara.tcd.ie/bitstream/handle/2262/17623/automatic.pdf?sequence=1\n",
    "def labeltotext(val):\n",
    "    if val in ['N','L','R','e','j'] :\n",
    "        return 0 #N\n",
    "    elif val in ['A','a','J','S']:\n",
    "        return 1 #S\n",
    "    elif val in ['V','E']:\n",
    "        return 2 #V\n",
    "    elif val == 'F':\n",
    "        return 3 #F\n",
    "    elif val in ['/','f','Q']:\n",
    "        return 4 #Q\n",
    "    else: \n",
    "        pass\n",
    "    \n",
    "rootdir = '/data/fjsdata/physionet/MIT-BIH/mitdb/'\n",
    "right_len = 180 #right sample length around of peak value of QRS\n",
    "left_len = 180 #left sample length around of peak value of QRS\n",
    "#get trainset\n",
    "trData = [] #[QRS value, label]\n",
    "for bt in [101,106,108,109,112,114,115,116,118,119,122,124,201,203,205,207,208,209,215,220,223,230]:#22 records for train\n",
    "    file = os.path.join(rootdir,str(bt))\n",
    "    try:\n",
    "        annotation = wfdb.rdann(file, 'atr') \n",
    "        qrs_spl = annotation.sample #numpy.ndarray\n",
    "        qrs_sym = annotation.symbol #list\n",
    "        record = wfdb.rdrecord(file)\n",
    "        signal = record.p_signal #numpy.ndarray\n",
    "        max_len = record.sig_len #length of samples\n",
    "        lead_name =  record.sig_name #names of lead channels,list\n",
    "        for i in range(annotation.ann_len):\n",
    "            if qrs_sym[i] in ['N','L','R','e','j','A','a','J','S','V','E','F','/','f','Q']:#seven diseases samples\n",
    "                pos = qrs_spl[i] #corresponding position of peak value of QRS\n",
    "                if pos+right_len<=max_len and pos-left_len>=0:\n",
    "                    max_idx = pos+right_len#np.min([max_len, pos+trunc_len])\n",
    "                    min_idx = pos-left_len#np.max([0, pos-trunc_len])\n",
    "                    QRS_value = signal[:,0][min_idx:max_idx] #only one lead\n",
    "                    trData.append([QRS_value,labeltotext(qrs_sym[i])])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "NOR = 14846 #normal samples    \n",
    "trData = pd.DataFrame(np.array(trData))\n",
    "NData =  trData[trData[1]==0].sample(n=NOR, random_state=1)\n",
    "UNData = trData[trData[1]!=0]\n",
    "trData = pd.concat([NData,UNData],axis=0).sample(frac=1) #shuffle\n",
    "X_DS1 = pd.DataFrame(trData[0].values.tolist())\n",
    "y_DS1 = trData[1]\n",
    "print('The shape of DS1 is: (%d,%d)'%(X_DS1.shape[0],X_DS1.shape[1]))\n",
    "print(trData[1].value_counts())\n",
    "\n",
    "#get testset\n",
    "teData = [] #[QRS value, label]\n",
    "for bt in [100,103,105,111,113,117,121,123,200,202,210,212,213,214,219,221,222,228,231,232,233,234]:#22 records for test\n",
    "    file = os.path.join(rootdir,str(bt))\n",
    "    try:\n",
    "        annotation = wfdb.rdann(file, 'atr') \n",
    "        qrs_spl = annotation.sample #numpy.ndarray\n",
    "        qrs_sym = annotation.symbol #list\n",
    "        record = wfdb.rdrecord(file)\n",
    "        signal = record.p_signal #numpy.ndarray\n",
    "        max_len = record.sig_len #length of samples\n",
    "        lead_name =  record.sig_name #names of lead channels,list\n",
    "        for i in range(annotation.ann_len):\n",
    "            if qrs_sym[i] in ['N','L','R','e','j','A','a','J','S','V','E','F','/','f','Q']:#seven diseases samples\n",
    "                pos = qrs_spl[i] #corresponding position of peak value of QRS\n",
    "                if pos+right_len<=max_len and pos-left_len>=0:\n",
    "                    max_idx = pos+right_len#np.min([max_len, pos+trunc_len])\n",
    "                    min_idx = pos-left_len#np.max([0, pos-trunc_len])\n",
    "                    QRS_value = signal[:,0][min_idx:max_idx] #only one lead\n",
    "                    teData.append([QRS_value,labeltotext(qrs_sym[i])])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "NOR = 14548 #normal samples    \n",
    "teData = pd.DataFrame(np.array(teData))\n",
    "NData =  teData[teData[1]==0].sample(n=NOR, random_state=1)\n",
    "UNData = teData[teData[1]!=0]\n",
    "teData = pd.concat([NData,UNData],axis=0).sample(frac=1) #shuffle\n",
    "X_DS2 = pd.DataFrame(teData[0].values.tolist())\n",
    "y_DS2 = teData[1]\n",
    "print('The shape of DS2 is: (%d,%d)'%(X_DS2.shape[0],X_DS2.shape[1]))\n",
    "print(teData[1].value_counts())\n",
    "\n",
    "#model: faiss+index\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(right_len+left_len) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(X_DS2, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "#performance\n",
    "scores, neighbors = gpu_index.search(np.ascontiguousarray(X_DS1, dtype=np.float32), k=1) #return top1\n",
    "y_pred = []\n",
    "for i in neighbors.flatten():\n",
    "    y_pred.append(np.array(y_DS2)[i]) #label of top1\n",
    "print ( 'Accuracy: %.6f'%accuracy_score(y_DS1.tolist(), y_pred))\n",
    "#confusion matrix\n",
    "labels = list(set(y_DS1))\n",
    "cm = confusion_matrix(y_DS1.tolist(), y_pred, labels=labels ) #labels=['N','S','V','F','Q']\n",
    "print (cm)\n",
    "print ('Specificity: %.6f'%float(cm[0][0]/np.sum(cm[0])))\n",
    "print ('Sensitivity of S: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity of V: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity of F: %.6f'%float(cm[3][3]/np.sum(cm[3])))\n",
    "print ('Sensitivity of Q: %.6f'%float(cm[4][4]/np.sum(cm[4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19999 / 20000 "
     ]
    }
   ],
   "source": [
    "#import ecg_plot#pip install ecg_plot, https://pypi.org/project/ecg-plot/\n",
    "#from scipy.misc import electrocardiogram \n",
    "#https://docs.scipy.org/doc/scipy/reference/generated/scipy.misc.electrocardiogram.html\n",
    "fs = 360\n",
    "for idx,row in X_DS2.iterrows():\n",
    "    label = np.array(y_DS2)[idx]\n",
    "    svpath = os.path.join('/data/tmpexec/ecg/train',str(idx)+'-'+str(label))\n",
    "    ecg = np.array(row)\n",
    "    time = np.arange(ecg.size) / fs\n",
    "    plt.figure(figsize=(5,3))\n",
    "    plt.plot(time, ecg)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(svpath,dpi=100) #(500=5*100,300=3*100)\n",
    "    plt.close()\n",
    "    sys.stdout.write('\\r{} / {} '.format(idx,X_DS2.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "for idx,row in X_DS1.iterrows():\n",
    "    label = np.array(y_DS1)[idx]\n",
    "    svpath = os.path.join('/data/tmpexec/ecg/test',str(idx)+'-'+str(label))\n",
    "    ecg = np.array(row)\n",
    "    time = np.arange(ecg.size) / fs\n",
    "    plt.figure(figsize=(5,3))\n",
    "    plt.plot(time, ecg)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(svpath,dpi=100) #(500=5*100,300=3*100)\n",
    "    plt.close()\n",
    "    sys.stdout.write('\\r{} / {} '.format(idx,X_DS1.shape[0]))\n",
    "    sys.stdout.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
