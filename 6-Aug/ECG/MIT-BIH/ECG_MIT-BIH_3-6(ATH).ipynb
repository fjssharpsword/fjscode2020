{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading faiss with AVX2 support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import itertools  \n",
    "from PIL import Image\n",
    "from io import StringIO,BytesIO \n",
    "from scipy.spatial.distance import pdist\n",
    "import cv2\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc \n",
    "from functools import reduce\n",
    "import wfdb#https://github.com/MIT-LCP/wfdb-python\n",
    "from wfdb import processing\n",
    "import faiss \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "torch.cuda.set_device(0)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 / 20000 The length of train set is 20000\n",
      "20000 / 20000 The length of test set is 20000\n"
     ]
    }
   ],
   "source": [
    "#read train image with CV\n",
    "train_dir = '/data/tmpexec/ecg/train' #the path of images\n",
    "trI, trY = [],[]\n",
    "for iname in os.listdir(train_dir):\n",
    "    if iname.endswith(\".png\"):\n",
    "        try:\n",
    "            image_path = os.path.join(train_dir, iname)\n",
    "            itype = int(os.path.splitext(iname)[0].split(\"-\")[1])\n",
    "            img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(500,300,3)->(256,256,3)\n",
    "            trI.append(img)\n",
    "            trY.append(itype)\n",
    "        except:\n",
    "            print(iname+\":\"+str(image_path))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(trY),20000))\n",
    "        sys.stdout.flush()\n",
    "print('The length of train set is %d'%len(trY))\n",
    "#read test image with CV\n",
    "test_dir = '/data/tmpexec/ecg/test' #the path of images\n",
    "teI, teY = [],[]\n",
    "for iname in os.listdir(test_dir):\n",
    "    if iname.endswith(\".png\"):\n",
    "        try:\n",
    "            image_path = os.path.join(test_dir, iname)\n",
    "            itype = int(os.path.splitext(iname)[0].split(\"-\")[1])\n",
    "            img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(500,300,3)->(256,256,3)\n",
    "            teI.append(img)\n",
    "            teY.append(itype)\n",
    "        except:\n",
    "            print(iname+\":\"+str(image_path))\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(teY),20000))\n",
    "        sys.stdout.flush()\n",
    "print('The length of test set is %d'%len(teY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 / 20000 "
     ]
    }
   ],
   "source": [
    "#Generate image pairs for model\n",
    "def onlineGenImgPairs( ):\n",
    "    idx_sf = []\n",
    "    idx_0 = np.where( np.array(trY) == 0 ) #class 0\n",
    "    idx_0 = list(idx_0[0])\n",
    "    idx_sf.extend(idx_0)\n",
    "    idx_1 = np.where( np.array(trY) == 1 ) #class 1\n",
    "    idx_1 = list(idx_1[0])\n",
    "    idx_sf.extend(idx_1)\n",
    "    idx_2 = np.where( np.array(trY) == 2 ) #class 2\n",
    "    idx_2 = list(idx_2[0])\n",
    "    idx_sf.extend(idx_2)\n",
    "    idx_3 = np.where( np.array(trY) == 3 ) #class 3\n",
    "    idx_3 = list(idx_3[0])\n",
    "    idx_sf.extend(idx_3)\n",
    "    idx_4 = np.where( np.array(trY) == 4 ) #class 4\n",
    "    idx_4 = list(idx_4[0])\n",
    "    idx_sf.extend(idx_4)\n",
    "    random.shuffle(idx_sf)   \n",
    "    trQ_sf, trP_sf, trN_sf = [], [], []\n",
    "    for iQ in idx_sf:\n",
    "        trQ_sf.append(trI[iQ])\n",
    "        if trY[iQ] == 0:\n",
    "            idx_tmp = idx_0.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_0))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "        elif trY[iQ] == 1:\n",
    "            idx_tmp = idx_1.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_1))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "        elif trY[iQ] == 2:\n",
    "            idx_tmp = idx_2.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_2))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "        elif trY[iQ] == 3:\n",
    "            idx_tmp = idx_3.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_3))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "        elif trY[iQ] == 4:\n",
    "            idx_tmp = idx_4.copy()\n",
    "            idx_tmp.remove(iQ)\n",
    "            iP =  random.sample(idx_tmp,1) #remove self,then get one positive sample\n",
    "            trP_sf.append(trI[iP[0]])\n",
    "            idx_sf_tmp = list(set(idx_sf) - set(idx_4))\n",
    "            iN =  random.sample(idx_sf_tmp,1) #remove positive and get one negative sample\n",
    "            trN_sf.append(trI[iN[0]])\n",
    "        else: pass\n",
    "        sys.stdout.write('\\r{} / {} '.format(len(trQ_sf),20000))\n",
    "        sys.stdout.flush()\n",
    "    return np.array(trQ_sf),np.array(trP_sf),np.array(trN_sf)\n",
    "trQ_sf, trP_sf, trN_sf = onlineGenImgPairs() #sample \n",
    "assert (trQ_sf.shape==trP_sf.shape)\n",
    "assert (trQ_sf.shape==trN_sf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttention(nn.Module):#spatial attention layer\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels, out_channels=out_channels,\n",
    "                kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        self.downsample_layer = None\n",
    "        self.do_downsample = False\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.do_downsample = True\n",
    "            self.downsample_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.net(x)\n",
    "\n",
    "        if self.do_downsample:\n",
    "            identity = self.downsample_layer(x)\n",
    "\n",
    "        return F.relu(out + identity, inplace=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            \n",
    "class ASHNet(nn.Module):\n",
    "    def __init__(self, hash_size: int, class_size:int):\n",
    "        super().__init__()\n",
    "        #Resnet\n",
    "        self.net = nn.Sequential(\n",
    "            ResBlock(in_channels=3, out_channels=16),\n",
    "            ResBlock(in_channels=16, out_channels=16),\n",
    "            ResBlock(in_channels=16, out_channels=16, stride=2),\n",
    "        ) \n",
    "        #Attention \n",
    "        self.sa = SpatialAttention() \n",
    "        #fully connected\n",
    "        self.hash = nn.Sequential(\n",
    "            nn.Linear(16*128*128, hash_size),\n",
    "            nn.ReLU(inplace=True)\n",
    "            #nn.Sigmoid()\n",
    "            #nn.Tanh()\n",
    "        )\n",
    "        self.classes = nn.Linear(hash_size, class_size)\n",
    "        \n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = self.sa(x)*x\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x_hash = self.hash(x)\n",
    "        x_class = self.classes(x_hash)\n",
    "        return x_hash,x_class\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "#https://github.com/clcarwin/focal_loss_pytorch/blob/master/focalloss.py   \n",
    "class FocalLoss(nn.Module):\n",
    "    #Loss(x, class) = - \\alpha (1-softmax(x)[class])^gamma \\log(softmax(x)[class])\n",
    "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n",
    "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, out, y):\n",
    "        y = y.view(-1,1)\n",
    "        logpt = F.log_softmax(out,dim=1)#default ,dim=1\n",
    "        logpt = logpt.gather(1,y)# dim=1, index=y, max\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = Variable(logpt.data.exp())\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type()!=out.data.type():\n",
    "                self.alpha = self.alpha.type_as(out.data)\n",
    "            at = self.alpha.gather(0,y.data.view(-1))\n",
    "            logpt = logpt * Variable(at)\n",
    "\n",
    "        loss = -1 * (1-pt)**self.gamma * logpt\n",
    "        if self.size_average: return loss.mean()\n",
    "        else: return loss.sum()\n",
    "        \n",
    "#https://github.com/luyajie/triplet-deep-hash-pytorch#triplet-deep-hash-pytorch            \n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=0.5):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin #margin threshold\n",
    "        self.mse_loss = nn.MSELoss(reduction='none')\n",
    "    \n",
    "    def forward(self,H_q,H_p,H_n):    \n",
    "        margin_val = self.margin * H_q.shape[1]\n",
    "        squared_loss_pos = torch.mean(self.mse_loss(H_q, H_p), dim=1)\n",
    "        squared_loss_neg = torch.mean(self.mse_loss(H_q, H_n), dim=1)\n",
    "        zeros = torch.zeros_like(squared_loss_neg)\n",
    "        loss  = torch.max(zeros, margin_val - squared_loss_neg + squared_loss_pos)\n",
    "        return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2000 / 2000 : loss = 0.014966Eopch:     1 mean_loss = 0.089737\n",
      " 2000 / 2000 : loss = 0.003948Eopch:     2 mean_loss = 0.021633\n",
      " 2000 / 2000 : loss = 0.028069Eopch:     3 mean_loss = 0.010420\n",
      " 2000 / 2000 : loss = 0.000411Eopch:     4 mean_loss = 0.008388\n",
      " 2000 / 2000 : loss = 5.6e-054Eopch:     5 mean_loss = 0.004036\n",
      " 2000 / 2000 : loss = 0.013773Eopch:     6 mean_loss = 0.003952\n",
      " 2000 / 2000 : loss = 5.5e-051Eopch:     7 mean_loss = 0.003601\n",
      " 2000 / 2000 : loss = 2e-06164Eopch:     8 mean_loss = 0.001086\n",
      " 2000 / 2000 : loss = 0.000394Eopch:     9 mean_loss = 0.004103\n",
      " 2000 / 2000 : loss = 1.4e-057Eopch:    10 mean_loss = 0.001012\n",
      "best_loss = 0.001012\n",
      " 2000 / 2000 : loss = 0.0194866Eopch:     1 mean_loss = 0.633161\n",
      " 2000 / 2000 : loss = 0.1601597Eopch:     2 mean_loss = 0.085518\n",
      " 2000 / 2000 : loss = 0.0639379Eopch:     3 mean_loss = 0.067639\n",
      " 2000 / 2000 : loss = 0.044612Eopch:     4 mean_loss = 0.086150\n",
      " 2000 / 2000 : loss = 0.066019Eopch:     5 mean_loss = 0.038407\n",
      " 2000 / 2000 : loss = 0.0392072Eopch:     6 mean_loss = 0.067139\n",
      " 2000 / 2000 : loss = 0.0578345Eopch:     7 mean_loss = 0.049909\n",
      " 2000 / 2000 : loss = 0.018658Eopch:     8 mean_loss = 0.037405\n",
      " 2000 / 2000 : loss = 0.058536Eopch:     9 mean_loss = 0.020239\n",
      " 2000 / 2000 : loss = 0.0077557Eopch:    10 mean_loss = 0.089335\n",
      "best_loss = 0.020239\n"
     ]
    }
   ],
   "source": [
    "#define model\n",
    "model = ASHNet(hash_size=36, class_size=5).cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "\n",
    "#define FocalLoss gamma=[0,0.5,1,2,5] alpha=[0.25,0.25,0.25,0.25,0.25]\n",
    "criterion  = FocalLoss(gamma=2).cuda() \n",
    "#train model with focal loss\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(10):#iteration\n",
    "    losses = []\n",
    "    num_batches = len(trY) // batchSize\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY), (i+1)*batchSize])\n",
    "        X_batch = torch.from_numpy(np.array(trI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "        y_batch = torch.from_numpy(np.array(trY[min_idx:max_idx])).type(torch.LongTensor).cuda()\n",
    "        #forword\n",
    "        _, out_class = model(X_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        #binary-like loss\n",
    "        loss = criterion(out_class, y_batch) #F.log_softmax+F.nll_loss\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "\n",
    "#train model with triplet loss\n",
    "criterion  = TripletLoss(margin=0.5).cuda() #define pairwise loss\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(10):#iteration\n",
    "    losses = []\n",
    "    num_batches = len(trQ_sf) // batchSize\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trQ_sf), (i+1)*batchSize])\n",
    "        Q_batch = torch.from_numpy(trQ_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        P_batch = torch.from_numpy(trP_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        N_batch = torch.from_numpy(trN_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        #forword\n",
    "        Q_hash, _ = model(Q_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        P_hash, _ = model(P_batch.permute(0, 3, 1, 2))\n",
    "        N_hash, _ = model(N_batch.permute(0, 3, 1, 2))\n",
    "        #binary-like loss\n",
    "        loss = criterion(Q_hash,P_hash,N_hash)\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1999 / 2000 Completed buliding index in 1 seconds\n",
      "Accuracy: 0.773350\n",
      "[[11757   239  2781    69     0]\n",
      " [  403   305   235     1     0]\n",
      " [  343    35  3401     9     0]\n",
      " [  335     0    75     4     0]\n",
      " [    4     0     4     0     0]]\n",
      "Specificity: 0.791930\n",
      "Sensitivity of S: 0.323093\n",
      "Sensitivity of V: 0.897835\n",
      "Sensitivity of F: 0.009662\n",
      "Sensitivity of Q: 0.000000\n",
      " 1999 / 2000 Accuracy: 0.691900\n",
      "[[10143  2066  2577    60     0]\n",
      " [  238   510   196     0     0]\n",
      " [  310   286  3183     9     0]\n",
      " [  338    11    63     2     0]\n",
      " [    4     0     4     0     0]]\n",
      "Specificity: 0.683214\n",
      "Sensitivity of S: 0.540254\n",
      "Sensitivity of V: 0.840285\n",
      "Sensitivity of F: 0.004831\n",
      "Sensitivity of Q: 0.000000\n"
     ]
    }
   ],
   "source": [
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "criterion=criterion.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "#hash code of train data from model\n",
    "#torch.cuda.synchronize()\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize\n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_hash, _ = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_hash = X_hash.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_hash.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#hash code of test data from model\n",
    "#torch.cuda.synchronize()\n",
    "teF = []\n",
    "num_batches = len(teI) // batchSize \n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(teI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_hash, _ = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_hash = X_hash.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    teF.extend(X_hash.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "#performance with hash\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(36) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "#performance\n",
    "scores, neighbors = gpu_index.search(np.ascontiguousarray(teF, dtype=np.float32), k=1) #return top1\n",
    "y_pred = []\n",
    "for i in neighbors.flatten():\n",
    "    y_pred.append(np.array(trY)[i]) #label of top1\n",
    "print ( 'Accuracy: %.6f'%accuracy_score(teY, y_pred))\n",
    "#confusion matrix\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, y_pred, labels=labels ) #labels=['N','S','V','F','Q']\n",
    "print (cm)\n",
    "print ('Specificity: %.6f'%float(cm[0][0]/np.sum(cm[0])))\n",
    "print ('Sensitivity of S: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity of V: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity of F: %.6f'%float(cm[3][3]/np.sum(cm[3])))\n",
    "print ('Sensitivity of Q: %.6f'%float(cm[4][4]/np.sum(cm[4])))\n",
    "\n",
    "#performance with class\n",
    "teY_pred = []\n",
    "teF = [] \n",
    "num_batches = len(teY) // batchSize \n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teY), (i+1)*batchSize])\n",
    "    X_batch = torch.from_numpy(np.array(teI[min_idx:max_idx])).type(torch.FloatTensor).cuda()\n",
    "    _, out_class = best_net(X_batch.permute(0, 3, 1, 2))#forword\n",
    "    teF.extend(out_class.cpu().data.numpy().tolist()) #record feature\n",
    "    out_class = F.log_softmax(out_class,dim=1) \n",
    "    pred = out_class.max(1,keepdim=True)[1]\n",
    "    teY_pred.extend(pred.cpu().data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "#confusion matrix\n",
    "print ( 'Accuracy: %.6f'%accuracy_score(teY, teY_pred))\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, teY_pred, labels=labels ) #labels=['N','S','V','F','Q']\n",
    "print (cm)\n",
    "print ('Specificity: %.6f'%float(cm[0][0]/np.sum(cm[0])))\n",
    "print ('Sensitivity of S: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "print ('Sensitivity of V: %.6f'%float(cm[2][2]/np.sum(cm[2])))\n",
    "print ('Sensitivity of F: %.6f'%float(cm[3][3]/np.sum(cm[3])))\n",
    "print ('Sensitivity of Q: %.6f'%float(cm[4][4]/np.sum(cm[4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Org data dimension is 5.Embedded data dimension is 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize : t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import random\n",
    "def scatter(X, y):\n",
    "    #X,y:numpy-array\n",
    "    classes = len(list(set(y.tolist())))#get number of classes\n",
    "    #palette = np.array(sns.color_palette(\"hls\", classes))# choose a color palette with seaborn.\n",
    "    color = ['c','y','m','b','g','r']\n",
    "    marker = ['o','x','+','*','s']\n",
    "    plt.figure(figsize=(8,8))#create a plot\n",
    "    for i in range(classes):\n",
    "        plt.scatter(X[y == i,0], X[y == i,1], c=color[i], marker=marker[i], label=str(i))\n",
    "    plt.axis('off')\n",
    "    plt.legend(loc='upper left')\n",
    "    #plt.savefig('digits_tsne-generated.png', dpi=100)\n",
    "    plt.show()\n",
    "\n",
    "#prepare dataï¼Œclasses=5\n",
    "#idx= random.sample(np.where(np.array(teY)==0)[0].tolist(),100)\n",
    "idx= np.where(np.array(teY)==0)[0].tolist()[0:100]\n",
    "X0= np.array(teF)[idx]\n",
    "y0= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==1)[0].tolist()[0:100]\n",
    "X1= np.array(teF)[idx]\n",
    "y1= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==2)[0].tolist()[0:100]\n",
    "X2= np.array(teF)[idx]\n",
    "y2= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==3)[0].tolist()[0:100]\n",
    "X3= np.array(teF)[idx]\n",
    "y3= np.array(teY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==4)[0].tolist()\n",
    "X4= np.array(teF)[idx]\n",
    "y4= np.array(teY)[idx]\n",
    "\n",
    "y = np.append(y0,y1)\n",
    "y = np.append(y,y2)\n",
    "y = np.append(y,y3)\n",
    "y = np.append(y,y4)\n",
    "X = np.vstack((X0,X1))\n",
    "X = np.vstack((X,X2))\n",
    "X = np.vstack((X,X3))\n",
    "X = np.vstack((X,X4))\n",
    "#training t-sne \n",
    "tsne = TSNE(n_components=2, init='pca', random_state=501)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "print(\"Org data dimension is {}.Embedded data dimension is {}\".format(X.shape[-1], X_tsne.shape[-1]))\n",
    "\n",
    "#visualize\n",
    "scatter(X_tsne, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5fc42d9150>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADXCAYAAAC51IK9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAADeUlEQVR4nO3bwUldQRSA4Ts+twHFhaVZhiWENJA6LMKGsggJupaxAd/Ak8sveL9vezZn9TMMM2POuQHQuPrqBQCORHQBQqILEBJdgJDoAoREFyB0vRqO8ct7MoALzflznJsto/t7vuy/DcCBjdXniD9jOOkCXOh+zs+ddJ/23wXg23tczJbRvdl5EYCjW14vvLleALjYaXG94MkYQGh5vXCqtgA4CCddgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugCh69XwrdoC4Bs5LWbL6P7feRGAI7hbzJbRfd55EYAjeFjMxpzz7PDfdnd+CMCHbre/49xsGd3xYxNdgAvN1+1z0QVgX56MAYREFyAkugAh0QUIiS5ASHQBQu9/gSxmHpbq3QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#feature map\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    " \n",
    "# normalizing the output\n",
    "def normalize_output(img):\n",
    "    img = img - img.min()\n",
    "    img = img / img.max()\n",
    "    return img\n",
    "\n",
    "image_path = '/data/tmpexec/ecg/test/9929-2.png' #V:Ventricular ectopic beat\n",
    "oriImg = cv2.imread(image_path)\n",
    "height, width, _ = oriImg.shape\n",
    "#plt.axis('off')\n",
    "#plt.imshow(oriImg)\n",
    "data = []\n",
    "oriImg = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))\n",
    "data.append(oriImg)\n",
    "data = torch.from_numpy(np.array(data)).type(torch.FloatTensor).cuda() \n",
    "\n",
    "activation = {}\n",
    "best_net.sa.register_forward_hook(get_activation('sa'))#spatial attention\n",
    "output = best_net(data.permute(0, 3, 1, 2))\n",
    "feature = activation['sa'].squeeze()\n",
    "feature_0 = feature[0].cpu().numpy()\n",
    "feature_0 = normalize_output(feature_0)\n",
    "feature_0 = np.uint8(255 * feature_0)\n",
    "#plot\n",
    "featuremap = cv2.applyColorMap(cv2.resize(feature_0,(width, height)), cv2.COLORMAP_JET)\n",
    "plt.axis('off')\n",
    "plt.imshow(featuremap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1999 / 2000 Completed buliding index in 24 seconds\n",
      "mHR@5=0.767000, mAP@5=0.755568, mRR@5=0.969637\n",
      "mHR@10=0.767155, mAP@10=0.752808, mRR@10=0.959251\n",
      "mHR@15=0.766840, mAP@15=0.751467, mRR@15=0.952275\n",
      "mHR@20=0.766660, mAP@20=0.750577, mRR@20=0.948231\n",
      " 1999 / 2000 Accuracy: 0.619650\n",
      "[[8303 1254 4892  397    0]\n",
      " [ 149  350  430   15    0]\n",
      " [  26   10 3687   65    0]\n",
      " [ 165    8  188   53    0]\n",
      " [   0    2    6    0    0]]\n",
      "Specificity: 0.559275\n",
      "Sensitivity of S: 0.370763\n",
      "Sensitivity of V: 0.973337\n",
      "Sensitivity of F: 0.128019\n",
      "Sensitivity of Q: 0.000000\n"
     ]
    }
   ],
   "source": [
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "criterion=criterion.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "#hash code of train data from model\n",
    "#torch.cuda.synchronize()\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize\n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_hash, _ = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_hash = X_hash.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_hash.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#hash code of test data from model\n",
    "#torch.cuda.synchronize()\n",
    "teF = []\n",
    "num_batches = len(teI) // batchSize \n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(teI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_hash, _ = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_hash = X_hash.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    teF.extend(X_hash.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "#performance with hash\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(36) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "#performance\n",
    "for topk in [10]:#[5,10,15,20]:\n",
    "    MHR = [] #mean Hit ratio \n",
    "    MAP = [] #mean average precision\n",
    "    MRR = [] #mean reciprocal rank\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        scores, neighbors = gpu_index.search(np.array(teF)[i:i+1].astype('float32'), k=topk)\n",
    "        #map_item_score = {}\n",
    "        #for j, trVal in enumerate(trF):\n",
    "        #    map_item_score[j] = pdist(np.vstack([teVal,trVal]),'hamming')\n",
    "        #ranklist = heapq.nsmallest(topk, map_item_score, key=map_item_score.get)\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        mrr_flag = 0\n",
    "        #for j in ranklist:\n",
    "        for j in neighbors.flatten():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                MHR.append(1)\n",
    "                pos_len = pos_len +1\n",
    "                MAP.append(pos_len/rank_len) \n",
    "                if mrr_flag==0: \n",
    "                    MRR.append(pos_len/rank_len)\n",
    "                    mrr_flag =1\n",
    "            else: \n",
    "                MHR.append(0)\n",
    "                MAP.append(0)   \n",
    "    print(\"mHR@{}={:.6f}, mAP@{}={:.6f}, mRR@{}={:.6f}\".format(topk,np.mean(MHR),topk,np.mean(MAP), topk, np.mean(MRR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.000080108642578\n",
      "net.0.net.0.weight\n",
      "tensor([0.1009, 0.1183, 0.0598], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "17.973249435424805\n",
      "net.0.net.0.weight\n",
      "tensor([0.1016, 0.1175, 0.0605], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "17.716821670532227\n",
      "net.0.net.0.weight\n",
      "tensor([0.1024, 0.1167, 0.0607], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "17.584300994873047\n",
      "net.0.net.0.weight\n",
      "tensor([0.1027, 0.1160, 0.0608], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "17.504169464111328\n",
      "net.0.net.0.weight\n",
      "tensor([0.1026, 0.1154, 0.0610], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "17.44349479675293\n",
      "net.0.net.0.weight\n",
      "tensor([0.1025, 0.1150, 0.0611], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "17.424943923950195\n",
      "net.0.net.0.weight\n",
      "tensor([0.1025, 0.1145, 0.0611], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "17.4094181060791\n",
      "net.0.net.0.weight\n",
      "tensor([0.1024, 0.1139, 0.0610], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "17.38896369934082\n",
      "net.0.net.0.weight\n",
      "tensor([0.1023, 0.1132, 0.0609], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "17.37741470336914\n",
      "net.0.net.0.weight\n",
      "tensor([0.1020, 0.1127, 0.0609], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "torch.Size([10, 36])\n"
     ]
    }
   ],
   "source": [
    "#test network: valid\n",
    "xq = torch.rand(10,3,256,256).cuda()\n",
    "xp = torch.rand(10,3,256,256).cuda()\n",
    "xn = torch.rand(10,3,256,256).cuda()\n",
    "model = ASHNet(hash_size=36, class_size=5).cuda()#initialize model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "criterion  = TripletLoss(margin=0.5).cuda() #define pairwise loss\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    outq,_ = model(xq)#out.grad_fn\n",
    "    outp,_ = model(xp)\n",
    "    outn,_ = model(xn)\n",
    "    loss = criterion(outq,outp,outn)\n",
    "    print (loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #observe the variant of model.parameters\n",
    "    for i in model.named_parameters():\n",
    "        print(i[0])\n",
    "        print(i[1][0][0][0])\n",
    "        break\n",
    "#output\n",
    "x = torch.rand(10,3,256,256).cuda()\n",
    "out,_ = model(x)\n",
    "#out = torch.sign(out) #Binarization,[-1,1]->{-1,1}\n",
    "print (out.size())\n",
    "x = x.cpu()\n",
    "xq = xq.cpu()\n",
    "xp = xp.cpu()\n",
    "xn = xn.cpu()\n",
    "model = model.cpu()\n",
    "criterion = criterion.cpu()\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
