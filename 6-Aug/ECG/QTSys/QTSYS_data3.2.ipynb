{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading faiss with AVX2 support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import copy\n",
    "import gc\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import shutil\n",
    "from functools import reduce\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc \n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import faiss \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import baostock as bs#pip install baostock\n",
    "import mplfinance as mpf #pip install mplfinance\n",
    "from matplotlib.pylab import date2num\n",
    "import tushare as ts # pip install tushare\n",
    "tstoken='2621bdfffbde695d0d256a69a71d9344c94c1d8a58f389cd391ceeeb' #youer token\n",
    "ts.set_token(tstoken)\n",
    "pro = ts.pro_api()\n",
    "torch.cuda.set_device(6)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.Training model and output database(faiss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3)\n"
     ]
    }
   ],
   "source": [
    "root_dir = '/data/fjsdata/qtsys/img/' #the path of images\n",
    "data = pd.read_csv('/data/fjsdata/qtsys/label.csv') \n",
    "print(data.shape)\n",
    "#name = []\n",
    "#for idx, row in data.iterrows():\n",
    "#    if '20200328' in row['name']:\n",
    "#        if os.path.exists(root_dir+row['name']):\n",
    "#            shutil.copyfile( root_dir+row['name'], '/data/tmpexec/qtsysimg0328/'+row['name'])  \n",
    "#            name.append(row['name'])\n",
    "#print(len(name))\n",
    "\n",
    "#data['flag'] = data['flag'].fillna('Y')\n",
    "#data.to_csv('/data/fjsdata/qtsys/label.csv',index=False)\n",
    "#data_n = data[data['flag']=='N']\n",
    "#data_y = data[data['flag']=='Y']\n",
    "#print(data_n.shape)\n",
    "#print(data_y.shape)\n",
    "#for idx, row in data_n.iterrows():\n",
    "#    os.remove(root_dir+row['name']) #remove file\n",
    "#data_y.to_csv('/data/fjsdata/qtsys/label.csv',index=False)\n",
    "\n",
    "#for idx, row in data.iterrows():\n",
    "#    if '20200327' in row['name']:\n",
    "#        if os.path.exists(root_dir+row['name']):\n",
    "#            os.remove(root_dir+row['name']) #remove file\n",
    "#        data = data.drop(idx)\n",
    "#print(data.shape)\n",
    "#data.to_csv('/data/fjsdata/qtsys/label.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model: ATH\n",
    "class SpatialAttention(nn.Module):#spatial attention layer\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels, out_channels=out_channels,\n",
    "                kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        self.downsample_layer = None\n",
    "        self.do_downsample = False\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.do_downsample = True\n",
    "            self.downsample_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.net(x)\n",
    "\n",
    "        if self.do_downsample:\n",
    "            identity = self.downsample_layer(x)\n",
    "\n",
    "        return F.relu(out + identity, inplace=True) #resnet\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            \n",
    "class ATHNet(nn.Module):\n",
    "    def __init__(self, code_size: int):\n",
    "        super().__init__()\n",
    "        #resnet and maxpool\n",
    "        self.net1 = nn.Sequential(#(3,256,256)->(16,128,128)\n",
    "            ResBlock(in_channels=3, out_channels=16, stride=2), \n",
    "            nn.MaxPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        )\n",
    "        \n",
    "        #Attention (16,128,128)->(16,128,128)\n",
    "        self.sa = SpatialAttention()\n",
    "        \n",
    "        #resnet and meanpool\n",
    "        self.net2 =nn.Sequential( #(16,128,128)->(8,64,64)\n",
    "            ResBlock(in_channels=16, out_channels=8, stride=2),\n",
    "            nn.AvgPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        ) \n",
    "         \n",
    "        #fully connected with conv (8,64,64)->(1,32,32)\n",
    "        self.dense=ResBlock(in_channels=8, out_channels=1, stride=2)\n",
    "        #fully connected (1,32,32)->class_size\n",
    "        self.linear = nn.Linear(1*32*32, code_size)\n",
    "    \n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net1(x)\n",
    "        x = self.sa(x)*x\n",
    "        x = self.net2(x)\n",
    "        x = self.dense(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "#define loss function:pairwise loss            \n",
    "class PairwiseLoss(nn.Module):\n",
    "    def __init__(self, margin=0.5, alpha=0.01):\n",
    "        super(PairwiseLoss, self).__init__()\n",
    "        self.alpha = alpha #regularization\n",
    "        self.margin = margin #margin threshold\n",
    "        self.mse_loss = nn.MSELoss(reduction='none')\n",
    "        self.l1_loss = nn.L1Loss(reduction='mean')\n",
    "    \n",
    "    def forward(self,h1,h2,y):    \n",
    "        margin_val = self.margin * h1.shape[1]\n",
    "        squared_loss = torch.mean(self.mse_loss(h1, h2), dim=1)\n",
    "        # T1: 0.5 * (1 - y) * dist(x1, x2)\n",
    "        positive_pair_loss = (0.5 * (1 - y) * squared_loss)\n",
    "        mean_positive_pair_loss = torch.mean(positive_pair_loss)\n",
    "        # T2: 0.5 * y * max(margin - dist(x1, x2), 0)\n",
    "        zeros = torch.zeros_like(squared_loss)\n",
    "        marginMat = margin_val * torch.ones_like(squared_loss)\n",
    "        negative_pair_loss = 0.5 * y * torch.max(zeros, marginMat - squared_loss)\n",
    "        mean_negative_pair_loss = torch.mean(negative_pair_loss)\n",
    "\n",
    "        # T3: alpha(dst_l1(abs(x1), 1)) + dist_l1(abs(x2), 1)))\n",
    "        mean_value_regularization = self.alpha * (\n",
    "                self.l1_loss(torch.abs(h1), torch.ones_like(h1)) +\n",
    "                self.l1_loss(torch.abs(h2), torch.ones_like(h2)))\n",
    "\n",
    "        loss = mean_positive_pair_loss + mean_negative_pair_loss + mean_value_regularization\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50 / 50 : loss = 0.762963Eopch:     1 mean_loss = 2.455346\n",
      " 50 / 50 : loss = 0.656638Eopch:     2 mean_loss = 0.622784\n",
      " 50 / 50 : loss = 0.148172Eopch:     3 mean_loss = 0.467256\n",
      " 50 / 50 : loss = 0.154426Eopch:     4 mean_loss = 0.389885\n",
      " 50 / 50 : loss = 0.527933Eopch:     5 mean_loss = 0.403736\n",
      " 50 / 50 : loss = 0.339648Eopch:     6 mean_loss = 0.328763\n",
      " 50 / 50 : loss = 0.071686Eopch:     7 mean_loss = 0.324158\n",
      " 50 / 50 : loss = 0.107123Eopch:     8 mean_loss = 0.301706\n",
      " 50 / 50 : loss = 1.636551Eopch:     9 mean_loss = 0.326051\n",
      " 50 / 50 : loss = 0.097742Eopch:    10 mean_loss = 0.289728\n",
      "best_loss = 0.289728\n",
      " 99 / 100 Completed buliding index in 22 seconds\n"
     ]
    }
   ],
   "source": [
    "#Generate Dataset\n",
    "root_dir = '/data/fjsdata/qtsys/img/' #the path of images\n",
    "data = pd.read_csv('/data/fjsdata/qtsys/label.csv') \n",
    "data = data.drop_duplicates()\n",
    "data = data.sample(frac=1).reset_index(drop=True) #shuffle\n",
    "#Dataset\n",
    "trN,trI, trY =[], [],[]\n",
    "for _, row in data.iterrows():\n",
    "    try:\n",
    "        image_path = os.path.join(root_dir, row['name'])\n",
    "        img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(1600,800,3)->(256,256,3)\n",
    "        trN.append(row['name'])\n",
    "        trI.append(img)\n",
    "        if row['label']=='B':\n",
    "            trY.append(0) #buy\n",
    "        else:# row['label']=='S':\n",
    "            trY.append(1) #sell\n",
    "    except:\n",
    "        print(iname+\":\"+str(image_path))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(trY),data.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#Generate image pairs for model\n",
    "def onlineGenImgPairs():\n",
    "    if (len(trY) % 2) == 0: spls = len(trY)\n",
    "    else:  spls = len(trY)-1\n",
    "    idx_sf = random.sample(range(0, spls),spls)\n",
    "    trI1_sf, trI2_sf, trY1_sf, trY2_sf = [],[],[],[]\n",
    "    flag = 0\n",
    "    for i in idx_sf:\n",
    "        if flag==0:\n",
    "            trI1_sf.append(trI[i])\n",
    "            trY1_sf.append(trY[i])\n",
    "            flag =1\n",
    "        else:\n",
    "            trI2_sf.append(trI[i])\n",
    "            trY2_sf.append(trY[i])\n",
    "            flag =0\n",
    "    trY_sf = np.where((np.array(trY1_sf)-np.array(trY2_sf))!=0,1,0)\n",
    "    return np.array(trI1_sf),np.array(trI2_sf),trY_sf\n",
    "\n",
    "#define model\n",
    "model = ATHNet(code_size=36).cuda()\n",
    "criterion  = PairwiseLoss(margin=0.5).cuda() #define loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(10):#iteration\n",
    "    trI1_sf, trI2_sf, trY_sf = onlineGenImgPairs()\n",
    "    losses = []\n",
    "    num_batches = len(trY_sf) // batchSize +1\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY_sf), (i+1)*batchSize])\n",
    "        I1_batch = torch.from_numpy(trI1_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        I2_batch = torch.from_numpy(trI2_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        Y_batch = torch.from_numpy(trY_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        #forword\n",
    "        X1_batch = model(I1_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        X2_batch = model(I2_batch.permute(0, 3, 1, 2))\n",
    "        #binary-like loss\n",
    "        loss = criterion(X1_batch,X2_batch,Y_batch)\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "loss=loss.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "#output the feature with best model\n",
    "#torch.cuda.synchronize()\n",
    "batchSize = 10\n",
    "if (len(trY) % 10) == 0: num_batches = len(trI) // batchSize\n",
    "else:  num_batches = len(trI) // batchSize +1\n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    X_batch = torch.tanh(X_batch) #[-1,1]\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "# buliding index for retrieval\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(36) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2. Generate the K line and retrieve from database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "login success!\n",
      "sh.600732-20200328.png-B<-->sz.002799-20200326.png\n",
      "sh.601231-20200328.png-B<-->sz.000969-20200326.png\n",
      "sh.603960-20200328.png-B<-->sz.002512-20200326.png\n",
      "logout success!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<baostock.data.resultset.ResultData at 0x7f82802b6450>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate MACD\n",
    "def cal_macd_system(data,short_,long_,m):\n",
    "    '''\n",
    "    data=['Open','High','Low','Close','Volume']\n",
    "    parameter: short_,long_,m\n",
    "    return:data=['Open','High','Low','Close','Volume','diff','dea','macd']\n",
    "    '''\n",
    "    data['diff']=data['Close'].ewm(adjust=False,alpha=2/(short_+1),ignore_na=True).mean()-\\\n",
    "                data['Close'].ewm(adjust=False,alpha=2/(long_+1),ignore_na=True).mean()\n",
    "    data['dea']=data['diff'].ewm(adjust=False,alpha=2/(m+1),ignore_na=True).mean()\n",
    "    data['macd']=2*(data['diff']-data['dea'])\n",
    "    return data\n",
    "def macd_zero(macd):\n",
    "    pos_signal, neg_signal = [],[]\n",
    "    for idx,value in macd.iteritems():\n",
    "        if value > 0:\n",
    "            pos_signal.append(value)\n",
    "            neg_signal.append(np.nan)\n",
    "        else:\n",
    "            neg_signal.append(value)\n",
    "            pos_signal.append(np.nan)\n",
    "    return pos_signal,neg_signal\n",
    "\n",
    "#http://baostock.com/baostock/index.php/Python_API\n",
    "#generate market chart\n",
    "lg = bs.login() #login\n",
    "#read stocks information\n",
    "df_stocks = pro.stock_basic(exchange='', list_status='L', fields='symbol,name')\n",
    "#read k data\n",
    "fields= \"Date,Code,Open,High,Low,Close,Volume\"\n",
    "today  = (datetime.datetime.now()+datetime.timedelta(hours=8)).strftime('%Y%m%d')#UTC->CTS +8hours\n",
    "#today =datetime.datetime.now().strftime('%Y%m%d') \n",
    "df_cal = pro.trade_cal(exchange='', start_date='20200101', end_date=today)\n",
    "df_cal =df_cal[df_cal['is_open']==1].reset_index(drop=True)\n",
    "edate = df_cal[-21:][-1:]['cal_date'].tolist()[0] #last-1\n",
    "sdate = df_cal[-21:].head(1)['cal_date'].tolist()[0] #first\n",
    "edate = datetime.datetime.strptime(edate, '%Y%m%d').strftime('%Y-%m-%d') #turn to datetime\n",
    "sdate = datetime.datetime.strptime(sdate, '%Y%m%d').strftime('%Y-%m-%d')  #turn to datetime\n",
    "for code in df_stocks['symbol'].tolist():\n",
    "    if code[0]=='6': code = 'sh.'+ code\n",
    "    elif code[0]=='0' or code[0]=='3': code = 'sz.'+ code\n",
    "    else: continue\n",
    "    #read transaction data\n",
    "    rs = bs.query_history_k_data(code=code, fields=fields, \\\n",
    "                                 start_date=sdate, end_date=edate, \\\n",
    "                                 frequency=\"30\",adjustflag=\"3\") #40days，one k line per 60 minutes\n",
    "    data_list = []\n",
    "    while (rs.error_code == '0') & rs.next():\n",
    "        data_list.append(rs.get_row_data())\n",
    "    result = pd.DataFrame(data_list, columns=rs.fields)\n",
    "    result=result.apply(pd.to_numeric, errors='ignore')\n",
    "    if result.shape[0] ==160:\n",
    "        #plot K line \n",
    "        result = result[['Open','High','Low','Close','Volume']]\n",
    "        result.index=pd.to_datetime(result.index)#turn index to datatime\n",
    "        result = cal_macd_system(result,12,26,9)\n",
    "        pos_macd, neg_macd  = macd_zero(result['macd']) \n",
    "        apds = [ mpf.make_addplot(result['diff'],panel='lower',color='b'),\n",
    "                     mpf.make_addplot(result['dea'],panel='lower',color='y'),\n",
    "                     mpf.make_addplot(pos_macd,panel='lower',color='r',scatter=True),\n",
    "                     mpf.make_addplot(neg_macd,panel='lower',color='g',scatter=True)\n",
    "                   ]\n",
    "        kwargs = dict(type='candle',figratio =(16,8),volume=False,figscale=1)#line，mav=(5,10)\n",
    "        file_name = code+'-'+today+'.png'\n",
    "        Kline_path ='/data/fjsdata/qtsys/img/'+file_name\n",
    "        save = dict(fname=Kline_path,dpi=100, pad_inches=0.2)\n",
    "        mpf.plot(result,**kwargs,addplot=apds,style='sas',savefig=save)#charles\n",
    "        plt.close()\n",
    "        Kline_img = cv2.resize(cv2.imread(Kline_path).astype(np.float32), (256, 256)) #read image \n",
    "        teI = []\n",
    "        teI.append(Kline_img)\n",
    "        #output feature with model\n",
    "        teI = torch.from_numpy(np.array(teI)).type(torch.FloatTensor).cuda()\n",
    "        teI = best_net(teI.permute(0, 3, 1, 2))#forword\n",
    "        teI = torch.tanh(teI) #[-1,1]\n",
    "        teI = teI.cpu().data.numpy().tolist()\n",
    "        #retrieve from DB\n",
    "        #np.linalg.norm(vec1 - vec2) #consine l2-norm \n",
    "        scores, neighbors = gpu_index.search(np.ascontiguousarray(teI, dtype=np.float32), k=1) #return top1\n",
    "        if scores.flatten()[0]< 0.05: #similarity for sell\n",
    "            label = trY[neighbors.flatten()[0]] \n",
    "            name = trN[neighbors.flatten()[0]]\n",
    "            with open('/data/fjsdata/qtsys/label.csv','a+') as f:\n",
    "                csv_write = csv.writer(f)\n",
    "                if label == 0:\n",
    "                    print('%s-B<-->%s'%(file_name,name))\n",
    "                    csv_write.writerow([file_name,'B']) \n",
    "                elif label == 1 : #and scores.flatten()[0]< 0.001)\n",
    "                    print('%s-S<-->%s'%(file_name,name))\n",
    "                    csv_write.writerow([file_name,'S'])\n",
    "                else:os.remove(Kline_path) #remove the image file if no handle   \n",
    "        else: os.remove(Kline_path) #remove the image file if no handle \n",
    "    else: pass #print('Error in collecting data:%s' % (code))\n",
    "bs.logout()#logout"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "below is test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Org data dimension is 36.Embedded data dimension is 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize : t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import random\n",
    "def scatter(X, y):\n",
    "    #X,y:numpy-array\n",
    "    classes = len(list(set(y.tolist())))#get number of classes\n",
    "    #palette = np.array(sns.color_palette(\"hls\", classes))# choose a color palette with seaborn.\n",
    "    color = ['c','y','m','b','g','r']\n",
    "    marker = ['o','x','+','*','s']\n",
    "    plt.figure(figsize=(8,8))#create a plot\n",
    "    for i in range(classes):\n",
    "        plt.scatter(X[y == i,0], X[y == i,1], c=color[i], marker=marker[i], label=str(i))\n",
    "    plt.axis('off')\n",
    "    plt.legend(loc='lower left')\n",
    "    #plt.savefig('digits_tsne-generated.png', dpi=100)\n",
    "    plt.show()\n",
    "\n",
    "#prepare data，classes=2\n",
    "idx= np.where(np.array(teY)==0)[0].tolist()\n",
    "X0= np.array(trF)[idx]\n",
    "y0= np.array(trY)[idx]\n",
    "\n",
    "idx= np.where(np.array(teY)==1)[0].tolist()\n",
    "X1= np.array(trF)[idx]\n",
    "y1= np.array(trY)[idx]\n",
    "\n",
    "y = np.append(y0,y1)\n",
    "X = np.vstack((X0,X1))\n",
    "#training t-sne \n",
    "tsne = TSNE(n_components=2, init='pca', random_state=501)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "print(\"Org data dimension is {}.Embedded data dimension is {}\".format(X.shape[-1], X_tsne.shape[-1]))\n",
    "\n",
    "#visualize\n",
    "scatter(X_tsne, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850 / 850 The length of train set is 765\n",
      "The length of test set is 85\n",
      " 39 / 39 : loss = 0.065036Eopch:     1 mean_loss = 1.422379\n",
      " 39 / 39 : loss = 0.086033Eopch:     2 mean_loss = 1.027365\n",
      " 39 / 39 : loss = 0.034579Eopch:     3 mean_loss = 0.423771\n",
      " 39 / 39 : loss = 0.053811Eopch:     4 mean_loss = 0.241761\n",
      " 39 / 39 : loss = 2.826695Eopch:     5 mean_loss = 0.308919\n",
      " 39 / 39 : loss = 0.038412Eopch:     6 mean_loss = 0.308893\n",
      " 39 / 39 : loss = 0.210814Eopch:     7 mean_loss = 0.176090\n",
      " 39 / 39 : loss = 0.039367Eopch:     8 mean_loss = 0.127167\n",
      " 39 / 39 : loss = 0.028646Eopch:     9 mean_loss = 0.104719\n",
      " 39 / 39 : loss = 0.036144Eopch:    10 mean_loss = 0.088281\n",
      "best_loss = 0.088281\n",
      " 8 / 9 7 Completed buliding index in 1 seconds\n",
      "Accuracy: 1.000000\n",
      "[[58  0]\n",
      " [ 0 27]]\n",
      "Sensitivity of B: 1.000000\n",
      "Sensitivity of S: 1.000000\n",
      "mHR@10=0.995294, mAP@10=0.994471, mRR@10=1.000000\n"
     ]
    }
   ],
   "source": [
    "#Generate Dataset\n",
    "root_dir = '/data/fjsdata/qtsys/img/' #the path of images\n",
    "data = pd.read_csv('/data/fjsdata/qtsys/label.csv') \n",
    "data = data.drop_duplicates()\n",
    "data = data.sample(frac=1).reset_index(drop=True) #shuffle\n",
    "#Dataset\n",
    "X, Y = [],[]\n",
    "for _, row in data.iterrows():\n",
    "    try:\n",
    "        image_path = os.path.join(root_dir, row['name'])\n",
    "        img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(1600,800,3)->(256,256,3)\n",
    "        X.append(img)\n",
    "        if row['label']=='B':\n",
    "            Y.append(0) #buy\n",
    "        else:# row['label']=='S':\n",
    "            Y.append(1) #sell\n",
    "    except:\n",
    "        print(iname+\":\"+str(image_path))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(Y),data.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "#split trainset and testset \n",
    "trI, teI, trY, teY = train_test_split(X, Y, test_size=0.1, random_state=42) #list after return\n",
    "print('The length of train set is %d'%len(trI))\n",
    "print('The length of test set is %d'%len(teI))\n",
    "    \n",
    "#define model: ASH\n",
    "class SpatialAttention(nn.Module):#spatial attention layer\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels, out_channels=out_channels,\n",
    "                kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        self.downsample_layer = None\n",
    "        self.do_downsample = False\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.do_downsample = True\n",
    "            self.downsample_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.net(x)\n",
    "\n",
    "        if self.do_downsample:\n",
    "            identity = self.downsample_layer(x)\n",
    "\n",
    "        return F.relu(out + identity, inplace=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            \n",
    "class ASHNet(nn.Module):\n",
    "    def __init__(self, code_size: int):\n",
    "        super().__init__()\n",
    "        #Resnet\n",
    "        self.net = nn.Sequential(\n",
    "            ResBlock(in_channels=3, out_channels=16),\n",
    "            ResBlock(in_channels=16, out_channels=16),\n",
    "            ResBlock(in_channels=16, out_channels=16, stride=2),\n",
    "        ) \n",
    "        #Attention \n",
    "        self.sa = SpatialAttention() \n",
    "        #fully connected\n",
    "        self.linear = nn.Sequential(\n",
    "            #nn.Linear(16*128*128, 4096),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            nn.Linear(16*128*128, code_size),\n",
    "            #nn.ReLU(inplace=True) #nn.Tanh()#[-1,1]\n",
    "        )\n",
    "        \n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = self.sa(x)*x\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "#define loss function:pairwise loss            \n",
    "class HashLossFunc(nn.Module):\n",
    "    def __init__(self, margin=0.5, alpha=0.01):\n",
    "        super(HashLossFunc, self).__init__()\n",
    "        self.alpha = alpha #regularization\n",
    "        self.margin = margin #margin threshold\n",
    "        self.mse_loss = nn.MSELoss(reduction='none')\n",
    "        self.l1_loss = nn.L1Loss(reduction='mean')\n",
    "    \n",
    "    def forward(self,h1,h2,y):    \n",
    "        margin_val = self.margin * h1.shape[1]\n",
    "        squared_loss = torch.mean(self.mse_loss(h1, h2), dim=1)\n",
    "        # T1: 0.5 * (1 - y) * dist(x1, x2)\n",
    "        positive_pair_loss = (0.5 * (1 - y) * squared_loss)\n",
    "        mean_positive_pair_loss = torch.mean(positive_pair_loss)\n",
    "        # T2: 0.5 * y * max(margin - dist(x1, x2), 0)\n",
    "        zeros = torch.zeros_like(squared_loss)\n",
    "        marginMat = margin_val * torch.ones_like(squared_loss)\n",
    "        negative_pair_loss = 0.5 * y * torch.max(zeros, marginMat - squared_loss)\n",
    "        mean_negative_pair_loss = torch.mean(negative_pair_loss)\n",
    "\n",
    "        # T3: alpha(dst_l1(abs(x1), 1)) + dist_l1(abs(x2), 1)))\n",
    "        mean_value_regularization = self.alpha * (\n",
    "                self.l1_loss(torch.abs(h1), torch.ones_like(h1)) +\n",
    "                self.l1_loss(torch.abs(h2), torch.ones_like(h2)))\n",
    "\n",
    "        loss = mean_positive_pair_loss + mean_negative_pair_loss + mean_value_regularization\n",
    "        return loss\n",
    "\n",
    "\n",
    "#Generate image pairs for model\n",
    "def onlineGenImgPairs():\n",
    "    if (len(trY) % 2) == 0: spls = len(trY)\n",
    "    else:  spls = len(trY)-1\n",
    "    idx_sf = random.sample(range(0, spls),spls)\n",
    "    trI1_sf, trI2_sf, trY1_sf, trY2_sf = [],[],[],[]\n",
    "    flag = 0\n",
    "    for i in idx_sf:\n",
    "        if flag==0:\n",
    "            trI1_sf.append(trI[i])\n",
    "            trY1_sf.append(trY[i])\n",
    "            flag =1\n",
    "        else:\n",
    "            trI2_sf.append(trI[i])\n",
    "            trY2_sf.append(trY[i])\n",
    "            flag =0\n",
    "    trY_sf = np.where((np.array(trY1_sf)-np.array(trY2_sf))!=0,1,0)\n",
    "    return np.array(trI1_sf),np.array(trI2_sf),trY_sf\n",
    "\n",
    "\n",
    "#define model\n",
    "hash_size=36\n",
    "model = ASHNet(code_size=hash_size).cuda()\n",
    "criterion  = HashLossFunc(margin=0.5).cuda() #define loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(10):#iteration\n",
    "    trI1_sf, trI2_sf, trY_sf = onlineGenImgPairs()\n",
    "    losses = []\n",
    "    num_batches = len(trY_sf) // batchSize +1\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY_sf), (i+1)*batchSize])\n",
    "        I1_batch = torch.from_numpy(trI1_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        I2_batch = torch.from_numpy(trI2_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        Y_batch = torch.from_numpy(trY_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        #forword\n",
    "        X1_batch = model(I1_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        X2_batch = model(I2_batch.permute(0, 3, 1, 2))\n",
    "        #binary-like loss\n",
    "        loss = criterion(X1_batch,X2_batch,Y_batch)\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "loss=loss.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "#hash code of train data from model\n",
    "#torch.cuda.synchronize()\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize +1\n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    #X_batch = torch.sign(torch.tanh(X_batch))\n",
    "    X_batch = torch.tanh(X_batch)\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#hash code of test data from model\n",
    "#torch.cuda.synchronize()\n",
    "teF = []\n",
    "num_batches = len(teI) // batchSize + 1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(teI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    #X_batch = torch.sign(torch.tanh(X_batch))\n",
    "    X_batch = torch.tanh(X_batch)\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    teF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(hash_size) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "#performance\n",
    "scores, neighbors = gpu_index.search(np.ascontiguousarray(teF, dtype=np.float32), k=1) #return top1\n",
    "y_pred = []\n",
    "for i in neighbors.flatten():\n",
    "    y_pred.append(np.array(trY)[i]) #label of top1\n",
    "print ( 'Accuracy: %.6f'%accuracy_score(teY, y_pred))\n",
    "#confusion matrix\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, y_pred, labels=labels ) #labels=[B,S]\n",
    "print (cm)\n",
    "print ('Sensitivity of B: %.6f'%float(cm[0][0]/np.sum(cm[0])))\n",
    "print ('Sensitivity of S: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "\n",
    "for topk in [10]:#[5,10,15,20]:\n",
    "    MHR = [] #mean Hit ratio \n",
    "    MAP = [] #mean average precision\n",
    "    MRR = [] #mean reciprocal rank\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        scores, neighbors = gpu_index.search(np.array(teF)[i:i+1].astype('float32'), k=topk)\n",
    "        #map_item_score = {}\n",
    "        #for j, trVal in enumerate(trF):\n",
    "        #    map_item_score[j] = pdist(np.vstack([teVal,trVal]),'hamming')\n",
    "        #ranklist = heapq.nsmallest(topk, map_item_score, key=map_item_score.get)\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        mrr_flag = 0\n",
    "        #for j in ranklist:\n",
    "        for j in neighbors.flatten():\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                MHR.append(1)\n",
    "                pos_len = pos_len +1\n",
    "                MAP.append(pos_len/rank_len) \n",
    "                if mrr_flag==0: \n",
    "                    MRR.append(pos_len/rank_len)\n",
    "                    mrr_flag =1\n",
    "            else: \n",
    "                MHR.append(0)\n",
    "                MAP.append(0)   \n",
    "    print(\"mHR@{}={:.6f}, mAP@{}={:.6f}, mRR@{}={:.6f}\".format(topk,np.mean(MHR),topk,np.mean(MAP), topk, np.mean(MRR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850 / 850 The length of train set is 765\n",
      "The length of test set is 85\n",
      " 39 / 39 : loss = 4.486623Eopch:     1 mean_loss = 4.318382\n",
      " 39 / 39 : loss = 1.045279Eopch:     2 mean_loss = 2.624930\n",
      " 39 / 39 : loss = 1.491477Eopch:     3 mean_loss = 0.547569\n",
      " 39 / 39 : loss = 0.039266Eopch:     4 mean_loss = 0.411702\n",
      " 39 / 39 : loss = 0.036401Eopch:     5 mean_loss = 0.334284\n",
      " 39 / 39 : loss = 0.044971Eopch:     6 mean_loss = 0.319785\n",
      " 39 / 39 : loss = 0.107745Eopch:     7 mean_loss = 0.326193\n",
      " 39 / 39 : loss = 0.031921Eopch:     8 mean_loss = 0.320163\n",
      " 39 / 39 : loss = 0.079289Eopch:     9 mean_loss = 0.311246\n",
      " 39 / 39 : loss = 0.062247Eopch:    10 mean_loss = 0.291225\n",
      "best_loss = 0.291225\n",
      " 8 / 9 7 Completed buliding index in 1 seconds\n",
      "Accuracy: 0.988235\n",
      "[[55  1]\n",
      " [ 0 29]]\n",
      "Sensitivity of B: 0.982143\n",
      "Sensitivity of S: 1.000000\n",
      "mHR@10=0.961176, mAP@10=0.949074, mRR@10=0.982353\n"
     ]
    }
   ],
   "source": [
    "#Generate Dataset\n",
    "root_dir = '/data/fjsdata/qtsys/img/' #the path of images\n",
    "data = pd.read_csv('/data/fjsdata/qtsys/label.csv') \n",
    "data = data.drop_duplicates()\n",
    "data = data.sample(frac=1).reset_index(drop=True) #shuffle\n",
    "#Dataset\n",
    "X, Y = [],[]\n",
    "for _, row in data.iterrows():\n",
    "    try:\n",
    "        image_path = os.path.join(root_dir, row['name'])\n",
    "        img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(1600,800,3)->(256,256,3)\n",
    "        X.append(img)\n",
    "        if row['label']=='B':\n",
    "            Y.append(0) #buy\n",
    "        else:# row['label']=='S':\n",
    "            Y.append(1) #sell\n",
    "    except:\n",
    "        print(iname+\":\"+str(image_path))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(Y),data.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "#split trainset and testset \n",
    "trI, teI, trY, teY = train_test_split(X, Y, test_size=0.1, random_state=42) #list after return\n",
    "print('The length of train set is %d'%len(trI))\n",
    "print('The length of test set is %d'%len(teI))\n",
    "    \n",
    "#define model: ASH\n",
    "class SpatialAttention(nn.Module):#spatial attention layer\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels, out_channels=out_channels,\n",
    "                kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        self.downsample_layer = None\n",
    "        self.do_downsample = False\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.do_downsample = True\n",
    "            self.downsample_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.net(x)\n",
    "\n",
    "        if self.do_downsample:\n",
    "            identity = self.downsample_layer(x)\n",
    "\n",
    "        return F.relu(out + identity, inplace=True) #resnet\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            \n",
    "class ATHNet(nn.Module):\n",
    "    def __init__(self, code_size: int):\n",
    "        super().__init__()\n",
    "        #resnet and maxpool\n",
    "        self.net1 = nn.Sequential(#(3,256,256)->(16,128,128)\n",
    "            ResBlock(in_channels=3, out_channels=16, stride=2), \n",
    "            nn.MaxPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        )\n",
    "        \n",
    "        #Attention (16,128,128)->(16,128,128)\n",
    "        self.sa = SpatialAttention()\n",
    "        \n",
    "        #resnet and meanpool\n",
    "        self.net2 =nn.Sequential( #(16,128,128)->(8,64,64)\n",
    "            ResBlock(in_channels=16, out_channels=8, stride=2),\n",
    "            nn.AvgPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        ) \n",
    "         \n",
    "        #fully connected with conv (8,64,64)->(1,32,32)\n",
    "        self.dense=ResBlock(in_channels=8, out_channels=1, stride=2)\n",
    "        #fully connected (1,32,32)->class_size\n",
    "        self.linear = nn.Linear(1*32*32, code_size)\n",
    "    \n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net1(x)\n",
    "        x = self.sa(x)*x\n",
    "        x = self.net2(x)\n",
    "        x = self.dense(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "#define loss function:pairwise loss            \n",
    "class HashLossFunc(nn.Module):\n",
    "    def __init__(self, margin=0.5, alpha=0.01):\n",
    "        super(HashLossFunc, self).__init__()\n",
    "        self.alpha = alpha #regularization\n",
    "        self.margin = margin #margin threshold\n",
    "        self.mse_loss = nn.MSELoss(reduction='none')\n",
    "        self.l1_loss = nn.L1Loss(reduction='mean')\n",
    "    \n",
    "    def forward(self,h1,h2,y):    \n",
    "        margin_val = self.margin * h1.shape[1]\n",
    "        squared_loss = torch.mean(self.mse_loss(h1, h2), dim=1)\n",
    "        # T1: 0.5 * (1 - y) * dist(x1, x2)\n",
    "        positive_pair_loss = (0.5 * (1 - y) * squared_loss)\n",
    "        mean_positive_pair_loss = torch.mean(positive_pair_loss)\n",
    "        # T2: 0.5 * y * max(margin - dist(x1, x2), 0)\n",
    "        zeros = torch.zeros_like(squared_loss)\n",
    "        marginMat = margin_val * torch.ones_like(squared_loss)\n",
    "        negative_pair_loss = 0.5 * y * torch.max(zeros, marginMat - squared_loss)\n",
    "        mean_negative_pair_loss = torch.mean(negative_pair_loss)\n",
    "\n",
    "        # T3: alpha(dst_l1(abs(x1), 1)) + dist_l1(abs(x2), 1)))\n",
    "        mean_value_regularization = self.alpha * (\n",
    "                self.l1_loss(torch.abs(h1), torch.ones_like(h1)) +\n",
    "                self.l1_loss(torch.abs(h2), torch.ones_like(h2)))\n",
    "\n",
    "        loss = mean_positive_pair_loss + mean_negative_pair_loss + mean_value_regularization\n",
    "        return loss\n",
    "\n",
    "\n",
    "#Generate image pairs for model\n",
    "def onlineGenImgPairs():\n",
    "    if (len(trY) % 2) == 0: spls = len(trY)\n",
    "    else:  spls = len(trY)-1\n",
    "    idx_sf = random.sample(range(0, spls),spls)\n",
    "    trI1_sf, trI2_sf, trY1_sf, trY2_sf = [],[],[],[]\n",
    "    flag = 0\n",
    "    for i in idx_sf:\n",
    "        if flag==0:\n",
    "            trI1_sf.append(trI[i])\n",
    "            trY1_sf.append(trY[i])\n",
    "            flag =1\n",
    "        else:\n",
    "            trI2_sf.append(trI[i])\n",
    "            trY2_sf.append(trY[i])\n",
    "            flag =0\n",
    "    trY_sf = np.where((np.array(trY1_sf)-np.array(trY2_sf))!=0,1,0)\n",
    "    return np.array(trI1_sf),np.array(trI2_sf),trY_sf\n",
    "\n",
    "\n",
    "#define model\n",
    "hash_size=36\n",
    "model = ATHNet(code_size=hash_size).cuda()\n",
    "criterion  = HashLossFunc(margin=0.5).cuda() #define loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(10):#iteration\n",
    "    trI1_sf, trI2_sf, trY_sf = onlineGenImgPairs()\n",
    "    losses = []\n",
    "    num_batches = len(trY_sf) // batchSize +1\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY_sf), (i+1)*batchSize])\n",
    "        I1_batch = torch.from_numpy(trI1_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        I2_batch = torch.from_numpy(trI2_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        Y_batch = torch.from_numpy(trY_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        #forword\n",
    "        X1_batch = model(I1_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        X2_batch = model(I2_batch.permute(0, 3, 1, 2))\n",
    "        #binary-like loss\n",
    "        loss = criterion(X1_batch,X2_batch,Y_batch)\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "loss=loss.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "#hash code of train data from model\n",
    "#torch.cuda.synchronize()\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize +1\n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    #X_batch = torch.sign(torch.tanh(X_batch))\n",
    "    X_batch = torch.tanh(X_batch)\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#hash code of test data from model\n",
    "#torch.cuda.synchronize()\n",
    "teF = []\n",
    "num_batches = len(teI) // batchSize + 1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(teI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(teI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    #X_batch = torch.sign(torch.tanh(X_batch))\n",
    "    X_batch = torch.tanh(X_batch)\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    teF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# buliding index of trainset\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(hash_size) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))\n",
    "#performance\n",
    "scores, neighbors = gpu_index.search(np.ascontiguousarray(teF, dtype=np.float32), k=1) #return top1\n",
    "y_pred = []\n",
    "for i in neighbors.flatten():\n",
    "    y_pred.append(np.array(trY)[i]) #label of top1\n",
    "print ( 'Accuracy: %.6f'%accuracy_score(teY, y_pred))\n",
    "#confusion matrix\n",
    "labels = list(set(teY))\n",
    "cm = confusion_matrix(teY, y_pred, labels=labels ) #labels=[B,S]\n",
    "print (cm)\n",
    "print ('Sensitivity of B: %.6f'%float(cm[0][0]/np.sum(cm[0])))\n",
    "print ('Sensitivity of S: %.6f'%float(cm[1][1]/np.sum(cm[1])))\n",
    "for topk in [10]:#[5,10,15,20]:\n",
    "    MHR = [] #mean Hit ratio \n",
    "    MAP = [] #mean average precision\n",
    "    MRR = [] #mean reciprocal rank\n",
    "    for i, teVal in enumerate(teF):\n",
    "        stype = teY[i]\n",
    "        map_item_score = {}\n",
    "        for j, trVal in enumerate(trF):\n",
    "            map_item_score[j] = pdist(np.vstack([teVal,trVal]),'cosine')\n",
    "        ranklist = heapq.nsmallest(topk, map_item_score, key=map_item_score.get)\n",
    "        #perfromance\n",
    "        pos_len = 0\n",
    "        rank_len = 0\n",
    "        mrr_flag = 0\n",
    "        for j in ranklist:\n",
    "            dtype = trY[j]\n",
    "            rank_len=rank_len+1\n",
    "            if stype==dtype:  #hit\n",
    "                MHR.append(1)\n",
    "                pos_len = pos_len +1\n",
    "                MAP.append(pos_len/rank_len) \n",
    "                if mrr_flag==0: \n",
    "                    MRR.append(pos_len/rank_len)\n",
    "                    mrr_flag =1\n",
    "            else: \n",
    "                MHR.append(0)\n",
    "                MAP.append(0)   \n",
    "    print(\"mHR@{}={:.6f}, mAP@{}={:.6f}, mRR@{}={:.6f}\".format(topk,np.mean(MHR),topk,np.mean(MAP), topk, np.mean(MRR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-27\n",
      "2020-02-28\n",
      "20200327\n"
     ]
    }
   ],
   "source": [
    "print(edate)\n",
    "print(sdate)\n",
    "print(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
