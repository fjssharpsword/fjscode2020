{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading faiss with AVX2 support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tushare.pro.client.DataApi object at 0x7f84fad22bd0>\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import datetime\n",
    "import copy\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import threading\n",
    "import csv\n",
    "import shutil\n",
    "from functools import reduce\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc \n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import date2num\n",
    "import cv2\n",
    "import faiss \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import baostock as bs#pip install baostock\n",
    "import mplfinance as mpf #pip install mplfinance\n",
    "import easyquotation #pip install easyquotation\n",
    "import tushare as ts # pip install tushare\n",
    "tstoken='2621bdfffbde695d0d256a69a71d9344c94c1d8a58f389cd391ceeeb' #youer token\n",
    "ts.set_token(tstoken)\n",
    "pro = ts.pro_api()\n",
    "print(pro)\n",
    "torch.cuda.set_device(7)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Training model and output database(faiss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model: ATH\n",
    "class SpatialAttention(nn.Module):#spatial attention layer\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels, out_channels=out_channels,\n",
    "                kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        self.downsample_layer = None\n",
    "        self.do_downsample = False\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.do_downsample = True\n",
    "            self.downsample_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.net(x)\n",
    "\n",
    "        if self.do_downsample:\n",
    "            identity = self.downsample_layer(x)\n",
    "\n",
    "        return F.relu(out + identity, inplace=True) #resnet\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            \n",
    "class ATHNet(nn.Module):\n",
    "    def __init__(self, code_size: int):\n",
    "        super().__init__()\n",
    "        #resnet and maxpool\n",
    "        self.net1 = nn.Sequential(#(3,256,256)->(16,128,128)\n",
    "            ResBlock(in_channels=3, out_channels=16, stride=2), \n",
    "            nn.MaxPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        )\n",
    "        \n",
    "        #Attention (16,128,128)->(16,128,128)\n",
    "        self.sa = SpatialAttention()\n",
    "        \n",
    "        #resnet and meanpool\n",
    "        self.net2 =nn.Sequential( #(16,128,128)->(8,64,64)\n",
    "            ResBlock(in_channels=16, out_channels=8, stride=2),\n",
    "            nn.AvgPool2d(kernel_size=3, padding=1, stride=1)\n",
    "        ) \n",
    "         \n",
    "        #fully connected with conv (8,64,64)->(1,32,32)\n",
    "        self.dense=ResBlock(in_channels=8, out_channels=1, stride=2)\n",
    "        #fully connected (1,32,32)->class_size\n",
    "        self.linear = nn.Linear(1*32*32, code_size)\n",
    "    \n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net1(x)\n",
    "        x = self.sa(x)*x\n",
    "        x = self.net2(x)\n",
    "        x = self.dense(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "#define loss function:pairwise loss            \n",
    "class PairwiseLoss(nn.Module):\n",
    "    def __init__(self, margin=0.5, alpha=0.01):\n",
    "        super(PairwiseLoss, self).__init__()\n",
    "        self.alpha = alpha #regularization\n",
    "        self.margin = margin #margin threshold\n",
    "        self.mse_loss = nn.MSELoss(reduction='none')\n",
    "        self.l1_loss = nn.L1Loss(reduction='mean')\n",
    "    \n",
    "    def forward(self,h1,h2,y):    \n",
    "        margin_val = self.margin * h1.shape[1]\n",
    "        squared_loss = torch.mean(self.mse_loss(h1, h2), dim=1)\n",
    "        # T1: 0.5 * (1 - y) * dist(x1, x2)\n",
    "        positive_pair_loss = (0.5 * (1 - y) * squared_loss)\n",
    "        mean_positive_pair_loss = torch.mean(positive_pair_loss)\n",
    "        # T2: 0.5 * y * max(margin - dist(x1, x2), 0)\n",
    "        zeros = torch.zeros_like(squared_loss)\n",
    "        marginMat = margin_val * torch.ones_like(squared_loss)\n",
    "        negative_pair_loss = 0.5 * y * torch.max(zeros, marginMat - squared_loss)\n",
    "        mean_negative_pair_loss = torch.mean(negative_pair_loss)\n",
    "\n",
    "        # T3: alpha(dst_l1(abs(x1), 1)) + dist_l1(abs(x2), 1)))\n",
    "        mean_value_regularization = self.alpha * (\n",
    "                self.l1_loss(torch.abs(h1), torch.ones_like(h1)) +\n",
    "                self.l1_loss(torch.abs(h2), torch.ones_like(h2)))\n",
    "\n",
    "        loss = mean_positive_pair_loss + mean_negative_pair_loss + mean_value_regularization\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 132 / 132 : loss = 0.440149Eopch:     1 mean_loss = 1.426969\n",
      " 132 / 132 : loss = 0.180453Eopch:     2 mean_loss = 0.265301\n",
      " 132 / 132 : loss = 0.048961Eopch:     3 mean_loss = 0.241884\n",
      " 132 / 132 : loss = 0.163586Eopch:     4 mean_loss = 0.208901\n",
      " 132 / 132 : loss = 0.028439Eopch:     5 mean_loss = 0.210488\n",
      " 132 / 132 : loss = 0.039822Eopch:     6 mean_loss = 0.211126\n",
      " 132 / 132 : loss = 0.073874Eopch:     7 mean_loss = 0.202595\n",
      " 132 / 132 : loss = 0.038942Eopch:     8 mean_loss = 0.199675\n",
      " 132 / 132 : loss = 0.041049Eopch:     9 mean_loss = 0.193950\n",
      " 132 / 132 : loss = 0.047678Eopch:    10 mean_loss = 0.184141\n",
      " 132 / 132 : loss = 0.040227Eopch:    11 mean_loss = 0.166440\n",
      " 132 / 132 : loss = 0.069055Eopch:    12 mean_loss = 0.169919\n",
      " 132 / 132 : loss = 0.393391Eopch:    13 mean_loss = 0.178542\n",
      " 132 / 132 : loss = 0.090279Eopch:    14 mean_loss = 0.161389\n",
      " 132 / 132 : loss = 0.041435Eopch:    15 mean_loss = 0.169071\n",
      " 132 / 132 : loss = 0.080906Eopch:    16 mean_loss = 0.172053\n",
      " 132 / 132 : loss = 0.237575Eopch:    17 mean_loss = 0.163299\n",
      " 132 / 132 : loss = 0.113522Eopch:    18 mean_loss = 0.149365\n",
      " 132 / 132 : loss = 0.158716Eopch:    19 mean_loss = 0.152676\n",
      " 132 / 132 : loss = 0.031452Eopch:    20 mean_loss = 0.134687\n",
      "best_loss = 0.134687\n",
      " 262 / 263 Completed buliding index in 21 seconds\n"
     ]
    }
   ],
   "source": [
    "#Generate Dataset\n",
    "root_dir = '/data/fjsdata/qtsys/img/' #the path of images\n",
    "data = pd.read_csv('/data/fjsdata/qtsys/label.csv') \n",
    "data = data.drop_duplicates()\n",
    "data = data.sample(frac=1).reset_index(drop=True) #shuffle\n",
    "#Dataset\n",
    "trN,trI, trY =[], [],[]\n",
    "for _, row in data.iterrows():\n",
    "    try:\n",
    "        image_path = os.path.join(root_dir, row['name'])\n",
    "        img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(1600,800,3)->(256,256,3)\n",
    "        trN.append(row['name'])\n",
    "        trI.append(img)\n",
    "        if row['label']=='B':\n",
    "            trY.append(0) #buy\n",
    "        else:# row['label']=='S':\n",
    "            trY.append(1) #sell\n",
    "    except:\n",
    "        print(iname+\":\"+str(image_path))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(trY),data.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#Generate image pairs for model\n",
    "def onlineGenImgPairs():\n",
    "    if (len(trY) % 2) == 0: spls = len(trY)\n",
    "    else:  spls = len(trY)-1\n",
    "    idx_sf = random.sample(range(0, spls),spls)\n",
    "    trI1_sf, trI2_sf, trY1_sf, trY2_sf = [],[],[],[]\n",
    "    flag = 0\n",
    "    for i in idx_sf:\n",
    "        if flag==0:\n",
    "            trI1_sf.append(trI[i])\n",
    "            trY1_sf.append(trY[i])\n",
    "            flag =1\n",
    "        else:\n",
    "            trI2_sf.append(trI[i])\n",
    "            trY2_sf.append(trY[i])\n",
    "            flag =0\n",
    "    trY_sf = np.where((np.array(trY1_sf)-np.array(trY2_sf))!=0,1,0)\n",
    "    return np.array(trI1_sf),np.array(trI2_sf),trY_sf\n",
    "\n",
    "#define model\n",
    "model = ATHNet(code_size=36).cuda()\n",
    "criterion  = PairwiseLoss(margin=0.5).cuda() #define loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "#train model\n",
    "batchSize = 10\n",
    "best_net, best_loss = None, float('inf')\n",
    "for epoch in range(20):#iteration\n",
    "    trI1_sf, trI2_sf, trY_sf = onlineGenImgPairs()\n",
    "    if (len(trY_sf) % batchSize) == 0: num_batches = len(trY_sf) // batchSize\n",
    "    else:  num_batches = len(trY_sf) // batchSize +1\n",
    "    losses = []\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY_sf), (i+1)*batchSize])\n",
    "        I1_batch = torch.from_numpy(trI1_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        I2_batch = torch.from_numpy(trI2_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        Y_batch = torch.from_numpy(trY_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        #forword\n",
    "        X1_batch = model(I1_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        X2_batch = model(I2_batch.permute(0, 3, 1, 2))\n",
    "        #binary-like loss\n",
    "        loss = criterion(X1_batch,X2_batch,Y_batch)\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "loss=loss.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "#output the feature with best model\n",
    "#torch.cuda.synchronize()\n",
    "trF = []\n",
    "if (len(trY) % batchSize) == 0: num_batches = len(trY) // batchSize\n",
    "else:  num_batches = len(trY) // batchSize +1\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    X_batch = torch.tanh(X_batch) #[-1,1]\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "# buliding index for retrieval\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(36) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 2. Online Generate Kline picture and predict whether buy or not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "login success!\n",
      "Codes: 3748 have been collected\n",
      "Start thread at 13:09:31\n",
      "Start thread at 13:40:05\n",
      "Start thread at 14:10:55\n",
      "Start thread at 14:41:26\n"
     ]
    }
   ],
   "source": [
    "#Calculate MACD\n",
    "def cal_macd_system(data,short_,long_,m):\n",
    "    '''\n",
    "    data=['Open','High','Low','Close']\n",
    "    parameter: short_,long_,m\n",
    "    return:data=['Open','High','Low','Close','diff','dea','macd']\n",
    "    '''\n",
    "    data['diff']=data['Close'].ewm(adjust=False,alpha=2/(short_+1),ignore_na=True).mean()-\\\n",
    "                data['Close'].ewm(adjust=False,alpha=2/(long_+1),ignore_na=True).mean()\n",
    "    data['dea']=data['diff'].ewm(adjust=False,alpha=2/(m+1),ignore_na=True).mean()\n",
    "    data['macd']=2*(data['diff']-data['dea'])\n",
    "    return data\n",
    "def macd_zero(macd):\n",
    "    pos_signal, neg_signal = [],[]\n",
    "    for idx,value in macd.iteritems():\n",
    "        if value > 0:\n",
    "            pos_signal.append(value)\n",
    "            neg_signal.append(np.nan)\n",
    "        else:\n",
    "            neg_signal.append(value)\n",
    "            pos_signal.append(np.nan)\n",
    "    return pos_signal,neg_signal\n",
    "\n",
    "#http://tushare.org/trading.html               \n",
    "#https://tushare.pro/document/2\n",
    "def his_kline():\n",
    "    #read stocks information\n",
    "    df_stocks = pro.stock_basic(exchange='', list_status='L', fields='symbol')\n",
    "    #read k data\n",
    "    today  = (datetime.datetime.now()+datetime.timedelta(hours=8)).strftime('%Y%m%d')#UTC->CTS +8hours\n",
    "    df_cal = pro.trade_cal(exchange='', start_date='20200101', end_date=today)\n",
    "    df_cal =df_cal[df_cal['is_open']==1].reset_index(drop=True)\n",
    "    edate = df_cal[-21:][-1:]['cal_date'].tolist()[0] #last-1\n",
    "    sdate = df_cal[-21:].head(1)['cal_date'].tolist()[0] #first\n",
    "    edate = datetime.datetime.strptime(edate, '%Y%m%d').strftime('%Y-%m-%d') #turn to datetime\n",
    "    sdate = datetime.datetime.strptime(sdate, '%Y%m%d').strftime('%Y-%m-%d')  #turn to datetime\n",
    "    fields= \"Open,High,Low,Close\"\n",
    "    All_His_KLine = {}\n",
    "    for code in df_stocks['symbol'].tolist():\n",
    "        if code[0]=='6': bs_code = 'sh.'+ code\n",
    "        elif code[0]=='0' or code[0]=='3': bs_code = 'sz.'+ code\n",
    "        else: continue\n",
    "        #read transaction data\n",
    "        rs = bs.query_history_k_data(code=bs_code, fields=fields, \\\n",
    "                                    start_date=sdate, end_date=edate, \\\n",
    "                                    frequency=\"30\",adjustflag=\"3\") #40days，one k line per 60 minutes\n",
    "        data_list = []\n",
    "        while (rs.error_code == '0') & rs.next():\n",
    "            data_list.append(rs.get_row_data())\n",
    "        result = pd.DataFrame(data_list, columns=rs.fields)\n",
    "        result=result.apply(pd.to_numeric, errors='ignore')\n",
    "        if result.shape[0] ==160:\n",
    "            All_His_KLine[code]=result\n",
    "    return All_His_KLine\n",
    "\n",
    "def plot_predict_thread(best_net):\n",
    "    best_net = best_net.cuda()\n",
    "    global All_His_KLine, All_Now_KLine\n",
    "    today  = (datetime.datetime.now()+datetime.timedelta(hours=8)).strftime('%Y%m%d')#UTC->CTS +8hours\n",
    "    now_time  = (datetime.datetime.now()+datetime.timedelta(hours=8)).strftime('%H:%M:%S')#UTC->CTS +8hours\n",
    "    print('Start thread at %s'%(now_time))\n",
    "    tstart = time.time()\n",
    "    hit_list = []\n",
    "    for code in random.sample(list(All_His_KLine.keys()),len(list(All_His_KLine.keys()))):\n",
    "        elapsed = time.time() - tstart \n",
    "        if elapsed>25*60:\n",
    "            now_time  = (datetime.datetime.now()+datetime.timedelta(hours=8)).strftime('%H:%M:%S')#UTC->CTS +8hours\n",
    "            #print('Stop thread at %s'%(now_time))\n",
    "            break #end thread\n",
    "        try:\n",
    "            his_kline = All_His_KLine[code] #dataframe\n",
    "            if code in list(All_Now_KLine.keys()): #not open,\n",
    "                lock.acquire()\n",
    "                price_list = All_Now_KLine[code]\n",
    "                lock.release()\n",
    "                his_kline.loc[his_kline.shape[0]]={'Open':price_list[0],'High':np.array(price_list).max(),\\\n",
    "                                                    'Low':np.array(price_list).min(),'Close':price_list[-1]}         \n",
    "            df_kline = his_kline[-160:].reset_index(drop=True) #get last 160\n",
    "            lowest_price =  np.array(his_kline[-4:].reset_index(drop=True)).flatten().min()\n",
    "            highest_price =  np.array(his_kline[-4:].reset_index(drop=True)).flatten().max()\n",
    "            #plot\n",
    "            df_kline.index=pd.to_datetime(df_kline.index)#turn index to datatime\n",
    "            df_kline = cal_macd_system(df_kline,12,26,9)\n",
    "            pos_macd, neg_macd  = macd_zero(df_kline['macd']) \n",
    "            apds = [ mpf.make_addplot(df_kline['diff'],panel='lower',color='b'),\n",
    "                         mpf.make_addplot(df_kline['dea'],panel='lower',color='y'),\n",
    "                         mpf.make_addplot(pos_macd,panel='lower',color='r',scatter=True),\n",
    "                         mpf.make_addplot(neg_macd,panel='lower',color='g',scatter=True)\n",
    "                        ]\n",
    "            kwargs = dict(type='candle',figratio =(16,8),volume=False,figscale=1)#line，mav=(5,10)      \n",
    "            file_name = code+'-'+today+'-'+now_time+'.png'\n",
    "            Kline_path ='/data/fjsdata/qtsys/realimg/'+file_name\n",
    "            save = dict(fname=Kline_path,dpi=100, pad_inches=0.2)\n",
    "            lock.acquire()\n",
    "            mpf.plot(df_kline,**kwargs,addplot=apds,style='sas',savefig=save)#charles\n",
    "            plt.close()\n",
    "            lock.release()\n",
    "            #predict\n",
    "            Kline_img = cv2.resize(cv2.imread(Kline_path).astype(np.float32), (256, 256)) #read image \n",
    "            teI = []\n",
    "            teI.append(Kline_img)\n",
    "            teI = torch.from_numpy(np.array(teI)).type(torch.FloatTensor).cuda()#output feature with model\n",
    "            teI = best_net(teI.permute(0, 3, 1, 2))#forword\n",
    "            teI = torch.tanh(teI) #[-1,1]\n",
    "            teI = teI.cpu().data.numpy().tolist()\n",
    "            scores, neighbors = gpu_index.search(np.ascontiguousarray(teI, dtype=np.float32), k=1) #return top1\n",
    "            if scores.flatten()[0]< 0.001: #similarity \n",
    "                label = trY[neighbors.flatten()[0]] \n",
    "                name =  trN[neighbors.flatten()[0]]\n",
    "                real_data = quotation.real(code)\n",
    "                price =  list(real_data.values())[0]['now']\n",
    "                if (label == 0 and (price<lowest_price or (price-lowest_price)/lowest_price<0.02)):\n",
    "                    hit_list.append([file_name,'B', scores.flatten()[0], price, 'Y']) \n",
    "                    #print('%s-B<-->%s'%(file_name,name))\n",
    "                elif (label == 1 and (price>highest_price or (highest_price-price)/price<0.02)):\n",
    "                    hit_list.append([file_name,'S', scores.flatten()[0], price, 'Y'])\n",
    "                    #print('%s-S<-->%s'%(file_name,name))\n",
    "                else:os.remove(Kline_path) #remove the image file if no handle\n",
    "            else: os.remove(Kline_path) #remove the image file if no handle \n",
    "        except: continue \n",
    "    #write csv file\n",
    "    df_hit = pd.DataFrame(hit_list, columns=['code','label','score','price','flag'])\n",
    "    file_path = '/data/fjsdata/qtsys/realcsv/'+today+'-'+now_time+'.csv'\n",
    "    df_hit.to_csv(file_path,index=False)\n",
    "            \n",
    "#https://github.com/shidenggui/easyquotation\n",
    "lg = bs.login() #login\n",
    "All_His_KLine = his_kline()#get history kline\n",
    "print('Codes: %d have been collected'%(len(All_His_KLine)))\n",
    "All_Now_KLine = {}\n",
    "quotation = easyquotation.use('sina')\n",
    "lock = threading.Lock()\n",
    "open_flag = True\n",
    "while True:\n",
    "    if open_flag: #open am and pm\n",
    "        tstart = time.time()\n",
    "        t = threading.Thread(target=plot_predict_thread,args=(best_net.cpu(),))\n",
    "        t.start()\n",
    "        open_flag = False        \n",
    "    else:\n",
    "        #time.sleep(2)#2seconds waiting\n",
    "        elapsed = time.time() - tstart \n",
    "        if elapsed>30*60: #plot Kline and predict,30minutes \n",
    "            tstart = time.time()\n",
    "            t = threading.Thread(target=plot_predict_thread,args=(best_net.cpu(),))\n",
    "            t.start()  \n",
    "            All_Now_KLine = {} #empty\n",
    "        else: #collect real data\n",
    "            for code in list(All_His_KLine.keys()):\n",
    "                real_data = quotation.real(code)\n",
    "                price =  list(real_data.values())[0]['now']\n",
    "                if code in list(All_Now_KLine.keys()):\n",
    "                    price_list = All_Now_KLine[code]\n",
    "                    if price not in price_list:\n",
    "                        price_list.append(price)\n",
    "                        All_Now_KLine[code] = price_list                      \n",
    "                else:\n",
    "                    All_Now_KLine.setdefault(code,[price])#value is list\n",
    "bs.logout()#logout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(763, 4)\n",
      "(656, 4)\n",
      "(1974, 2)\n",
      "(2630, 2)\n"
     ]
    }
   ],
   "source": [
    "root_dir = '/data/fjsdata/qtsys/real/' #the path of images\n",
    "data = pd.read_csv('/data/fjsdata/qtsys/real_0403.csv') \n",
    "data_n = data[data['flag']=='N']\n",
    "data_y = data[data['flag']=='Y']\n",
    "print(data_n.shape)\n",
    "for idx, row in data_n.iterrows():\n",
    "    if os.path.exists(root_dir+row['name']):\n",
    "        os.remove(root_dir+row['name'])\n",
    "        \n",
    "print(data_y.shape)\n",
    "for idx, row in data_y.iterrows():\n",
    "    if os.path.exists(root_dir+row['name']):\n",
    "        shutil.copyfile( root_dir+row['name'], '/data/fjsdata/qtsys/img/'+row['name'])\n",
    "        os.remove(root_dir+row['name'])\n",
    "\n",
    "data_y = data_y[['name','label']]\n",
    "data_label = pd.read_csv('/data/fjsdata/qtsys/label.csv') \n",
    "print(data_label.shape)\n",
    "data_label = pd.concat([data_label,data_y],axis=0)\n",
    "print(data_label.shape)\n",
    "data_label.to_csv('/data/fjsdata/qtsys/label.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "below is test code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Getting data:]#############################################################################[Getting data:]#############################Error reading file 'http://vip.stock.finance.sina.com.cn/quotes_service/view/vMS_tradedetail.php?symbol=sz000002&date=2020-03-23&page=29': failed to load HTTP resource\n",
      "Error reading file 'http://vip.stock.finance.sina.com.cn/quotes_service/view/vMS_tradedetail.php?symbol=sz000002&date=2020-03-23&page=29': failed to load HTTP resource\n",
      "##Error reading file 'http://vip.stock.finance.sina.com.cn/quotes_service/view/vMS_tradedetail.php?symbol=sz000002&date=2020-03-23&page=31': failed to load HTTP resource\n",
      "#Error reading file 'http://vip.stock.finance.sina.com.cn/quotes_service/view/vMS_tradedetail.php?symbol=sz000002&date=2020-03-23&page=32': failed to load HTTP resource\n",
      "Error reading file 'http://vip.stock.finance.sina.com.cn/quotes_service/view/vMS_tradedetail.php?symbol=sz000002&date=2020-03-23&page=32': failed to load HTTP resource\n",
      "Error reading file 'http://vip.stock.finance.sina.com.cn/quotes_service/view/vMS_tradedetail.php?symbol=sz000002&date=2020-03-23&page=32': failed to load HTTP resource\n",
      "获取失败，请检查网络.\n",
      "HTTP Error 456: \n",
      "HTTP Error 456: \n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "获取失败，请检查网络.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-206-45dc8e6d679c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mdf_kline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_kline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#inverse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_kline\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdf_kline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0mkline_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0mdf_today\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_today_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#get today\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0mnow_time_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnow_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%H:%M:%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mnow_time_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnow_time_end\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminutes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tushare/stock/trading.py\u001b[0m in \u001b[0;36mget_today_ticks\u001b[0;34m(code, retry_count, pause)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNETWORK_URL_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: 获取失败，请检查网络."
     ]
    }
   ],
   "source": [
    "#Calculate MACD\n",
    "def cal_macd_system(data,short_,long_,m):\n",
    "    '''\n",
    "    data=['Open','High','Low','Close']\n",
    "    parameter: short_,long_,m\n",
    "    return:data=['Open','High','Low','Close','diff','dea','macd']\n",
    "    '''\n",
    "    data['diff']=data['Close'].ewm(adjust=False,alpha=2/(short_+1),ignore_na=True).mean()-\\\n",
    "                data['Close'].ewm(adjust=False,alpha=2/(long_+1),ignore_na=True).mean()\n",
    "    data['dea']=data['diff'].ewm(adjust=False,alpha=2/(m+1),ignore_na=True).mean()\n",
    "    data['macd']=2*(data['diff']-data['dea'])\n",
    "    return data\n",
    "def macd_zero(macd):\n",
    "    pos_signal, neg_signal = [],[]\n",
    "    for idx,value in macd.iteritems():\n",
    "        if value > 0:\n",
    "            pos_signal.append(value)\n",
    "            neg_signal.append(np.nan)\n",
    "        else:\n",
    "            neg_signal.append(value)\n",
    "            pos_signal.append(np.nan)\n",
    "    return pos_signal,neg_signal\n",
    "\n",
    "#http://tushare.org/trading.html               \n",
    "#https://tushare.pro/document/2\n",
    "#https://github.com/shidenggui/easyquotation\n",
    "#iteration when on charge\n",
    "frs = 30  #Get the 30 minute K-line for the last 20 trading days\n",
    "kline_len = 160 #length of kline\n",
    "trans_time = ['9:30:00','10:00:00','10:30:00','11:00:00','13:00:00','13:30:00','14:00:00','14:30:00']\n",
    "while True:\n",
    "    now_time  = (datetime.datetime.now()+datetime.timedelta(hours=8)).strftime('%H:%M:%S')#UTC->CTS +8hours\n",
    "    now_time = '14:30:00'\n",
    "    if now_time in trans_time:   \n",
    "        df_stocks = pro.stock_basic(exchange='', list_status='L', fields='symbol,name')\n",
    "        for code in df_stocks['symbol'].tolist():\n",
    "            today =datetime.datetime.now().strftime('%Y%m%d') \n",
    "            df_cal = pro.trade_cal(exchange='', start_date='20200101', end_date=today)\n",
    "            df_cal =df_cal[df_cal['is_open']==1].reset_index(drop=True)\n",
    "            edate = df_cal[-22:][-1:]['cal_date'].tolist()[0] #last-1\n",
    "            sdate = df_cal[-22:].head(1)['cal_date'].tolist()[0] #first\n",
    "            edate = datetime.datetime.strptime(edate, '%Y%m%d').strftime('%Y-%m-%d') #turn to datetime\n",
    "            sdate = datetime.datetime.strptime(sdate, '%Y%m%d').strftime('%Y-%m-%d')  #turn to datetime\n",
    "            df_kline = ts.get_hist_data(code, ktype=str(frs), start=sdate,end=edate)[['open','high','low','close']].reset_index(drop=True)\n",
    "            df_kline = df_kline.sort_index(ascending=False) #inverse\n",
    "            if (df_kline is not None and df_kline.shape[0] ==kline_len): \n",
    "                df_today = ts.get_today_ticks(code)[['time','price']] #get today \n",
    "                now_time_end = datetime.datetime.strptime(now_time, '%H:%M:%S')\n",
    "                now_time_start = (now_time_end + datetime.timedelta(minutes=-30))\n",
    "                df_today['flag']= df_today['time'].apply(lambda x: 1 if now_time_start<datetime.datetime.strptime(x, '%H:%M:%S')<now_time_end else 0)\n",
    "                df_today = df_today[df_today['flag']==1]\n",
    "                if (len(df_today))>0:\n",
    "                    df_kline.loc[df_kline.shape[0]]={'open':df_today['price'].tolist()[0],'high':df_today['price'].max(),\\\n",
    "                                         'low':df_today['price'].min(),'close':df_today['price'].tolist()[-1]}\n",
    "                    df_kline = df_kline[-160:]\n",
    "                    df_kline = df_kline.rename(columns={\"open\": \"Open\", \"high\": \"High\", \"low\": \"Low\", \"close\": \"Close\"})\n",
    "                    df_kline.index=pd.to_datetime(df_kline.index)#turn index to datatime\n",
    "                    df_kline = cal_macd_system(df_kline,12,26,9)\n",
    "                    pos_macd, neg_macd  = macd_zero(df_kline['macd']) \n",
    "                    apds = [ mpf.make_addplot(df_kline['diff'],panel='lower',color='b'),\n",
    "                                 mpf.make_addplot(df_kline['dea'],panel='lower',color='y'),\n",
    "                                 mpf.make_addplot(pos_macd,panel='lower',color='r',scatter=True),\n",
    "                                 mpf.make_addplot(neg_macd,panel='lower',color='g',scatter=True)\n",
    "                               ]\n",
    "                    kwargs = dict(type='candle',figratio =(16,8),volume=False,figscale=1)#line，mav=(5,10)\n",
    "                    Kline_path ='/data/fjsdata/qtsys/real/'+code+'.png'\n",
    "                    save = dict(fname=Kline_path,dpi=100, pad_inches=0.2)\n",
    "                    mpf.plot(df_kline,**kwargs,addplot=apds,style='sas',savefig=save)#charles\n",
    "                    plt.close()\n",
    "                    Kline_img = cv2.resize(cv2.imread(Kline_path).astype(np.float32), (256, 256)) #read image \n",
    "                    teI = []\n",
    "                    teI.append(Kline_img)\n",
    "                    #output feature with model\n",
    "                    teI = torch.from_numpy(np.array(teI)).type(torch.FloatTensor).cuda()\n",
    "                    teI = best_net(teI.permute(0, 3, 1, 2))#forword\n",
    "                    teI = torch.tanh(teI) #[-1,1]\n",
    "                    teI = teI.cpu().data.numpy().tolist()\n",
    "                    scores, neighbors = gpu_index.search(np.ascontiguousarray(teI, dtype=np.float32), k=1) #return top1\n",
    "                    if scores.flatten()[0]< 0.001: #similarity for buy\n",
    "                        label = trY[neighbors.flatten()[0]] \n",
    "                        if label == 0: print('%s-B'%(code))\n",
    "                    else:os.remove(Kline_path) #remove the image file if no handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.57\n"
     ]
    }
   ],
   "source": [
    "quotation = easyquotation.use('sina')\n",
    "df = quotation.real('000651')\n",
    "price =  list(df.values())[0]['now']\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start thread at 08:51:15\n"
     ]
    }
   ],
   "source": [
    "now_time  = (datetime.datetime.now()+datetime.timedelta(hours=8)).strftime('%H:%M:%S')#UTC->CTS +8hours\n",
    "print('Start thread at %s'%(now_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
