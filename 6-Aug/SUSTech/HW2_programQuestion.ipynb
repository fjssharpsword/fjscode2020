{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Southern University of Science and Technology-Department of Computer Science and Engineering\n",
    "\n",
    "Course: Machine Learning(CS 405)-Professor: Qi Hao\n",
    "\n",
    "## Homework #2\n",
    "#### Due date: October, 7th, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import libraries that you might require.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement the KNN algorithm for the breast cancer dataset. Refer to the pdf and the following functions for the instructions. Complete all the functions as indicated below. The four functions would be autograded as mentioned in the pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Task 1: Classification\n",
    "\n",
    "Please implement KNN for K: 3, 5, and 7 with the following norms:\n",
    "L1\n",
    "L2\n",
    "L-inf\n",
    "\"\"\"\n",
    "\n",
    "# Read data (Breast Cancer Dataset). Remember to comment out the code not contained in a function.\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "breast = load_breast_cancer()\n",
    "\n",
    "X = breast['data']\n",
    "y = breast['target']\n",
    "\n",
    "np.random.seed(100)\n",
    "p = np.random.permutation(len(X))\n",
    "X, y = X[p], y[p]\n",
    "\n",
    "X_train, y_train = X[:400], y[:400]\n",
    "X_val, y_val = X[400:500], y[400:500]\n",
    "X_test, y_test = X[500:], y[500:]\n",
    "\n",
    "\n",
    "def distanceFunc(metric_type, vec1, vec2):\n",
    "    \"\"\"\n",
    "    Computes the distance between two d-dimension vectors. \n",
    "    \n",
    "    Please DO NOT use Numpy's norm function when implementing this function. \n",
    "    \n",
    "    Args:\n",
    "        metric_type (str): Metric: L1, L2, or L-inf\n",
    "        vec1 ((d,) np.ndarray): d-dim vector\n",
    "        vec2 ((d,)) np.ndarray): d-dim vector\n",
    "    \n",
    "    Returns:\n",
    "        distance (float): distance between the two vectors\n",
    "    \"\"\"\n",
    "\n",
    "    diff = vec1 - vec2\n",
    "    if metric_type == \"L1\":\n",
    "        distance = np.sum(vec1-vec2)\n",
    "        #distance = 0 #complete\n",
    "\n",
    "    if metric_type == \"L2\":\n",
    "        distance = np.sqrt(np.sum(np.square(vec1-vec2)))\n",
    "        #distance = 0 #complete\n",
    "        \n",
    "    if metric_type == \"L-inf\":\n",
    "        distance = np.max(vec1-vec2)\n",
    "        #distance = 0 #complete\n",
    "        \n",
    "    return distance\n",
    "\n",
    "\n",
    "def computeDistancesNeighbors(K, metric_type, X_train, y_train, sample):\n",
    "    \"\"\"\n",
    "    Compute the distances between every datapoint in the train_data and the \n",
    "    given sample. Then, find the k-nearest neighbors.\n",
    "    \n",
    "    Return a numpy array of the label of the k-nearest neighbors.\n",
    "    \n",
    "    Args:\n",
    "        K (int): K-value\n",
    "        metric_type (str): metric type\n",
    "        X_train ((n,p) np.ndarray): Training data with n samples and p features\n",
    "        y_train : Training labels\n",
    "        sample ((p,) np.ndarray): Single sample whose distance is to computed with every entry in the dataset\n",
    "        \n",
    "    Returns:\n",
    "        neighbors (list): K-nearest neighbors' labels\n",
    "    \"\"\"\n",
    "\n",
    "    # You will also call the function \"distanceFunc\" here\n",
    "    # Complete this function\n",
    "    distances = []\n",
    "    for i in range(X_train.shape[0]):\n",
    "        dist = distanceFunc(metric_type, X_train[i], sample)\n",
    "        distances.append((i, dist))\n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for j in range(K):\n",
    "        neighbors.append(y_train[distances[j][0]])\n",
    "    return neighbors\n",
    "\n",
    "\n",
    "def Majority(neighbors):\n",
    "    \"\"\"\n",
    "    Performs majority voting and returns the predicted value for the test sample.\n",
    "    \n",
    "    Since we're performing binary classification the possible values are [0,1].\n",
    "    \n",
    "    Args:\n",
    "        neighbors (list): K-nearest neighbors' labels\n",
    "        \n",
    "    Returns:\n",
    "        predicted_value (int): predicted label for the given sample\n",
    "    \"\"\"\n",
    "    \n",
    "    # Performs majority voting\n",
    "    # Complete this function\n",
    "    classVotes = {}\n",
    "    for i in range(len(neighbors)):\n",
    "        response = neighbors[i]\n",
    "        if response in classVotes:\n",
    "            classVotes[response] += 1\n",
    "        else:\n",
    "            classVotes[response] = 1\n",
    "    sortedVotes = sorted(classVotes.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    predicted_value=sortedVotes[0][0]\n",
    "    return predicted_value\n",
    "\n",
    "\n",
    "def KNN(K, metric_type, X_train, y_train, X_val):\n",
    "    \"\"\"\n",
    "    Returns the predicted values for the entire validation or test set.\n",
    "    \n",
    "    Please DO NOT use Scikit's KNN model when implementing this function. \n",
    "\n",
    "    Args:\n",
    "        K (int): K-value\n",
    "        metric_type (str): metric type\n",
    "        X_train ((n,p) np.ndarray): Training data with n samples and p features\n",
    "        y_train : Training labels\n",
    "        X_val ((n, p) np.ndarray): Validation or test data\n",
    "        \n",
    "    Returns:\n",
    "        predicted_values (list): output for every entry in validation/test dataset \n",
    "    \"\"\"\n",
    "    \n",
    "    # Complete this function\n",
    "    # Loop through the val_data or the test_data (as required)\n",
    "    # and compute the output for every entry in that dataset  \n",
    "    # You will also call the function \"Majority\" here\n",
    "    predictions = []\n",
    "    for i in range(X_val.shape[0]):\n",
    "        neighbors = computeDistancesNeighbors(K, metric_type, X_train, y_train, X_val[i])\n",
    "        predicted_value = Majority(neighbors)\n",
    "        predictions.append(predicted_value)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def evaluation(predicted_values, actual_values):\n",
    "    \"\"\"\n",
    "    Computes the accuracy of the given datapoints.\n",
    "    \n",
    "    Args:\n",
    "        predicted_values ((n,) np.ndarray): Predicted values for n samples\n",
    "        actual_values ((n,) np.ndarray): Actual values for n samples\n",
    "    \n",
    "    Returns:\n",
    "        accuracy (float): accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    return accuracy_score(predicted_values, actual_values)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Calls the above functions in order to implement the KNN algorithm.\n",
    "    \n",
    "    Test over the following range K = 3,5,7 and all three metrics. \n",
    "    In total you will have nine combinations to try.\n",
    "    \n",
    "    PRINTS out the accuracies for the nine combinations on the validation set,\n",
    "    and the accuracy on the test set for the selected K value and appropriate norm.\n",
    "    \n",
    "    REMEMBER: You have to report these values by populating the Table 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    ## Complete this function\n",
    "    \n",
    "    K = [3,5,7]\n",
    "    norm = [\"L1\", \"L2\", \"L-inf\"]\n",
    "    for K in [3,5,7]:\n",
    "        for norm in [\"L1\", \"L2\", \"L-inf\"]:\n",
    "            print(\"<<<<VALIDATION DATA PREDICTIONS>>>>\")\n",
    "            predicted_values = KNN(K, norm, X_train, y_train, X_val)\n",
    "            print(\"K@{}, norm@{}, Accuracy:{}\".format(K, norm, evaluation(predicted_values, y_val)))\n",
    "            ## Complete\n",
    "            print(\"<<<<TEST DATA PREDICTIONS>>>>\")\n",
    "            predicted_values = KNN(K, norm, X_train, y_train, X_test)\n",
    "            print(\"K@{}, norm@{}, Accuracy:{}\".format(K, norm, evaluation(predicted_values, y_test)))\n",
    "            ## Complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the code below to run the main function (Remember to recomment the code before submitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<VALIDATION DATA PREDICTIONS>>>>\n",
      "K@3, norm@L1, Accuracy:0.6\n",
      "<<<<TEST DATA PREDICTIONS>>>>\n",
      "K@3, norm@L1, Accuracy:0.5652173913043478\n",
      "<<<<VALIDATION DATA PREDICTIONS>>>>\n",
      "K@3, norm@L2, Accuracy:0.95\n",
      "<<<<TEST DATA PREDICTIONS>>>>\n",
      "K@3, norm@L2, Accuracy:0.8840579710144928\n",
      "<<<<VALIDATION DATA PREDICTIONS>>>>\n",
      "K@3, norm@L-inf, Accuracy:0.6\n",
      "<<<<TEST DATA PREDICTIONS>>>>\n",
      "K@3, norm@L-inf, Accuracy:0.5942028985507246\n",
      "<<<<VALIDATION DATA PREDICTIONS>>>>\n",
      "K@5, norm@L1, Accuracy:0.6\n",
      "<<<<TEST DATA PREDICTIONS>>>>\n",
      "K@5, norm@L1, Accuracy:0.5652173913043478\n",
      "<<<<VALIDATION DATA PREDICTIONS>>>>\n",
      "K@5, norm@L2, Accuracy:0.93\n",
      "<<<<TEST DATA PREDICTIONS>>>>\n",
      "K@5, norm@L2, Accuracy:0.8985507246376812\n",
      "<<<<VALIDATION DATA PREDICTIONS>>>>\n",
      "K@5, norm@L-inf, Accuracy:0.6\n",
      "<<<<TEST DATA PREDICTIONS>>>>\n",
      "K@5, norm@L-inf, Accuracy:0.5652173913043478\n",
      "<<<<VALIDATION DATA PREDICTIONS>>>>\n",
      "K@7, norm@L1, Accuracy:0.6\n",
      "<<<<TEST DATA PREDICTIONS>>>>\n",
      "K@7, norm@L1, Accuracy:0.5652173913043478\n",
      "<<<<VALIDATION DATA PREDICTIONS>>>>\n",
      "K@7, norm@L2, Accuracy:0.92\n",
      "<<<<TEST DATA PREDICTIONS>>>>\n",
      "K@7, norm@L2, Accuracy:0.9130434782608695\n",
      "<<<<VALIDATION DATA PREDICTIONS>>>>\n",
      "K@7, norm@L-inf, Accuracy:0.6\n",
      "<<<<TEST DATA PREDICTIONS>>>>\n",
      "K@7, norm@L-inf, Accuracy:0.5652173913043478\n"
     ]
    }
   ],
   "source": [
    "# Finally, call the main function\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the following questions here:\n",
    "\n",
    "1. How could having a larger dataset influence the performance of KNN?\n",
    "\n",
    "2. Tabulate your results from `main()` in the table provided.\n",
    "\n",
    "3. Finally, mention the best K and the norm combination you have settled upon and report the accuracy on the test set using that combination."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.KNN is a method of lazy learning. This can rapidly consume memory and affect the run performance. The other factor is that K is sensitive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1Validate Set\n",
    "K   Norm   Accuracy\n",
    "3   L1    0.6\n",
    "3   L2    0.95\n",
    "3   L-Inf  0.6 \n",
    "5   L1    0.6\n",
    "5   L2    0.93\n",
    "5   L-Inf  0.6 \n",
    "7   L1    0.6\n",
    "7   L2    0.92\n",
    "7   L-Inf  0.6 \n",
    "2.2 Test Set\n",
    "K   Norm   Accuracy\n",
    "3   L1    0.56\n",
    "3   L2    0.88\n",
    "3   L-Inf  0.59 \n",
    "5   L1    0.56\n",
    "5   L2    0.89\n",
    "5   L-Inf  0.56 \n",
    "7   L1    0.56\n",
    "7   L2    0.91\n",
    "7   L-Inf  0.56 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.For validate set, the best combination is k=3 and norm =L2 , and the test set achieve accuracy=0.88 which is not the best performance. There exists little over-fitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
