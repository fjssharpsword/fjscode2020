{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "3.6.6 (default, Jun 28 2018, 04:42:43) \n",
      "[GCC 5.4.0 20160609]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Enviroment: Ubuntu 16.04 + TensorFlow 1.12.0 + cuda 9.0 + python 3.6\n",
    "Dataset: Cityscapes, https://www.kaggle.com/dansbecker/cityscapes-image-pairs\n",
    "Segmentation Model: UNet \n",
    "Adversarial Model: ??\n",
    "Metric: Mean Intersection over Union(MIoU)=TP/(TP+FN+FP)\n",
    "'''\n",
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "from os.path import join\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "from PIL import Image , ImageOps\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow.contrib.eager as tfe\n",
    "import sys\n",
    "print(tf.VERSION) \n",
    "print(sys.version)\n",
    "#tf.enable_eager_execution()\n",
    "#tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of feature in Train set is : (2975, 128, 128, 3)\n",
      "The size of label in Train set is : (2975, 128, 128, 6)\n",
      "The size of feature in Val set is: (500, 128, 128, 3)\n",
      "The size of label in Val set is : (500, 128, 128, 6)\n"
     ]
    }
   ],
   "source": [
    "#dataset: https://www.kaggle.com/dansbecker/cityscapes-image-pairs\n",
    "def binarize( pixel ):\n",
    "    if np.array_equal( pixel , [ 128, 63,127 ]):#road \n",
    "        return np.array( [ 0, 1, 0, 0, 0, 0 ] )\n",
    "    elif np.array_equal( pixel , [ 70, 70, 70 ]):#building\n",
    "        return np.array( [ 0, 0, 1, 0, 0, 0 ] )\n",
    "    elif np.array_equal( pixel , [ 220, 20, 60 ]):#person\n",
    "        return np.array( [ 0, 0, 0, 1, 0, 0 ] )\n",
    "    elif np.array_equal( pixel , [ 0,  0, 142 ]):#car\n",
    "        return np.array( [ 0, 0, 0, 0, 1, 0 ] )\n",
    "    elif np.array_equal( pixel , [ 70,130,180 ]):#sky\n",
    "        return np.array( [ 0, 0, 0, 0, 0, 1 ] )\n",
    "    else :\n",
    "        return np.array( [ 1, 0, 0, 0, 0, 0 ] )\n",
    "#train set\n",
    "def trainDataset(train_dir):\n",
    "    X_train = list()\n",
    "    Y_train = list()\n",
    "    for filename in os.listdir( train_dir ): \n",
    "        image = Image.open(os.path.join( train_dir, filename))\n",
    "        X_train.append( np.asarray( ImageOps.crop( image , ( 0 , 0 , 256 , 0 ) ).resize( ( 128, 128 )) ) ) #real image\n",
    "        Y_train.append( np.asarray( ImageOps.crop( image, (256, 0, 0, 0)).resize( ( 128 , 128 ) ) )) #labelled image\n",
    "    return np.array(X_train)/255, np.array(Y_train)\n",
    "train_dir = '/data/comcode/models/research/deeplab/datasets/cityscapes/kaggle/train'\n",
    "X_train, Y_train = trainDataset(train_dir)\n",
    "Y_train = np.apply_along_axis( binarize , axis=3 , arr=np.array(Y_train) ) #classify the pixel\n",
    "print ('The size of feature in Train set is : {}'.format(X_train.shape))\n",
    "print ('The size of label in Train set is : {}'.format(Y_train.shape))\n",
    "\n",
    "#val set\n",
    "def valDataset(val_dir):\n",
    "    X_val = list()\n",
    "    Y_val = list()\n",
    "    for filename in os.listdir( val_dir ): \n",
    "        image = Image.open(os.path.join( val_dir, filename))\n",
    "        X_val.append( np.asarray( ImageOps.crop( image , ( 0 , 0 , 256 , 0 ) ).resize( ( 128, 128 )) ) )\n",
    "        Y_val.append( np.asarray( ImageOps.crop( image, (256, 0, 0, 0)).resize( ( 128 , 128 ) ) ))\n",
    "    return np.array(X_val)/255, np.array(Y_val)\n",
    "val_dir = '/data/comcode/models/research/deeplab/datasets/cityscapes/kaggle/val'\n",
    "X_val,Y_val = valDataset(val_dir)\n",
    "Y_val = np.apply_along_axis( binarize , axis=3 , arr=np.array(Y_val) ) #classify the pixel\n",
    "print ('The size of feature in Val set is: {}'.format(X_val.shape))\n",
    "print ('The size of label in Val set is : {}'.format(Y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 81920, 1: 16384}\n",
      "{0: 81920, 1: 16384}\n"
     ]
    }
   ],
   "source": [
    "#check dataset\n",
    "def value_count(arr):\n",
    "    arr = np.array(arr)\n",
    "    key = np.unique(arr)\n",
    "    result = {}\n",
    "    for k in key:\n",
    "        mask = (arr == k)\n",
    "        arr_new = arr[mask]\n",
    "        v = arr_new.size\n",
    "        result[k] = v\n",
    "    return result\n",
    "print (value_count(Y_train[100]))\n",
    "print (value_count(Y_val[100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct model \n",
    "class unet_seg:\n",
    "    def __init__(self, lr=0.001):\n",
    "        #global parameters\n",
    "        self.lr = lr\n",
    "        #set network structure\n",
    "        self.add_placeholders()\n",
    "        self.add_weight()\n",
    "        self.add_model()\n",
    "        self.add_loss()\n",
    "        self.add_optimizer()\n",
    "        self.init_sess()\n",
    "        \n",
    "    def add_placeholders(self):    \n",
    "        self.X_input = tf.placeholder(tf.float32)\n",
    "        self.Y_input = tf.placeholder(tf.float32)\n",
    "    \n",
    "    def add_weight(self):\n",
    "        initializer = tf.initializers.glorot_uniform()\n",
    "        def get_weight( shape , name ):\n",
    "            return tf.Variable( initializer( shape ) , name=name , trainable=True )\n",
    "\n",
    "        shapes = [ [ 3 , 3 , 3 , 16 ] ,   [ 3 , 3 , 16 , 16 ] , \n",
    "                   [ 3 , 3 , 16 , 32 ] ,  [ 3 , 3 , 32 , 32 ] ,\n",
    "                   [ 3 , 3 , 32 , 64 ] ,  [ 3 , 3 , 64 , 64 ] ,\n",
    "                   [ 3 , 3 , 64 , 128 ] , [ 3 , 3 , 128 , 128 ] ,\n",
    "                   [ 3 , 3 , 128 , 256 ] ,[ 3 , 3 , 256 , 256 ] ,\n",
    "                   [ 3 , 3 , 128 , 384 ], [ 3 , 3 , 128 , 128 ],\n",
    "                   [ 3 , 3 , 64 , 192 ],  [ 3 , 3 , 64 , 64 ],\n",
    "                   [ 3 , 3 , 32 , 96 ],   [ 3 , 3 , 32 , 32 ],\n",
    "                   [ 3 , 3 , 16 , 48 ],   [ 3 , 3 , 16 , 16 ],\n",
    "                   [ 1 , 1 , 16 , 6 ] #[ 1 , 1 , 16 , 1 ] \n",
    "                 ]\n",
    "        weights = []\n",
    "        for i in range( len( shapes ) ):\n",
    "            weights.append( get_weight( shapes[ i ] , 'weight{}'.format( i ) ) )\n",
    "        self.weights = weights\n",
    "        \n",
    "    def add_model(self):\n",
    "        def conv2d_down( inputs , filters , stride_size ):\n",
    "            #print( 'conv2d down' )\n",
    "            out = tf.nn.conv2d( inputs , filters , strides=stride_size , padding='SAME' ) \n",
    "            return tf.nn.leaky_relu( out , alpha=0.2 ) \n",
    "\n",
    "        def maxpool_down( inputs , pool_size , stride_size ):\n",
    "            #print( 'maxpool down' )\n",
    "            return tf.nn.max_pool( inputs , ksize=pool_size , padding='VALID' , strides=stride_size )\n",
    "\n",
    "        def conv2d_up( inputs , filters , stride_size , output_shape ):\n",
    "            #print( 'conv2d up' )\n",
    "            out = tf.nn.conv2d_transpose( inputs , filters , output_shape=output_shape , strides=stride_size , padding='SAME' ) \n",
    "            return tf.nn.leaky_relu( out , alpha=0.2 ) \n",
    "\n",
    "        def maxpool_up( inputs , size ):\n",
    "            #print( 'maxpool up' )\n",
    "            in_dimen = tf.shape( inputs )[ 1 ]\n",
    "            out_dimen = tf.cast( tf.round( in_dimen * size ) , dtype=tf.int32 ) \n",
    "            return tf.image.resize_images( inputs , [ out_dimen , out_dimen ] , method=1 )#nearest\n",
    "        #forward\n",
    "        x = tf.cast(self.X_input , dtype=tf.float32 )\n",
    "        batch_size = tf.shape( x )[0]\n",
    "        c1 = conv2d_down( x , self.weights[ 0 ] , stride_size=[1,1,1,1] ) \n",
    "        c1 = conv2d_down( c1 , self.weights[ 1 ] , stride_size=[1,1,1,1] ) \n",
    "        p1 = maxpool_down( c1 , pool_size=[1,2,2,1] , stride_size=[1,2,2,1] )\n",
    "\n",
    "        c2 = conv2d_down( p1 , self.weights[ 2 ] , stride_size=[1,1,1,1] )\n",
    "        c2 = conv2d_down( c2 , self.weights[ 3 ] , stride_size=[1,1,1,1] ) \n",
    "        p2 = maxpool_down( c2 , pool_size=[1,2,2,1] , stride_size=[1,2,2,1] )\n",
    "\n",
    "        c3 = conv2d_down( p2 , self.weights[ 4 ] , stride_size=[1,1,1,1] ) \n",
    "        c3 = conv2d_down( c3 , self.weights[ 5 ] , stride_size=[1,1,1,1] ) \n",
    "        p3 = maxpool_down( c3 , pool_size=[1,2,2,1] , stride_size=[1,2,2,1] )\n",
    "\n",
    "        c4 = conv2d_down( p3 , self.weights[ 6 ] , stride_size=[1,1,1,1] )\n",
    "        c4 = conv2d_down( c4 , self.weights[ 7 ] , stride_size=[1,1,1,1] )\n",
    "        p4 = maxpool_down( c4 , pool_size=[1,2,2,1] , stride_size=[1,2,2,1] )\n",
    "\n",
    "        c5 = conv2d_down( p4 , self.weights[ 8 ] , stride_size=[1,1,1,1] )\n",
    "        c5 = conv2d_down( c5 , self.weights[ 9 ] , stride_size=[1,1,1,1] )   \n",
    "\n",
    "        p5 = maxpool_up( c5 , 2 )\n",
    "        concat_1 = tf.concat( [ p5 , c4 ] , axis=-1 ) \n",
    "        c6 = conv2d_up( concat_1 , self.weights[ 10 ] , stride_size=[1,1,1,1] , output_shape=[ batch_size , 16 , 16 , 128 ] )\n",
    "        c6 = conv2d_up( c6 , self.weights[ 11 ] , stride_size=[1,1,1,1] , output_shape=[ batch_size , 16 , 16 , 128 ] )  \n",
    "\n",
    "        p6 = maxpool_up( c6 , 2 )\n",
    "        concat_2 = tf.concat( [ p6 , c3 ] , axis=-1 ) \n",
    "        c7 = conv2d_up( concat_2 , self.weights[ 12 ] , stride_size=[1,1,1,1] , output_shape=[ batch_size , 32 , 32 , 64 ] )\n",
    "        c7 = conv2d_up( c7 , self.weights[ 13 ] , stride_size=[1,1,1,1] , output_shape=[ batch_size , 32 , 32 , 64 ] )  \n",
    "\n",
    "        p7 = maxpool_up( c7 , 2 )\n",
    "        concat_3 = tf.concat( [ p7 , c2 ] , axis=-1 ) \n",
    "        c8 = conv2d_up( concat_3 , self.weights[ 14 ] , stride_size=[1,1,1,1] , output_shape=[ batch_size , 64 , 64 , 32 ] )\n",
    "        c8 = conv2d_up( c8 , self.weights[ 15 ] , stride_size=[1,1,1,1] , output_shape=[ batch_size , 64 , 64 , 32 ] )   \n",
    "\n",
    "        p8 = maxpool_up( c8 , 2 )\n",
    "        concat_4 = tf.concat( [ p8 , c1 ] , axis=-1 ) \n",
    "        c9 = conv2d_up( concat_4 , self.weights[ 16 ] , stride_size=[1,1,1,1] , output_shape=[ batch_size , 128 , 128 , 16 ] )\n",
    "        c9 = conv2d_up( c9 , self.weights[ 17 ] , stride_size=[1,1,1,1] , output_shape=[ batch_size , 128 , 128 , 16 ] )  \n",
    "\n",
    "        output = tf.nn.conv2d( c9 , self.weights[ 18 ] , strides=[ 1 , 1 , 1 , 1 ] , padding='SAME' ) \n",
    "        self.Y_output = output\n",
    "    \n",
    "    def add_loss(self):\n",
    "        #self.loss = tf.losses.sigmoid_cross_entropy( self.Y_input , self.Y_output ) \n",
    "        _loss = tf.nn.softmax_cross_entropy_with_logits( labels=self.Y_input , logits =self.Y_output ) \n",
    "        self.loss = tf.reduce_mean(_loss)\n",
    "    \n",
    "    def add_optimizer(self):\n",
    "        optimizer = tf.train.AdamOptimizer(self.lr)\n",
    "        self.train_step = optimizer.minimize(self.loss)\n",
    "        \n",
    "    def init_sess(self):\n",
    "        self.config = tf.ConfigProto()\n",
    "        self.config.gpu_options.allow_growth = True\n",
    "        self.config.allow_soft_placement = True\n",
    "        self.sess = tf.Session(config=self.config)\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "#define model\n",
    "tf_model = unet_seg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 / 12 : loss = 1.8047491312026978\n",
      "Mean loss in this epoch is: 1.7870874404907227\n",
      "10 / 12 : loss = 1.2952834367752075\n",
      "Mean loss in this epoch is: 1.3044605255126953\n",
      "10 / 12 : loss = 1.0438886880874634\n",
      "Mean loss in this epoch is: 1.0421375036239624\n",
      "10 / 12 : loss = 0.8534859418869019\n",
      "Mean loss in this epoch is: 0.8515220284461975\n",
      "10 / 12 : loss = 0.7398453950881958\n",
      "Mean loss in this epoch is: 0.7414156794548035\n",
      "10 / 12 : loss = 0.6635382175445557\n",
      "Mean loss in this epoch is: 0.6595187783241272\n",
      "10 / 12 : loss = 0.6163498759269714\n",
      "Mean loss in this epoch is: 0.6125821471214294\n",
      "10 / 12 : loss = 0.5760394930839539\n",
      "Mean loss in this epoch is: 0.5731634497642517\n",
      "10 / 12 : loss = 0.5449191331863403\n",
      "Mean loss in this epoch is: 0.5419337153434753\n",
      "10 / 12 : loss = 0.540737509727478\n",
      "Mean loss in this epoch is: 0.5357694029808044\n"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "verbose = 10\n",
    "batchSize=256\n",
    "num_batches = X_train.shape[0] // batchSize + 1 \n",
    "for epoch in range(10):\n",
    "    losses = []\n",
    "    for i in range(num_batches):\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([X_train.shape[0], (i+1)*batchSize])\n",
    "        X_batch = X_train[min_idx: max_idx]\n",
    "        Y_batch = Y_train[min_idx: max_idx]\n",
    "        _, tmp_loss = tf_model.sess.run([tf_model.train_step, tf_model.loss], \n",
    "                                         feed_dict={tf_model.X_input: X_batch,tf_model.Y_input: Y_batch})\n",
    "        losses.append(tmp_loss)\n",
    "        if verbose and i % verbose == 0:\n",
    "            sys.stdout.write('\\r{} / {} : loss = {}'.format(i, num_batches, np.mean(losses[-verbose:])))\n",
    "            sys.stdout.flush()\n",
    "    print(\"\\nMean loss in this epoch is: {}\".format(np.mean(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0]\n",
      "[1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "Y_pred = tf_model.sess.run(tf_model.Y_output, feed_dict={tf_model.X_input: X_train[0:1],tf_model.Y_input: Y_train[0:1]})\n",
    "op = tf.nn.softmax(Y_pred)\n",
    "Y_pred = tf_model.sess.run(op)\n",
    "a = Y_pred[0]\n",
    "one_hot_a = tf.one_hot(tf.nn.top_k(a).indices, tf.shape(a)[2])#turn softmax to onehot with per line\n",
    "Y_pred = tf_model.sess.run(one_hot_a).astype(int)\n",
    "print()\n",
    "print(Y_train[0])\n",
    "np.logical_and()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499 / 500 : loss = 0.79639274162600747===> mIoU: 66.84\n"
     ]
    }
   ],
   "source": [
    "#performance-all\n",
    "Y_pred = tf_model.sess.run(tf_model.Y_output, feed_dict={tf_model.X_input: X_val,tf_model.Y_input: Y_val}) #prediction\n",
    "Y_pred = tf_model.sess.run(tf.nn.softmax(Y_pred)) #turn to softmax\n",
    "mIoUs = []\n",
    "intersection = []\n",
    "union = []\n",
    "for i in range(len(Y_val)):\n",
    "    a = Y_pred[i]\n",
    "    a_one_hot = tf.one_hot(tf.nn.top_k(a).indices, tf.shape(a)[2])#turn softmax to onehot \n",
    "    a = tf_model.sess.run(a_one_hot).astype(int)\n",
    "    b = Y_val[i]\n",
    "    intersection=np.logical_and(a.flatten(),b.flatten())\n",
    "    union=np.logical_or(a.flatten(),b.flatten())\n",
    "    iou_score = np.sum(intersection) / np.sum(union)\n",
    "    mIoUs.append(iou_score)\n",
    "    sys.stdout.write('\\r{} / {} : IoU = {}'.format(i, len(Y_val), iou_score))\n",
    "    sys.stdout.flush()\n",
    "print('===> mIoU: ' + str(round(np.nanmean(mIoUs) * 100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of cityscapes labels:\n",
      "\n",
      "                     name |  id | trainId |       category | categoryId | hasInstances | ignoreInEval\n",
      "    --------------------------------------------------------------------------------------------------\n",
      "                unlabeled |   0 |     255 |           void |          0 |            0 |            1\n",
      "              ego vehicle |   1 |     255 |           void |          0 |            0 |            1\n",
      "     rectification border |   2 |     255 |           void |          0 |            0 |            1\n",
      "               out of roi |   3 |     255 |           void |          0 |            0 |            1\n",
      "                   static |   4 |     255 |           void |          0 |            0 |            1\n",
      "                  dynamic |   5 |     255 |           void |          0 |            0 |            1\n",
      "                   ground |   6 |     255 |           void |          0 |            0 |            1\n",
      "                     road |   7 |       0 |           flat |          1 |            0 |            0\n",
      "                 sidewalk |   8 |       1 |           flat |          1 |            0 |            0\n",
      "                  parking |   9 |     255 |           flat |          1 |            0 |            1\n",
      "               rail track |  10 |     255 |           flat |          1 |            0 |            1\n",
      "                 building |  11 |       2 |   construction |          2 |            0 |            0\n",
      "                     wall |  12 |       3 |   construction |          2 |            0 |            0\n",
      "                    fence |  13 |       4 |   construction |          2 |            0 |            0\n",
      "               guard rail |  14 |     255 |   construction |          2 |            0 |            1\n",
      "                   bridge |  15 |     255 |   construction |          2 |            0 |            1\n",
      "                   tunnel |  16 |     255 |   construction |          2 |            0 |            1\n",
      "                     pole |  17 |       5 |         object |          3 |            0 |            0\n",
      "                polegroup |  18 |     255 |         object |          3 |            0 |            1\n",
      "            traffic light |  19 |       6 |         object |          3 |            0 |            0\n",
      "             traffic sign |  20 |       7 |         object |          3 |            0 |            0\n",
      "               vegetation |  21 |       8 |         nature |          4 |            0 |            0\n",
      "                  terrain |  22 |       9 |         nature |          4 |            0 |            0\n",
      "                      sky |  23 |      10 |            sky |          5 |            0 |            0\n",
      "                   person |  24 |      11 |          human |          6 |            1 |            0\n",
      "                    rider |  25 |      12 |          human |          6 |            1 |            0\n",
      "                      car |  26 |      13 |        vehicle |          7 |            1 |            0\n",
      "                    truck |  27 |      14 |        vehicle |          7 |            1 |            0\n",
      "                      bus |  28 |      15 |        vehicle |          7 |            1 |            0\n",
      "                  caravan |  29 |     255 |        vehicle |          7 |            1 |            1\n",
      "                  trailer |  30 |     255 |        vehicle |          7 |            1 |            1\n",
      "                    train |  31 |      16 |        vehicle |          7 |            1 |            0\n",
      "               motorcycle |  32 |      17 |        vehicle |          7 |            1 |            0\n",
      "                  bicycle |  33 |      18 |        vehicle |          7 |            1 |            0\n",
      "            license plate |  -1 |      -1 |        vehicle |          7 |            0 |            1\n",
      "\n",
      "Example usages:\n",
      "ID of label 'car': 26\n",
      "Category of label with ID '26': vehicle\n",
      "Name of label with trainID '0': road\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/mcordts/cityscapesScripts/blob/master/cityscapesscripts/helpers/labels.py\n",
    "#https://paperswithcode.com/sota/semantic-segmentation-on-cityscapes\n",
    "#https://github.com/tensorflow/gan\n",
    "#https://towardsdatascience.com/cityscape-segmentation-with-tensorflow-2-0-b320b6605cbf\n",
    "#!/usr/bin/python\n",
    "#\n",
    "# Cityscapes labels\n",
    "#\n",
    "\n",
    "from __future__ import print_function, absolute_import, division\n",
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Definitions\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# a label and all meta information\n",
    "Label = namedtuple( 'Label' , [\n",
    "\n",
    "    'name'        , # The identifier of this label, e.g. 'car', 'person', ... .\n",
    "                    # We use them to uniquely name a class\n",
    "\n",
    "    'id'          , # An integer ID that is associated with this label.\n",
    "                    # The IDs are used to represent the label in ground truth images\n",
    "                    # An ID of -1 means that this label does not have an ID and thus\n",
    "                    # is ignored when creating ground truth images (e.g. license plate).\n",
    "                    # Do not modify these IDs, since exactly these IDs are expected by the\n",
    "                    # evaluation server.\n",
    "\n",
    "    'trainId'     , # Feel free to modify these IDs as suitable for your method. Then create\n",
    "                    # ground truth images with train IDs, using the tools provided in the\n",
    "                    # 'preparation' folder. However, make sure to validate or submit results\n",
    "                    # to our evaluation server using the regular IDs above!\n",
    "                    # For trainIds, multiple labels might have the same ID. Then, these labels\n",
    "                    # are mapped to the same class in the ground truth images. For the inverse\n",
    "                    # mapping, we use the label that is defined first in the list below.\n",
    "                    # For example, mapping all void-type classes to the same ID in training,\n",
    "                    # might make sense for some approaches.\n",
    "                    # Max value is 255!\n",
    "\n",
    "    'category'    , # The name of the category that this label belongs to\n",
    "\n",
    "    'categoryId'  , # The ID of this category. Used to create ground truth images\n",
    "                    # on category level.\n",
    "\n",
    "    'hasInstances', # Whether this label distinguishes between single instances or not\n",
    "\n",
    "    'ignoreInEval', # Whether pixels having this class as ground truth label are ignored\n",
    "                    # during evaluations or not\n",
    "\n",
    "    'color'       , # The color of this label\n",
    "    ] )\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# A list of all labels\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# Please adapt the train IDs as appropriate for your approach.\n",
    "# Note that you might want to ignore labels with ID 255 during training.\n",
    "# Further note that the current train IDs are only a suggestion. You can use whatever you like.\n",
    "# Make sure to provide your results using the original IDs and not the training IDs.\n",
    "# Note that many IDs are ignored in evaluation and thus you never need to predict these!\n",
    "\n",
    "labels = [\n",
    "    #       name                     id    trainId   category            catId     hasInstances   ignoreInEval   color\n",
    "    Label(  'unlabeled'            ,  0 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'ego vehicle'          ,  1 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'rectification border' ,  2 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'out of roi'           ,  3 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'static'               ,  4 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'dynamic'              ,  5 ,      255 , 'void'            , 0       , False        , True         , (111, 74,  0) ),\n",
    "    Label(  'ground'               ,  6 ,      255 , 'void'            , 0       , False        , True         , ( 81,  0, 81) ),\n",
    "    Label(  'road'                 ,  7 ,        0 , 'flat'            , 1       , False        , False        , (128, 64,128) ),\n",
    "    Label(  'sidewalk'             ,  8 ,        1 , 'flat'            , 1       , False        , False        , (244, 35,232) ),\n",
    "    Label(  'parking'              ,  9 ,      255 , 'flat'            , 1       , False        , True         , (250,170,160) ),\n",
    "    Label(  'rail track'           , 10 ,      255 , 'flat'            , 1       , False        , True         , (230,150,140) ),\n",
    "    Label(  'building'             , 11 ,        2 , 'construction'    , 2       , False        , False        , ( 70, 70, 70) ),\n",
    "    Label(  'wall'                 , 12 ,        3 , 'construction'    , 2       , False        , False        , (102,102,156) ),\n",
    "    Label(  'fence'                , 13 ,        4 , 'construction'    , 2       , False        , False        , (190,153,153) ),\n",
    "    Label(  'guard rail'           , 14 ,      255 , 'construction'    , 2       , False        , True         , (180,165,180) ),\n",
    "    Label(  'bridge'               , 15 ,      255 , 'construction'    , 2       , False        , True         , (150,100,100) ),\n",
    "    Label(  'tunnel'               , 16 ,      255 , 'construction'    , 2       , False        , True         , (150,120, 90) ),\n",
    "    Label(  'pole'                 , 17 ,        5 , 'object'          , 3       , False        , False        , (153,153,153) ),\n",
    "    Label(  'polegroup'            , 18 ,      255 , 'object'          , 3       , False        , True         , (153,153,153) ),\n",
    "    Label(  'traffic light'        , 19 ,        6 , 'object'          , 3       , False        , False        , (250,170, 30) ),\n",
    "    Label(  'traffic sign'         , 20 ,        7 , 'object'          , 3       , False        , False        , (220,220,  0) ),\n",
    "    Label(  'vegetation'           , 21 ,        8 , 'nature'          , 4       , False        , False        , (107,142, 35) ),\n",
    "    Label(  'terrain'              , 22 ,        9 , 'nature'          , 4       , False        , False        , (152,251,152) ),\n",
    "    Label(  'sky'                  , 23 ,       10 , 'sky'             , 5       , False        , False        , ( 70,130,180) ),\n",
    "    Label(  'person'               , 24 ,       11 , 'human'           , 6       , True         , False        , (220, 20, 60) ),\n",
    "    Label(  'rider'                , 25 ,       12 , 'human'           , 6       , True         , False        , (255,  0,  0) ),\n",
    "    Label(  'car'                  , 26 ,       13 , 'vehicle'         , 7       , True         , False        , (  0,  0,142) ),\n",
    "    Label(  'truck'                , 27 ,       14 , 'vehicle'         , 7       , True         , False        , (  0,  0, 70) ),\n",
    "    Label(  'bus'                  , 28 ,       15 , 'vehicle'         , 7       , True         , False        , (  0, 60,100) ),\n",
    "    Label(  'caravan'              , 29 ,      255 , 'vehicle'         , 7       , True         , True         , (  0,  0, 90) ),\n",
    "    Label(  'trailer'              , 30 ,      255 , 'vehicle'         , 7       , True         , True         , (  0,  0,110) ),\n",
    "    Label(  'train'                , 31 ,       16 , 'vehicle'         , 7       , True         , False        , (  0, 80,100) ),\n",
    "    Label(  'motorcycle'           , 32 ,       17 , 'vehicle'         , 7       , True         , False        , (  0,  0,230) ),\n",
    "    Label(  'bicycle'              , 33 ,       18 , 'vehicle'         , 7       , True         , False        , (119, 11, 32) ),\n",
    "    Label(  'license plate'        , -1 ,       -1 , 'vehicle'         , 7       , False        , True         , (  0,  0,142) ),\n",
    "]\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Create dictionaries for a fast lookup\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# Please refer to the main method below for example usages!\n",
    "\n",
    "# name to label object\n",
    "name2label      = { label.name    : label for label in labels           }\n",
    "# id to label object\n",
    "id2label        = { label.id      : label for label in labels           }\n",
    "# trainId to label object\n",
    "trainId2label   = { label.trainId : label for label in reversed(labels) }\n",
    "# category to list of label objects\n",
    "category2labels = {}\n",
    "for label in labels:\n",
    "    category = label.category\n",
    "    if category in category2labels:\n",
    "        category2labels[category].append(label)\n",
    "    else:\n",
    "        category2labels[category] = [label]\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Assure single instance name\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# returns the label name that describes a single instance (if possible)\n",
    "# e.g.     input     |   output\n",
    "#        ----------------------\n",
    "#          car       |   car\n",
    "#          cargroup  |   car\n",
    "#          foo       |   None\n",
    "#          foogroup  |   None\n",
    "#          skygroup  |   None\n",
    "def assureSingleInstanceName( name ):\n",
    "    # if the name is known, it is not a group\n",
    "    if name in name2label:\n",
    "        return name\n",
    "    # test if the name actually denotes a group\n",
    "    if not name.endswith(\"group\"):\n",
    "        return None\n",
    "    # remove group\n",
    "    name = name[:-len(\"group\")]\n",
    "    # test if the new name exists\n",
    "    if not name in name2label:\n",
    "        return None\n",
    "    # test if the new name denotes a label that actually has instances\n",
    "    if not name2label[name].hasInstances:\n",
    "        return None\n",
    "    # all good then\n",
    "    return name\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Main for testing\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# just a dummy main\n",
    "if __name__ == \"__main__\":\n",
    "    # Print all the labels\n",
    "    print(\"List of cityscapes labels:\")\n",
    "    print(\"\")\n",
    "    print(\"    {:>21} | {:>3} | {:>7} | {:>14} | {:>10} | {:>12} | {:>12}\".format( 'name', 'id', 'trainId', 'category', 'categoryId', 'hasInstances', 'ignoreInEval' ))\n",
    "    print(\"    \" + ('-' * 98))\n",
    "    for label in labels:\n",
    "        print(\"    {:>21} | {:>3} | {:>7} | {:>14} | {:>10} | {:>12} | {:>12}\".format( label.name, label.id, label.trainId, label.category, label.categoryId, label.hasInstances, label.ignoreInEval ))\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"Example usages:\")\n",
    "\n",
    "    # Map from name to label\n",
    "    name = 'car'\n",
    "    id   = name2label[name].id\n",
    "    print(\"ID of label '{name}': {id}\".format( name=name, id=id ))\n",
    "\n",
    "    # Map from ID to label\n",
    "    category = id2label[id].category\n",
    "    print(\"Category of label with ID '{id}': {category}\".format( id=id, category=category ))\n",
    "\n",
    "    # Map from trainID to label\n",
    "    trainId = 0\n",
    "    name = trainId2label[trainId].name\n",
    "    print(\"Name of label with trainID '{id}': {name}\".format( id=trainId, name=name ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
